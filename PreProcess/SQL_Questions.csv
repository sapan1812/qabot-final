,Id,A_Score,Q_Score,Tag,Title,Q_Body,A_Body
441,192220,316,370,sql,What is the most efficient/elegant way to parse a flat table into a tree?,"<p>Assume you have a flat table that stores an ordered tree hierarchy:</p>

<pre><code>Id   Name         ParentId   Order
 1   'Node 1'            0      10
 2   'Node 1.1'          1      10
 3   'Node 2'            0      20
 4   'Node 1.1.1'        2      10
 5   'Node 2.1'          3      10
 6   'Node 1.2'          1      20
</code></pre>

<p>Here's a diagram, where we have <code>[id] Name</code>.  Root node 0 is fictional.</p>

<pre>
                       [0] ROOT
                          /    \ 
              [1] Node 1          [3] Node 2
              /       \                   \
    [2] Node 1.1     [6] Node 1.2      [5] Node 2.1
          /          
 [4] Node 1.1.1
</pre>

<p>What minimalistic approach would you use to output that to HTML (or text, for that matter) as a correctly ordered, correctly indented tree? </p>

<p>Assume further you only have basic data structures (arrays and hashmaps), no fancy objects with parent/children references, no ORM, no framework, just your two hands. The table is represented as a result set, which can be accessed randomly. </p>

<p>Pseudo code or plain English is okay, this is purely a conceptional question.</p>

<p>Bonus question: Is there a fundamentally better way to store a tree structure like this in a RDBMS?</p>

<hr>

<p><strong>EDITS AND ADDITIONS</strong></p>

<p>To answer one commenter's (<a href=""http://stackoverflow.com/users/17826/mark-bessey"">Mark Bessey</a>'s) question: A root node is not necessary, because it is never going to be displayed anyway. ParentId = 0 is the convention to express ""these are top level"". The Order column defines how nodes with the same parent are going to be sorted.</p>

<p>The ""result set"" I spoke of can be pictured as an array of hashmaps (to stay in that terminology). For my example was meant to be already there. Some answers go the extra mile and construct it first, but thats okay.</p>

<p>The tree can be arbitrarily deep. Each node can have N children. I did not exactly have a ""millions of entries"" tree in mind, though.</p>

<p>Don't mistake my choice of node naming ('Node 1.1.1') for something to rely on. The nodes could equally well be called 'Frank' or 'Bob', no naming structure is implied, this was merely to make it readable.</p>

<p><em>I have posted my own solution so you guys can pull it to pieces.</em></p>
","<p>There are several ways to store tree-structured data in a relational database.  What you show in your example uses two methods:  </p>

<ul>
<li><strong>Adjacency List</strong> (the ""parent"" column) and </li>
<li><strong>Path Enumeration</strong> (the dotted-numbers in your name column).  </li>
</ul>

<p>Another solution is called <strong>Nested Sets</strong>, and it can be stored in the same table too.  Read ""<a href=""http://rads.stackoverflow.com/amzn/click/1558609202"">Trees and Hierarchies in SQL for Smarties</a>"" by Joe Celko for a lot more information on these designs.</p>

<p>I usually prefer a design called <strong>Closure Table</strong> (aka ""Adjacency Relation"") for storing tree-structured data.  It requires another table, but then querying trees is pretty easy.</p>

<p>I cover Closure Table in my presentation <a href=""http://www.slideshare.net/billkarwin/models-for-hierarchical-data"">Models for Hierarchical Data with SQL and PHP</a> and in my book <a href=""http://pragprog.com/book/bksqla/sql-antipatterns"">SQL Antipatterns: Avoiding the Pitfalls of Database Programming</a>.</p>

<pre><code>CREATE TABLE ClosureTable (
  ancestor_id   INT NOT NULL REFERENCES FlatTable(id),
  descendant_id INT NOT NULL REFERENCES FlatTable(id),
  PRIMARY KEY (ancestor_id, descendant_id)
);
</code></pre>

<p>Store all paths in the Closure Table, where there is a direct ancestry from one node to another.  Include a row for each node to reference itself.  For example, using the data set you showed in your question:</p>

<pre><code>INSERT INTO ClosureTable (ancestor_id, descendant_id) VALUES
  (1,1), (1,2), (1,4), (1,6),
  (2,2), (2,4),
  (3,3), (3,5),
  (4,4),
  (5,5),
  (6,6);
</code></pre>

<p>Now you can get a tree starting at node 1 like this:</p>

<pre><code>SELECT f.* 
FROM FlatTable f 
  JOIN ClosureTable a ON (f.id = a.descendant_id)
WHERE a.ancestor_id = 1;
</code></pre>

<p>The output (in MySQL client) looks like the following:</p>

<pre><code>+----+
| id |
+----+
|  1 | 
|  2 | 
|  4 | 
|  6 | 
+----+
</code></pre>

<p>In other words, nodes 3 and 5 are excluded, because they're part of a separate hierarchy, not descending from node 1.</p>

<hr>

<p>Re: comment from e-satis about immediate children (or immediate parent).  You can add a ""<code>path_length</code>"" column to the <code>ClosureTable</code> to make it easier to query specifically for an immediate child or parent (or any other distance).</p>

<pre><code>INSERT INTO ClosureTable (ancestor_id, descendant_id, path_length) VALUES
  (1,1,0), (1,2,1), (1,4,2), (1,6,1),
  (2,2,0), (2,4,1),
  (3,3,0), (3,5,1),
  (4,4,0),
  (5,5,0),
  (6,6,0);
</code></pre>

<p>Then you can add a term in your search for querying the immediate children of a given node.  These are descendants whose <code>path_length</code> is 1.</p>

<pre><code>SELECT f.* 
FROM FlatTable f 
  JOIN ClosureTable a ON (f.id = a.descendant_id)
WHERE a.ancestor_id = 1
  AND path_length = 1;

+----+
| id |
+----+
|  2 | 
|  6 | 
+----+
</code></pre>

<hr>

<p>Re comment from @ashraf: ""How about sorting the whole tree [by name]?""</p>

<p>Here's an example query to return all nodes that are descendants of node 1, join them to the FlatTable that contains other node attributes such as <code>name</code>, and sort by the name.</p>

<pre><code>SELECT f.name
FROM FlatTable f 
JOIN ClosureTable a ON (f.id = a.descendant_id)
WHERE a.ancestor_id = 1
ORDER BY f.name;
</code></pre>

<hr>

<p>Re comment from @Nate:</p>

<pre><code>SELECT f.name, GROUP_CONCAT(b.ancestor_id order by b.path_length desc) AS breadcrumbs
FROM FlatTable f 
JOIN ClosureTable a ON (f.id = a.descendant_id) 
JOIN ClosureTable b ON (b.descendant_id = a.descendant_id) 
WHERE a.ancestor_id = 1 
GROUP BY a.descendant_id 
ORDER BY f.name

+------------+-------------+
| name       | breadcrumbs |
+------------+-------------+
| Node 1     | 1           |
| Node 1.1   | 1,2         |
| Node 1.1.1 | 1,2,4       |
| Node 1.2   | 1,6         |
+------------+-------------+
</code></pre>

<hr>

<p>A user suggested an edit today. SO moderators approved the edit, but I am reversing it.</p>

<p>The edit suggested that the ORDER BY in the last query above should be <code>ORDER BY b.path_length, f.name</code>, presumably to make sure the ordering matches the hierarchy. But this doesn't work, because it would order ""Node 1.1.1"" after ""Node 1.2"".</p>

<p>If you want the ordering to match the hierarchy in a sensible way, that is possible, but not simply by ordering by the path length. For example, see my answer to <a href=""http://stackoverflow.com/questions/8252323/mysql-closure-table-hierarchical-database-how-to-pull-information-out-in-the-c"">MySQL Closure Table hierarchical database - How to pull information out in the correct order</a>.</p>
"
447,192220,0,370,sql,What is the most efficient/elegant way to parse a flat table into a tree?,"<p>Assume you have a flat table that stores an ordered tree hierarchy:</p>

<pre><code>Id   Name         ParentId   Order
 1   'Node 1'            0      10
 2   'Node 1.1'          1      10
 3   'Node 2'            0      20
 4   'Node 1.1.1'        2      10
 5   'Node 2.1'          3      10
 6   'Node 1.2'          1      20
</code></pre>

<p>Here's a diagram, where we have <code>[id] Name</code>.  Root node 0 is fictional.</p>

<pre>
                       [0] ROOT
                          /    \ 
              [1] Node 1          [3] Node 2
              /       \                   \
    [2] Node 1.1     [6] Node 1.2      [5] Node 2.1
          /          
 [4] Node 1.1.1
</pre>

<p>What minimalistic approach would you use to output that to HTML (or text, for that matter) as a correctly ordered, correctly indented tree? </p>

<p>Assume further you only have basic data structures (arrays and hashmaps), no fancy objects with parent/children references, no ORM, no framework, just your two hands. The table is represented as a result set, which can be accessed randomly. </p>

<p>Pseudo code or plain English is okay, this is purely a conceptional question.</p>

<p>Bonus question: Is there a fundamentally better way to store a tree structure like this in a RDBMS?</p>

<hr>

<p><strong>EDITS AND ADDITIONS</strong></p>

<p>To answer one commenter's (<a href=""http://stackoverflow.com/users/17826/mark-bessey"">Mark Bessey</a>'s) question: A root node is not necessary, because it is never going to be displayed anyway. ParentId = 0 is the convention to express ""these are top level"". The Order column defines how nodes with the same parent are going to be sorted.</p>

<p>The ""result set"" I spoke of can be pictured as an array of hashmaps (to stay in that terminology). For my example was meant to be already there. Some answers go the extra mile and construct it first, but thats okay.</p>

<p>The tree can be arbitrarily deep. Each node can have N children. I did not exactly have a ""millions of entries"" tree in mind, though.</p>

<p>Don't mistake my choice of node naming ('Node 1.1.1') for something to rely on. The nodes could equally well be called 'Frank' or 'Bob', no naming structure is implied, this was merely to make it readable.</p>

<p><em>I have posted my own solution so you guys can pull it to pieces.</em></p>
","<p>Here is how I do it currently: (This solution assumes you actually can index into the result set, as indicated in the question.)</p>

<ul>
<li><p>Make sure the result set is ""<code>ORDER BY Order</code>"" so all nodes with the same parent come out in the right order.</p></li>
<li><p>Iterate the result set, write down each row index (not node Id!) in a hashmap <code>children</code>, keyed by ParentId:</p>

<p><code>{0:[1,3], 1:[2,6], 2:[4], 3:[5]}</code></p></li>
<li><p>Depth-first recurse into <code>children</code>, starting with the default parent node ""0"". The row index in the child array is used to pull out any other information from the result set.</p></li>
<li><p>Maintain info about the row index and its nesting level (e.g. recursion depth), building this array (let's call it <code>sequence</code>): </p>

<p><code>[{row:1,lvl:0}, {row:2,lvl:1}, {row:4,lvl:2}, {row:6,lvl:1}, {row:3,lvl:0}, {row:5,lvl:1}]</code></p></li>
<li><p>Use that array to access the result set sequentially (simple loop) any time I need to print out the tree. Assuming I have to do it more than once, I spare me the repeated recursion.</p></li>
</ul>

<p>Pseude-Code:</p>

<pre><code>children = {}

foreach row in resultSet
  parentId = row.fields['ParentId']
  if parentId not in children
    children[parentId] = []
  end if
  chidren[parentId].push(row.index)
next row

function buildSequence(parentId = 0, depth = 0)
  sequence = []
  foreach rowIndex in children[parentId]
    sequence.push( {row: rowIndex, lvl: depth} )
    thisId = resultSet[rowIndex].fields['Id']
    if thisId in children
      sequence.append( buildSequence(thisId, depth + 1) )
    end if
  next rowIndex
  return sequence
end function

sequence = buildSequence()
</code></pre>
"
437,192220,3,370,sql,What is the most efficient/elegant way to parse a flat table into a tree?,"<p>Assume you have a flat table that stores an ordered tree hierarchy:</p>

<pre><code>Id   Name         ParentId   Order
 1   'Node 1'            0      10
 2   'Node 1.1'          1      10
 3   'Node 2'            0      20
 4   'Node 1.1.1'        2      10
 5   'Node 2.1'          3      10
 6   'Node 1.2'          1      20
</code></pre>

<p>Here's a diagram, where we have <code>[id] Name</code>.  Root node 0 is fictional.</p>

<pre>
                       [0] ROOT
                          /    \ 
              [1] Node 1          [3] Node 2
              /       \                   \
    [2] Node 1.1     [6] Node 1.2      [5] Node 2.1
          /          
 [4] Node 1.1.1
</pre>

<p>What minimalistic approach would you use to output that to HTML (or text, for that matter) as a correctly ordered, correctly indented tree? </p>

<p>Assume further you only have basic data structures (arrays and hashmaps), no fancy objects with parent/children references, no ORM, no framework, just your two hands. The table is represented as a result set, which can be accessed randomly. </p>

<p>Pseudo code or plain English is okay, this is purely a conceptional question.</p>

<p>Bonus question: Is there a fundamentally better way to store a tree structure like this in a RDBMS?</p>

<hr>

<p><strong>EDITS AND ADDITIONS</strong></p>

<p>To answer one commenter's (<a href=""http://stackoverflow.com/users/17826/mark-bessey"">Mark Bessey</a>'s) question: A root node is not necessary, because it is never going to be displayed anyway. ParentId = 0 is the convention to express ""these are top level"". The Order column defines how nodes with the same parent are going to be sorted.</p>

<p>The ""result set"" I spoke of can be pictured as an array of hashmaps (to stay in that terminology). For my example was meant to be already there. Some answers go the extra mile and construct it first, but thats okay.</p>

<p>The tree can be arbitrarily deep. Each node can have N children. I did not exactly have a ""millions of entries"" tree in mind, though.</p>

<p>Don't mistake my choice of node naming ('Node 1.1.1') for something to rely on. The nodes could equally well be called 'Frank' or 'Bob', no naming structure is implied, this was merely to make it readable.</p>

<p><em>I have posted my own solution so you guys can pull it to pieces.</em></p>
","<p>Assuming that you know that the root elements are zero, here's the pseudocode to output to text:</p>

<pre><code>function PrintLevel (int curr, int level)
    //print the indents
    for (i=1; i&lt;=level; i++)
    	print a tab
    print curr \n;
    for each child in the table with a parent of curr
    	PrintLevel (child, level+1)


for each elementID where the parentid is zero
    PrintLevel(elementID, 0)
</code></pre>
"
438,192220,1,370,sql,What is the most efficient/elegant way to parse a flat table into a tree?,"<p>Assume you have a flat table that stores an ordered tree hierarchy:</p>

<pre><code>Id   Name         ParentId   Order
 1   'Node 1'            0      10
 2   'Node 1.1'          1      10
 3   'Node 2'            0      20
 4   'Node 1.1.1'        2      10
 5   'Node 2.1'          3      10
 6   'Node 1.2'          1      20
</code></pre>

<p>Here's a diagram, where we have <code>[id] Name</code>.  Root node 0 is fictional.</p>

<pre>
                       [0] ROOT
                          /    \ 
              [1] Node 1          [3] Node 2
              /       \                   \
    [2] Node 1.1     [6] Node 1.2      [5] Node 2.1
          /          
 [4] Node 1.1.1
</pre>

<p>What minimalistic approach would you use to output that to HTML (or text, for that matter) as a correctly ordered, correctly indented tree? </p>

<p>Assume further you only have basic data structures (arrays and hashmaps), no fancy objects with parent/children references, no ORM, no framework, just your two hands. The table is represented as a result set, which can be accessed randomly. </p>

<p>Pseudo code or plain English is okay, this is purely a conceptional question.</p>

<p>Bonus question: Is there a fundamentally better way to store a tree structure like this in a RDBMS?</p>

<hr>

<p><strong>EDITS AND ADDITIONS</strong></p>

<p>To answer one commenter's (<a href=""http://stackoverflow.com/users/17826/mark-bessey"">Mark Bessey</a>'s) question: A root node is not necessary, because it is never going to be displayed anyway. ParentId = 0 is the convention to express ""these are top level"". The Order column defines how nodes with the same parent are going to be sorted.</p>

<p>The ""result set"" I spoke of can be pictured as an array of hashmaps (to stay in that terminology). For my example was meant to be already there. Some answers go the extra mile and construct it first, but thats okay.</p>

<p>The tree can be arbitrarily deep. Each node can have N children. I did not exactly have a ""millions of entries"" tree in mind, though.</p>

<p>Don't mistake my choice of node naming ('Node 1.1.1') for something to rely on. The nodes could equally well be called 'Frank' or 'Bob', no naming structure is implied, this was merely to make it readable.</p>

<p><em>I have posted my own solution so you guys can pull it to pieces.</em></p>
","<p>If nested hash maps or arrays can be created, then I can simply go down the table from the beginning and add each item to the nested array. I must trace each line to the root node in order to know which level in the nested array to insert into. I can employ memoization so that I do not need to look up the same parent over and over again.</p>

<p>Edit: I would read the entire table into an array first, so it will not query the DB repeatedly. Of course this won't be practical if your table is very large.</p>

<p>After the structure is built, I must do a depth first traverse through it and print out the HTML.</p>

<p>There's no better fundamental way to store this information using one table (I could be wrong though ;), and would love to see a better solution ). However, if you create a scheme to employ dynamically created db tables, then you opened up a whole new world at the sacrifice of simplicity, and the risk of SQL hell ;).</p>
"
439,192220,3,370,sql,What is the most efficient/elegant way to parse a flat table into a tree?,"<p>Assume you have a flat table that stores an ordered tree hierarchy:</p>

<pre><code>Id   Name         ParentId   Order
 1   'Node 1'            0      10
 2   'Node 1.1'          1      10
 3   'Node 2'            0      20
 4   'Node 1.1.1'        2      10
 5   'Node 2.1'          3      10
 6   'Node 1.2'          1      20
</code></pre>

<p>Here's a diagram, where we have <code>[id] Name</code>.  Root node 0 is fictional.</p>

<pre>
                       [0] ROOT
                          /    \ 
              [1] Node 1          [3] Node 2
              /       \                   \
    [2] Node 1.1     [6] Node 1.2      [5] Node 2.1
          /          
 [4] Node 1.1.1
</pre>

<p>What minimalistic approach would you use to output that to HTML (or text, for that matter) as a correctly ordered, correctly indented tree? </p>

<p>Assume further you only have basic data structures (arrays and hashmaps), no fancy objects with parent/children references, no ORM, no framework, just your two hands. The table is represented as a result set, which can be accessed randomly. </p>

<p>Pseudo code or plain English is okay, this is purely a conceptional question.</p>

<p>Bonus question: Is there a fundamentally better way to store a tree structure like this in a RDBMS?</p>

<hr>

<p><strong>EDITS AND ADDITIONS</strong></p>

<p>To answer one commenter's (<a href=""http://stackoverflow.com/users/17826/mark-bessey"">Mark Bessey</a>'s) question: A root node is not necessary, because it is never going to be displayed anyway. ParentId = 0 is the convention to express ""these are top level"". The Order column defines how nodes with the same parent are going to be sorted.</p>

<p>The ""result set"" I spoke of can be pictured as an array of hashmaps (to stay in that terminology). For my example was meant to be already there. Some answers go the extra mile and construct it first, but thats okay.</p>

<p>The tree can be arbitrarily deep. Each node can have N children. I did not exactly have a ""millions of entries"" tree in mind, though.</p>

<p>Don't mistake my choice of node naming ('Node 1.1.1') for something to rely on. The nodes could equally well be called 'Frank' or 'Bob', no naming structure is implied, this was merely to make it readable.</p>

<p><em>I have posted my own solution so you guys can pull it to pieces.</em></p>
","<p>You can emulate any other data structure with a hashmap, so that's not a terrible limitation.  Scanning from the top to the bottom, you create a hashmap for each row of the database, with an entry for each column. Add each of these hashmaps to a ""master"" hashmap, keyed on the id. If any node has a ""parent"" that you haven't seen yet, create an placeholder entry for it in the master hashmap, and fill it in when you see the actual node.</p>

<p>To print it out, do a simple depth-first pass through the data, keeping track of indent level along the way. You can make this easier by keeping a ""children"" entry for each row, and populating it as you scan the data.</p>

<p>As for whether there's a ""better"" way to store a tree in a database, that depends on how you're going to use the data. I've seen systems that had a known maximum depth that used a different table for each level in the hierarchy. That makes a lot of sense if the levels in the tree aren't quite equivalent after all (top level categories being different than the leaves).</p>
"
440,192220,7,370,sql,What is the most efficient/elegant way to parse a flat table into a tree?,"<p>Assume you have a flat table that stores an ordered tree hierarchy:</p>

<pre><code>Id   Name         ParentId   Order
 1   'Node 1'            0      10
 2   'Node 1.1'          1      10
 3   'Node 2'            0      20
 4   'Node 1.1.1'        2      10
 5   'Node 2.1'          3      10
 6   'Node 1.2'          1      20
</code></pre>

<p>Here's a diagram, where we have <code>[id] Name</code>.  Root node 0 is fictional.</p>

<pre>
                       [0] ROOT
                          /    \ 
              [1] Node 1          [3] Node 2
              /       \                   \
    [2] Node 1.1     [6] Node 1.2      [5] Node 2.1
          /          
 [4] Node 1.1.1
</pre>

<p>What minimalistic approach would you use to output that to HTML (or text, for that matter) as a correctly ordered, correctly indented tree? </p>

<p>Assume further you only have basic data structures (arrays and hashmaps), no fancy objects with parent/children references, no ORM, no framework, just your two hands. The table is represented as a result set, which can be accessed randomly. </p>

<p>Pseudo code or plain English is okay, this is purely a conceptional question.</p>

<p>Bonus question: Is there a fundamentally better way to store a tree structure like this in a RDBMS?</p>

<hr>

<p><strong>EDITS AND ADDITIONS</strong></p>

<p>To answer one commenter's (<a href=""http://stackoverflow.com/users/17826/mark-bessey"">Mark Bessey</a>'s) question: A root node is not necessary, because it is never going to be displayed anyway. ParentId = 0 is the convention to express ""these are top level"". The Order column defines how nodes with the same parent are going to be sorted.</p>

<p>The ""result set"" I spoke of can be pictured as an array of hashmaps (to stay in that terminology). For my example was meant to be already there. Some answers go the extra mile and construct it first, but thats okay.</p>

<p>The tree can be arbitrarily deep. Each node can have N children. I did not exactly have a ""millions of entries"" tree in mind, though.</p>

<p>Don't mistake my choice of node naming ('Node 1.1.1') for something to rely on. The nodes could equally well be called 'Frank' or 'Bob', no naming structure is implied, this was merely to make it readable.</p>

<p><em>I have posted my own solution so you guys can pull it to pieces.</em></p>
","<p>Well given the choice, I'd be using objects. I'd create an object for each record where each object has a <code>children</code> collection and store them all in an assoc array (/hashtable) where the Id is the key. And blitz through the collection once, adding the children to the relevant children fields. <strong>Simple.</strong></p>

<p>But because you're being no fun by restricting use of some good OOP, I'd probably iterate based on:</p>

<pre><code>function PrintLine(int pID, int level)
    foreach record where ParentID == pID
        print level*tabs + record-data
        PrintLine(record.ID, level + 1)

PrintLine(0, 0)
</code></pre>

<p>Edit: this is similar to a couple of other entries, but I think it's slightly cleaner. One thing I'll add: this is extremely SQL-intensive. It's <em>nasty</em>. <strong>If you have the choice, go the OOP route.</strong></p>
"
442,192220,4,370,sql,What is the most efficient/elegant way to parse a flat table into a tree?,"<p>Assume you have a flat table that stores an ordered tree hierarchy:</p>

<pre><code>Id   Name         ParentId   Order
 1   'Node 1'            0      10
 2   'Node 1.1'          1      10
 3   'Node 2'            0      20
 4   'Node 1.1.1'        2      10
 5   'Node 2.1'          3      10
 6   'Node 1.2'          1      20
</code></pre>

<p>Here's a diagram, where we have <code>[id] Name</code>.  Root node 0 is fictional.</p>

<pre>
                       [0] ROOT
                          /    \ 
              [1] Node 1          [3] Node 2
              /       \                   \
    [2] Node 1.1     [6] Node 1.2      [5] Node 2.1
          /          
 [4] Node 1.1.1
</pre>

<p>What minimalistic approach would you use to output that to HTML (or text, for that matter) as a correctly ordered, correctly indented tree? </p>

<p>Assume further you only have basic data structures (arrays and hashmaps), no fancy objects with parent/children references, no ORM, no framework, just your two hands. The table is represented as a result set, which can be accessed randomly. </p>

<p>Pseudo code or plain English is okay, this is purely a conceptional question.</p>

<p>Bonus question: Is there a fundamentally better way to store a tree structure like this in a RDBMS?</p>

<hr>

<p><strong>EDITS AND ADDITIONS</strong></p>

<p>To answer one commenter's (<a href=""http://stackoverflow.com/users/17826/mark-bessey"">Mark Bessey</a>'s) question: A root node is not necessary, because it is never going to be displayed anyway. ParentId = 0 is the convention to express ""these are top level"". The Order column defines how nodes with the same parent are going to be sorted.</p>

<p>The ""result set"" I spoke of can be pictured as an array of hashmaps (to stay in that terminology). For my example was meant to be already there. Some answers go the extra mile and construct it first, but thats okay.</p>

<p>The tree can be arbitrarily deep. Each node can have N children. I did not exactly have a ""millions of entries"" tree in mind, though.</p>

<p>Don't mistake my choice of node naming ('Node 1.1.1') for something to rely on. The nodes could equally well be called 'Frank' or 'Bob', no naming structure is implied, this was merely to make it readable.</p>

<p><em>I have posted my own solution so you guys can pull it to pieces.</em></p>
","<p>This was written quickly, and is neither pretty nor efficient (plus it autoboxes alot, converting between <code>int</code> and <code>Integer</code> is annoying!), but it works.</p>

<p>It probably breaks the rules since I'm creating my own objects but hey I'm doing this as a diversion from real work :)</p>

<p>This also assumes that the resultSet/table is completely read into some sort of structure before you start building Nodes, which wouldn't be the best solution if you have hundreds of thousands of rows.</p>

<pre><code>public class Node {

    private Node parent = null;

    private List&lt;Node&gt; children;

    private String name;

    private int id = -1;

    public Node(Node parent, int id, String name) {
    	this.parent = parent;
    	this.children = new ArrayList&lt;Node&gt;();
    	this.name = name;
    	this.id = id;
    }

    public int getId() {
    	return this.id;
    }

    public String getName() {
    	return this.name;
    }

    public void addChild(Node child) {
    	children.add(child);
    }

    public List&lt;Node&gt; getChildren() {
    	return children;
    }

    public boolean isRoot() {
    	return (this.parent == null);
    }

    @Override
    public String toString() {
    	return ""id="" + id + "", name="" + name + "", parent="" + parent;
    }
}

public class NodeBuilder {

    public static Node build(List&lt;Map&lt;String, String&gt;&gt; input) {

    	// maps id of a node to it's Node object
    	Map&lt;Integer, Node&gt; nodeMap = new HashMap&lt;Integer, Node&gt;();

    	// maps id of a node to the id of it's parent
    	Map&lt;Integer, Integer&gt; childParentMap = new HashMap&lt;Integer, Integer&gt;();

    	// create special 'root' Node with id=0
    	Node root = new Node(null, 0, ""root"");
    	nodeMap.put(root.getId(), root);

    	// iterate thru the input
    	for (Map&lt;String, String&gt; map : input) {

    		// expect each Map to have keys for ""id"", ""name"", ""parent"" ... a
    		// real implementation would read from a SQL object or resultset
    		int id = Integer.parseInt(map.get(""id""));
    		String name = map.get(""name"");
    		int parent = Integer.parseInt(map.get(""parent""));

    		Node node = new Node(null, id, name);
    		nodeMap.put(id, node);

    		childParentMap.put(id, parent);
    	}

    	// now that each Node is created, setup the child-parent relationships
    	for (Map.Entry&lt;Integer, Integer&gt; entry : childParentMap.entrySet()) {
    		int nodeId = entry.getKey();
    		int parentId = entry.getValue();

    		Node child = nodeMap.get(nodeId);
    		Node parent = nodeMap.get(parentId);
    		parent.addChild(child);
    	}

    	return root;
    }
}

public class NodePrinter {

    static void printRootNode(Node root) {
    	printNodes(root, 0);
    }

    static void printNodes(Node node, int indentLevel) {

    	printNode(node, indentLevel);
    	// recurse
    	for (Node child : node.getChildren()) {
    		printNodes(child, indentLevel + 1);
    	}
    }

    static void printNode(Node node, int indentLevel) {
    	StringBuilder sb = new StringBuilder();
    	for (int i = 0; i &lt; indentLevel; i++) {
    		sb.append(""\t"");
    	}
    	sb.append(node);

    	System.out.println(sb.toString());
    }

    public static void main(String[] args) {

    	// setup dummy data
    	List&lt;Map&lt;String, String&gt;&gt; resultSet = new ArrayList&lt;Map&lt;String, String&gt;&gt;();
    	resultSet.add(newMap(""1"", ""Node 1"", ""0""));
    	resultSet.add(newMap(""2"", ""Node 1.1"", ""1""));
    	resultSet.add(newMap(""3"", ""Node 2"", ""0""));
    	resultSet.add(newMap(""4"", ""Node 1.1.1"", ""2""));
    	resultSet.add(newMap(""5"", ""Node 2.1"", ""3""));
    	resultSet.add(newMap(""6"", ""Node 1.2"", ""1""));

    	Node root = NodeBuilder.build(resultSet);
    	printRootNode(root);

    }

    //convenience method for creating our dummy data
    private static Map&lt;String, String&gt; newMap(String id, String name, String parentId) {
    	Map&lt;String, String&gt; row = new HashMap&lt;String, String&gt;();
    	row.put(""id"", id);
    	row.put(""name"", name);
    	row.put(""parent"", parentId);
    	return row;
    }
}
</code></pre>
"
444,192220,15,370,sql,What is the most efficient/elegant way to parse a flat table into a tree?,"<p>Assume you have a flat table that stores an ordered tree hierarchy:</p>

<pre><code>Id   Name         ParentId   Order
 1   'Node 1'            0      10
 2   'Node 1.1'          1      10
 3   'Node 2'            0      20
 4   'Node 1.1.1'        2      10
 5   'Node 2.1'          3      10
 6   'Node 1.2'          1      20
</code></pre>

<p>Here's a diagram, where we have <code>[id] Name</code>.  Root node 0 is fictional.</p>

<pre>
                       [0] ROOT
                          /    \ 
              [1] Node 1          [3] Node 2
              /       \                   \
    [2] Node 1.1     [6] Node 1.2      [5] Node 2.1
          /          
 [4] Node 1.1.1
</pre>

<p>What minimalistic approach would you use to output that to HTML (or text, for that matter) as a correctly ordered, correctly indented tree? </p>

<p>Assume further you only have basic data structures (arrays and hashmaps), no fancy objects with parent/children references, no ORM, no framework, just your two hands. The table is represented as a result set, which can be accessed randomly. </p>

<p>Pseudo code or plain English is okay, this is purely a conceptional question.</p>

<p>Bonus question: Is there a fundamentally better way to store a tree structure like this in a RDBMS?</p>

<hr>

<p><strong>EDITS AND ADDITIONS</strong></p>

<p>To answer one commenter's (<a href=""http://stackoverflow.com/users/17826/mark-bessey"">Mark Bessey</a>'s) question: A root node is not necessary, because it is never going to be displayed anyway. ParentId = 0 is the convention to express ""these are top level"". The Order column defines how nodes with the same parent are going to be sorted.</p>

<p>The ""result set"" I spoke of can be pictured as an array of hashmaps (to stay in that terminology). For my example was meant to be already there. Some answers go the extra mile and construct it first, but thats okay.</p>

<p>The tree can be arbitrarily deep. Each node can have N children. I did not exactly have a ""millions of entries"" tree in mind, though.</p>

<p>Don't mistake my choice of node naming ('Node 1.1.1') for something to rely on. The nodes could equally well be called 'Frank' or 'Bob', no naming structure is implied, this was merely to make it readable.</p>

<p><em>I have posted my own solution so you guys can pull it to pieces.</em></p>
","<p>As of Oracle 9i, you can use CONNECT BY.</p>

<pre><code>SELECT LPAD(' ', (LEVEL - 1) * 4) || ""Name"" AS ""Name""
FROM (SELECT * FROM TMP_NODE ORDER BY ""Order"")
CONNECT BY PRIOR ""Id"" = ""ParentId""
START WITH ""Id"" IN (SELECT ""Id"" FROM TMP_NODE WHERE ""ParentId"" = 0)
</code></pre>

<p>As of SQL Server 2005, you can use a recursive common table expression (CTE).</p>

<pre><code>WITH [NodeList] (
  [Id]
  , [ParentId]
  , [Level]
  , [Order]
) AS (
  SELECT [Node].[Id]
    , [Node].[ParentId]
    , 0 AS [Level]
    , CONVERT([varchar](MAX), [Node].[Order]) AS [Order]
  FROM [Node]
  WHERE [Node].[ParentId] = 0
  UNION ALL
  SELECT [Node].[Id]
    , [Node].[ParentId]
    , [NodeList].[Level] + 1 AS [Level]
    , [NodeList].[Order] + '|'
      + CONVERT([varchar](MAX), [Node].[Order]) AS [Order]
  FROM [Node]
    INNER JOIN [NodeList] ON [NodeList].[Id] = [Node].[ParentId]
) SELECT REPLICATE(' ', [NodeList].[Level] * 4) + [Node].[Name] AS [Name]
FROM [Node]
  INNER JOIN [NodeList] ON [NodeList].[Id] = [Node].[Id]
ORDER BY [NodeList].[Order]
</code></pre>

<p>Both will output the following results.</p>

<pre>
Name
'Node 1'
'    Node 1.1'
'        Node 1.1.1'
'    Node 1.2'
'Node 2'
'    Node 2.1'
</pre>
"
445,192220,1,370,sql,What is the most efficient/elegant way to parse a flat table into a tree?,"<p>Assume you have a flat table that stores an ordered tree hierarchy:</p>

<pre><code>Id   Name         ParentId   Order
 1   'Node 1'            0      10
 2   'Node 1.1'          1      10
 3   'Node 2'            0      20
 4   'Node 1.1.1'        2      10
 5   'Node 2.1'          3      10
 6   'Node 1.2'          1      20
</code></pre>

<p>Here's a diagram, where we have <code>[id] Name</code>.  Root node 0 is fictional.</p>

<pre>
                       [0] ROOT
                          /    \ 
              [1] Node 1          [3] Node 2
              /       \                   \
    [2] Node 1.1     [6] Node 1.2      [5] Node 2.1
          /          
 [4] Node 1.1.1
</pre>

<p>What minimalistic approach would you use to output that to HTML (or text, for that matter) as a correctly ordered, correctly indented tree? </p>

<p>Assume further you only have basic data structures (arrays and hashmaps), no fancy objects with parent/children references, no ORM, no framework, just your two hands. The table is represented as a result set, which can be accessed randomly. </p>

<p>Pseudo code or plain English is okay, this is purely a conceptional question.</p>

<p>Bonus question: Is there a fundamentally better way to store a tree structure like this in a RDBMS?</p>

<hr>

<p><strong>EDITS AND ADDITIONS</strong></p>

<p>To answer one commenter's (<a href=""http://stackoverflow.com/users/17826/mark-bessey"">Mark Bessey</a>'s) question: A root node is not necessary, because it is never going to be displayed anyway. ParentId = 0 is the convention to express ""these are top level"". The Order column defines how nodes with the same parent are going to be sorted.</p>

<p>The ""result set"" I spoke of can be pictured as an array of hashmaps (to stay in that terminology). For my example was meant to be already there. Some answers go the extra mile and construct it first, but thats okay.</p>

<p>The tree can be arbitrarily deep. Each node can have N children. I did not exactly have a ""millions of entries"" tree in mind, though.</p>

<p>Don't mistake my choice of node naming ('Node 1.1.1') for something to rely on. The nodes could equally well be called 'Frank' or 'Bob', no naming structure is implied, this was merely to make it readable.</p>

<p><em>I have posted my own solution so you guys can pull it to pieces.</em></p>
","<p>If elements are in tree order, as shown in your example, you can use something like the following Python example:</p>

<pre><code>delimiter = '.'
stack = []
for item in items:
  while stack and not item.startswith(stack[-1]+delimiter):
    print ""&lt;/div&gt;""
    stack.pop()
  print ""&lt;div&gt;""
  print item
  stack.append(item)
</code></pre>

<p>What this does is maintain a stack representing the current position in the tree. For each element in the table, it pops stack elements (closing the matching divs) until it finds the parent of the current item. Then it outputs the start of that node and pushes it to the stack.</p>

<p>If you want to output the tree using indenting rather than nested elements, you can simply skip the print statements to print the divs, and print a number of spaces equal to some multiple of the size of the stack before each item. For example, in Python:</p>

<pre><code>print ""  "" * len(stack)
</code></pre>

<p>You could also easily use this method to construct a set of nested lists or dictionaries.</p>

<p>Edit: I see from your clarification that the names were not intended to be node paths. That suggests an alternate approach:</p>

<pre><code>idx = {}
idx[0] = []
for node in results:
  child_list = []
  idx[node.Id] = child_list
  idx[node.ParentId].append((node, child_list))
</code></pre>

<p>This constructs a tree of arrays of tuples(!). idx[0] represents the root(s) of the tree. Each element in an array is a 2-tuple consisting of the node itself and a list of all its children. Once constructed, you can hold on to idx[0] and discard idx, unless you want to access nodes by their ID.</p>
"
446,192220,47,370,sql,What is the most efficient/elegant way to parse a flat table into a tree?,"<p>Assume you have a flat table that stores an ordered tree hierarchy:</p>

<pre><code>Id   Name         ParentId   Order
 1   'Node 1'            0      10
 2   'Node 1.1'          1      10
 3   'Node 2'            0      20
 4   'Node 1.1.1'        2      10
 5   'Node 2.1'          3      10
 6   'Node 1.2'          1      20
</code></pre>

<p>Here's a diagram, where we have <code>[id] Name</code>.  Root node 0 is fictional.</p>

<pre>
                       [0] ROOT
                          /    \ 
              [1] Node 1          [3] Node 2
              /       \                   \
    [2] Node 1.1     [6] Node 1.2      [5] Node 2.1
          /          
 [4] Node 1.1.1
</pre>

<p>What minimalistic approach would you use to output that to HTML (or text, for that matter) as a correctly ordered, correctly indented tree? </p>

<p>Assume further you only have basic data structures (arrays and hashmaps), no fancy objects with parent/children references, no ORM, no framework, just your two hands. The table is represented as a result set, which can be accessed randomly. </p>

<p>Pseudo code or plain English is okay, this is purely a conceptional question.</p>

<p>Bonus question: Is there a fundamentally better way to store a tree structure like this in a RDBMS?</p>

<hr>

<p><strong>EDITS AND ADDITIONS</strong></p>

<p>To answer one commenter's (<a href=""http://stackoverflow.com/users/17826/mark-bessey"">Mark Bessey</a>'s) question: A root node is not necessary, because it is never going to be displayed anyway. ParentId = 0 is the convention to express ""these are top level"". The Order column defines how nodes with the same parent are going to be sorted.</p>

<p>The ""result set"" I spoke of can be pictured as an array of hashmaps (to stay in that terminology). For my example was meant to be already there. Some answers go the extra mile and construct it first, but thats okay.</p>

<p>The tree can be arbitrarily deep. Each node can have N children. I did not exactly have a ""millions of entries"" tree in mind, though.</p>

<p>Don't mistake my choice of node naming ('Node 1.1.1') for something to rely on. The nodes could equally well be called 'Frank' or 'Bob', no naming structure is implied, this was merely to make it readable.</p>

<p><em>I have posted my own solution so you guys can pull it to pieces.</em></p>
","<p>If you use nested sets (sometimes referred to as Modified Pre-order Tree Traversal) you can extract the entire tree structure or any subtree within it in tree order with a single query, at the cost of inserts being more expensive, as you need to manage columns which describe an in-order path through thee tree structure.</p>

<p>For <a href=""http://code.google.com/p/django-mptt/"">django-mptt</a>, I used a structure like this:</p>

<pre>
id  parent_id  tree_id  level  lft  rght
--  ---------  -------  -----  ---  ----
 1       null        1      0    1    14
 2          1        1      1    2     7
 3          2        1      2    3     4
 4          2        1      2    5     6
 5          1        1      1    8    13
 6          5        1      2    9    10
 7          5        1      2    11   12
</pre>

<p>Which describes a tree which looks like this (with <code>id</code> representing each item):</p>

<pre>
 1
 +-- 2
 |   +-- 3
 |   +-- 4
 |
 +-- 5
     +-- 6
     +-- 7
</pre>

<p>Or, as a nested set diagram which makes it more obvious how the <code>lft</code> and <code>rght</code> values work:</p>

<pre>
 __________________________________________________________________________
|  Root 1                                                                  |
|   ________________________________    ________________________________   |
|  |  Child 1.1                     |  |  Child 1.2                     |  |
|  |   ___________    ___________   |  |   ___________    ___________   |  |
|  |  |  C 1.1.1  |  |  C 1.1.2  |  |  |  |  C 1.2.1  |  |  C 1.2.2  |  |  |
1  2  3___________4  5___________6  7  8  9___________10 11__________12 13 14
|  |________________________________|  |________________________________|  |
|__________________________________________________________________________|
</pre>

<p>As you can see, to get the entire subtree for a given node, in tree order, you simply have to select all rows which have <code>lft</code> and <code>rght</code> values between its <code>lft</code> and <code>rght</code> values. It's also simple to retrieve the tree of ancestors for a given node.</p>

<p>The <code>level</code> column is a bit of denormalisation for convenience more than anything and the <code>tree_id</code> column allows you to restart the <code>lft</code> and <code>rght</code> numbering for each top-level node, which reduces the number of columns affected by inserts, moves and deletions, as the <code>lft</code> and <code>rght</code> columns have to be adjusted accordingly when these operations take place in order to create or close gaps. I made some <a href=""http://code.google.com/p/django-mptt/source/browse/trunk/NOTES"">development notes</a> at the time when I was trying to wrap my head around the queries required for each operation.</p>

<p>In terms of actually working with this data to display a tree, I created a <a href=""http://code.google.com/p/django-mptt/source/browse/trunk/mptt/utils.py#29""><code>tree_item_iterator</code></a> utility function which, for each node, should give you sufficient information to generate whatever kind of display you want.</p>

<p>More info about MPTT:</p>

<ul>
<li><a href=""http://www.intelligententerprise.com/001020/celko.jhtml"">Trees in SQL</a></li>
<li><a href=""http://www.sitepoint.com/print/hierarchical-data-database"">Storing Hierarchical Data in a Database</a></li>
<li><a href=""http://mikehillyer.com/articles/managing-hierarchical-data-in-mysql/"">Managing Hierarchical Data in MySQL</a></li>
</ul>
"
443,192220,1,370,sql,What is the most efficient/elegant way to parse a flat table into a tree?,"<p>Assume you have a flat table that stores an ordered tree hierarchy:</p>

<pre><code>Id   Name         ParentId   Order
 1   'Node 1'            0      10
 2   'Node 1.1'          1      10
 3   'Node 2'            0      20
 4   'Node 1.1.1'        2      10
 5   'Node 2.1'          3      10
 6   'Node 1.2'          1      20
</code></pre>

<p>Here's a diagram, where we have <code>[id] Name</code>.  Root node 0 is fictional.</p>

<pre>
                       [0] ROOT
                          /    \ 
              [1] Node 1          [3] Node 2
              /       \                   \
    [2] Node 1.1     [6] Node 1.2      [5] Node 2.1
          /          
 [4] Node 1.1.1
</pre>

<p>What minimalistic approach would you use to output that to HTML (or text, for that matter) as a correctly ordered, correctly indented tree? </p>

<p>Assume further you only have basic data structures (arrays and hashmaps), no fancy objects with parent/children references, no ORM, no framework, just your two hands. The table is represented as a result set, which can be accessed randomly. </p>

<p>Pseudo code or plain English is okay, this is purely a conceptional question.</p>

<p>Bonus question: Is there a fundamentally better way to store a tree structure like this in a RDBMS?</p>

<hr>

<p><strong>EDITS AND ADDITIONS</strong></p>

<p>To answer one commenter's (<a href=""http://stackoverflow.com/users/17826/mark-bessey"">Mark Bessey</a>'s) question: A root node is not necessary, because it is never going to be displayed anyway. ParentId = 0 is the convention to express ""these are top level"". The Order column defines how nodes with the same parent are going to be sorted.</p>

<p>The ""result set"" I spoke of can be pictured as an array of hashmaps (to stay in that terminology). For my example was meant to be already there. Some answers go the extra mile and construct it first, but thats okay.</p>

<p>The tree can be arbitrarily deep. Each node can have N children. I did not exactly have a ""millions of entries"" tree in mind, though.</p>

<p>Don't mistake my choice of node naming ('Node 1.1.1') for something to rely on. The nodes could equally well be called 'Frank' or 'Bob', no naming structure is implied, this was merely to make it readable.</p>

<p><em>I have posted my own solution so you guys can pull it to pieces.</em></p>
","<p>To Extend Bill's SQL solution you can basically do the same using a flat array.  Further more if your strings all have the same lenght and your maximum number of children are known (say in a binary tree) you can do it using a single string (character array).  If you have arbitrary number of children this complicates things a bit...  I would have to check my old notes to see what can be done.</p>

<p>Then, sacrificing a bit of memory, especially if your tree is sparse and/or unballanced, you can, with a bit of index math, access all the strings randomly by storing your tree, width first in the array like so (for a binary tree):</p>

<pre><code>String[] nodeArray = [L0root, L1child1, L1child2, L2Child1, L2Child2, L2Child3, L2Child4] ...
</code></pre>

<p>yo know your string length, you know it

<p>I'm at work now so cannot spend much time on it but with interest I can fetch a bit of code to do this.  </p>

<p>We use to do it to search in binary trees made of DNA codons, a process built the tree, then we flattened it to search text patterns and when found, though index math (revers from above) we get the node back...  very fast and efficient, tough our tree rarely had empty nodes, but we could searh gigabytes of data in a jiffy.</p>
"
812,354070,5,330,sql,SQL join: where clause vs. on clause,"<p>After reading it, this is <em>not</em> a duplicate of <a href=""http://stackoverflow.com/questions/44917/explicit-vs-implicit-sql-joins"">Explicit vs Implicit SQL Joins</a>.
The answer may be related (or even the same) but the <strong>question</strong> is different.</p>

<p><hr /></p>

<p>What is the difference and what should go in each?</p>

<p>If I understand the theory correctly, the query optimizer should be able to use both interchangeably.</p>
","<p>In terms of the optimizer, it shouldn't make a difference whether you define your join clauses with ON or WHERE.</p>

<p>However, IMHO, I think it's much clearer to use the ON clause when performing joins.  That way you have a specific section of you query that dictates how the join is handled versus intermixed with the rest of the WHERE clauses.</p>
"
813,354070,21,330,sql,SQL join: where clause vs. on clause,"<p>After reading it, this is <em>not</em> a duplicate of <a href=""http://stackoverflow.com/questions/44917/explicit-vs-implicit-sql-joins"">Explicit vs Implicit SQL Joins</a>.
The answer may be related (or even the same) but the <strong>question</strong> is different.</p>

<p><hr /></p>

<p>What is the difference and what should go in each?</p>

<p>If I understand the theory correctly, the query optimizer should be able to use both interchangeably.</p>
","<p>The way I do it is:</p>

<p>Always put the join conditions in the on clause
If you are doing an inner join, so not add any where conditions to the on clause, put them in the where clause </p>

<p>If you are doing a left join, add any where conditions to the on clause for the table in the right side of the join. This is a must because adding a where clause that references the right side of the join will convert the join to an inner join (With one exception described below). </p>

<p>The exception is that when you are looking for the records that are not in a particular table, you would add the refernce to a unique identifier(that is not ever null) in the right join table to the where clause this way ""Where t2.idfield is null"". So the only time you should reference a table on the right side of the join is to find those records which are not in the table.</p>
"
809,354070,26,330,sql,SQL join: where clause vs. on clause,"<p>After reading it, this is <em>not</em> a duplicate of <a href=""http://stackoverflow.com/questions/44917/explicit-vs-implicit-sql-joins"">Explicit vs Implicit SQL Joins</a>.
The answer may be related (or even the same) but the <strong>question</strong> is different.</p>

<p><hr /></p>

<p>What is the difference and what should go in each?</p>

<p>If I understand the theory correctly, the query optimizer should be able to use both interchangeably.</p>
","<p>On an inner join, they mean the same thing. However you will get different results in an outer join depending on if you put the join condition in the WHERE vs the ON clause. Take a look at <a href=""http://stackoverflow.com/questions/219046/help-with-a-where-on-a-left-join-sql-query"">this related question</a> and <a href=""http://stackoverflow.com/questions/219046/help-with-a-where-on-a-left-join-sql-query#219053"">this answer</a> (by me).</p>

<p>I think it makes the most sense to be in the habit of always putting the join condition in the ON clause (unless it is an outer join and you actually do want it in the where clause) as it makes it clearer to anyone reading your query what conditions the tables are being joined on, and also it helps prevent the WHERE clause from being dozens of lines long.</p>
"
810,354070,475,330,sql,SQL join: where clause vs. on clause,"<p>After reading it, this is <em>not</em> a duplicate of <a href=""http://stackoverflow.com/questions/44917/explicit-vs-implicit-sql-joins"">Explicit vs Implicit SQL Joins</a>.
The answer may be related (or even the same) but the <strong>question</strong> is different.</p>

<p><hr /></p>

<p>What is the difference and what should go in each?</p>

<p>If I understand the theory correctly, the query optimizer should be able to use both interchangeably.</p>
","<p>They are not the same thing.</p>

<p>Consider these queries:</p>

<pre><code>SELECT *
FROM Orders
LEFT JOIN OrderLines ON OrderLines.OrderID=Orders.ID
WHERE Orders.ID = 12345
</code></pre>

<p>and</p>

<pre><code>SELECT *
FROM Orders
LEFT JOIN OrderLines ON OrderLines.OrderID=Orders.ID 
    AND Orders.ID = 12345
</code></pre>

<p>The first will return an order and its lines, if any, for order number <code>12345</code>.  The second will return all orders, but only order <code>12345</code> will have any lines associated with it.</p>

<p>With an <code>INNER JOIN</code>, the clauses are <em>effectively</em> equivalent. However, just because they are functionally the same, in that they produce the same results, does not mean the two kinds of clauses have the same semantic meaning.</p>
"
811,354070,120,330,sql,SQL join: where clause vs. on clause,"<p>After reading it, this is <em>not</em> a duplicate of <a href=""http://stackoverflow.com/questions/44917/explicit-vs-implicit-sql-joins"">Explicit vs Implicit SQL Joins</a>.
The answer may be related (or even the same) but the <strong>question</strong> is different.</p>

<p><hr /></p>

<p>What is the difference and what should go in each?</p>

<p>If I understand the theory correctly, the query optimizer should be able to use both interchangeably.</p>
","<p>On <code>INNER JOIN</code>s they are interchangeable, and the optimizer will rearrange them at will.</p>

<p>On <code>OUTER JOIN</code>s, they are not necessarily interchangeable, depending on which side of the join they depend on.</p>

<p>I put them in either place depending on the readability.</p>
"
414,187770,19,266,sql,Copy tables from one database to another in SQL Server,"<p>I have a database called foo and a database called bar. I have a table in foo called tblFoobar that I want to move (data and all) to database bar from database foo. What is the SQL statement to do this?</p>
","<ol>
<li><p>Script the <code>create table</code> in management studio, run that script in bar to create the table. (Right click table in object explorer, script table as, create to...)</p></li>
<li><p><code>INSERT bar.[schema].table SELECT * FROM foo.[schema].table</code></p></li>
</ol>
"
415,187770,489,266,sql,Copy tables from one database to another in SQL Server,"<p>I have a database called foo and a database called bar. I have a table in foo called tblFoobar that I want to move (data and all) to database bar from database foo. What is the SQL statement to do this?</p>
","<p>SQL Server Management Studio's ""Import Data"" task (right-click on the DB name, then tasks) will do most of this for you.  Run it from the database you want to copy the data into.</p>

<p>If the tables don't exist it will create them for you, but you'll probably have to recreate any indexes and such.  If the tables do exist, it will append the new data by default but you can adjust that (edit mappings) so it will delete all existing data.</p>

<p>I use this all the time and it works fairly well.</p>
"
413,187770,76,266,sql,Copy tables from one database to another in SQL Server,"<p>I have a database called foo and a database called bar. I have a table in foo called tblFoobar that I want to move (data and all) to database bar from database foo. What is the SQL statement to do this?</p>
","<p>This should work:</p>

<pre><code>SELECT * 
INTO DestinationDB..MyDestinationTable 
FROM SourceDB..MySourceTable 
</code></pre>

<p>It will <strong>not</strong> copy constaints, defaults or indexes. The table created will <strong>not</strong> have a clustered index.</p>

<p>Alternatively you could:  </p>

<pre><code>INSERT INTO DestinationDB..MyDestinationTable 
SELECT * FROM SourceDB..MySourceTable
</code></pre>

<p>If your destination table exists and is empty. </p>
"
412,187770,159,266,sql,Copy tables from one database to another in SQL Server,"<p>I have a database called foo and a database called bar. I have a table in foo called tblFoobar that I want to move (data and all) to database bar from database foo. What is the SQL statement to do this?</p>
","<p>On SQL Server? and on the same database server? Use three part naming.</p>

<pre><code>INSERT INTO bar..tblFoobar( *fieldlist* )
SELECT *fieldlist* FROM foo..tblFoobar
</code></pre>

<p>This just moves the data.  If you want to move the table definition (and other attributes such as permissions and indexes), you'll have to do something else.</p>
"
1198,536350,1,208,sql,"Drop all the tables, stored procedures, triggers, constraints and all the dependencies in one sql statement","<p>Is there any way in which I can clean a database in SQl Server 2005 by dropping all the tables and deleting stored procedures, triggers, constraints and all the dependencies in one SQL statement?</p>

<p><strong>REASON FOR REQUEST:</strong></p>

<p>I want to have a DB script for cleaning up an existing DB which is not in use rather than creating new ones, especially when you have to put in a request to your DB admin and wait for a while to get it done!</p>
","<p>There is no single statement that can be used to achieve this aim.</p>

<p>You could of course create yourself a <code>stored procedure</code> that you could use to perform these various administrative tasks.</p>

<p>You could then execute the procedure using this single statement.</p>

<pre><code>Exec sp_CleanDatabases @DatabaseName='DBname'
</code></pre>
"
1199,536350,12,208,sql,"Drop all the tables, stored procedures, triggers, constraints and all the dependencies in one sql statement","<p>Is there any way in which I can clean a database in SQl Server 2005 by dropping all the tables and deleting stored procedures, triggers, constraints and all the dependencies in one SQL statement?</p>

<p><strong>REASON FOR REQUEST:</strong></p>

<p>I want to have a DB script for cleaning up an existing DB which is not in use rather than creating new ones, especially when you have to put in a request to your DB admin and wait for a while to get it done!</p>
","<p>I'd do it in two statements: <a href=""http://msdn.microsoft.com/de-de/library/ms178613.aspx""><code>DROP DATABASE ???</code></a></p>

<p>and then <a href=""http://msdn.microsoft.com/de-de/library/ms176061.aspx""><code>CREATE DATABASE ???</code></a></p>
"
1200,536350,36,208,sql,"Drop all the tables, stored procedures, triggers, constraints and all the dependencies in one sql statement","<p>Is there any way in which I can clean a database in SQl Server 2005 by dropping all the tables and deleting stored procedures, triggers, constraints and all the dependencies in one SQL statement?</p>

<p><strong>REASON FOR REQUEST:</strong></p>

<p>I want to have a DB script for cleaning up an existing DB which is not in use rather than creating new ones, especially when you have to put in a request to your DB admin and wait for a while to get it done!</p>
","<p>To drop all tables:</p>

<pre><code>exec sp_MSforeachtable 'DROP TABLE ?'
</code></pre>

<p>This will, of course, drop all constraints, triggers etc., everything but the stored procedures.</p>

<p>For the stored procedures I'm afraid you will need another stored procedure stored in <code>master</code>.</p>
"
525,233870,12,181,sql,How can I create a copy of an Oracle table without copying the data?,"<p>I know the statement:</p>

<pre><code>create table xyz_new as select * from xyz;
</code></pre>

<p>Which copies the structure and the data, but what if I just want the structure?</p>
","<p>Using sql developer select the table and click on the DDL tab</p>

<p>You can use that code to create a new table with no data when you run it in a sql worksheet</p>

<p>sqldeveloper is a free to use app from oracle.</p>

<p>If the table has sequences or triggers the ddl will sometimes generate those for you too. You just have to be careful what order you make them in and know when to turn the triggers on or off.</p>
"
526,233870,284,181,sql,How can I create a copy of an Oracle table without copying the data?,"<p>I know the statement:</p>

<pre><code>create table xyz_new as select * from xyz;
</code></pre>

<p>Which copies the structure and the data, but what if I just want the structure?</p>
","<p>Just use a where clause that won't select any rows:</p>

<pre><code>create table xyz_new as select * from xyz where 1=0;
</code></pre>
"
124,43870,11,181,sql,How to concatenate strings of a string field in a PostgreSQL 'group by' query?,"<p>I am looking for a way to concatenate the strings of a field within a group by query. So for example, I have a table:</p>

<pre><code>ID   COMPANY_ID   EMPLOYEE
1    1            Anna
2    1            Bill
3    2            Carol
4    2            Dave
</code></pre>

<p>and I wanted to group by company_id to get something like:</p>

<pre><code>COMPANY_ID   EMPLOYEE
1            Anna, Bill
2            Carol, Dave
</code></pre>

<p>There is a built-in function in mySQL to do this <a href=""http://dev.mysql.com/doc/refman/5.0/en/group-by-functions.html#function_group-concat"">group_concat</a></p>
","<p>I claim no credit for the answer because I found it after some searching:</p>

<p>What I didn't know is that PostgreSQL allows you to define your own aggregate functions with <a href=""http://www.postgresql.org/docs/8.3/interactive/sql-createaggregate.html"">CREATE AGGREGATE</a></p>

<p><a href=""http://archives.postgresql.org/pgsql-novice/2003-09/msg00177.php"">This post</a> on the PostgreSQL list shows how trivial it is to create a function to do what's required:</p>

<pre><code>CREATE AGGREGATE textcat_all(
  basetype    = text,
  sfunc       = textcat,
  stype       = text,
  initcond    = ''
);

SELECT company_id, textcat_all(employee || ', ')
FROM mytable
GROUP BY company_id;
</code></pre>
"
127,43870,4,181,sql,How to concatenate strings of a string field in a PostgreSQL 'group by' query?,"<p>I am looking for a way to concatenate the strings of a field within a group by query. So for example, I have a table:</p>

<pre><code>ID   COMPANY_ID   EMPLOYEE
1    1            Anna
2    1            Bill
3    2            Carol
4    2            Dave
</code></pre>

<p>and I wanted to group by company_id to get something like:</p>

<pre><code>COMPANY_ID   EMPLOYEE
1            Anna, Bill
2            Carol, Dave
</code></pre>

<p>There is a built-in function in mySQL to do this <a href=""http://dev.mysql.com/doc/refman/5.0/en/group-by-functions.html#function_group-concat"">group_concat</a></p>
","<p>This latest announcement list snippet might be of interest if you'll be upgrading to 8.4:</p>

<blockquote>
  <p>Until 8.4 comes out with a
  super-effient native one, you can add
  the array_accum() function in the
  PostgreSQL documentation for rolling
  up any column into an array, which can
  then be used by application code, or
  combined with array_to_string() to
  format it as a list:</p>
  
  <p><a href=""http://www.postgresql.org/docs/current/static/xaggr.html"" rel=""nofollow"">http://www.postgresql.org/docs/current/static/xaggr.html</a></p>
</blockquote>

<p>I'd link to the 8.4 development docs but they don't seem to list this feature yet.</p>
"
126,43870,6,181,sql,How to concatenate strings of a string field in a PostgreSQL 'group by' query?,"<p>I am looking for a way to concatenate the strings of a field within a group by query. So for example, I have a table:</p>

<pre><code>ID   COMPANY_ID   EMPLOYEE
1    1            Anna
2    1            Bill
3    2            Carol
4    2            Dave
</code></pre>

<p>and I wanted to group by company_id to get something like:</p>

<pre><code>COMPANY_ID   EMPLOYEE
1            Anna, Bill
2            Carol, Dave
</code></pre>

<p>There is a built-in function in mySQL to do this <a href=""http://dev.mysql.com/doc/refman/5.0/en/group-by-functions.html#function_group-concat"">group_concat</a></p>
","<p>As already mentioned, creating your own aggregate function is the right thing to do. Here is my concatenation aggregate function (you can find <a href=""http://www.bortzmeyer.org/agregats-postgresql.html"">details in French</a>): </p>

<pre><code>CREATE OR REPLACE FUNCTION concat2(text, text) RETURNS text AS '
    SELECT CASE WHEN $1 IS NULL OR $1 = \'\' THEN $2
            WHEN $2 IS NULL OR $2 = \'\' THEN $1
            ELSE $1 || \' / \' || $2
            END; 
'
 LANGUAGE SQL;

CREATE AGGREGATE concatenate (
  sfunc = concat2,
  basetype = text,
  stype = text,
  initcond = ''
</code></pre>

<p>);</p>

<p>And then use it as:</p>

<pre><code>SELECT company_id, concatenate(employee) AS employees FROM ...
</code></pre>
"
527,233870,66,181,sql,How can I create a copy of an Oracle table without copying the data?,"<p>I know the statement:</p>

<pre><code>create table xyz_new as select * from xyz;
</code></pre>

<p>Which copies the structure and the data, but what if I just want the structure?</p>
","<p>I used the method that you accepted a lot, but as someone pointed out it doesn't duplicate constraints (except for NOT NULL, I think).</p>

<p>A more advanced method if you want to duplicate the full structure is:</p>

<pre><code>SET LONG 5000
SELECT dbms_metadata.get_ddl( 'TABLE', 'MY_TABLE_NAME' ) FROM DUAL;
</code></pre>

<p>This will give you the full create statement text which you can modify as you wish for creating the new table.  You would have to change the names of the table and all constraints of course.</p>

<p>(You could also do this in older versions using EXP/IMP, but it's much easier now.)</p>

<p><strong>Edited to add</strong>
If the table you are after is in a different schema:</p>

<pre><code>SELECT dbms_metadata.get_ddl( 'TABLE', 'MY_TABLE_NAME', 'OTHER_SCHEMA_NAME' ) FROM DUAL;
</code></pre>
"
125,43870,272,181,sql,How to concatenate strings of a string field in a PostgreSQL 'group by' query?,"<p>I am looking for a way to concatenate the strings of a field within a group by query. So for example, I have a table:</p>

<pre><code>ID   COMPANY_ID   EMPLOYEE
1    1            Anna
2    1            Bill
3    2            Carol
4    2            Dave
</code></pre>

<p>and I wanted to group by company_id to get something like:</p>

<pre><code>COMPANY_ID   EMPLOYEE
1            Anna, Bill
2            Carol, Dave
</code></pre>

<p>There is a built-in function in mySQL to do this <a href=""http://dev.mysql.com/doc/refman/5.0/en/group-by-functions.html#function_group-concat"">group_concat</a></p>
","<h3>Update as of PostgreSQL 9.0:</h3>

<p>Recent versions of Postgres (since late 2010) have the <a href=""http://www.postgresql.org/docs/current/static/functions-aggregate.html#FUNCTIONS-AGGREGATE-TABLE""><code>string_agg(expression, delimiter)</code></a> function that will do exactly what the question asked for, even letting you specify the delimiter string:</p>

<pre><code>SELECT company_id, string_agg(employee, ', ')
FROM mytable
GROUP BY company_id;
</code></pre>

<h3>Update as of PostgreSQL 8.4:</h3>

<p>PostgreSQL 8.4 (in 2009) introduced <a href=""http://www.postgresql.org/docs/8.4/interactive/functions-aggregate.html"">the aggregate function <code>array_agg(expression)</code></a> which concatenates the values into an array. Then <code>array_to_string()</code> can be used to give the desired result:</p>

<pre><code>SELECT company_id, array_to_string(array_agg(employee), ', ')
FROM mytable
GROUP BY company_id;
</code></pre>

<h3>Original Answer (for pre-8.4 PostgreSQL):</h3>

<p>There is no built-in aggregate function to concatenate strings. It seems like this would be needed, but it's not part of the default set. A web search however reveals some manual implementations <a href=""http://archives.postgresql.org/pgsql-novice/2003-09/msg00177.php"">the same example</a>:</p>

<pre><code>CREATE AGGREGATE textcat_all(
  basetype    = text,
  sfunc       = textcat,
  stype       = text,
  initcond    = ''
);
</code></pre>

<p><a href=""http://www.postgresql.org/docs/8.3/static/sql-createaggregate.html"">Here is the <code>CREATE AGGREGATE</code> documentation.</a></p>

<p>In order to get the "", "" inserted in between them without having it at the end, you might want to make your own concatenation function and substitute it for the ""textcat"" above. Here is one I put together but haven't tested (<strong><em>update:</strong> tested on 8.3.12 and working fine</em>):</p>

<pre><code>CREATE FUNCTION commacat(acc text, instr text) RETURNS text AS $$
  BEGIN
    IF acc IS NULL OR acc = '' THEN
      RETURN instr;
    ELSE
      RETURN acc || ', ' || instr;
    END IF;
  END;
$$ LANGUAGE plpgsql;
</code></pre>

<p><strong><em>Note:</strong> The function above will output a comma even if the value in the row is null/empty, which outputs:</em></p>

<pre><code>a, b, c, , e, , g
</code></pre>

<p><em>If you would prefer to remove extra commas to output:</em></p>

<pre><code>a, b, c, e, g
</code></pre>

<p><em>just add an <code>ELSIF</code> check to the function:</em></p>

<pre><code>CREATE FUNCTION commacat_ignore_nulls(acc text, instr text) RETURNS text AS $$
  BEGIN
    IF acc IS NULL OR acc = '' THEN
      RETURN instr;
    ELSIF instr IS NULL OR instr = '' THEN
      RETURN acc;
    ELSE
      RETURN acc || ', ' || instr;
    END IF;
  END;
$$ LANGUAGE plpgsql;
</code></pre>
"
1222,543580,8,160,sql,Equals(=) vs. LIKE,"<p>When using SQL, are there any benefits of using <code>=</code> in a <code>WHERE</code> clause instead of <code>LIKE</code>?</p>

<p>Without any special operators, <code>LIKE</code> and <code>=</code> are the same, right?</p>
","<p>Depends on the database system.</p>

<p>Generally with no special characters, yes, = and LIKE are the same.</p>

<p>Some database systems, however, may treat collation settings differently with the different operators.</p>

<p>For instance, in MySQL comparisons with = on strings is always case-insensitive by default, so LIKE without special characters is the same. On some other RDBMS's LIKE is case-insensitive while = is not.</p>
"
1218,543580,4,160,sql,Equals(=) vs. LIKE,"<p>When using SQL, are there any benefits of using <code>=</code> in a <code>WHERE</code> clause instead of <code>LIKE</code>?</p>

<p>Without any special operators, <code>LIKE</code> and <code>=</code> are the same, right?</p>
","<p>Using = avoids wildcards and special characters conflicts in the string when you build the query at run time. </p>

<p>This makes the programmer's life easier by not having to escape all special wildcard characters that might slip in the LIKE clause and not producing the intended result. After all, = is the 99% use case scenario, it would be a pain to have to escape them every time.</p>

<p><em>rolls eyes at '90s</em></p>

<p>I also suspect it's a little bit slower, but I doubt it's significant if there are no wildcards in the pattern.</p>
"
1220,543580,8,160,sql,Equals(=) vs. LIKE,"<p>When using SQL, are there any benefits of using <code>=</code> in a <code>WHERE</code> clause instead of <code>LIKE</code>?</p>

<p>Without any special operators, <code>LIKE</code> and <code>=</code> are the same, right?</p>
","<p>One difference - apart from the possibility to use wildcards with LIKE - is in trailing spaces: The = operator ignores trailing space, but LIKE does not.</p>
"
1226,543580,154,160,sql,Equals(=) vs. LIKE,"<p>When using SQL, are there any benefits of using <code>=</code> in a <code>WHERE</code> clause instead of <code>LIKE</code>?</p>

<p>Without any special operators, <code>LIKE</code> and <code>=</code> are the same, right?</p>
","<p>The equals (=) operator is a ""comparison operator compares two values for equality.""  In other words, in an SQL statement, it won't return true unless both sides of the equation are equal.  For example:</p>

<pre><code>SELECT * FROM Store WHERE Quantity = 200;
</code></pre>

<p>The LIKE operator ""implements a pattern match comparison"" that attempts to match ""a string value against a pattern string containing wild-card characters.""  For example:</p>

<pre><code>SELECT * FROM Employees WHERE Name LIKE 'Chris%';
</code></pre>

<p>LIKE is generally used only with strings and equals (I believe) is faster.  The equals operator treats wild-card characters as literal characters.  The difference in results returned are as follows:</p>

<pre><code>SELECT * FROM Employees WHERE Name = 'Chris';
</code></pre>

<p>And</p>

<pre><code>SELECT * FROM Employees WHERE Name LIKE 'Chris';
</code></pre>

<p>Would return the same result, though using LIKE would generally take longer as its a pattern match.  However,</p>

<pre><code>SELECT * FROM Employees WHERE Name = 'Chris%';
</code></pre>

<p>And</p>

<pre><code>SELECT * FROM Employees WHERE Name LIKE 'Chris%';
</code></pre>

<p>Would return different results, where using ""="" results in only results with ""Chris%"" being returned and the LIKE operator will return anything starting with ""Chris"".</p>

<p>Hope that helps.  Some good info can be found <a href=""http://www.firstsql.com/tutor2.htm"">here</a>.</p>
"
1224,543580,4,160,sql,Equals(=) vs. LIKE,"<p>When using SQL, are there any benefits of using <code>=</code> in a <code>WHERE</code> clause instead of <code>LIKE</code>?</p>

<p>Without any special operators, <code>LIKE</code> and <code>=</code> are the same, right?</p>
","<p>If you search for an exact match, you can use both,  = and LIKE.</p>

<p>Using ""="" is a tiny bit faster in this case (searching for an exact match) - you can check this yourself by having the same query twice in SQL Server Management Studio, once using ""="", once using ""LIKE"", and then using the ""Query"" / ""Include actual execution plan"".</p>

<p>Execute the two queries and you should see your results twice, plus the two actual execution plans. In my case, they were split 50% vs. 50%, but the ""="" execution plan has a smaller ""estimated subtree cost"" (displayed when you hover over the left-most ""SELECT"" box) - but again, it's really not a huge difference.</p>

<p>But when you start searching with wildcards in your LIKE expression, search performance will dimish. Search ""LIKE Mill%"" can still be quite fast - SQL Server can use an index on that column, if there is one. Searching ""LIKE %expression%"" is horribly slow, since the only way SQL Server can satisfy this search is by doing a full table scan. So be careful with your LIKE's ! </p>

<p>Marc</p>
"
1223,543580,10,160,sql,Equals(=) vs. LIKE,"<p>When using SQL, are there any benefits of using <code>=</code> in a <code>WHERE</code> clause instead of <code>LIKE</code>?</p>

<p>Without any special operators, <code>LIKE</code> and <code>=</code> are the same, right?</p>
","<p><code>LIKE</code> and <code>=</code> are different. <code>LIKE</code> is what you would use in a search query. It also allows wildcards like <code>_</code> (simple character wildcard) and <code>%</code> (multi-character wildcard).</p>

<p><code>=</code> should be used if you want exact matches and it will be faster.</p>

<p><a href=""http://www.techonthenet.com/sql/like.php"" rel=""nofollow"">This site explains <code>LIKE</code></a></p>
"
1225,543580,2,160,sql,Equals(=) vs. LIKE,"<p>When using SQL, are there any benefits of using <code>=</code> in a <code>WHERE</code> clause instead of <code>LIKE</code>?</p>

<p>Without any special operators, <code>LIKE</code> and <code>=</code> are the same, right?</p>
","<p>The LIKE keyword undoubtedly comes with a ""performance price-tag"" attached.  That said, if you have an input field that could potentially include wild card characters to be used in your query, I would recommend using LIKE <strong>only if</strong> the input contains one of the wild cards.  Otherwise, use the standard equal to comparison.</p>

<p>Best regards...</p>
"
1221,543580,1,160,sql,Equals(=) vs. LIKE,"<p>When using SQL, are there any benefits of using <code>=</code> in a <code>WHERE</code> clause instead of <code>LIKE</code>?</p>

<p>Without any special operators, <code>LIKE</code> and <code>=</code> are the same, right?</p>
","<p>Really it comes down to what you want the query to do.  If you mean an exact match then use =.  If you mean a fuzzier match, then use LIKE.  Saying what you mean is usually a good policy with code.</p>
"
1219,543580,-1,160,sql,Equals(=) vs. LIKE,"<p>When using SQL, are there any benefits of using <code>=</code> in a <code>WHERE</code> clause instead of <code>LIKE</code>?</p>

<p>Without any special operators, <code>LIKE</code> and <code>=</code> are the same, right?</p>
","<p><code>=</code> and <code>LIKE</code> is not the same; </p>

<ol>
<li><code>=</code> matches the exact string </li>
<li><code>LIKE</code> matches a string that may contain wildcards (%)</li>
</ol>
"
405,185520,94,125,sql,Convert Month Number to Month Name Function in SQL,"<p>I have months stored in SQL Server as 1,2,3,4,...12. I would like to display them as January,February etc. Is there a function in SQL Server like MonthName(1) = January? I am trying to avoid a CASE statement, if possible.</p>
","<p>A little hacky but should work:</p>

<pre><code>SELECT DATENAME(month, DATEADD(month, @mydate-1, CAST('2008-01-01' AS datetime)))
</code></pre>
"
406,185520,2,125,sql,Convert Month Number to Month Name Function in SQL,"<p>I have months stored in SQL Server as 1,2,3,4,...12. I would like to display them as January,February etc. Is there a function in SQL Server like MonthName(1) = January? I am trying to avoid a CASE statement, if possible.</p>
","<p>In some locales like Hebrew, there are <a href=""http://en.wikipedia.org/wiki/Hebrew_calendar#Leap_months"" rel=""nofollow"">leap months</a> dependant upon the year so to avoid errors in such locales you might consider the following solution:</p>

<pre><code>SELECT DATENAME(month, STR(YEAR(GETDATE()), 4) + REPLACE(STR(@month, 2), ' ', '0') + '01')
</code></pre>
"
407,185520,169,125,sql,Convert Month Number to Month Name Function in SQL,"<p>I have months stored in SQL Server as 1,2,3,4,...12. I would like to display them as January,February etc. Is there a function in SQL Server like MonthName(1) = January? I am trying to avoid a CASE statement, if possible.</p>
","<p>I think this is the best way to get the <strong>month name</strong> when you have the <strong>month number</strong></p>

<pre><code>Select DateName( month , DateAdd( month , @MonthNumber , 0 ) - 1 )
</code></pre>

<p><strong>[EDIT]</strong></p>

<p>As Asif said below, another way of doing this would be </p>

<pre><code>Select DateName( month , DateAdd( month , @MonthNumber , -1 ) )
</code></pre>
"
139,51470,106,115,sql,How do I reset a sequence in Oracle?,"<p>In <a href=""http://en.wikipedia.org/wiki/PostgreSQL"">PostgreSQL</a>, I can do something like this:</p>

<pre><code>ALTER SEQUENCE serial RESTART WITH 0;
</code></pre>

<p>Is there an Oracle equivalent?</p>
","<p>Here is a good procedure for resetting any sequence to 0 from Oracle guru <a href=""http://asktom.oracle.com"">Tom Kyte</a>.  Great discussion on the pros and cons in the links below too.</p>

<pre><code>tkyte@TKYTE901.US.ORACLE.COM&gt; 
create or replace
procedure reset_seq( p_seq_name in varchar2 )
is
    l_val number;
begin
    execute immediate
    'select ' || p_seq_name || '.nextval from dual' INTO l_val;

    execute immediate
    'alter sequence ' || p_seq_name || ' increment by -' || l_val || 
                                                          ' minvalue 0';

    execute immediate
    'select ' || p_seq_name || '.nextval from dual' INTO l_val;

    execute immediate
    'alter sequence ' || p_seq_name || ' increment by 1 minvalue 0';
end;
/
</code></pre>

<p>From this page: <a href=""http://asktom.oracle.com/pls/asktom/f?p=100:11:0::::P11_QUESTION_ID:951269671592"">Dynamic SQL to reset sequence value</a><br />
Another good discussion is also here: <a href=""http://asktom.oracle.com/pls/asktom/f?p=100:11:0::::P11_QUESTION_ID:1119633817597"">How to reset sequences?</a></p>
"
138,51470,1,115,sql,How do I reset a sequence in Oracle?,"<p>In <a href=""http://en.wikipedia.org/wiki/PostgreSQL"">PostgreSQL</a>, I can do something like this:</p>

<pre><code>ALTER SEQUENCE serial RESTART WITH 0;
</code></pre>

<p>Is there an Oracle equivalent?</p>
","<p>Altering the sequence's INCREMENT value, incrementing it, and then altering it back is pretty painless, plus you have the added benefit of not having to re-establish all of the grants as you would had you dropped/recreated the sequence.</p>
"
137,51470,55,115,sql,How do I reset a sequence in Oracle?,"<p>In <a href=""http://en.wikipedia.org/wiki/PostgreSQL"">PostgreSQL</a>, I can do something like this:</p>

<pre><code>ALTER SEQUENCE serial RESTART WITH 0;
</code></pre>

<p>Is there an Oracle equivalent?</p>
","<p>A true restart is not possible <a href=""http://en.wiktionary.org/wiki/AFAIK"">AFAIK</a>. (Please correct me if I'm wrong!).</p>

<p>However, if you want to set it to 0, you can just delete and recreate it.</p>

<p>If you want to set it to a specific value, you can set the INCREMENT to a negative value and get the next value.</p>

<p>That is, if your sequence is at 500, you can set it to 100 via</p>

<pre><code>ALTER SEQUENCE serial INCREMENT BY -400;
SELECT serial.NEXTVAL FROM foo;
ALTER SEQUENCE serial INCREMENT BY 1;
</code></pre>
"
307,139630,10,105,sql,What's the difference between TRUNCATE and DELETE in SQL,"<p>I wrote up an answer to this question by mistake in response to a question about the difference between DROP and TRUNCATE, but I thought that it's a shame not to share so I'll post my own answer to my own question ... is that even ethical? :)</p>

<p>Edit: If your answer is platform specific can you please indicate that.</p>
","<p>""Truncate doesn't log anything"" is correct.  I'd go further:</p>

<p>Truncate is not executed in the context of a transaction.  </p>

<p>The speed advantage of truncate over delete should be obvious.  That advantage ranges from trivial to enormous, depending on your situation.</p>

<p>However, I've seen truncate unintentionally break referential integrity,  and violate other constraints.  The power that you gain by modifying data outside a transaction has to be balanced against the responsibility that you inherit when you walk the tightrope without a net.</p>
"
310,139630,1,105,sql,What's the difference between TRUNCATE and DELETE in SQL,"<p>I wrote up an answer to this question by mistake in response to a question about the difference between DROP and TRUNCATE, but I thought that it's a shame not to share so I'll post my own answer to my own question ... is that even ethical? :)</p>

<p>Edit: If your answer is platform specific can you please indicate that.</p>
","<p>Can't do DDL over a dblink.</p>
"
309,139630,18,105,sql,What's the difference between TRUNCATE and DELETE in SQL,"<p>I wrote up an answer to this question by mistake in response to a question about the difference between DROP and TRUNCATE, but I thought that it's a shame not to share so I'll post my own answer to my own question ... is that even ethical? :)</p>

<p>Edit: If your answer is platform specific can you please indicate that.</p>
","<p>All good answers, to which I must add:</p>

<p>Since <code>TRUNCATE TABLE</code> is a DDL (<a href=""https://en.wikipedia.org/wiki/Data_definition_language"" rel=""nofollow"">Data Defination Language</a>), not a DML (<a href=""https://en.wikipedia.org/wiki/Data_manipulation_language"" rel=""nofollow"">Data Manipulation Langauge</a>) command, the <code>Delete Triggers</code> do not run.</p>
"
308,139630,0,105,sql,What's the difference between TRUNCATE and DELETE in SQL,"<p>I wrote up an answer to this question by mistake in response to a question about the difference between DROP and TRUNCATE, but I thought that it's a shame not to share so I'll post my own answer to my own question ... is that even ethical? :)</p>

<p>Edit: If your answer is platform specific can you please indicate that.</p>
","<p>A big reason it is handy, is when you need to refresh the data in a multi-million row table, but don't want to rebuild it.  ""Delete *"" would take forever, whereas the perfomance impact of Truncate would be negligible.</p>
"
304,139630,9,105,sql,What's the difference between TRUNCATE and DELETE in SQL,"<p>I wrote up an answer to this question by mistake in response to a question about the difference between DROP and TRUNCATE, but I thought that it's a shame not to share so I'll post my own answer to my own question ... is that even ethical? :)</p>

<p>Edit: If your answer is platform specific can you please indicate that.</p>
","<p>With SQL Server or MySQL, if there is a PK with auto increment, truncate will reset the counter.</p>
"
306,139630,0,105,sql,What's the difference between TRUNCATE and DELETE in SQL,"<p>I wrote up an answer to this question by mistake in response to a question about the difference between DROP and TRUNCATE, but I thought that it's a shame not to share so I'll post my own answer to my own question ... is that even ethical? :)</p>

<p>Edit: If your answer is platform specific can you please indicate that.</p>
","<p>The biggest difference is that truncate is non logged operation while delete is.</p>

<p>Simply it means that in case of a database crash , you cannot recover the data operated upon by truncate but with delete you can. </p>

<p>More details <a href=""http://doc.ddart.net/mssql/sql70/8_des_02_8.htm"" rel=""nofollow"">here</a></p>
"
305,139630,0,105,sql,What's the difference between TRUNCATE and DELETE in SQL,"<p>I wrote up an answer to this question by mistake in response to a question about the difference between DROP and TRUNCATE, but I thought that it's a shame not to share so I'll post my own answer to my own question ... is that even ethical? :)</p>

<p>Edit: If your answer is platform specific can you please indicate that.</p>
","<p>In short, truncate doesn't log anything (so is much faster but can't be undone) whereas delete is logged (and can be part of a larger transaction, will rollback etc). If you have data that you don't want in a table in dev it is normally better to truncate as you don't run the risk of filling up the transaction log</p>
"
312,139630,-4,105,sql,What's the difference between TRUNCATE and DELETE in SQL,"<p>I wrote up an answer to this question by mistake in response to a question about the difference between DROP and TRUNCATE, but I thought that it's a shame not to share so I'll post my own answer to my own question ... is that even ethical? :)</p>

<p>Edit: If your answer is platform specific can you please indicate that.</p>
","<p>TRUNCATE is fast, DELETE is slow.</p>

<p>Although, TRUNCATE has no accountability.</p>
"
311,139630,0,105,sql,What's the difference between TRUNCATE and DELETE in SQL,"<p>I wrote up an answer to this question by mistake in response to a question about the difference between DROP and TRUNCATE, but I thought that it's a shame not to share so I'll post my own answer to my own question ... is that even ethical? :)</p>

<p>Edit: If your answer is platform specific can you please indicate that.</p>
","<p>I'd comment on matthieu's post, but I don't have the rep yet...</p>

<p>In MySQL, the auto increment counter gets reset with truncate, but not with delete.</p>
"
313,139630,5,105,sql,What's the difference between TRUNCATE and DELETE in SQL,"<p>I wrote up an answer to this question by mistake in response to a question about the difference between DROP and TRUNCATE, but I thought that it's a shame not to share so I'll post my own answer to my own question ... is that even ethical? :)</p>

<p>Edit: If your answer is platform specific can you please indicate that.</p>
","<p>Yes, DELETE is slower, TRUNCATE is faster. Why? </p>

<p>DELETE must read the records, check constraints, update the block, update indexes, and generate redo/undo. All of that takes time.</p>

<p>TRUNCATE simply adjusts a pointer in the database for the table (the High Water Mark) and poof! the data is gone. </p>

<p>This is Oracle specific, AFAIK.</p>
"
303,139630,130,105,sql,What's the difference between TRUNCATE and DELETE in SQL,"<p>I wrote up an answer to this question by mistake in response to a question about the difference between DROP and TRUNCATE, but I thought that it's a shame not to share so I'll post my own answer to my own question ... is that even ethical? :)</p>

<p>Edit: If your answer is platform specific can you please indicate that.</p>
","<p>Here's a list of differences. I've highlighted Oracle-specific features, and hopefully the community can add in other vendors' specific difference also. Differences that are common to most vendors can go directly below the headings, with differences highlighted below.</p>

<p><hr></p>

<h1>General Overview</h1>

<p>If you want to quickly delete all of the rows from a table, and you're really sure that you want to do it, and you do not have foreign keys against the tables, then a TRUNCATE is probably going to be faster than a DELETE.</p>

<p>Various system-specific issues have to be considered, as detailed below.</p>

<p><hr></p>

<h1>Statement type</h1>

<p>Delete is DML, Truncate is DDL</p>

<p><hr></p>

<h1>Commit and Rollback</h1>

<p>Variable by vendor</p>

<p><strong>SQL*Server</strong></p>

<p>Truncate can be rolled back.</p>

<p><strong>PostgreSQL</strong></p>

<p>Truncate can be rolled back.</p>

<p><strong>Oracle</strong></p>

<p>Because a TRUNCATE is DDL it involves two commits, one before and one after the statement execution. Truncate can therefore not be rolled back, and a failure in the truncate process will have issued a commit anyway.</p>

<p>However, see Flashback below.</p>

<p><hr></p>

<h1>Space reclamation</h1>

<p>Delete does not recover space, Truncate recovers space</p>

<p><strong>Oracle</strong></p>

<p>If you use the REUSE STORAGE clause then the data segments are not de-allocated, which can be marginally more efficient if the table is to be reloaded with data. The high water mark is reset.</p>

<p><hr></p>

<h1>Row scope</h1>

<p>Delete can remove only some rows. Truncate removes all rows.</p>

<p><strong>Oracle</strong></p>

<p>When a table is partitioned, the individual partitions can be truncated in isolation, thus a partial removal of all the table's data is possible.</p>

<p><hr></p>

<h1>Object types</h1>

<p>Delete can be applied to tables and tables inside a cluster. Truncate applies only to tables or the entire cluster. (May be Oracle specific)</p>

<p><hr></p>

<h1>Data Object Identity</h1>

<p><strong>Oracle</strong></p>

<p>Delete does not affect the data object id, but truncate assigns a new data object id <em>unless</em> there has never been an insert against the table since its creation Even a single insert that is rolled back will cause a new data object id to be assigned upon truncation.</p>

<p><hr></p>

<h1>Flashback (Oracle)</h1>

<p>Flashback works across deletes, but a truncate prevents flashback to states prior to the operation.</p>

<p>However, from 11gR2 the FLASHBACK ARCHIVE feature allows this, except in Express Edition</p>

<p><a href=""http://stackoverflow.com/questions/25950145/use-of-flashback-in-oracle"">Use of FLASHBACK in Oracle</a>
<a href=""http://docs.oracle.com/cd/E11882_01/appdev.112/e41502/adfns_flashback.htm#ADFNS638"">http://docs.oracle.com/cd/E11882_01/appdev.112/e41502/adfns_flashback.htm#ADFNS638</a></p>

<p><hr></p>

<h1>Privileges</h1>

<p>Variable</p>

<p><strong>Oracle</strong></p>

<p>Delete can be granted on a table to another user or role, but truncate cannot be without using a DROP ANY TABLE grant.</p>

<p><hr></p>

<h1>Redo/Undo</h1>

<p>Delete generates a small amount of redo and a large amount of undo. Truncate generates a negligible amount of each.</p>

<p><hr></p>

<h1>Indexes</h1>

<p><strong>Oracle</strong></p>

<p>A truncate operation renders unusable indexes usable again. Delete does not.</p>

<p><hr></p>

<h1>Foreign Keys</h1>

<p>A truncate cannot be applied when an enabled foreign key references the table. Treatment with delete depends on the configuration of the foreign keys.</p>

<p><hr></p>

<h1>Table Locking</h1>

<p><strong>Oracle</strong></p>

<p>Truncate requires an exclusive table lock, delete requires a shared table lock. Hence disabling table locks is a way of preventing truncate operations on a table.</p>

<p><hr></p>

<h1>Triggers</h1>

<p>DML triggers do not fire on a truncate.</p>

<p><strong>Oracle</strong></p>

<p>DDL triggers are available.</p>

<p><hr></p>

<h1>Remote Execution</h1>

<p><strong>Oracle</strong></p>

<p>Truncate cannot be issued over a database link.</p>

<p><hr></p>

<h1>Identity Columns</h1>

<p><strong>SQL*Server</strong></p>

<p>Truncate resets the sequence for IDENTITY column types, delete does not.</p>
"
314,139630,2,105,sql,What's the difference between TRUNCATE and DELETE in SQL,"<p>I wrote up an answer to this question by mistake in response to a question about the difference between DROP and TRUNCATE, but I thought that it's a shame not to share so I'll post my own answer to my own question ... is that even ethical? :)</p>

<p>Edit: If your answer is platform specific can you please indicate that.</p>
","<p>A small correction to the original answer - delete also generates significant amounts of redo (as undo is itself protected by redo).  This can be seen from autotrace output:</p>

<pre><code>SQL&gt; delete from t1;

10918 rows deleted.

Elapsed: 00:00:00.58

Execution Plan
----------------------------------------------------------
   0      DELETE STATEMENT Optimizer=FIRST_ROWS (Cost=43 Card=1)
   1    0   DELETE OF 'T1'
   2    1     TABLE ACCESS (FULL) OF 'T1' (TABLE) (Cost=43 Card=1)




Statistics
----------------------------------------------------------
         30  recursive calls
      12118  db block gets
        213  consistent gets
        142  physical reads
    3975328  redo size
        441  bytes sent via SQL*Net to client
        537  bytes received via SQL*Net from client
          4  SQL*Net roundtrips to/from client
          2  sorts (memory)
          0  sorts (disk)
      10918  rows processed
</code></pre>
"
332,149380,4,104,sql,Dynamic Sorting within SQL Stored Procedures,"<p>This is an issue that I've spent hours researching in the past.  It seems to me to be something that should have been addressed by modern <a href=""http://en.wikipedia.org/wiki/Relational%5Fdatabase%5Fmanagement%5Fsystem"">RDBMS</a> solutions but as yet I have not found anything that really addresses what I see to be an incredibly common need in any Web or Windows application with a database back-end.</p>

<p>I speak of dynamic sorting.  In my fantasy world, it should be as simple as something like:</p>

<pre><code>ORDER BY @sortCol1, @sortCol2
</code></pre>

<p>This is the canonical example given by newbie SQL and <a href=""http://en.wikipedia.org/wiki/Stored%5Fprocedure"">Stored Procedure</a> developers all over forums across the Internet.  ""Why isn't this possible?"" they ask.  Invariably, somebody eventually comes along to lecture them about the compiled nature of stored procedures, of execution plans in general, and all sorts of other reasons why it isn't possible to put a parameter directly into an <code>ORDER BY</code> clause.</p>

<hr>

<p>I know what some of you are already thinking:  ""Let the client do the sorting, then.""  Naturally, this offloads the work from your database.  In our case though, our database servers aren't even breaking a sweat 99% of the time and they aren't even multi-core yet or any of the other myriad improvements to system architecture that happen every 6 months.  For this reason alone, having our databases handle sorting wouldn't be a problem.  Additionally, databases are <em>very</em> good at sorting.  They are optimized for it and have had years to get it right, the language for doing it is incredibly flexible, intuitive, and simple and above all any beginner SQL writer knows how to do it and even more importantly they know how to edit it, make changes, do maintenance, etc.  When your databases are far from being taxed and you just want to simplify (and shorten!) development time this seems like an obvious choice.</p>

<p>Then there's the web issue.  I've played around with JavaScript that will do client-side sorting of HTML tables, but they inevitably aren't flexible enough for my needs and, again, since my databases aren't overly taxed and can do sorting really <em>really</em> easily, I have a hard time justifying the time it would take to re-write or roll-my-own JavaScript sorter.  The same generally goes for server-side sorting, though it is already probably much preferred over JavaScript.  I'm not one that particularly likes the overhead of DataSets, so sue me.</p>

<p>But this brings back the point that it isn't possible &mdash; or rather, not easily.  I've done, with prior systems, an incredibly hack way of getting dynamic sorting.  It wasn't pretty, nor intuitive, simple, or flexible and a beginner SQL writer would be lost within seconds.  Already this is looking to be not so much a ""solution"" but a ""complication.""</p>

<hr>

<p>The following examples are not meant to expose any sort of best practices or good coding style or anything, nor are they indicative of my abilities as a T-SQL programmer.  They are what they are and I fully admit they are confusing, bad form, and just plain hack.</p>

<p>We pass an integer value as a parameter to a stored procedure (let's call the parameter just ""sort"") and from that we determine a bunch of other variables.  For example... let's say sort is 1 (or the default):</p>

<pre><code>DECLARE @sortCol1 AS varchar(20)
DECLARE @sortCol2 AS varchar(20)
DECLARE @dir1 AS varchar(20)
DECLARE @dir2 AS varchar(20)
DECLARE @col1 AS varchar(20)
DECLARE @col2 AS varchar(20)

SET @col1 = 'storagedatetime';
SET @col2 = 'vehicleid';

IF @sort = 1                -- Default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'asc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'asc';
END
ELSE IF @sort = 2           -- Reversed order default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'desc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'desc';
END
</code></pre>

<p>You can already see how if I declared more @colX variables to define other columns I could really get creative with the columns to sort on based on the value of ""sort""... to use it, it usually ends up looking like the following incredibly messy clause:</p>

<pre><code>ORDER BY
    CASE @dir1
        WHEN 'desc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir1
        WHEN 'asc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END,
    CASE @dir2
        WHEN 'desc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir2
        WHEN 'asc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END
</code></pre>

<p>Obviously this is a very stripped down example.  The real stuff, since we usually have four or five columns to support sorting on, each with possible secondary or even a third column to sort on in addition to that (for example date descending then sorted secondarily by name ascending) and each supporting bi-directional sorting which effectively doubles the number of cases.  Yeah... it gets hairy really quick.</p>

<p>The idea is that one could ""easily"" change the sort cases such that vehicleid gets sorted before the storagedatetime... but the pseudo-flexibility, at least in this simple example, really ends there.  Essentially, each case that fails a test (because our sort method doesn't apply to it this time around) renders a NULL value.  And thus you end up with a clause that functions like the following:</p>

<pre><code>ORDER BY NULL DESC, NULL, [storagedatetime] DESC, blah blah
</code></pre>

<p>You get the idea.  It works because SQL Server effectively ignores null values in order by clauses.  This is incredibly hard to maintain, as anyone with any basic working knowledge of SQL can probably see.  If I've lost any of you, don't feel bad.  It took us a long time to get it working and we still get confused trying to edit it or create new ones like it.  Thankfully it doesn't need changing often, otherwise it would quickly become ""not worth the trouble.""</p>

<p>Yet it <em>did</em> work.</p>

<hr>

<p>My question is then:  <strong>is there a better way?</strong></p>

<p>I'm okay with solutions other than Stored Procedure ones, as I realize it may just not be the way to go.  Preferably, I'd like to know if anyone can do it better within the Stored Procedure, but if not, how do you all handle letting the user dynamically sort tables of data (bi-directionally, too) with ASP.NET?</p>

<p>And thank you for reading (or at least skimming) such a long question!</p>

<p>PS: Be glad I didn't show my example of a stored procedure that supports dynamic sorting, dynamic filtering/text-searching of columns, pagination via ROWNUMBER() OVER, <em>AND</em> try...catch with transaction rollbacking on errors... ""behemoth-sized"" doesn't even begin to describe them.</p>

<hr>

<p><strong>Update:</strong></p>

<ul>
<li>I would like to <strong>avoid dynamic SQL</strong>.  Parsing a string together and running an EXEC on it defeats a lot of the purpose of having a stored procedure in the first place.  Sometimes I wonder though if the cons of doing such a thing wouldn't be worth it, at least in these special dynamic sorting cases.  Still, I always feel dirty whenever I do dynamic SQL strings like that &mdash; like I'm still living in the Classic ASP world.</li>
<li>A lot of the reason we want stored procedures in the first place is for <strong>security</strong>.  I don't get to make the call on security concerns, only suggest solutions.  With SQL Server 2005 we can set permissions (on a per-user basis if need be) at the schema level on individual stored procedures and then deny any queries against the tables directly.  Critiquing the pros and cons of this approach is perhaps for another question, but again it's not my decision.  I'm just the lead code monkey. :)</li>
</ul>
","<p>There's a couple of different ways you can hack this in. </p>

<p>Prerequisites:</p>

<ol>
<li>Only one SELECT statement in the
sp </li>
<li>Leave out any sorting (or have
a default)</li>
</ol>

<p>Then insert into a temp table:</p>

<pre><code>create table #temp ( your columns )

insert #temp
exec foobar

select * from #temp order by whatever
</code></pre>

<p>Method #2: set up a linked server back to itself, then select from this using openquery:
<a href=""http://www.sommarskog.se/share_data.html#OPENQUERY"" rel=""nofollow"">http://www.sommarskog.se/share_data.html#OPENQUERY</a></p>
"
330,149380,2,104,sql,Dynamic Sorting within SQL Stored Procedures,"<p>This is an issue that I've spent hours researching in the past.  It seems to me to be something that should have been addressed by modern <a href=""http://en.wikipedia.org/wiki/Relational%5Fdatabase%5Fmanagement%5Fsystem"">RDBMS</a> solutions but as yet I have not found anything that really addresses what I see to be an incredibly common need in any Web or Windows application with a database back-end.</p>

<p>I speak of dynamic sorting.  In my fantasy world, it should be as simple as something like:</p>

<pre><code>ORDER BY @sortCol1, @sortCol2
</code></pre>

<p>This is the canonical example given by newbie SQL and <a href=""http://en.wikipedia.org/wiki/Stored%5Fprocedure"">Stored Procedure</a> developers all over forums across the Internet.  ""Why isn't this possible?"" they ask.  Invariably, somebody eventually comes along to lecture them about the compiled nature of stored procedures, of execution plans in general, and all sorts of other reasons why it isn't possible to put a parameter directly into an <code>ORDER BY</code> clause.</p>

<hr>

<p>I know what some of you are already thinking:  ""Let the client do the sorting, then.""  Naturally, this offloads the work from your database.  In our case though, our database servers aren't even breaking a sweat 99% of the time and they aren't even multi-core yet or any of the other myriad improvements to system architecture that happen every 6 months.  For this reason alone, having our databases handle sorting wouldn't be a problem.  Additionally, databases are <em>very</em> good at sorting.  They are optimized for it and have had years to get it right, the language for doing it is incredibly flexible, intuitive, and simple and above all any beginner SQL writer knows how to do it and even more importantly they know how to edit it, make changes, do maintenance, etc.  When your databases are far from being taxed and you just want to simplify (and shorten!) development time this seems like an obvious choice.</p>

<p>Then there's the web issue.  I've played around with JavaScript that will do client-side sorting of HTML tables, but they inevitably aren't flexible enough for my needs and, again, since my databases aren't overly taxed and can do sorting really <em>really</em> easily, I have a hard time justifying the time it would take to re-write or roll-my-own JavaScript sorter.  The same generally goes for server-side sorting, though it is already probably much preferred over JavaScript.  I'm not one that particularly likes the overhead of DataSets, so sue me.</p>

<p>But this brings back the point that it isn't possible &mdash; or rather, not easily.  I've done, with prior systems, an incredibly hack way of getting dynamic sorting.  It wasn't pretty, nor intuitive, simple, or flexible and a beginner SQL writer would be lost within seconds.  Already this is looking to be not so much a ""solution"" but a ""complication.""</p>

<hr>

<p>The following examples are not meant to expose any sort of best practices or good coding style or anything, nor are they indicative of my abilities as a T-SQL programmer.  They are what they are and I fully admit they are confusing, bad form, and just plain hack.</p>

<p>We pass an integer value as a parameter to a stored procedure (let's call the parameter just ""sort"") and from that we determine a bunch of other variables.  For example... let's say sort is 1 (or the default):</p>

<pre><code>DECLARE @sortCol1 AS varchar(20)
DECLARE @sortCol2 AS varchar(20)
DECLARE @dir1 AS varchar(20)
DECLARE @dir2 AS varchar(20)
DECLARE @col1 AS varchar(20)
DECLARE @col2 AS varchar(20)

SET @col1 = 'storagedatetime';
SET @col2 = 'vehicleid';

IF @sort = 1                -- Default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'asc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'asc';
END
ELSE IF @sort = 2           -- Reversed order default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'desc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'desc';
END
</code></pre>

<p>You can already see how if I declared more @colX variables to define other columns I could really get creative with the columns to sort on based on the value of ""sort""... to use it, it usually ends up looking like the following incredibly messy clause:</p>

<pre><code>ORDER BY
    CASE @dir1
        WHEN 'desc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir1
        WHEN 'asc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END,
    CASE @dir2
        WHEN 'desc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir2
        WHEN 'asc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END
</code></pre>

<p>Obviously this is a very stripped down example.  The real stuff, since we usually have four or five columns to support sorting on, each with possible secondary or even a third column to sort on in addition to that (for example date descending then sorted secondarily by name ascending) and each supporting bi-directional sorting which effectively doubles the number of cases.  Yeah... it gets hairy really quick.</p>

<p>The idea is that one could ""easily"" change the sort cases such that vehicleid gets sorted before the storagedatetime... but the pseudo-flexibility, at least in this simple example, really ends there.  Essentially, each case that fails a test (because our sort method doesn't apply to it this time around) renders a NULL value.  And thus you end up with a clause that functions like the following:</p>

<pre><code>ORDER BY NULL DESC, NULL, [storagedatetime] DESC, blah blah
</code></pre>

<p>You get the idea.  It works because SQL Server effectively ignores null values in order by clauses.  This is incredibly hard to maintain, as anyone with any basic working knowledge of SQL can probably see.  If I've lost any of you, don't feel bad.  It took us a long time to get it working and we still get confused trying to edit it or create new ones like it.  Thankfully it doesn't need changing often, otherwise it would quickly become ""not worth the trouble.""</p>

<p>Yet it <em>did</em> work.</p>

<hr>

<p>My question is then:  <strong>is there a better way?</strong></p>

<p>I'm okay with solutions other than Stored Procedure ones, as I realize it may just not be the way to go.  Preferably, I'd like to know if anyone can do it better within the Stored Procedure, but if not, how do you all handle letting the user dynamically sort tables of data (bi-directionally, too) with ASP.NET?</p>

<p>And thank you for reading (or at least skimming) such a long question!</p>

<p>PS: Be glad I didn't show my example of a stored procedure that supports dynamic sorting, dynamic filtering/text-searching of columns, pagination via ROWNUMBER() OVER, <em>AND</em> try...catch with transaction rollbacking on errors... ""behemoth-sized"" doesn't even begin to describe them.</p>

<hr>

<p><strong>Update:</strong></p>

<ul>
<li>I would like to <strong>avoid dynamic SQL</strong>.  Parsing a string together and running an EXEC on it defeats a lot of the purpose of having a stored procedure in the first place.  Sometimes I wonder though if the cons of doing such a thing wouldn't be worth it, at least in these special dynamic sorting cases.  Still, I always feel dirty whenever I do dynamic SQL strings like that &mdash; like I'm still living in the Classic ASP world.</li>
<li>A lot of the reason we want stored procedures in the first place is for <strong>security</strong>.  I don't get to make the call on security concerns, only suggest solutions.  With SQL Server 2005 we can set permissions (on a per-user basis if need be) at the schema level on individual stored procedures and then deny any queries against the tables directly.  Critiquing the pros and cons of this approach is perhaps for another question, but again it's not my decision.  I'm just the lead code monkey. :)</li>
</ul>
","<p>I agree, use client side.  But it appears that is not the answer you want to hear.</p>

<p>So, it is perfect the way it is. I don't know why you would want to change it, or even ask ""Is there a better way."" Really, it should be called ""The Way"". Besides, it seems to work and suit the needs of the project just fine and will probably be extensible enough for years to come. Since your databases aren't taxed and sorting is <em>really really easy</em> it should stay that way for years to come.</p>

<p>I wouldn't sweat it.</p>
"
325,149380,0,104,sql,Dynamic Sorting within SQL Stored Procedures,"<p>This is an issue that I've spent hours researching in the past.  It seems to me to be something that should have been addressed by modern <a href=""http://en.wikipedia.org/wiki/Relational%5Fdatabase%5Fmanagement%5Fsystem"">RDBMS</a> solutions but as yet I have not found anything that really addresses what I see to be an incredibly common need in any Web or Windows application with a database back-end.</p>

<p>I speak of dynamic sorting.  In my fantasy world, it should be as simple as something like:</p>

<pre><code>ORDER BY @sortCol1, @sortCol2
</code></pre>

<p>This is the canonical example given by newbie SQL and <a href=""http://en.wikipedia.org/wiki/Stored%5Fprocedure"">Stored Procedure</a> developers all over forums across the Internet.  ""Why isn't this possible?"" they ask.  Invariably, somebody eventually comes along to lecture them about the compiled nature of stored procedures, of execution plans in general, and all sorts of other reasons why it isn't possible to put a parameter directly into an <code>ORDER BY</code> clause.</p>

<hr>

<p>I know what some of you are already thinking:  ""Let the client do the sorting, then.""  Naturally, this offloads the work from your database.  In our case though, our database servers aren't even breaking a sweat 99% of the time and they aren't even multi-core yet or any of the other myriad improvements to system architecture that happen every 6 months.  For this reason alone, having our databases handle sorting wouldn't be a problem.  Additionally, databases are <em>very</em> good at sorting.  They are optimized for it and have had years to get it right, the language for doing it is incredibly flexible, intuitive, and simple and above all any beginner SQL writer knows how to do it and even more importantly they know how to edit it, make changes, do maintenance, etc.  When your databases are far from being taxed and you just want to simplify (and shorten!) development time this seems like an obvious choice.</p>

<p>Then there's the web issue.  I've played around with JavaScript that will do client-side sorting of HTML tables, but they inevitably aren't flexible enough for my needs and, again, since my databases aren't overly taxed and can do sorting really <em>really</em> easily, I have a hard time justifying the time it would take to re-write or roll-my-own JavaScript sorter.  The same generally goes for server-side sorting, though it is already probably much preferred over JavaScript.  I'm not one that particularly likes the overhead of DataSets, so sue me.</p>

<p>But this brings back the point that it isn't possible &mdash; or rather, not easily.  I've done, with prior systems, an incredibly hack way of getting dynamic sorting.  It wasn't pretty, nor intuitive, simple, or flexible and a beginner SQL writer would be lost within seconds.  Already this is looking to be not so much a ""solution"" but a ""complication.""</p>

<hr>

<p>The following examples are not meant to expose any sort of best practices or good coding style or anything, nor are they indicative of my abilities as a T-SQL programmer.  They are what they are and I fully admit they are confusing, bad form, and just plain hack.</p>

<p>We pass an integer value as a parameter to a stored procedure (let's call the parameter just ""sort"") and from that we determine a bunch of other variables.  For example... let's say sort is 1 (or the default):</p>

<pre><code>DECLARE @sortCol1 AS varchar(20)
DECLARE @sortCol2 AS varchar(20)
DECLARE @dir1 AS varchar(20)
DECLARE @dir2 AS varchar(20)
DECLARE @col1 AS varchar(20)
DECLARE @col2 AS varchar(20)

SET @col1 = 'storagedatetime';
SET @col2 = 'vehicleid';

IF @sort = 1                -- Default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'asc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'asc';
END
ELSE IF @sort = 2           -- Reversed order default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'desc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'desc';
END
</code></pre>

<p>You can already see how if I declared more @colX variables to define other columns I could really get creative with the columns to sort on based on the value of ""sort""... to use it, it usually ends up looking like the following incredibly messy clause:</p>

<pre><code>ORDER BY
    CASE @dir1
        WHEN 'desc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir1
        WHEN 'asc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END,
    CASE @dir2
        WHEN 'desc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir2
        WHEN 'asc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END
</code></pre>

<p>Obviously this is a very stripped down example.  The real stuff, since we usually have four or five columns to support sorting on, each with possible secondary or even a third column to sort on in addition to that (for example date descending then sorted secondarily by name ascending) and each supporting bi-directional sorting which effectively doubles the number of cases.  Yeah... it gets hairy really quick.</p>

<p>The idea is that one could ""easily"" change the sort cases such that vehicleid gets sorted before the storagedatetime... but the pseudo-flexibility, at least in this simple example, really ends there.  Essentially, each case that fails a test (because our sort method doesn't apply to it this time around) renders a NULL value.  And thus you end up with a clause that functions like the following:</p>

<pre><code>ORDER BY NULL DESC, NULL, [storagedatetime] DESC, blah blah
</code></pre>

<p>You get the idea.  It works because SQL Server effectively ignores null values in order by clauses.  This is incredibly hard to maintain, as anyone with any basic working knowledge of SQL can probably see.  If I've lost any of you, don't feel bad.  It took us a long time to get it working and we still get confused trying to edit it or create new ones like it.  Thankfully it doesn't need changing often, otherwise it would quickly become ""not worth the trouble.""</p>

<p>Yet it <em>did</em> work.</p>

<hr>

<p>My question is then:  <strong>is there a better way?</strong></p>

<p>I'm okay with solutions other than Stored Procedure ones, as I realize it may just not be the way to go.  Preferably, I'd like to know if anyone can do it better within the Stored Procedure, but if not, how do you all handle letting the user dynamically sort tables of data (bi-directionally, too) with ASP.NET?</p>

<p>And thank you for reading (or at least skimming) such a long question!</p>

<p>PS: Be glad I didn't show my example of a stored procedure that supports dynamic sorting, dynamic filtering/text-searching of columns, pagination via ROWNUMBER() OVER, <em>AND</em> try...catch with transaction rollbacking on errors... ""behemoth-sized"" doesn't even begin to describe them.</p>

<hr>

<p><strong>Update:</strong></p>

<ul>
<li>I would like to <strong>avoid dynamic SQL</strong>.  Parsing a string together and running an EXEC on it defeats a lot of the purpose of having a stored procedure in the first place.  Sometimes I wonder though if the cons of doing such a thing wouldn't be worth it, at least in these special dynamic sorting cases.  Still, I always feel dirty whenever I do dynamic SQL strings like that &mdash; like I'm still living in the Classic ASP world.</li>
<li>A lot of the reason we want stored procedures in the first place is for <strong>security</strong>.  I don't get to make the call on security concerns, only suggest solutions.  With SQL Server 2005 we can set permissions (on a per-user basis if need be) at the schema level on individual stored procedures and then deny any queries against the tables directly.  Critiquing the pros and cons of this approach is perhaps for another question, but again it's not my decision.  I'm just the lead code monkey. :)</li>
</ul>
","<p>How about handling sorting on the stuff displaying the results -- grids, reports, etc. rather than on SQL?</p>

<p><strong>EDIT:</strong></p>

<p>To clarify things since this answer got down-voted earlier, I'll elaborate a bit...</p>

<p>You stated you knew about client-side sorting but wanted to steer clear of it.  That's your call, of course.</p>

<p>What I want to point out, though, is that by doing it on the client-side, you're able to pull data ONCE and then work with it however you want -- versus doing multiple trips back and forth to the server each time the sort gets changed.</p>

<p>Your SQL Server isn't getting taxed right now and that's awesome. It shouldn't be. But just because it isn't overloaded yet doesn't mean that it'll stay like that forever.</p>

<p>If you're using any of the newer ASP.NET stuff for displaying on the web, a lot of that stuff is already baked right in.</p>

<p>Is it worth adding so much code to each stored procedure just to handle sorting? Again, your call. </p>

<p>I'm not the one who will ultimately be in charge of supporting it.  But give some thought to what will be involved as columns are added/removed within the various datasets used by the stored procedures (requiring modifications to the CASE statements) or when suddenly instead of sorting by two columns, the user decides they need three -- requiring you to now update every one of your stored procedures that uses this method.</p>

<p>For me, it's worth it to get a working client-side solution and apply it to the handful of user-facing displays of data and be done with it.  If a new column is added, it's already handled. If the user wants to sort by multiple columns, they can sort by two or twenty of them.</p>
"
326,149380,3,104,sql,Dynamic Sorting within SQL Stored Procedures,"<p>This is an issue that I've spent hours researching in the past.  It seems to me to be something that should have been addressed by modern <a href=""http://en.wikipedia.org/wiki/Relational%5Fdatabase%5Fmanagement%5Fsystem"">RDBMS</a> solutions but as yet I have not found anything that really addresses what I see to be an incredibly common need in any Web or Windows application with a database back-end.</p>

<p>I speak of dynamic sorting.  In my fantasy world, it should be as simple as something like:</p>

<pre><code>ORDER BY @sortCol1, @sortCol2
</code></pre>

<p>This is the canonical example given by newbie SQL and <a href=""http://en.wikipedia.org/wiki/Stored%5Fprocedure"">Stored Procedure</a> developers all over forums across the Internet.  ""Why isn't this possible?"" they ask.  Invariably, somebody eventually comes along to lecture them about the compiled nature of stored procedures, of execution plans in general, and all sorts of other reasons why it isn't possible to put a parameter directly into an <code>ORDER BY</code> clause.</p>

<hr>

<p>I know what some of you are already thinking:  ""Let the client do the sorting, then.""  Naturally, this offloads the work from your database.  In our case though, our database servers aren't even breaking a sweat 99% of the time and they aren't even multi-core yet or any of the other myriad improvements to system architecture that happen every 6 months.  For this reason alone, having our databases handle sorting wouldn't be a problem.  Additionally, databases are <em>very</em> good at sorting.  They are optimized for it and have had years to get it right, the language for doing it is incredibly flexible, intuitive, and simple and above all any beginner SQL writer knows how to do it and even more importantly they know how to edit it, make changes, do maintenance, etc.  When your databases are far from being taxed and you just want to simplify (and shorten!) development time this seems like an obvious choice.</p>

<p>Then there's the web issue.  I've played around with JavaScript that will do client-side sorting of HTML tables, but they inevitably aren't flexible enough for my needs and, again, since my databases aren't overly taxed and can do sorting really <em>really</em> easily, I have a hard time justifying the time it would take to re-write or roll-my-own JavaScript sorter.  The same generally goes for server-side sorting, though it is already probably much preferred over JavaScript.  I'm not one that particularly likes the overhead of DataSets, so sue me.</p>

<p>But this brings back the point that it isn't possible &mdash; or rather, not easily.  I've done, with prior systems, an incredibly hack way of getting dynamic sorting.  It wasn't pretty, nor intuitive, simple, or flexible and a beginner SQL writer would be lost within seconds.  Already this is looking to be not so much a ""solution"" but a ""complication.""</p>

<hr>

<p>The following examples are not meant to expose any sort of best practices or good coding style or anything, nor are they indicative of my abilities as a T-SQL programmer.  They are what they are and I fully admit they are confusing, bad form, and just plain hack.</p>

<p>We pass an integer value as a parameter to a stored procedure (let's call the parameter just ""sort"") and from that we determine a bunch of other variables.  For example... let's say sort is 1 (or the default):</p>

<pre><code>DECLARE @sortCol1 AS varchar(20)
DECLARE @sortCol2 AS varchar(20)
DECLARE @dir1 AS varchar(20)
DECLARE @dir2 AS varchar(20)
DECLARE @col1 AS varchar(20)
DECLARE @col2 AS varchar(20)

SET @col1 = 'storagedatetime';
SET @col2 = 'vehicleid';

IF @sort = 1                -- Default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'asc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'asc';
END
ELSE IF @sort = 2           -- Reversed order default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'desc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'desc';
END
</code></pre>

<p>You can already see how if I declared more @colX variables to define other columns I could really get creative with the columns to sort on based on the value of ""sort""... to use it, it usually ends up looking like the following incredibly messy clause:</p>

<pre><code>ORDER BY
    CASE @dir1
        WHEN 'desc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir1
        WHEN 'asc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END,
    CASE @dir2
        WHEN 'desc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir2
        WHEN 'asc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END
</code></pre>

<p>Obviously this is a very stripped down example.  The real stuff, since we usually have four or five columns to support sorting on, each with possible secondary or even a third column to sort on in addition to that (for example date descending then sorted secondarily by name ascending) and each supporting bi-directional sorting which effectively doubles the number of cases.  Yeah... it gets hairy really quick.</p>

<p>The idea is that one could ""easily"" change the sort cases such that vehicleid gets sorted before the storagedatetime... but the pseudo-flexibility, at least in this simple example, really ends there.  Essentially, each case that fails a test (because our sort method doesn't apply to it this time around) renders a NULL value.  And thus you end up with a clause that functions like the following:</p>

<pre><code>ORDER BY NULL DESC, NULL, [storagedatetime] DESC, blah blah
</code></pre>

<p>You get the idea.  It works because SQL Server effectively ignores null values in order by clauses.  This is incredibly hard to maintain, as anyone with any basic working knowledge of SQL can probably see.  If I've lost any of you, don't feel bad.  It took us a long time to get it working and we still get confused trying to edit it or create new ones like it.  Thankfully it doesn't need changing often, otherwise it would quickly become ""not worth the trouble.""</p>

<p>Yet it <em>did</em> work.</p>

<hr>

<p>My question is then:  <strong>is there a better way?</strong></p>

<p>I'm okay with solutions other than Stored Procedure ones, as I realize it may just not be the way to go.  Preferably, I'd like to know if anyone can do it better within the Stored Procedure, but if not, how do you all handle letting the user dynamically sort tables of data (bi-directionally, too) with ASP.NET?</p>

<p>And thank you for reading (or at least skimming) such a long question!</p>

<p>PS: Be glad I didn't show my example of a stored procedure that supports dynamic sorting, dynamic filtering/text-searching of columns, pagination via ROWNUMBER() OVER, <em>AND</em> try...catch with transaction rollbacking on errors... ""behemoth-sized"" doesn't even begin to describe them.</p>

<hr>

<p><strong>Update:</strong></p>

<ul>
<li>I would like to <strong>avoid dynamic SQL</strong>.  Parsing a string together and running an EXEC on it defeats a lot of the purpose of having a stored procedure in the first place.  Sometimes I wonder though if the cons of doing such a thing wouldn't be worth it, at least in these special dynamic sorting cases.  Still, I always feel dirty whenever I do dynamic SQL strings like that &mdash; like I'm still living in the Classic ASP world.</li>
<li>A lot of the reason we want stored procedures in the first place is for <strong>security</strong>.  I don't get to make the call on security concerns, only suggest solutions.  With SQL Server 2005 we can set permissions (on a per-user basis if need be) at the schema level on individual stored procedures and then deny any queries against the tables directly.  Critiquing the pros and cons of this approach is perhaps for another question, but again it's not my decision.  I'm just the lead code monkey. :)</li>
</ul>
","<p>At some point, doesn't it become worth it to move away from stored procedures and just use parameterized queries to avoid this sort of hackery?</p>
"
327,149380,6,104,sql,Dynamic Sorting within SQL Stored Procedures,"<p>This is an issue that I've spent hours researching in the past.  It seems to me to be something that should have been addressed by modern <a href=""http://en.wikipedia.org/wiki/Relational%5Fdatabase%5Fmanagement%5Fsystem"">RDBMS</a> solutions but as yet I have not found anything that really addresses what I see to be an incredibly common need in any Web or Windows application with a database back-end.</p>

<p>I speak of dynamic sorting.  In my fantasy world, it should be as simple as something like:</p>

<pre><code>ORDER BY @sortCol1, @sortCol2
</code></pre>

<p>This is the canonical example given by newbie SQL and <a href=""http://en.wikipedia.org/wiki/Stored%5Fprocedure"">Stored Procedure</a> developers all over forums across the Internet.  ""Why isn't this possible?"" they ask.  Invariably, somebody eventually comes along to lecture them about the compiled nature of stored procedures, of execution plans in general, and all sorts of other reasons why it isn't possible to put a parameter directly into an <code>ORDER BY</code> clause.</p>

<hr>

<p>I know what some of you are already thinking:  ""Let the client do the sorting, then.""  Naturally, this offloads the work from your database.  In our case though, our database servers aren't even breaking a sweat 99% of the time and they aren't even multi-core yet or any of the other myriad improvements to system architecture that happen every 6 months.  For this reason alone, having our databases handle sorting wouldn't be a problem.  Additionally, databases are <em>very</em> good at sorting.  They are optimized for it and have had years to get it right, the language for doing it is incredibly flexible, intuitive, and simple and above all any beginner SQL writer knows how to do it and even more importantly they know how to edit it, make changes, do maintenance, etc.  When your databases are far from being taxed and you just want to simplify (and shorten!) development time this seems like an obvious choice.</p>

<p>Then there's the web issue.  I've played around with JavaScript that will do client-side sorting of HTML tables, but they inevitably aren't flexible enough for my needs and, again, since my databases aren't overly taxed and can do sorting really <em>really</em> easily, I have a hard time justifying the time it would take to re-write or roll-my-own JavaScript sorter.  The same generally goes for server-side sorting, though it is already probably much preferred over JavaScript.  I'm not one that particularly likes the overhead of DataSets, so sue me.</p>

<p>But this brings back the point that it isn't possible &mdash; or rather, not easily.  I've done, with prior systems, an incredibly hack way of getting dynamic sorting.  It wasn't pretty, nor intuitive, simple, or flexible and a beginner SQL writer would be lost within seconds.  Already this is looking to be not so much a ""solution"" but a ""complication.""</p>

<hr>

<p>The following examples are not meant to expose any sort of best practices or good coding style or anything, nor are they indicative of my abilities as a T-SQL programmer.  They are what they are and I fully admit they are confusing, bad form, and just plain hack.</p>

<p>We pass an integer value as a parameter to a stored procedure (let's call the parameter just ""sort"") and from that we determine a bunch of other variables.  For example... let's say sort is 1 (or the default):</p>

<pre><code>DECLARE @sortCol1 AS varchar(20)
DECLARE @sortCol2 AS varchar(20)
DECLARE @dir1 AS varchar(20)
DECLARE @dir2 AS varchar(20)
DECLARE @col1 AS varchar(20)
DECLARE @col2 AS varchar(20)

SET @col1 = 'storagedatetime';
SET @col2 = 'vehicleid';

IF @sort = 1                -- Default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'asc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'asc';
END
ELSE IF @sort = 2           -- Reversed order default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'desc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'desc';
END
</code></pre>

<p>You can already see how if I declared more @colX variables to define other columns I could really get creative with the columns to sort on based on the value of ""sort""... to use it, it usually ends up looking like the following incredibly messy clause:</p>

<pre><code>ORDER BY
    CASE @dir1
        WHEN 'desc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir1
        WHEN 'asc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END,
    CASE @dir2
        WHEN 'desc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir2
        WHEN 'asc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END
</code></pre>

<p>Obviously this is a very stripped down example.  The real stuff, since we usually have four or five columns to support sorting on, each with possible secondary or even a third column to sort on in addition to that (for example date descending then sorted secondarily by name ascending) and each supporting bi-directional sorting which effectively doubles the number of cases.  Yeah... it gets hairy really quick.</p>

<p>The idea is that one could ""easily"" change the sort cases such that vehicleid gets sorted before the storagedatetime... but the pseudo-flexibility, at least in this simple example, really ends there.  Essentially, each case that fails a test (because our sort method doesn't apply to it this time around) renders a NULL value.  And thus you end up with a clause that functions like the following:</p>

<pre><code>ORDER BY NULL DESC, NULL, [storagedatetime] DESC, blah blah
</code></pre>

<p>You get the idea.  It works because SQL Server effectively ignores null values in order by clauses.  This is incredibly hard to maintain, as anyone with any basic working knowledge of SQL can probably see.  If I've lost any of you, don't feel bad.  It took us a long time to get it working and we still get confused trying to edit it or create new ones like it.  Thankfully it doesn't need changing often, otherwise it would quickly become ""not worth the trouble.""</p>

<p>Yet it <em>did</em> work.</p>

<hr>

<p>My question is then:  <strong>is there a better way?</strong></p>

<p>I'm okay with solutions other than Stored Procedure ones, as I realize it may just not be the way to go.  Preferably, I'd like to know if anyone can do it better within the Stored Procedure, but if not, how do you all handle letting the user dynamically sort tables of data (bi-directionally, too) with ASP.NET?</p>

<p>And thank you for reading (or at least skimming) such a long question!</p>

<p>PS: Be glad I didn't show my example of a stored procedure that supports dynamic sorting, dynamic filtering/text-searching of columns, pagination via ROWNUMBER() OVER, <em>AND</em> try...catch with transaction rollbacking on errors... ""behemoth-sized"" doesn't even begin to describe them.</p>

<hr>

<p><strong>Update:</strong></p>

<ul>
<li>I would like to <strong>avoid dynamic SQL</strong>.  Parsing a string together and running an EXEC on it defeats a lot of the purpose of having a stored procedure in the first place.  Sometimes I wonder though if the cons of doing such a thing wouldn't be worth it, at least in these special dynamic sorting cases.  Still, I always feel dirty whenever I do dynamic SQL strings like that &mdash; like I'm still living in the Classic ASP world.</li>
<li>A lot of the reason we want stored procedures in the first place is for <strong>security</strong>.  I don't get to make the call on security concerns, only suggest solutions.  With SQL Server 2005 we can set permissions (on a per-user basis if need be) at the schema level on individual stored procedures and then deny any queries against the tables directly.  Critiquing the pros and cons of this approach is perhaps for another question, but again it's not my decision.  I'm just the lead code monkey. :)</li>
</ul>
","<p>Dynamic SQL is still an option. You just have to decide whether that option is more palatable than what you currently have.</p>

<p>Here is an article that shows that: <a href=""http://www.4guysfromrolla.com/webtech/010704-1.shtml"">http://www.4guysfromrolla.com/webtech/010704-1.shtml</a>. </p>
"
335,149380,16,104,sql,Dynamic Sorting within SQL Stored Procedures,"<p>This is an issue that I've spent hours researching in the past.  It seems to me to be something that should have been addressed by modern <a href=""http://en.wikipedia.org/wiki/Relational%5Fdatabase%5Fmanagement%5Fsystem"">RDBMS</a> solutions but as yet I have not found anything that really addresses what I see to be an incredibly common need in any Web or Windows application with a database back-end.</p>

<p>I speak of dynamic sorting.  In my fantasy world, it should be as simple as something like:</p>

<pre><code>ORDER BY @sortCol1, @sortCol2
</code></pre>

<p>This is the canonical example given by newbie SQL and <a href=""http://en.wikipedia.org/wiki/Stored%5Fprocedure"">Stored Procedure</a> developers all over forums across the Internet.  ""Why isn't this possible?"" they ask.  Invariably, somebody eventually comes along to lecture them about the compiled nature of stored procedures, of execution plans in general, and all sorts of other reasons why it isn't possible to put a parameter directly into an <code>ORDER BY</code> clause.</p>

<hr>

<p>I know what some of you are already thinking:  ""Let the client do the sorting, then.""  Naturally, this offloads the work from your database.  In our case though, our database servers aren't even breaking a sweat 99% of the time and they aren't even multi-core yet or any of the other myriad improvements to system architecture that happen every 6 months.  For this reason alone, having our databases handle sorting wouldn't be a problem.  Additionally, databases are <em>very</em> good at sorting.  They are optimized for it and have had years to get it right, the language for doing it is incredibly flexible, intuitive, and simple and above all any beginner SQL writer knows how to do it and even more importantly they know how to edit it, make changes, do maintenance, etc.  When your databases are far from being taxed and you just want to simplify (and shorten!) development time this seems like an obvious choice.</p>

<p>Then there's the web issue.  I've played around with JavaScript that will do client-side sorting of HTML tables, but they inevitably aren't flexible enough for my needs and, again, since my databases aren't overly taxed and can do sorting really <em>really</em> easily, I have a hard time justifying the time it would take to re-write or roll-my-own JavaScript sorter.  The same generally goes for server-side sorting, though it is already probably much preferred over JavaScript.  I'm not one that particularly likes the overhead of DataSets, so sue me.</p>

<p>But this brings back the point that it isn't possible &mdash; or rather, not easily.  I've done, with prior systems, an incredibly hack way of getting dynamic sorting.  It wasn't pretty, nor intuitive, simple, or flexible and a beginner SQL writer would be lost within seconds.  Already this is looking to be not so much a ""solution"" but a ""complication.""</p>

<hr>

<p>The following examples are not meant to expose any sort of best practices or good coding style or anything, nor are they indicative of my abilities as a T-SQL programmer.  They are what they are and I fully admit they are confusing, bad form, and just plain hack.</p>

<p>We pass an integer value as a parameter to a stored procedure (let's call the parameter just ""sort"") and from that we determine a bunch of other variables.  For example... let's say sort is 1 (or the default):</p>

<pre><code>DECLARE @sortCol1 AS varchar(20)
DECLARE @sortCol2 AS varchar(20)
DECLARE @dir1 AS varchar(20)
DECLARE @dir2 AS varchar(20)
DECLARE @col1 AS varchar(20)
DECLARE @col2 AS varchar(20)

SET @col1 = 'storagedatetime';
SET @col2 = 'vehicleid';

IF @sort = 1                -- Default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'asc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'asc';
END
ELSE IF @sort = 2           -- Reversed order default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'desc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'desc';
END
</code></pre>

<p>You can already see how if I declared more @colX variables to define other columns I could really get creative with the columns to sort on based on the value of ""sort""... to use it, it usually ends up looking like the following incredibly messy clause:</p>

<pre><code>ORDER BY
    CASE @dir1
        WHEN 'desc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir1
        WHEN 'asc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END,
    CASE @dir2
        WHEN 'desc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir2
        WHEN 'asc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END
</code></pre>

<p>Obviously this is a very stripped down example.  The real stuff, since we usually have four or five columns to support sorting on, each with possible secondary or even a third column to sort on in addition to that (for example date descending then sorted secondarily by name ascending) and each supporting bi-directional sorting which effectively doubles the number of cases.  Yeah... it gets hairy really quick.</p>

<p>The idea is that one could ""easily"" change the sort cases such that vehicleid gets sorted before the storagedatetime... but the pseudo-flexibility, at least in this simple example, really ends there.  Essentially, each case that fails a test (because our sort method doesn't apply to it this time around) renders a NULL value.  And thus you end up with a clause that functions like the following:</p>

<pre><code>ORDER BY NULL DESC, NULL, [storagedatetime] DESC, blah blah
</code></pre>

<p>You get the idea.  It works because SQL Server effectively ignores null values in order by clauses.  This is incredibly hard to maintain, as anyone with any basic working knowledge of SQL can probably see.  If I've lost any of you, don't feel bad.  It took us a long time to get it working and we still get confused trying to edit it or create new ones like it.  Thankfully it doesn't need changing often, otherwise it would quickly become ""not worth the trouble.""</p>

<p>Yet it <em>did</em> work.</p>

<hr>

<p>My question is then:  <strong>is there a better way?</strong></p>

<p>I'm okay with solutions other than Stored Procedure ones, as I realize it may just not be the way to go.  Preferably, I'd like to know if anyone can do it better within the Stored Procedure, but if not, how do you all handle letting the user dynamically sort tables of data (bi-directionally, too) with ASP.NET?</p>

<p>And thank you for reading (or at least skimming) such a long question!</p>

<p>PS: Be glad I didn't show my example of a stored procedure that supports dynamic sorting, dynamic filtering/text-searching of columns, pagination via ROWNUMBER() OVER, <em>AND</em> try...catch with transaction rollbacking on errors... ""behemoth-sized"" doesn't even begin to describe them.</p>

<hr>

<p><strong>Update:</strong></p>

<ul>
<li>I would like to <strong>avoid dynamic SQL</strong>.  Parsing a string together and running an EXEC on it defeats a lot of the purpose of having a stored procedure in the first place.  Sometimes I wonder though if the cons of doing such a thing wouldn't be worth it, at least in these special dynamic sorting cases.  Still, I always feel dirty whenever I do dynamic SQL strings like that &mdash; like I'm still living in the Classic ASP world.</li>
<li>A lot of the reason we want stored procedures in the first place is for <strong>security</strong>.  I don't get to make the call on security concerns, only suggest solutions.  With SQL Server 2005 we can set permissions (on a per-user basis if need be) at the schema level on individual stored procedures and then deny any queries against the tables directly.  Critiquing the pros and cons of this approach is perhaps for another question, but again it's not my decision.  I'm just the lead code monkey. :)</li>
</ul>
","<p>This approach keeps the sortable columns from being duplicated twice in the order by, and is a little more readable IMO:</p>

<pre><code>SELECT
  s.*
FROM
  (SELECT
    CASE @SortCol1
      WHEN 'Foo' THEN t.Foo
      WHEN 'Bar' THEN t.Bar
      ELSE null
    END as SortCol1,
    CASE @SortCol2
      WHEN 'Foo' THEN t.Foo
      WHEN 'Bar' THEN t.Bar
      ELSE null
    END as SortCol2,
    t.*
  FROM
    MyTable t) as s
ORDER BY
  CASE WHEN @dir1 = 'ASC'  THEN SortCol1 END ASC,
  CASE WHEN @dir1 = 'DESC' THEN SortCol1 END DESC,
  CASE WHEN @dir2 = 'ASC'  THEN SortCol2 END ASC,
  CASE WHEN @dir2 = 'DESC' THEN SortCol2 END DESC
</code></pre>
"
334,149380,-6,104,sql,Dynamic Sorting within SQL Stored Procedures,"<p>This is an issue that I've spent hours researching in the past.  It seems to me to be something that should have been addressed by modern <a href=""http://en.wikipedia.org/wiki/Relational%5Fdatabase%5Fmanagement%5Fsystem"">RDBMS</a> solutions but as yet I have not found anything that really addresses what I see to be an incredibly common need in any Web or Windows application with a database back-end.</p>

<p>I speak of dynamic sorting.  In my fantasy world, it should be as simple as something like:</p>

<pre><code>ORDER BY @sortCol1, @sortCol2
</code></pre>

<p>This is the canonical example given by newbie SQL and <a href=""http://en.wikipedia.org/wiki/Stored%5Fprocedure"">Stored Procedure</a> developers all over forums across the Internet.  ""Why isn't this possible?"" they ask.  Invariably, somebody eventually comes along to lecture them about the compiled nature of stored procedures, of execution plans in general, and all sorts of other reasons why it isn't possible to put a parameter directly into an <code>ORDER BY</code> clause.</p>

<hr>

<p>I know what some of you are already thinking:  ""Let the client do the sorting, then.""  Naturally, this offloads the work from your database.  In our case though, our database servers aren't even breaking a sweat 99% of the time and they aren't even multi-core yet or any of the other myriad improvements to system architecture that happen every 6 months.  For this reason alone, having our databases handle sorting wouldn't be a problem.  Additionally, databases are <em>very</em> good at sorting.  They are optimized for it and have had years to get it right, the language for doing it is incredibly flexible, intuitive, and simple and above all any beginner SQL writer knows how to do it and even more importantly they know how to edit it, make changes, do maintenance, etc.  When your databases are far from being taxed and you just want to simplify (and shorten!) development time this seems like an obvious choice.</p>

<p>Then there's the web issue.  I've played around with JavaScript that will do client-side sorting of HTML tables, but they inevitably aren't flexible enough for my needs and, again, since my databases aren't overly taxed and can do sorting really <em>really</em> easily, I have a hard time justifying the time it would take to re-write or roll-my-own JavaScript sorter.  The same generally goes for server-side sorting, though it is already probably much preferred over JavaScript.  I'm not one that particularly likes the overhead of DataSets, so sue me.</p>

<p>But this brings back the point that it isn't possible &mdash; or rather, not easily.  I've done, with prior systems, an incredibly hack way of getting dynamic sorting.  It wasn't pretty, nor intuitive, simple, or flexible and a beginner SQL writer would be lost within seconds.  Already this is looking to be not so much a ""solution"" but a ""complication.""</p>

<hr>

<p>The following examples are not meant to expose any sort of best practices or good coding style or anything, nor are they indicative of my abilities as a T-SQL programmer.  They are what they are and I fully admit they are confusing, bad form, and just plain hack.</p>

<p>We pass an integer value as a parameter to a stored procedure (let's call the parameter just ""sort"") and from that we determine a bunch of other variables.  For example... let's say sort is 1 (or the default):</p>

<pre><code>DECLARE @sortCol1 AS varchar(20)
DECLARE @sortCol2 AS varchar(20)
DECLARE @dir1 AS varchar(20)
DECLARE @dir2 AS varchar(20)
DECLARE @col1 AS varchar(20)
DECLARE @col2 AS varchar(20)

SET @col1 = 'storagedatetime';
SET @col2 = 'vehicleid';

IF @sort = 1                -- Default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'asc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'asc';
END
ELSE IF @sort = 2           -- Reversed order default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'desc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'desc';
END
</code></pre>

<p>You can already see how if I declared more @colX variables to define other columns I could really get creative with the columns to sort on based on the value of ""sort""... to use it, it usually ends up looking like the following incredibly messy clause:</p>

<pre><code>ORDER BY
    CASE @dir1
        WHEN 'desc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir1
        WHEN 'asc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END,
    CASE @dir2
        WHEN 'desc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir2
        WHEN 'asc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END
</code></pre>

<p>Obviously this is a very stripped down example.  The real stuff, since we usually have four or five columns to support sorting on, each with possible secondary or even a third column to sort on in addition to that (for example date descending then sorted secondarily by name ascending) and each supporting bi-directional sorting which effectively doubles the number of cases.  Yeah... it gets hairy really quick.</p>

<p>The idea is that one could ""easily"" change the sort cases such that vehicleid gets sorted before the storagedatetime... but the pseudo-flexibility, at least in this simple example, really ends there.  Essentially, each case that fails a test (because our sort method doesn't apply to it this time around) renders a NULL value.  And thus you end up with a clause that functions like the following:</p>

<pre><code>ORDER BY NULL DESC, NULL, [storagedatetime] DESC, blah blah
</code></pre>

<p>You get the idea.  It works because SQL Server effectively ignores null values in order by clauses.  This is incredibly hard to maintain, as anyone with any basic working knowledge of SQL can probably see.  If I've lost any of you, don't feel bad.  It took us a long time to get it working and we still get confused trying to edit it or create new ones like it.  Thankfully it doesn't need changing often, otherwise it would quickly become ""not worth the trouble.""</p>

<p>Yet it <em>did</em> work.</p>

<hr>

<p>My question is then:  <strong>is there a better way?</strong></p>

<p>I'm okay with solutions other than Stored Procedure ones, as I realize it may just not be the way to go.  Preferably, I'd like to know if anyone can do it better within the Stored Procedure, but if not, how do you all handle letting the user dynamically sort tables of data (bi-directionally, too) with ASP.NET?</p>

<p>And thank you for reading (or at least skimming) such a long question!</p>

<p>PS: Be glad I didn't show my example of a stored procedure that supports dynamic sorting, dynamic filtering/text-searching of columns, pagination via ROWNUMBER() OVER, <em>AND</em> try...catch with transaction rollbacking on errors... ""behemoth-sized"" doesn't even begin to describe them.</p>

<hr>

<p><strong>Update:</strong></p>

<ul>
<li>I would like to <strong>avoid dynamic SQL</strong>.  Parsing a string together and running an EXEC on it defeats a lot of the purpose of having a stored procedure in the first place.  Sometimes I wonder though if the cons of doing such a thing wouldn't be worth it, at least in these special dynamic sorting cases.  Still, I always feel dirty whenever I do dynamic SQL strings like that &mdash; like I'm still living in the Classic ASP world.</li>
<li>A lot of the reason we want stored procedures in the first place is for <strong>security</strong>.  I don't get to make the call on security concerns, only suggest solutions.  With SQL Server 2005 we can set permissions (on a per-user basis if need be) at the schema level on individual stored procedures and then deny any queries against the tables directly.  Critiquing the pros and cons of this approach is perhaps for another question, but again it's not my decision.  I'm just the lead code monkey. :)</li>
</ul>
","<p>You should avoid the SQL Server sorting, unless if necessary. Why not sort on app server or client side? Also .NET Generics does exceptional sortin</p>
"
333,149380,-1,104,sql,Dynamic Sorting within SQL Stored Procedures,"<p>This is an issue that I've spent hours researching in the past.  It seems to me to be something that should have been addressed by modern <a href=""http://en.wikipedia.org/wiki/Relational%5Fdatabase%5Fmanagement%5Fsystem"">RDBMS</a> solutions but as yet I have not found anything that really addresses what I see to be an incredibly common need in any Web or Windows application with a database back-end.</p>

<p>I speak of dynamic sorting.  In my fantasy world, it should be as simple as something like:</p>

<pre><code>ORDER BY @sortCol1, @sortCol2
</code></pre>

<p>This is the canonical example given by newbie SQL and <a href=""http://en.wikipedia.org/wiki/Stored%5Fprocedure"">Stored Procedure</a> developers all over forums across the Internet.  ""Why isn't this possible?"" they ask.  Invariably, somebody eventually comes along to lecture them about the compiled nature of stored procedures, of execution plans in general, and all sorts of other reasons why it isn't possible to put a parameter directly into an <code>ORDER BY</code> clause.</p>

<hr>

<p>I know what some of you are already thinking:  ""Let the client do the sorting, then.""  Naturally, this offloads the work from your database.  In our case though, our database servers aren't even breaking a sweat 99% of the time and they aren't even multi-core yet or any of the other myriad improvements to system architecture that happen every 6 months.  For this reason alone, having our databases handle sorting wouldn't be a problem.  Additionally, databases are <em>very</em> good at sorting.  They are optimized for it and have had years to get it right, the language for doing it is incredibly flexible, intuitive, and simple and above all any beginner SQL writer knows how to do it and even more importantly they know how to edit it, make changes, do maintenance, etc.  When your databases are far from being taxed and you just want to simplify (and shorten!) development time this seems like an obvious choice.</p>

<p>Then there's the web issue.  I've played around with JavaScript that will do client-side sorting of HTML tables, but they inevitably aren't flexible enough for my needs and, again, since my databases aren't overly taxed and can do sorting really <em>really</em> easily, I have a hard time justifying the time it would take to re-write or roll-my-own JavaScript sorter.  The same generally goes for server-side sorting, though it is already probably much preferred over JavaScript.  I'm not one that particularly likes the overhead of DataSets, so sue me.</p>

<p>But this brings back the point that it isn't possible &mdash; or rather, not easily.  I've done, with prior systems, an incredibly hack way of getting dynamic sorting.  It wasn't pretty, nor intuitive, simple, or flexible and a beginner SQL writer would be lost within seconds.  Already this is looking to be not so much a ""solution"" but a ""complication.""</p>

<hr>

<p>The following examples are not meant to expose any sort of best practices or good coding style or anything, nor are they indicative of my abilities as a T-SQL programmer.  They are what they are and I fully admit they are confusing, bad form, and just plain hack.</p>

<p>We pass an integer value as a parameter to a stored procedure (let's call the parameter just ""sort"") and from that we determine a bunch of other variables.  For example... let's say sort is 1 (or the default):</p>

<pre><code>DECLARE @sortCol1 AS varchar(20)
DECLARE @sortCol2 AS varchar(20)
DECLARE @dir1 AS varchar(20)
DECLARE @dir2 AS varchar(20)
DECLARE @col1 AS varchar(20)
DECLARE @col2 AS varchar(20)

SET @col1 = 'storagedatetime';
SET @col2 = 'vehicleid';

IF @sort = 1                -- Default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'asc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'asc';
END
ELSE IF @sort = 2           -- Reversed order default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'desc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'desc';
END
</code></pre>

<p>You can already see how if I declared more @colX variables to define other columns I could really get creative with the columns to sort on based on the value of ""sort""... to use it, it usually ends up looking like the following incredibly messy clause:</p>

<pre><code>ORDER BY
    CASE @dir1
        WHEN 'desc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir1
        WHEN 'asc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END,
    CASE @dir2
        WHEN 'desc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir2
        WHEN 'asc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END
</code></pre>

<p>Obviously this is a very stripped down example.  The real stuff, since we usually have four or five columns to support sorting on, each with possible secondary or even a third column to sort on in addition to that (for example date descending then sorted secondarily by name ascending) and each supporting bi-directional sorting which effectively doubles the number of cases.  Yeah... it gets hairy really quick.</p>

<p>The idea is that one could ""easily"" change the sort cases such that vehicleid gets sorted before the storagedatetime... but the pseudo-flexibility, at least in this simple example, really ends there.  Essentially, each case that fails a test (because our sort method doesn't apply to it this time around) renders a NULL value.  And thus you end up with a clause that functions like the following:</p>

<pre><code>ORDER BY NULL DESC, NULL, [storagedatetime] DESC, blah blah
</code></pre>

<p>You get the idea.  It works because SQL Server effectively ignores null values in order by clauses.  This is incredibly hard to maintain, as anyone with any basic working knowledge of SQL can probably see.  If I've lost any of you, don't feel bad.  It took us a long time to get it working and we still get confused trying to edit it or create new ones like it.  Thankfully it doesn't need changing often, otherwise it would quickly become ""not worth the trouble.""</p>

<p>Yet it <em>did</em> work.</p>

<hr>

<p>My question is then:  <strong>is there a better way?</strong></p>

<p>I'm okay with solutions other than Stored Procedure ones, as I realize it may just not be the way to go.  Preferably, I'd like to know if anyone can do it better within the Stored Procedure, but if not, how do you all handle letting the user dynamically sort tables of data (bi-directionally, too) with ASP.NET?</p>

<p>And thank you for reading (or at least skimming) such a long question!</p>

<p>PS: Be glad I didn't show my example of a stored procedure that supports dynamic sorting, dynamic filtering/text-searching of columns, pagination via ROWNUMBER() OVER, <em>AND</em> try...catch with transaction rollbacking on errors... ""behemoth-sized"" doesn't even begin to describe them.</p>

<hr>

<p><strong>Update:</strong></p>

<ul>
<li>I would like to <strong>avoid dynamic SQL</strong>.  Parsing a string together and running an EXEC on it defeats a lot of the purpose of having a stored procedure in the first place.  Sometimes I wonder though if the cons of doing such a thing wouldn't be worth it, at least in these special dynamic sorting cases.  Still, I always feel dirty whenever I do dynamic SQL strings like that &mdash; like I'm still living in the Classic ASP world.</li>
<li>A lot of the reason we want stored procedures in the first place is for <strong>security</strong>.  I don't get to make the call on security concerns, only suggest solutions.  With SQL Server 2005 we can set permissions (on a per-user basis if need be) at the schema level on individual stored procedures and then deny any queries against the tables directly.  Critiquing the pros and cons of this approach is perhaps for another question, but again it's not my decision.  I'm just the lead code monkey. :)</li>
</ul>
","<p>This solution might only work in .NET, I don't know.   </p>

<p>I fetch the data into the C# with the initial sort order in the SQL order by clause, put that data in a DataView, cache it in a Session variable, and use it to build a page.</p>

<p>When the user clicks on a column heading to sort (or page, or filter), I don't go back to the database.  Instead, I go back to my cached DataView and set its ""Sort"" property to an expression I build dynamically, just like I would dynamic SQL.    ( I do the filtering the same way, using the ""RowFilter"" property).</p>

<p>You can see/feel it working in a demo of my app, BugTracker.NET, at <a href=""http://ifdefined.com/btnet/bugs.aspx"" rel=""nofollow"">http://ifdefined.com/btnet/bugs.aspx</a></p>
"
328,149380,69,104,sql,Dynamic Sorting within SQL Stored Procedures,"<p>This is an issue that I've spent hours researching in the past.  It seems to me to be something that should have been addressed by modern <a href=""http://en.wikipedia.org/wiki/Relational%5Fdatabase%5Fmanagement%5Fsystem"">RDBMS</a> solutions but as yet I have not found anything that really addresses what I see to be an incredibly common need in any Web or Windows application with a database back-end.</p>

<p>I speak of dynamic sorting.  In my fantasy world, it should be as simple as something like:</p>

<pre><code>ORDER BY @sortCol1, @sortCol2
</code></pre>

<p>This is the canonical example given by newbie SQL and <a href=""http://en.wikipedia.org/wiki/Stored%5Fprocedure"">Stored Procedure</a> developers all over forums across the Internet.  ""Why isn't this possible?"" they ask.  Invariably, somebody eventually comes along to lecture them about the compiled nature of stored procedures, of execution plans in general, and all sorts of other reasons why it isn't possible to put a parameter directly into an <code>ORDER BY</code> clause.</p>

<hr>

<p>I know what some of you are already thinking:  ""Let the client do the sorting, then.""  Naturally, this offloads the work from your database.  In our case though, our database servers aren't even breaking a sweat 99% of the time and they aren't even multi-core yet or any of the other myriad improvements to system architecture that happen every 6 months.  For this reason alone, having our databases handle sorting wouldn't be a problem.  Additionally, databases are <em>very</em> good at sorting.  They are optimized for it and have had years to get it right, the language for doing it is incredibly flexible, intuitive, and simple and above all any beginner SQL writer knows how to do it and even more importantly they know how to edit it, make changes, do maintenance, etc.  When your databases are far from being taxed and you just want to simplify (and shorten!) development time this seems like an obvious choice.</p>

<p>Then there's the web issue.  I've played around with JavaScript that will do client-side sorting of HTML tables, but they inevitably aren't flexible enough for my needs and, again, since my databases aren't overly taxed and can do sorting really <em>really</em> easily, I have a hard time justifying the time it would take to re-write or roll-my-own JavaScript sorter.  The same generally goes for server-side sorting, though it is already probably much preferred over JavaScript.  I'm not one that particularly likes the overhead of DataSets, so sue me.</p>

<p>But this brings back the point that it isn't possible &mdash; or rather, not easily.  I've done, with prior systems, an incredibly hack way of getting dynamic sorting.  It wasn't pretty, nor intuitive, simple, or flexible and a beginner SQL writer would be lost within seconds.  Already this is looking to be not so much a ""solution"" but a ""complication.""</p>

<hr>

<p>The following examples are not meant to expose any sort of best practices or good coding style or anything, nor are they indicative of my abilities as a T-SQL programmer.  They are what they are and I fully admit they are confusing, bad form, and just plain hack.</p>

<p>We pass an integer value as a parameter to a stored procedure (let's call the parameter just ""sort"") and from that we determine a bunch of other variables.  For example... let's say sort is 1 (or the default):</p>

<pre><code>DECLARE @sortCol1 AS varchar(20)
DECLARE @sortCol2 AS varchar(20)
DECLARE @dir1 AS varchar(20)
DECLARE @dir2 AS varchar(20)
DECLARE @col1 AS varchar(20)
DECLARE @col2 AS varchar(20)

SET @col1 = 'storagedatetime';
SET @col2 = 'vehicleid';

IF @sort = 1                -- Default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'asc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'asc';
END
ELSE IF @sort = 2           -- Reversed order default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'desc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'desc';
END
</code></pre>

<p>You can already see how if I declared more @colX variables to define other columns I could really get creative with the columns to sort on based on the value of ""sort""... to use it, it usually ends up looking like the following incredibly messy clause:</p>

<pre><code>ORDER BY
    CASE @dir1
        WHEN 'desc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir1
        WHEN 'asc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END,
    CASE @dir2
        WHEN 'desc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir2
        WHEN 'asc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END
</code></pre>

<p>Obviously this is a very stripped down example.  The real stuff, since we usually have four or five columns to support sorting on, each with possible secondary or even a third column to sort on in addition to that (for example date descending then sorted secondarily by name ascending) and each supporting bi-directional sorting which effectively doubles the number of cases.  Yeah... it gets hairy really quick.</p>

<p>The idea is that one could ""easily"" change the sort cases such that vehicleid gets sorted before the storagedatetime... but the pseudo-flexibility, at least in this simple example, really ends there.  Essentially, each case that fails a test (because our sort method doesn't apply to it this time around) renders a NULL value.  And thus you end up with a clause that functions like the following:</p>

<pre><code>ORDER BY NULL DESC, NULL, [storagedatetime] DESC, blah blah
</code></pre>

<p>You get the idea.  It works because SQL Server effectively ignores null values in order by clauses.  This is incredibly hard to maintain, as anyone with any basic working knowledge of SQL can probably see.  If I've lost any of you, don't feel bad.  It took us a long time to get it working and we still get confused trying to edit it or create new ones like it.  Thankfully it doesn't need changing often, otherwise it would quickly become ""not worth the trouble.""</p>

<p>Yet it <em>did</em> work.</p>

<hr>

<p>My question is then:  <strong>is there a better way?</strong></p>

<p>I'm okay with solutions other than Stored Procedure ones, as I realize it may just not be the way to go.  Preferably, I'd like to know if anyone can do it better within the Stored Procedure, but if not, how do you all handle letting the user dynamically sort tables of data (bi-directionally, too) with ASP.NET?</p>

<p>And thank you for reading (or at least skimming) such a long question!</p>

<p>PS: Be glad I didn't show my example of a stored procedure that supports dynamic sorting, dynamic filtering/text-searching of columns, pagination via ROWNUMBER() OVER, <em>AND</em> try...catch with transaction rollbacking on errors... ""behemoth-sized"" doesn't even begin to describe them.</p>

<hr>

<p><strong>Update:</strong></p>

<ul>
<li>I would like to <strong>avoid dynamic SQL</strong>.  Parsing a string together and running an EXEC on it defeats a lot of the purpose of having a stored procedure in the first place.  Sometimes I wonder though if the cons of doing such a thing wouldn't be worth it, at least in these special dynamic sorting cases.  Still, I always feel dirty whenever I do dynamic SQL strings like that &mdash; like I'm still living in the Classic ASP world.</li>
<li>A lot of the reason we want stored procedures in the first place is for <strong>security</strong>.  I don't get to make the call on security concerns, only suggest solutions.  With SQL Server 2005 we can set permissions (on a per-user basis if need be) at the schema level on individual stored procedures and then deny any queries against the tables directly.  Critiquing the pros and cons of this approach is perhaps for another question, but again it's not my decision.  I'm just the lead code monkey. :)</li>
</ul>
","<p>Yeah, it's a pain, and the way you're doing it looks similar to what I do:</p>

<pre><code>order by
case when @SortExpr = 'CustomerName' and @SortDir = 'ASC' 
    then CustomerName end asc, 
case when @SortExpr = 'CustomerName' and @SortDir = 'DESC' 
    then CustomerName end desc,
...
</code></pre>

<p>This, to me, is still much better than building dynamic SQL from code, which turns into a scalability and maintenance nightmare for DBAs.</p>

<p>What I do from code is refactor the paging and sorting so I at least don't have a lot of repetition there with populating values for @SortExpr and @SortDir.</p>

<p>As far as the SQL is concerned, keep the design and formatting the same between different stored procedures, so it's at least neat and recognizable when you go in to make changes.</p>
"
329,149380,4,104,sql,Dynamic Sorting within SQL Stored Procedures,"<p>This is an issue that I've spent hours researching in the past.  It seems to me to be something that should have been addressed by modern <a href=""http://en.wikipedia.org/wiki/Relational%5Fdatabase%5Fmanagement%5Fsystem"">RDBMS</a> solutions but as yet I have not found anything that really addresses what I see to be an incredibly common need in any Web or Windows application with a database back-end.</p>

<p>I speak of dynamic sorting.  In my fantasy world, it should be as simple as something like:</p>

<pre><code>ORDER BY @sortCol1, @sortCol2
</code></pre>

<p>This is the canonical example given by newbie SQL and <a href=""http://en.wikipedia.org/wiki/Stored%5Fprocedure"">Stored Procedure</a> developers all over forums across the Internet.  ""Why isn't this possible?"" they ask.  Invariably, somebody eventually comes along to lecture them about the compiled nature of stored procedures, of execution plans in general, and all sorts of other reasons why it isn't possible to put a parameter directly into an <code>ORDER BY</code> clause.</p>

<hr>

<p>I know what some of you are already thinking:  ""Let the client do the sorting, then.""  Naturally, this offloads the work from your database.  In our case though, our database servers aren't even breaking a sweat 99% of the time and they aren't even multi-core yet or any of the other myriad improvements to system architecture that happen every 6 months.  For this reason alone, having our databases handle sorting wouldn't be a problem.  Additionally, databases are <em>very</em> good at sorting.  They are optimized for it and have had years to get it right, the language for doing it is incredibly flexible, intuitive, and simple and above all any beginner SQL writer knows how to do it and even more importantly they know how to edit it, make changes, do maintenance, etc.  When your databases are far from being taxed and you just want to simplify (and shorten!) development time this seems like an obvious choice.</p>

<p>Then there's the web issue.  I've played around with JavaScript that will do client-side sorting of HTML tables, but they inevitably aren't flexible enough for my needs and, again, since my databases aren't overly taxed and can do sorting really <em>really</em> easily, I have a hard time justifying the time it would take to re-write or roll-my-own JavaScript sorter.  The same generally goes for server-side sorting, though it is already probably much preferred over JavaScript.  I'm not one that particularly likes the overhead of DataSets, so sue me.</p>

<p>But this brings back the point that it isn't possible &mdash; or rather, not easily.  I've done, with prior systems, an incredibly hack way of getting dynamic sorting.  It wasn't pretty, nor intuitive, simple, or flexible and a beginner SQL writer would be lost within seconds.  Already this is looking to be not so much a ""solution"" but a ""complication.""</p>

<hr>

<p>The following examples are not meant to expose any sort of best practices or good coding style or anything, nor are they indicative of my abilities as a T-SQL programmer.  They are what they are and I fully admit they are confusing, bad form, and just plain hack.</p>

<p>We pass an integer value as a parameter to a stored procedure (let's call the parameter just ""sort"") and from that we determine a bunch of other variables.  For example... let's say sort is 1 (or the default):</p>

<pre><code>DECLARE @sortCol1 AS varchar(20)
DECLARE @sortCol2 AS varchar(20)
DECLARE @dir1 AS varchar(20)
DECLARE @dir2 AS varchar(20)
DECLARE @col1 AS varchar(20)
DECLARE @col2 AS varchar(20)

SET @col1 = 'storagedatetime';
SET @col2 = 'vehicleid';

IF @sort = 1                -- Default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'asc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'asc';
END
ELSE IF @sort = 2           -- Reversed order default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'desc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'desc';
END
</code></pre>

<p>You can already see how if I declared more @colX variables to define other columns I could really get creative with the columns to sort on based on the value of ""sort""... to use it, it usually ends up looking like the following incredibly messy clause:</p>

<pre><code>ORDER BY
    CASE @dir1
        WHEN 'desc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir1
        WHEN 'asc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END,
    CASE @dir2
        WHEN 'desc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir2
        WHEN 'asc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END
</code></pre>

<p>Obviously this is a very stripped down example.  The real stuff, since we usually have four or five columns to support sorting on, each with possible secondary or even a third column to sort on in addition to that (for example date descending then sorted secondarily by name ascending) and each supporting bi-directional sorting which effectively doubles the number of cases.  Yeah... it gets hairy really quick.</p>

<p>The idea is that one could ""easily"" change the sort cases such that vehicleid gets sorted before the storagedatetime... but the pseudo-flexibility, at least in this simple example, really ends there.  Essentially, each case that fails a test (because our sort method doesn't apply to it this time around) renders a NULL value.  And thus you end up with a clause that functions like the following:</p>

<pre><code>ORDER BY NULL DESC, NULL, [storagedatetime] DESC, blah blah
</code></pre>

<p>You get the idea.  It works because SQL Server effectively ignores null values in order by clauses.  This is incredibly hard to maintain, as anyone with any basic working knowledge of SQL can probably see.  If I've lost any of you, don't feel bad.  It took us a long time to get it working and we still get confused trying to edit it or create new ones like it.  Thankfully it doesn't need changing often, otherwise it would quickly become ""not worth the trouble.""</p>

<p>Yet it <em>did</em> work.</p>

<hr>

<p>My question is then:  <strong>is there a better way?</strong></p>

<p>I'm okay with solutions other than Stored Procedure ones, as I realize it may just not be the way to go.  Preferably, I'd like to know if anyone can do it better within the Stored Procedure, but if not, how do you all handle letting the user dynamically sort tables of data (bi-directionally, too) with ASP.NET?</p>

<p>And thank you for reading (or at least skimming) such a long question!</p>

<p>PS: Be glad I didn't show my example of a stored procedure that supports dynamic sorting, dynamic filtering/text-searching of columns, pagination via ROWNUMBER() OVER, <em>AND</em> try...catch with transaction rollbacking on errors... ""behemoth-sized"" doesn't even begin to describe them.</p>

<hr>

<p><strong>Update:</strong></p>

<ul>
<li>I would like to <strong>avoid dynamic SQL</strong>.  Parsing a string together and running an EXEC on it defeats a lot of the purpose of having a stored procedure in the first place.  Sometimes I wonder though if the cons of doing such a thing wouldn't be worth it, at least in these special dynamic sorting cases.  Still, I always feel dirty whenever I do dynamic SQL strings like that &mdash; like I'm still living in the Classic ASP world.</li>
<li>A lot of the reason we want stored procedures in the first place is for <strong>security</strong>.  I don't get to make the call on security concerns, only suggest solutions.  With SQL Server 2005 we can set permissions (on a per-user basis if need be) at the schema level on individual stored procedures and then deny any queries against the tables directly.  Critiquing the pros and cons of this approach is perhaps for another question, but again it's not my decision.  I'm just the lead code monkey. :)</li>
</ul>
","<p>There may be a third option, since your server has lots of spare cycles - use a helper procedure to do the sorting via a temporary table. Something like</p>

<pre><code>create procedure uspCallAndSort
(
    @sql varchar(2048),        --exec dbo.uspSomeProcedure arg1,'arg2',etc.
    @sortClause varchar(512)    --comma-delimited field list
)
AS
insert into #tmp EXEC(@sql)
declare @msql varchar(3000)
set @msql = 'select * from #tmp order by ' + @sortClause
EXEC(@msql)
drop table #tmp
GO
</code></pre>

<p>Caveat: I haven't tested this, but it ""should"" work in SQL Server 2005 (which will create a temporary table from a result set without specifying the columns in advance.)</p>
"
331,149380,5,104,sql,Dynamic Sorting within SQL Stored Procedures,"<p>This is an issue that I've spent hours researching in the past.  It seems to me to be something that should have been addressed by modern <a href=""http://en.wikipedia.org/wiki/Relational%5Fdatabase%5Fmanagement%5Fsystem"">RDBMS</a> solutions but as yet I have not found anything that really addresses what I see to be an incredibly common need in any Web or Windows application with a database back-end.</p>

<p>I speak of dynamic sorting.  In my fantasy world, it should be as simple as something like:</p>

<pre><code>ORDER BY @sortCol1, @sortCol2
</code></pre>

<p>This is the canonical example given by newbie SQL and <a href=""http://en.wikipedia.org/wiki/Stored%5Fprocedure"">Stored Procedure</a> developers all over forums across the Internet.  ""Why isn't this possible?"" they ask.  Invariably, somebody eventually comes along to lecture them about the compiled nature of stored procedures, of execution plans in general, and all sorts of other reasons why it isn't possible to put a parameter directly into an <code>ORDER BY</code> clause.</p>

<hr>

<p>I know what some of you are already thinking:  ""Let the client do the sorting, then.""  Naturally, this offloads the work from your database.  In our case though, our database servers aren't even breaking a sweat 99% of the time and they aren't even multi-core yet or any of the other myriad improvements to system architecture that happen every 6 months.  For this reason alone, having our databases handle sorting wouldn't be a problem.  Additionally, databases are <em>very</em> good at sorting.  They are optimized for it and have had years to get it right, the language for doing it is incredibly flexible, intuitive, and simple and above all any beginner SQL writer knows how to do it and even more importantly they know how to edit it, make changes, do maintenance, etc.  When your databases are far from being taxed and you just want to simplify (and shorten!) development time this seems like an obvious choice.</p>

<p>Then there's the web issue.  I've played around with JavaScript that will do client-side sorting of HTML tables, but they inevitably aren't flexible enough for my needs and, again, since my databases aren't overly taxed and can do sorting really <em>really</em> easily, I have a hard time justifying the time it would take to re-write or roll-my-own JavaScript sorter.  The same generally goes for server-side sorting, though it is already probably much preferred over JavaScript.  I'm not one that particularly likes the overhead of DataSets, so sue me.</p>

<p>But this brings back the point that it isn't possible &mdash; or rather, not easily.  I've done, with prior systems, an incredibly hack way of getting dynamic sorting.  It wasn't pretty, nor intuitive, simple, or flexible and a beginner SQL writer would be lost within seconds.  Already this is looking to be not so much a ""solution"" but a ""complication.""</p>

<hr>

<p>The following examples are not meant to expose any sort of best practices or good coding style or anything, nor are they indicative of my abilities as a T-SQL programmer.  They are what they are and I fully admit they are confusing, bad form, and just plain hack.</p>

<p>We pass an integer value as a parameter to a stored procedure (let's call the parameter just ""sort"") and from that we determine a bunch of other variables.  For example... let's say sort is 1 (or the default):</p>

<pre><code>DECLARE @sortCol1 AS varchar(20)
DECLARE @sortCol2 AS varchar(20)
DECLARE @dir1 AS varchar(20)
DECLARE @dir2 AS varchar(20)
DECLARE @col1 AS varchar(20)
DECLARE @col2 AS varchar(20)

SET @col1 = 'storagedatetime';
SET @col2 = 'vehicleid';

IF @sort = 1                -- Default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'asc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'asc';
END
ELSE IF @sort = 2           -- Reversed order default sort.
BEGIN
    SET @sortCol1 = @col1;
    SET @dir1 = 'desc';
    SET @sortCol2 = @col2;
    SET @dir2 = 'desc';
END
</code></pre>

<p>You can already see how if I declared more @colX variables to define other columns I could really get creative with the columns to sort on based on the value of ""sort""... to use it, it usually ends up looking like the following incredibly messy clause:</p>

<pre><code>ORDER BY
    CASE @dir1
        WHEN 'desc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir1
        WHEN 'asc' THEN
            CASE @sortCol1
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END,
    CASE @dir2
        WHEN 'desc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END DESC,
    CASE @dir2
        WHEN 'asc' THEN
            CASE @sortCol2
                WHEN @col1 THEN [storagedatetime]
                WHEN @col2 THEN [vehicleid]
            END
    END
</code></pre>

<p>Obviously this is a very stripped down example.  The real stuff, since we usually have four or five columns to support sorting on, each with possible secondary or even a third column to sort on in addition to that (for example date descending then sorted secondarily by name ascending) and each supporting bi-directional sorting which effectively doubles the number of cases.  Yeah... it gets hairy really quick.</p>

<p>The idea is that one could ""easily"" change the sort cases such that vehicleid gets sorted before the storagedatetime... but the pseudo-flexibility, at least in this simple example, really ends there.  Essentially, each case that fails a test (because our sort method doesn't apply to it this time around) renders a NULL value.  And thus you end up with a clause that functions like the following:</p>

<pre><code>ORDER BY NULL DESC, NULL, [storagedatetime] DESC, blah blah
</code></pre>

<p>You get the idea.  It works because SQL Server effectively ignores null values in order by clauses.  This is incredibly hard to maintain, as anyone with any basic working knowledge of SQL can probably see.  If I've lost any of you, don't feel bad.  It took us a long time to get it working and we still get confused trying to edit it or create new ones like it.  Thankfully it doesn't need changing often, otherwise it would quickly become ""not worth the trouble.""</p>

<p>Yet it <em>did</em> work.</p>

<hr>

<p>My question is then:  <strong>is there a better way?</strong></p>

<p>I'm okay with solutions other than Stored Procedure ones, as I realize it may just not be the way to go.  Preferably, I'd like to know if anyone can do it better within the Stored Procedure, but if not, how do you all handle letting the user dynamically sort tables of data (bi-directionally, too) with ASP.NET?</p>

<p>And thank you for reading (or at least skimming) such a long question!</p>

<p>PS: Be glad I didn't show my example of a stored procedure that supports dynamic sorting, dynamic filtering/text-searching of columns, pagination via ROWNUMBER() OVER, <em>AND</em> try...catch with transaction rollbacking on errors... ""behemoth-sized"" doesn't even begin to describe them.</p>

<hr>

<p><strong>Update:</strong></p>

<ul>
<li>I would like to <strong>avoid dynamic SQL</strong>.  Parsing a string together and running an EXEC on it defeats a lot of the purpose of having a stored procedure in the first place.  Sometimes I wonder though if the cons of doing such a thing wouldn't be worth it, at least in these special dynamic sorting cases.  Still, I always feel dirty whenever I do dynamic SQL strings like that &mdash; like I'm still living in the Classic ASP world.</li>
<li>A lot of the reason we want stored procedures in the first place is for <strong>security</strong>.  I don't get to make the call on security concerns, only suggest solutions.  With SQL Server 2005 we can set permissions (on a per-user basis if need be) at the schema level on individual stored procedures and then deny any queries against the tables directly.  Critiquing the pros and cons of this approach is perhaps for another question, but again it's not my decision.  I'm just the lead code monkey. :)</li>
</ul>
","<p>My applications do this a lot but they are all dynamically building the SQL. However, when I deal with stored procedures I do this:</p>

<ol>
<li>Make the stored procedure a function that returns a table of your values - no sort.</li>
<li>Then in your application code do a <code>select * from dbo.fn_myData() where ... order by ...</code> so you can dynamically specify the sort order there.</li>
</ol>

<p>Then at least the dynamic part is in your application, but the database is still doing the heavy lifting.</p>
"
81,32100,5,89,sql,What is the simplest SQL Query to find the second largest value?,"<p>What is the simplest SQL query to find the second largest integer value in a specific column? </p>

<p>There are maybe duplicate values in the column.</p>
","<p>The easiest would be to get the second value from this result set in the application:</p>

<pre><code>SELECT DISTINCT value FROM Table ORDER BY value DESC LIMIT 2
</code></pre>

<p>But if you must select the second value using SQL, how about:</p>

<pre><code>SELECT MIN(value) FROM (SELECT DISTINCT value FROM Table ORDER BY value DESC LIMIT 2) AS t
</code></pre>
"
84,32100,0,89,sql,What is the simplest SQL Query to find the second largest value?,"<p>What is the simplest SQL query to find the second largest integer value in a specific column? </p>

<p>There are maybe duplicate values in the column.</p>
","<pre><code>select top 1 MyIntColumn from MyTable
where
 MyIntColumn &lt;&gt; (select top 1 MyIntColumn from MyTable order by MyIntColumn desc)
order by MyIntColumn desc
</code></pre>
"
83,32100,163,89,sql,What is the simplest SQL Query to find the second largest value?,"<p>What is the simplest SQL query to find the second largest integer value in a specific column? </p>

<p>There are maybe duplicate values in the column.</p>
","<pre><code>SELECT MAX( col )
  FROM table
 WHERE col &lt; ( SELECT MAX( col )
                 FROM table )
</code></pre>
"
85,32100,0,89,sql,What is the simplest SQL Query to find the second largest value?,"<p>What is the simplest SQL query to find the second largest integer value in a specific column? </p>

<p>There are maybe duplicate values in the column.</p>
","<p>This works in MS SQL:</p>

<pre><code>select max([COLUMN_NAME]) from [TABLE_NAME] where [COLUMN_NAME] &lt; 
 ( select max([COLUMN_NAME]) from [TABLE_NAME] )
</code></pre>
"
87,32100,24,89,sql,What is the simplest SQL Query to find the second largest value?,"<p>What is the simplest SQL query to find the second largest integer value in a specific column? </p>

<p>There are maybe duplicate values in the column.</p>
","<p>In T-Sql there are two ways:</p>

<pre><code>--filter out the max
select max( col )
from [table]
where col &lt; ( 
    select max( col )
    from [table] )

--sort top two then bottom one
select top 1 col 
from (
    select top 2 col 
    from [table]
    order by col) topTwo
order by col desc 
</code></pre>

<p>In Microsoft SQL the first way is twice as fast as the second, even if the column in question is clustered.</p>

<p>This is because the sort operation is relatively slow compared to the table or index scan that the <code>max</code> aggregation uses.</p>

<p>Alternatively, in Microsoft SQL 2005 and above you can use the <code>ROW_NUMBER()</code> function:</p>

<pre><code>select col
from (
    select ROW_NUMBER() over (order by col asc) as 'rowNum', col
    from [table] ) withRowNum 
where rowNum = 2
</code></pre>
"
86,32100,0,89,sql,What is the simplest SQL Query to find the second largest value?,"<p>What is the simplest SQL query to find the second largest integer value in a specific column? </p>

<p>There are maybe duplicate values in the column.</p>
","<p>Something like this? I haven't tested it, though:</p>

<pre><code>select top 1 x
from (
  select top 2 distinct x 
  from y 
  order by x desc
) z
order by x
</code></pre>
"
88,32100,0,89,sql,What is the simplest SQL Query to find the second largest value?,"<p>What is the simplest SQL query to find the second largest integer value in a specific column? </p>

<p>There are maybe duplicate values in the column.</p>
","<p>See <a href=""http://stackoverflow.com/questions/16568"" rel=""nofollow"">http://stackoverflow.com/questions/16568</a>.</p>

<p>Sybase SQL Anywhere supports:</p>

<pre><code>SELECT TOP 1 START AT 2 value from table ORDER BY value
</code></pre>
"
89,32100,12,89,sql,What is the simplest SQL Query to find the second largest value?,"<p>What is the simplest SQL query to find the second largest integer value in a specific column? </p>

<p>There are maybe duplicate values in the column.</p>
","<p>I see both some SQL Server specific and some MySQL specific solutions here, so you might want to clarify which database you need.  Though if I had to guess I'd say SQL Server since this is trivial in MySQL.</p>

<p>I also see some solutions that won't work because they fail to take into account the possibility for duplicates, so be careful which ones you accept.  Finally, I see a few that will work but that will make two complete scans of the table.  You want to make sure the 2nd scan is only looking at 2 values.</p>

<p>SQL Server (pre-2012):</p>

<pre><code>SELECT MIN([column]) AS [column]
FROM (
    SELECT TOP 2 [column] 
    FROM [Table] 
    GROUP BY [column] 
    ORDER BY [column] DESC
) a
</code></pre>

<p>MySQL:</p>

<pre><code>SELECT `column` 
FROM `table` 
GROUP BY `column` 
ORDER BY `column` 
DESC LIMIT 1,1
</code></pre>

<p><strong>Update:</strong></p>

<p>SQL Server 2012 now supports a much cleaner (and <a href=""http://en.wikipedia.org/wiki/SQL:2011""><em>standard</em></a>) OFFSET/FETCH syntax:</p>

<pre><code>SELECT TOP 2 [column] 
FROM [Table] 
GROUP BY [column] 
ORDER BY [column] DESC
OFFSET 1 ROWS
FETCH NEXT 1 ROWS ONLY;
</code></pre>
"
82,32100,10,89,sql,What is the simplest SQL Query to find the second largest value?,"<p>What is the simplest SQL query to find the second largest integer value in a specific column? </p>

<p>There are maybe duplicate values in the column.</p>
","<p>I suppose you can do something like:</p>

<pre><code>SELECT * FROM Table ORDER BY NumericalColumn DESC LIMIT 1 OFFSET 1
</code></pre>

<p>or</p>

<pre><code>SELECT * FROM Table ORDER BY NumericalColumn DESC LIMIT (1, 1)
</code></pre>

<p>depending on your database server. Hint: SQL Server doesn't do LIMIT.</p>
"
30,13540,5,83,sql,Insert Update stored proc on SQL Server,"<p>I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:</p>

<pre><code>update myTable set Col1=@col1, Col2=@col2 where ID=@ID
if @@rowcount = 0
insert into myTable (Col1, Col2) values (@col1, @col2)
</code></pre>

<p>My logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.</p>

<p>The alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.</p>

<p>Is my logic sound here?
Is this how you would combine an insert and update into a stored proc?</p>
","<p>MERGE is one of the new features in SQL Server 2008, by the way.</p>
"
31,13540,7,83,sql,Insert Update stored proc on SQL Server,"<p>I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:</p>

<pre><code>update myTable set Col1=@col1, Col2=@col2 where ID=@ID
if @@rowcount = 0
insert into myTable (Col1, Col2) values (@col1, @col2)
</code></pre>

<p>My logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.</p>

<p>The alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.</p>

<p>Is my logic sound here?
Is this how you would combine an insert and update into a stored proc?</p>
","<p>If to be used with SQL Server 2000/2005 the original code needs to be enclosed in transaction to make sure that data remain consistent in concurrent scenario.</p>

<pre><code>BEGIN TRANSACTION Upsert
update myTable set Col1=@col1, Col2=@col2 where ID=@ID
if @@rowcount = 0
insert into myTable (Col1, Col2) values (@col1, @col2)
COMMIT TRANSACTION Upsert
</code></pre>

<p>This will incur additional performance cost, but will ensure data integrity.</p>

<p>Add, as already suggested, MERGE should be used where available.</p>
"
33,13540,1,83,sql,Insert Update stored proc on SQL Server,"<p>I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:</p>

<pre><code>update myTable set Col1=@col1, Col2=@col2 where ID=@ID
if @@rowcount = 0
insert into myTable (Col1, Col2) values (@col1, @col2)
</code></pre>

<p>My logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.</p>

<p>The alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.</p>

<p>Is my logic sound here?
Is this how you would combine an insert and update into a stored proc?</p>
","<p>Your logic seems sound, but you might want to consider adding some code to prevent the insert if you had passed in a specific primary key.</p>

<p>Otherwise, if you're always doing an insert if the update didn't affect any records, what happens when someone deletes the record before you ""UPSERT"" runs?  Now the record you were trying to update doesn't exist, so it'll create a record instead.  That probably isn't the behavior you were looking for.</p>
"
36,13540,44,83,sql,Insert Update stored proc on SQL Server,"<p>I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:</p>

<pre><code>update myTable set Col1=@col1, Col2=@col2 where ID=@ID
if @@rowcount = 0
insert into myTable (Col1, Col2) values (@col1, @col2)
</code></pre>

<p>My logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.</p>

<p>The alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.</p>

<p>Is my logic sound here?
Is this how you would combine an insert and update into a stored proc?</p>
","<p>Please read the <a href=""http://samsaffron.com/blog/archive/2007/04/04/14.aspx"">post on my blog</a> for a good, safe pattern you can use. There are a lot of considerations, and the accepted answer on this question is far from safe. </p>

<p>For a quick answer try the following pattern. It will work fine on SQL 2000 and above. SQL 2005 gives you error handling which opens up other options and SQL 2008 gives you a MERGE command. </p>

<pre><code>begin tran
   update t with (serializable)
   set hitCount = hitCount + 1
   where pk = @id
   if @@rowcount = 0
   begin
      insert t (pk, hitCount)
      values (@id,1)
   end
commit tran
</code></pre>
"
35,13540,5,83,sql,Insert Update stored proc on SQL Server,"<p>I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:</p>

<pre><code>update myTable set Col1=@col1, Col2=@col2 where ID=@ID
if @@rowcount = 0
insert into myTable (Col1, Col2) values (@col1, @col2)
</code></pre>

<p>My logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.</p>

<p>The alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.</p>

<p>Is my logic sound here?
Is this how you would combine an insert and update into a stored proc?</p>
","<p>You not only need to run it in transaction, it also needs high isolation level. I fact default isolation level is Read Commited and this code need Serializable. </p>

<pre><code>SET transaction isolation level SERIALIZABLE
BEGIN TRANSACTION Upsert
UPDATE myTable set Col1=@col1, Col2=@col2 where ID=@ID
if @@rowcount = 0
  begin
    INSERT into myTable (ID, Col1, Col2) values (@ID @col1, @col2)
  end
COMMIT TRANSACTION Upsert
</code></pre>

<p>Mayne adding also the @@error check and rollback could be good idea.</p>
"
34,13540,3,83,sql,Insert Update stored proc on SQL Server,"<p>I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:</p>

<pre><code>update myTable set Col1=@col1, Col2=@col2 where ID=@ID
if @@rowcount = 0
insert into myTable (Col1, Col2) values (@col1, @col2)
</code></pre>

<p>My logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.</p>

<p>The alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.</p>

<p>Is my logic sound here?
Is this how you would combine an insert and update into a stored proc?</p>
","<p>If you are not doing a merge in SQL 2008 you must change it to:</p>

<p>if @@rowcount = 0 and @@error=0</p>

<p>otherwise if the update fails for some reason then it will try and to an insert afterwards because the rowcount on a failed statement is 0</p>
"
29,13540,48,83,sql,Insert Update stored proc on SQL Server,"<p>I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:</p>

<pre><code>update myTable set Col1=@col1, Col2=@col2 where ID=@ID
if @@rowcount = 0
insert into myTable (Col1, Col2) values (@col1, @col2)
</code></pre>

<p>My logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.</p>

<p>The alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.</p>

<p>Is my logic sound here?
Is this how you would combine an insert and update into a stored proc?</p>
","<p>Your assumption is right, this is the optimal way to do it and it's called <a href=""http://en.wikipedia.org/wiki/Upsert"">upsert/merge</a>.</p>

<p><a href=""http://www.sqlservercentral.com/articles/T-SQL/61773/"">Importance of UPSERT - from sqlservercentral.com</a>: </p>

<blockquote>
  <p>For every update in the case mentioned above we are removing one
  additional read from the table if we
  use the UPSERT instead of EXISTS.
  Unfortunately for an Insert, both the
  UPSERT and IF EXISTS methods use the
  same number of reads on the table.
  Therefore the check for existence
  should only be done when there is a
  very valid reason to justify the
  additional I/O. The optimized way to
  do things is to make sure that you
  have little reads as possible on the
  DB.</p>
  
  <p>The best strategy is to attempt the
  update. If no rows are affected by the
  update then insert. In most
  circumstances, the row will already
  exist and only one I/O will be
  required.</p>
</blockquote>

<p><strong>Edit</strong>: 
Please check out <a href=""http://stackoverflow.com/questions/13540/insert-update-stored-proc-on-sql-server/193876#193876"">this answer</a> and the linked blog post to learn about the problems with this pattern and how to make it work safe.</p>
"
32,13540,3,83,sql,Insert Update stored proc on SQL Server,"<p>I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:</p>

<pre><code>update myTable set Col1=@col1, Col2=@col2 where ID=@ID
if @@rowcount = 0
insert into myTable (Col1, Col2) values (@col1, @col2)
</code></pre>

<p>My logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.</p>

<p>The alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.</p>

<p>Is my logic sound here?
Is this how you would combine an insert and update into a stored proc?</p>
","<p>Big fan of the UPSERT, really cuts down on the code to manage.  Here is another way I do it:  One of the input parameters is ID, if the ID is NULL or 0, you know it's an INSERT, otherwise it's an update.  Assumes the application knows if there is an ID, so wont work in all situations, but will cut the executes in half if you do.</p>
"
949,441600,26,78,sql,Write a number with two decimal places SQL server,"<p>How do you write a number with two decimal places for sql server?</p>
","<p>Generally you can define the precision of a number in SQL by defining it with parameters. For most cases this will be <code>NUMERIC(10,2)</code> or <code>Decimal(10,2)</code> - will define a column as a Number with 10 total digits with a precision of 2 (decimal places).</p>

<p><em>Edited for clarity</em></p>
"
164,59880,0,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>Realising this is a bit off-topic to the question, but if you are using a lot of stored procedures, make sure there is a consistent way to put them under some sort of source control (e.g., subversion or git) and be able to migrate updates from your development system to the test system to the production system.</p>

<p>When this is done by hand, with no way to easily audit what code is where, this quickly becomes a nightmare.</p>
"
950,441600,43,78,sql,Write a number with two decimal places SQL server,"<p>How do you write a number with two decimal places for sql server?</p>
","<p>Use <code>Str()</code> Function. It takes three arguments(the number, the number total characters to display, and the number of decimal places to display</p>

<pre><code>  Select Str(12345.6789, 12, 3)
</code></pre>

<p>displays:  '   12345.679'  ( 3 spaces, 5 digits 12345, a decimal point, and three decimal digits (679). - it rounds if it has to truncate, (unless the integer part is too large for the total size, in which case asterisks are displayed instead.)</p>

<p>for a Total of 12 characters, with 3 to the right of decimal point.</p>
"
152,59880,0,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>I don't know that they are faster. I like using ORM for data access (to not re-invent the wheel) but I realize that's not always a viable option. </p>

<p>Frans Bouma has a good article on this subject : <a href=""http://weblogs.asp.net/fbouma/archive/2003/11/18/38178.aspx"" rel=""nofollow"">http://weblogs.asp.net/fbouma/archive/2003/11/18/38178.aspx</a></p>
"
153,59880,0,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>Stored procs are great for cases where the SQL code is run frequently because the database stores it tokenized in memory.  If you repeatedly ran the same code outside of a stored proc, you will likey incur a performance hit from the database reparsing the same code over and over.</p>

<p>I typically frequently called code as a stored proc or as a SqlCommand (.NET) object and execute as many times as needed.</p>
"
154,59880,1,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>Read Frans Bouma's <a href=""http://weblogs.asp.net/fbouma/archive/2003/11/18/38178.aspx"" rel=""nofollow"">excellent post</a> (if a bit biased) on that.</p>
"
155,59880,14,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>In many cases, stored procedures are actually slower because they're more genaralized. While stored procedures can be highly tuned, in my experience there's enough development and institutional friction that they're left in place once they work, so stored procedures often tend to return a lot of columns ""just in case"" - because you don't want to deploy a new stored procedure every time you change your application. An OR/M, on the other hand, only requests the columns the application is using, which cuts down on network traffic, unnecessary joins, etc.</p>
"
156,59880,1,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>All I can speak to is SQL server. In that platform, stored procedures are lovely because the server stores the execution plan, which in most cases speeds up performance a good bit. I say ""in most cases"", because if the SP has widely varying paths of execution you might get suboptimal performance. However, even in those cases, some enlightened refactoring of the SPs can speed things up.</p>
"
157,59880,9,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>It's a debate that rages on and on (for instance, <a href=""http://stackoverflow.com/questions/22907/which-is-better-ad-hoc-queries-or-stored-procedures"" rel=""nofollow"">here</a>).</p>

<p>It's as easy to write bad stored procedures as it is to write bad data access logic in your app.</p>

<p>My preference is for Stored Procs, but that's because I'm typically working with very large and complex apps in an enterprise environment where there are dedicated DBAs who are responsible for keeping the database servers running sweetly.</p>

<p>In other situations, I'm happy enough for data access technologies such as LINQ to take care of the optimisation.</p>

<p>Pure performance isn't the only consideration, though. Aspects such as security and configuration management are typically at least as important.</p> 

<p>Edit: While Frans Bouma's article is indeed verbose, it misses the point with regard to security by a mile. The fact that it's 5 years old doesn't help its relevance, either.</p>
"
165,59880,3,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>The one topic that no one has yet mentioned as a benefit of stored procedures is security.  If you build the application exclusively with data access via stored procedures, you can lockdown the database so the ONLY access is via those stored procedures.  Therefor, even if someone gets a database ID and password, they will be limited in what they can see or do against that database.</p>
"
951,441600,121,78,sql,Write a number with two decimal places SQL server,"<p>How do you write a number with two decimal places for sql server?</p>
","<p>try this</p>

<pre><code>SELECT CONVERT(DECIMAL(10,2),YOURCOLUMN)
</code></pre>
"
158,59880,2,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>I prefer to use SP's when it makes sense to use them.  In SQL Server anyway there is no performance advantage to SP's over a parametrized query.</p>

<p>However, at my current job my boss mentioned that we are forced to use SP's because our customer's require them.  They feel that they are more secure.  I have not been here long enough to see if we are implementing role based security but I have a feeling we do.</p>

<p>So the customer's feelings trump all other arguments in this case.</p>
"
169,59880,-2,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>Reduced network traffic -- SP are generally worse then Dynamic SQL.  Because people don't create a new SP for every select, if you need just one column you are told use the SP that has the columns they need and ignore the rest.  Get an extra column and any less network usage you had just went away.  Also you tend to have a lot of client filtering when SP are used.</p>

<p>caching -- MS-SQL does not treat them any differently, not since MS-SQL 2000 may of been 7 but I don't remember.</p>

<p>permissions -- Not a problem since almost everything I do is web or have some middle application tier that does all the database access.  The only software I work with that have direct client to database access are 3rd party products that are designed for users to have direct access and are based around giving users permissions.  And yes MS-SQL permission security model SUCKS!!! (have not spent time on 2008 yet)  As a final part to this would like to see a survey of how many people are still doing direct client/server programming vs web and middle application server programming; and if they are doing large projects why no ORM.</p>

<p>Separation -- people would question why you are putting business logic outside of middle tier. Also if you are looking to separate data handling code there are ways of doing that without putting it in the database.</p>

<p>Ability to edit -- What you have no testing and version control you have to worry about?  Also only a problem with client/server, in the web world not problem.</p>

<p>Find the table -- Only if you can identify the SP that use it, will stick with the tools of the version control system, agent ransack or visual studio to find.</p>

<p>Optimization -- Your DBA should be using the tools of the database to find the queries that need optimization. Database can tell the DBA what statements are talking up the most time and resources and they can fix from there. For complex SQL statements the programmers should be told to talk to the DBA if simple selects don't worry about it.</p>

<p>SQL injection attacks -- SP offer no better protection.  The only thing they get the nod is that most of them teach using parameters vs dynamic SQL most examples ignore parameters.</p>
"
160,59880,2,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>Obviously, actual performance ought to be measured in individual cases, not assumed.  But even in cases where performance is <em>hampered</em> by a stored procedure, there are good reasons to use them:</p>

<ol>
<li><p>Application developers aren't always the best SQL coders.  Stored procedures hides SQL from the application.</p></li>
<li><p>Stored procedures automatically use bind variables.  Application developers often avoid bind variables because they seem like unneeded code and show little benefit in small test systems.  Later on, the failure to use bind variables can throttle RDBMS performance.</p></li>
<li><p>Stored procedures create a layer of indirection that might be useful later on.  It's possible to change implementation details (including table structure) on the database side without touching application code.</p></li>
<li><p>The exercise of creating stored procedures can be useful for documenting all database interactions for a system.  And it's easier to update the documentation when things change.</p></li>
</ol>

<p>That said, I usually stick raw SQL in my applications so that I can control it myself.  It depends on your development team and philosophy.</p>
"
161,59880,209,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<blockquote>
  <p><strong>NOTE</strong> that this is a general look at stored procedures not regulated to a specific
  DBMS. Some DBMS (and even, different
  versions of the same DBMS!) may operate
  contrary to this, so you'll want to
  double-check with your target DBMS
  before assuming all of this still holds.</p>
  
  <p>I've been a Sybase ASE, MySQL, and SQL Server DBA on-and off since for almost a decade (along with application development in C, PHP, PL/SQL, C#.NET, and Ruby). So, I have no particular axe to grind in this (sometimes) holy war.</p>
</blockquote>

<p>The historical performance benefit of stored procs have generally been from the following (in no particular order):</p>

<ul>
<li>Pre-parsed SQL</li>
<li>Pre-generated query execution plan</li>
<li>Reduced network latency</li>
<li>Potential cache benefits</li>
</ul>

<p><strong>Pre-parsed SQL</strong> -- similar benefits to compiled vs. interpreted code, except on a very micro level. </p>

<p><em>Still an advantage?</em> 
Not very noticeable at all on the modern CPU, but if you are sending a single SQL statement that is VERY large eleventy-billion times a second, the parsing overhead can add up.</p>

<p><strong>Pre-generated query execution plan</strong>. 
If you have many JOINs the permutations can grow quite unmanageable (modern optimizers have limits and cut-offs for performance reasons). It is not unknown for very complicated SQL to have distinct, measurable (I've seen a complicated query take 10+ seconds just to generate a plan, before we tweaked the DBMS) latencies due to the optimizer trying to figure out the ""near best"" execution plan. Stored procedures will, generally, store this in memory so you can avoid this overhead.</p>

<p><em>Still an advantage?</em> 
Most DBMS' (the latest editions) will cache the query plans for INDIVIDUAL SQL statements, greatly reducing the performance differential between stored procs and ad hoc SQL. There are some caveats and cases in which this isn't the case, so you'll need to test on your target DBMS.</p>

<p>Also, more and more DBMS allow you to provide optimizer path plans (abstract query plans) to significantly reduce optimization time (for both ad hoc and stored procedure SQL!!).</p>

<blockquote>
  <p><strong>WARNING</strong> Cached query plans are not a performance panacea. Occasionally the query plan that is generated is sub-optimal.
  For example, if you send <code>SELECT *
  FROM table WHERE id BETWEEN 1 AND
  99999999</code>, the DBMS may select a
  full-table scan instead of an index
  scan because you're grabbing every row
  in the table (so sayeth the
  statistics). If this is the cached
  version, then you can get poor
  performance when you later send
  <code>SELECT * FROM table WHERE id BETWEEN
  1 AND 2</code>. The reasoning behind this is
  outside the scope of this posting, but
  for further reading see:
  <a href=""http://www.microsoft.com/technet/prodtechnol/sql/2005/frcqupln.mspx"">http://www.microsoft.com/technet/prodtechnol/sql/2005/frcqupln.mspx</a>
  and
  <a href=""http://msdn.microsoft.com/en-us/library/ms181055.aspx"">http://msdn.microsoft.com/en-us/library/ms181055.aspx</a>
  and <a href=""http://www.simple-talk.com/sql/performance/execution-plan-basics/"">http://www.simple-talk.com/sql/performance/execution-plan-basics/</a></p>
  
  <p>""In summary, they determined that
  supplying anything other than the
  common values when a compile or
  recompile was performed resulted in
  the optimizer compiling and caching
  the query plan for that particular
  value. Yet, when that query plan was
  reused for subsequent executions of
  the same query for the common values
  (M, R, or T), it resulted in
  sub-optimal performance. This
  sub-optimal performance problem
  existed until the query was
  recompiled. At that point, based on
  the @P1 parameter value supplied, the
  query might or might not have a
  performance problem.""</p>
</blockquote>

<p><strong>Reduced network latency</strong>
A) If you are running the same SQL over and over -- and the SQL adds up to many KB of code -- replacing that with a simple ""exec foobar"" can really add up.
B) Stored procs can be used to move procedural code into the DBMS. This saves shuffling large amounts of data off to the client only to have it send a trickle of info back (or none at all!). Analogous to doing a JOIN in the DBMS vs. in your code (everyone's favorite WTF!)</p>

<p><em>Still an advantage?</em>
A) Modern 1Gb (and 10Gb and up!) Ethernet really make this negligible. 
B) Depends on how saturated your network is -- why shove several megabytes of data back and forth for no good reason?</p>

<p><strong>Potential cache benefits</strong>
Performing server-side transforms of data can potentially be faster if you have sufficient memory on the DBMS and the data you need is in memory of the server.</p>

<p><em>Still an advantage?</em>
Unless your app has shared memory access to DBMS data, the edge will always be to stored procs.</p>

<p>Of course, no discussion of Stored Procedure optimization would be complete without a discussion of parameterized and ad hoc SQL.</p>

<p><strong>Parameterized / Prepared SQL</strong><br />
Kind of a cross between stored procedures and ad hoc SQL, they are embedded SQL statements in a host language that uses ""parameters"" for query values, e.g.:</p>

<pre><code>SELECT .. FROM yourtable WHERE foo = ? AND bar = ?
</code></pre>

<p>These provide a more generalized version of a query that modern-day optimizers can use to cache (and re-use) the query execution plan, resulting in much of the performance benefit of stored procedures.</p>

<p><strong>Ad Hoc SQL</strong>
Just open a console window to your DBMS and type in a SQL statement. In the past, these were the ""worst"" performers (on average) since the DBMS had no way of pre-optimizing the queries as in the parameterized/stored proc method.</p>

<p><em>Still a disadvantage?</em>
Not necessarily. Most DBMS have the ability to ""abstract"" ad hoc SQL into parameterized versions -- thus more or less negating the difference between the two. Some do this implicitly or must be enabled with a command setting (SQL server: <a href=""http://msdn.microsoft.com/en-us/library/ms175037.aspx"">http://msdn.microsoft.com/en-us/library/ms175037.aspx</a> , Oracle: <a href=""http://www.praetoriate.com/oracle_tips_cursor_sharing.htm"">http://www.praetoriate.com/oracle_tips_cursor_sharing.htm</a>).</p>

<p><strong>Lessons learned?</strong>
Moore's law continues to march on and DBMS optimizers, with every release, get more sophisticated. Sure, you can place every single silly teeny SQL statement inside a stored proc, but just know that the programmers working on optimizers are very smart and are continually looking for ways to improve performance. Eventually (if it's not here already) ad hoc SQL performance will become indistinguishable (on average!) from stored procedure performance, so any sort of <em>massive</em> stored procedure use ** solely for ""performance reasons""** sure sounds like premature optimization to me.</p>

<p>Anyway, I think if you avoid the edge cases and have fairly vanilla SQL, you won't notice a difference between ad hoc and stored procedures.</p>
"
162,59880,0,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>Using stored procedures for CRUD operations is probably overkill, but it will depend on the tools be used and your own preferences (or requirements).  I prefer inline SQL, but I make sure to use parameterized queries to prevent SQL injection attacks.  I keep a print out of this <a href=""http://xkcd.com/327/"" rel=""nofollow"">xkcd comic</a> as a reminder of what can go wrong if you are not careful.</p>

<p>Stored procedures can have real performance benefits when you are working with multiple sets of data to return a single set of data.  It's usually more efficient to process sets of data in the stored procedure than sending them over the wire to be processed at the client end.</p>
"
163,59880,0,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>Yes, they are faster most of time. SQL composition is a huge performance tuning area too. If I am doing a back office type app I may skip them but anything production facing I use them for sure for all the reasons others spoke too...namely security. </p>
"
166,59880,0,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>IMHO...</p>

<p>Restricting ""C_UD"" operations to stored procedures can keep the data integrity logic in one place. This can also be done by restricting""C_UD"" operations to a single middle ware layer.</p>

<p>Read operations can be provided to the application so they can join only the tables / columns they need.</p>
"
167,59880,0,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>Stored procedures can also be used instead of parameterized queries (or ad-hoc queries) for some other advantages too :</p>

<ul>
<li>If you need to correct something (a sort order etc.) you don't need to recompile your app</li>
<li>You could deny access to all tables for that user account, grant access only to stored procedures and route all access through stored procedures. This way you can have custom validation of all input much more flexible than table constraints.</li>
</ul>
"
159,59880,6,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>There is no noticeable speed difference for stored procedures vs parameterized or prepared queries on most modern databases, because the database will also cache execution plans for those queries.  </p>

<p>Note that a parameterized query is not the same as ad hoc sql.</p>

<p>The main reason imo to still favor stored procedures today has more to do with security.  If you use stored procedures <em>exclusively</em>, you can disable INSERT, SELECT, UPDATE, DELETE, ALTER, DROP, and CREATE etc permissions for your application's user, only leaving it with EXECUTE.  </p>

<p>This provides a little extra protection against <em>2nd order</em> sql injection.  Parameterized queries only protect against <em>1st order</em> injection.</p>
"
168,59880,14,78,sql,"Are Stored Procedures more efficient, in general, than inline statements on modern RDBMS's?","<p>Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them <strong>ALL THE TIME</strong>.</p>

<p>I am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?</p>
","<p>Reasons for using stored procedures:</p>

<ul>
<li><strong>Reduce network traffic</strong> -- you have to send the SQL statement across the network. With sprocs, you can execute SQL in batches, which is also more efficient.</li>
<li><strong>Caching query plan</strong> -- the first time the sproc is executed, SQL Server creates an execution plan, which is cached for reuse. This is particularly performant for small queries run frequently.</li>
<li><strong>Ability to use output parameters</strong> -- if you send inline SQL that returns one row, you can only get back a recordset. With sprocs you can get them back as output parameters, which is considerably faster.</li>
<li><strong>Permissions</strong> -- when you send inline SQL, you have to grant permissions on the table(s) to the user, which is granting much more access than merely granting permission to execute a sproc</li>
<li><strong>Separation of logic</strong> -- remove the SQL-generating code and segregate it in the database.</li>
<li><strong>Ability to edit without recompiling</strong> -- this can be controversial. You can edit the SQL in a sproc without having to recompile the application.</li>
<li><strong>Find where a table is used</strong> -- with sprocs, if you want to find all SQL statements referencing a particular table, you can export the sproc code and search it. This is much easier than trying to find it in code.</li>
<li><strong>Optimization</strong> -- It's easier for a DBA to optimize the SQL and tune the database when sprocs are used. It's easier to find missing indexes and such.</li>
<li><strong>SQL injection attacks</strong> -- properly written inline SQL can defend against attacks, but sprocs are better for this protection.</li>
</ul>
"
8,2120,118,77,sql,Convert HashBytes to VarChar,"<p>I want to get the MD5 Hash of a string value in SQL Server 2005. I do this with the following command:</p>

<pre><code>SELECT HashBytes('MD5', 'HelloWorld')
</code></pre>

<p>However, this returns a VarBinary instead of a VarChar value. If I attempt to convert <code>0x68E109F0F40CA72A15E05CC22786F8E6</code> into a VarChar I get <code>h *\'</code> instead of <code>68E109F0F40CA72A15E05CC22786F8E6</code>.</p>

<p>Is there any SQL-based solution?</p>

<p><strong><a href=""http://stackoverflow.com/questions/2120/#2382"">Yes</a></strong></p>
","<p>I have found the solution else where:</p>

<pre><code>SELECT SUBSTRING(master.dbo.fn_varbintohexstr(HashBytes('MD5', 'HelloWorld')), 3, 32) <br></code></pre>"
494,207190,24,76,sql,Sql Server string to date conversion,"<p>I want to convert a string like this:</p>

<pre><code>'10/15/2008 10:06:32 PM'
</code></pre>

<p>into the equivalent DATETIME value in Sql Server.</p>

<p>In Oracle, I would say this:</p>

<pre><code>TO_DATE('10/15/2008 10:06:32 PM','MM/DD/YYYY HH:MI:SS AM')
</code></pre>

<p><a href=""http://stackoverflow.com/questions/202243/custom-datetime-formatting-in-sql-server"">This question</a> implies that I must parse the string into one of the <a href=""http://www.sql-server-helper.com/tips/date-formats.aspx"" rel=""nofollow"">standard formats</a>, and then convert using one of those codes.  That seems ludicrous for such a mundane operation.  Is there an easier way?</p>
","<p>SQL Server (2005, 2000, 7.0) does not have any flexible, or even non-flexible, way of taking an arbitrarily structured datetime in string format and converting it to the datetime data type.</p>

<p>By ""arbitrarily"", I mean ""a form that the person who wrote it, though perhaps not you or I or someone on the other side of the planet, would consider to be intuitive and completely obvious.""  Frankly, I'm not sure there is any such algorithm.</p>
"
493,207190,2,76,sql,Sql Server string to date conversion,"<p>I want to convert a string like this:</p>

<pre><code>'10/15/2008 10:06:32 PM'
</code></pre>

<p>into the equivalent DATETIME value in Sql Server.</p>

<p>In Oracle, I would say this:</p>

<pre><code>TO_DATE('10/15/2008 10:06:32 PM','MM/DD/YYYY HH:MI:SS AM')
</code></pre>

<p><a href=""http://stackoverflow.com/questions/202243/custom-datetime-formatting-in-sql-server"">This question</a> implies that I must parse the string into one of the <a href=""http://www.sql-server-helper.com/tips/date-formats.aspx"" rel=""nofollow"">standard formats</a>, and then convert using one of those codes.  That seems ludicrous for such a mundane operation.  Is there an easier way?</p>
","<p>This <a href=""http://msdn.microsoft.com/en-us/library/aa226054(SQL.80).aspx"" rel=""nofollow"">page</a> has some references for all of the specified datetime conversions available to the CONVERT function.  If your values don't fall into one of the acceptable patterns, then I think the best thing is to go the ParseExact route.</p>
"
492,207190,1,76,sql,Sql Server string to date conversion,"<p>I want to convert a string like this:</p>

<pre><code>'10/15/2008 10:06:32 PM'
</code></pre>

<p>into the equivalent DATETIME value in Sql Server.</p>

<p>In Oracle, I would say this:</p>

<pre><code>TO_DATE('10/15/2008 10:06:32 PM','MM/DD/YYYY HH:MI:SS AM')
</code></pre>

<p><a href=""http://stackoverflow.com/questions/202243/custom-datetime-formatting-in-sql-server"">This question</a> implies that I must parse the string into one of the <a href=""http://www.sql-server-helper.com/tips/date-formats.aspx"" rel=""nofollow"">standard formats</a>, and then convert using one of those codes.  That seems ludicrous for such a mundane operation.  Is there an easier way?</p>
","<p>If you want SQL Server to try and figure it out, just use CAST
CAST('whatever' AS datetime)
However that is a bad idea in general.  There are issues with international dates that would come up.  So as you've found, to avoid those issues, you want to use the ODBC canonical format of the date.  That is format number 120, 20 is the format for just two digit years.
I don't think SQL Server has a built-in function that allows you to provide a user given format.  You can write your own and might even find one if you search online.</p>
"
491,207190,25,76,sql,Sql Server string to date conversion,"<p>I want to convert a string like this:</p>

<pre><code>'10/15/2008 10:06:32 PM'
</code></pre>

<p>into the equivalent DATETIME value in Sql Server.</p>

<p>In Oracle, I would say this:</p>

<pre><code>TO_DATE('10/15/2008 10:06:32 PM','MM/DD/YYYY HH:MI:SS AM')
</code></pre>

<p><a href=""http://stackoverflow.com/questions/202243/custom-datetime-formatting-in-sql-server"">This question</a> implies that I must parse the string into one of the <a href=""http://www.sql-server-helper.com/tips/date-formats.aspx"" rel=""nofollow"">standard formats</a>, and then convert using one of those codes.  That seems ludicrous for such a mundane operation.  Is there an easier way?</p>
","<p>Run this through your query processor.  It formats dates and/or times like so and one of these should give you what you're looking for.  It wont be hard to adapt:  </p>

<pre><code>Declare @d datetime
select @d = getdate()

select @d as OriginalDate,
convert(varchar,@d,100) as ConvertedDate,
100 as FormatValue,
'mon dd yyyy hh:miAM (or PM)' as OutputFormat
union all
select @d,convert(varchar,@d,101),101,'mm/dd/yy'
union all
select @d,convert(varchar,@d,102),102,'yy.mm.dd'
union all
select @d,convert(varchar,@d,103),103,'dd/mm/yy'
union all
select @d,convert(varchar,@d,104),104,'dd.mm.yy'
union all
select @d,convert(varchar,@d,105),105,'dd-mm-yy'
union all
select @d,convert(varchar,@d,106),106,'dd mon yy'
union all
select @d,convert(varchar,@d,107),107,'Mon dd, yy'
union all
select @d,convert(varchar,@d,108),108,'hh:mm:ss'
union all
select @d,convert(varchar,@d,109),109,'mon dd yyyy hh:mi:ss:mmmAM (or PM)'
union all
select @d,convert(varchar,@d,110),110,'mm-dd-yy'
union all
select @d,convert(varchar,@d,111),111,'yy/mm/dd'
union all
select @d,convert(varchar,@d,12),12,'yymmdd'
union all
select @d,convert(varchar,@d,112),112,'yyyymmdd'
union all
select @d,convert(varchar,@d,113),113,'dd mon yyyy hh:mm:ss:mmm(24h)'
union all
select @d,convert(varchar,@d,114),114,'hh:mi:ss:mmm(24h)'
union all
select @d,convert(varchar,@d,120),120,'yyyy-mm-dd hh:mi:ss(24h)'
union all
select @d,convert(varchar,@d,121),121,'yyyy-mm-dd hh:mi:ss.mmm(24h)'
union all
select @d,convert(varchar,@d,126),126,'yyyy-mm-dd Thh:mm:ss:mmm(no spaces)'
</code></pre>
"
490,207190,10,76,sql,Sql Server string to date conversion,"<p>I want to convert a string like this:</p>

<pre><code>'10/15/2008 10:06:32 PM'
</code></pre>

<p>into the equivalent DATETIME value in Sql Server.</p>

<p>In Oracle, I would say this:</p>

<pre><code>TO_DATE('10/15/2008 10:06:32 PM','MM/DD/YYYY HH:MI:SS AM')
</code></pre>

<p><a href=""http://stackoverflow.com/questions/202243/custom-datetime-formatting-in-sql-server"">This question</a> implies that I must parse the string into one of the <a href=""http://www.sql-server-helper.com/tips/date-formats.aspx"" rel=""nofollow"">standard formats</a>, and then convert using one of those codes.  That seems ludicrous for such a mundane operation.  Is there an easier way?</p>
","<p>For this problem the best solution I use is to have a CLR function in Sql Server 2005 that uses one of DateTime.Parse or ParseExact function to return the DateTime value with a specified format.</p>
"
257,118190,118,74,sql,How do I ignore ampersands in a SQL script running from SQL Plus?,"<p>I have a SQL script that creates a package with a comment containing an ampersand (&amp;). When I run the script from SQL Plus, I am prompted to enter a substitute value for the string starting with &amp;. How do I disable this feature so that SQL Plus ignores the ampersand?</p>
","<p>This may work for you:</p>

<pre><code>set define off
</code></pre>

<p>Otherwise the ampersand needs to be at the end of a string, </p>

<pre><code>'StackOverflow &amp;' || ' you'
</code></pre>

<p>EDIT:  I was click-happy when saving...  This was referenced from a <a href=""http://blog.andrewbeacock.com/2008/09/using-ampersands-without-variable_15.html"">blog</a>.</p>
"
258,118190,1,74,sql,How do I ignore ampersands in a SQL script running from SQL Plus?,"<p>I have a SQL script that creates a package with a comment containing an ampersand (&amp;). When I run the script from SQL Plus, I am prompted to enter a substitute value for the string starting with &amp;. How do I disable this feature so that SQL Plus ignores the ampersand?</p>
","<p>According to <a href=""http://www.orafaq.com/wiki/SQL%2aPlus_FAQ#How_does_one_disable_interactive_prompting_in_SQL.2APlus.3F"" rel=""nofollow"">this nice FAQ</a> there are a couple solutions.</p>

<p>You might also be able to escape the ampersand with the backslash character ""\"" if you can modify the comment.</p>
"
1015,468990,33,71,sql,How can I combine multiple rows into a comma-delimited list in Oracle?,"<p>I have a simple query:</p>

<pre><code>select * from countries
</code></pre>

<p>with the following results:</p>

<pre><code>country_name
------------
Albania
Andorra
Antigua
.....
</code></pre>

<p>I would like to return the results in one row, so like this:</p>

<pre><code>Albania, Andorra, Antigua, ...
</code></pre>

<p>Of course, I can write a PL/SQL function to do the job (I already did in Oracle 10g), but is there a nicer, preferably non-Oracle-specific solution (or may be a built-in function) for this task?</p>

<p>I would generally use it to avoid multiple rows in a sub-query, so if a person has more then one citizenship, I do not want her/him to be a duplicate in the list.</p>

<p>My question is based on the similar question on <a href=""http://stackoverflow.com/questions/180032/how-can-i-combine-multiple-rows-into-a-comma-delimited-list-in-sql-server-2005"">SQL server 2005</a>.</p>

<p><strong>UPDATE</strong>:
My function looks like this:</p>

<pre><code>CREATE OR REPLACE FUNCTION APPEND_FIELD (sqlstr in varchar2, sep in varchar2 ) return varchar2 is
ret varchar2(4000) := '';
TYPE cur_typ IS REF CURSOR;
rec cur_typ;
field varchar2(4000);
begin
     OPEN rec FOR sqlstr;
     LOOP
         FETCH rec INTO field;
    	 EXIT WHEN rec%NOTFOUND;
         ret := ret || field || sep;
     END LOOP;
     if length(ret) = 0 then
          RETURN '';
     else
          RETURN substr(ret,1,length(ret)-length(sep));
     end if;
end;
</code></pre>
","<p>Here is a simple way without stragg or creating a function.  It is referenced in Tom Kyte's blog.  <a href=""http://tkyte.blogspot.com/2006/08/evolution.html"">http://tkyte.blogspot.com/2006/08/evolution.html</a></p>

<pre><code>create table countries ( country_name varchar2 (100));

insert into countries values ('Albania');

insert into countries values ('Andorra');

insert into countries values ('Antigua');


SELECT SUBSTR (SYS_CONNECT_BY_PATH (country_name , ','), 2) csv
      FROM (SELECT country_name , ROW_NUMBER () OVER (ORDER BY country_name ) rn,
                   COUNT (*) OVER () cnt
              FROM countries)
     WHERE rn = cnt
START WITH rn = 1
CONNECT BY rn = PRIOR rn + 1;

CSV                                                                             
--------------------------
Albania,Andorra,Antigua                                                         

1 row selected.
</code></pre>
"
1014,468990,1,71,sql,How can I combine multiple rows into a comma-delimited list in Oracle?,"<p>I have a simple query:</p>

<pre><code>select * from countries
</code></pre>

<p>with the following results:</p>

<pre><code>country_name
------------
Albania
Andorra
Antigua
.....
</code></pre>

<p>I would like to return the results in one row, so like this:</p>

<pre><code>Albania, Andorra, Antigua, ...
</code></pre>

<p>Of course, I can write a PL/SQL function to do the job (I already did in Oracle 10g), but is there a nicer, preferably non-Oracle-specific solution (or may be a built-in function) for this task?</p>

<p>I would generally use it to avoid multiple rows in a sub-query, so if a person has more then one citizenship, I do not want her/him to be a duplicate in the list.</p>

<p>My question is based on the similar question on <a href=""http://stackoverflow.com/questions/180032/how-can-i-combine-multiple-rows-into-a-comma-delimited-list-in-sql-server-2005"">SQL server 2005</a>.</p>

<p><strong>UPDATE</strong>:
My function looks like this:</p>

<pre><code>CREATE OR REPLACE FUNCTION APPEND_FIELD (sqlstr in varchar2, sep in varchar2 ) return varchar2 is
ret varchar2(4000) := '';
TYPE cur_typ IS REF CURSOR;
rec cur_typ;
field varchar2(4000);
begin
     OPEN rec FOR sqlstr;
     LOOP
         FETCH rec INTO field;
    	 EXIT WHEN rec%NOTFOUND;
         ret := ret || field || sep;
     END LOOP;
     if length(ret) = 0 then
          RETURN '';
     else
          RETURN substr(ret,1,length(ret)-length(sep));
     end if;
end;
</code></pre>
","<p>I have always had to write some PL/SQL for this or I just concatenate a ',' to the field and copy into an editor and remove the CR from the list giving me the single line.</p>

<p>That is,</p>

<pre><code>select country_name||', ' country from countries
</code></pre>

<p>A little bit long winded both ways.</p>

<p>If you look at Ask Tom you will see loads of possible solutions but they all revert to type declarations and/or PL/SQL</p>

<p><a href=""http://asktom.oracle.com/pls/asktom/f?p=100:11:0%3a%3a%3a%3aP11_QUESTION_ID:2196162600402"" rel=""nofollow"">Ask Tom</a></p>
"
1013,468990,4,71,sql,How can I combine multiple rows into a comma-delimited list in Oracle?,"<p>I have a simple query:</p>

<pre><code>select * from countries
</code></pre>

<p>with the following results:</p>

<pre><code>country_name
------------
Albania
Andorra
Antigua
.....
</code></pre>

<p>I would like to return the results in one row, so like this:</p>

<pre><code>Albania, Andorra, Antigua, ...
</code></pre>

<p>Of course, I can write a PL/SQL function to do the job (I already did in Oracle 10g), but is there a nicer, preferably non-Oracle-specific solution (or may be a built-in function) for this task?</p>

<p>I would generally use it to avoid multiple rows in a sub-query, so if a person has more then one citizenship, I do not want her/him to be a duplicate in the list.</p>

<p>My question is based on the similar question on <a href=""http://stackoverflow.com/questions/180032/how-can-i-combine-multiple-rows-into-a-comma-delimited-list-in-sql-server-2005"">SQL server 2005</a>.</p>

<p><strong>UPDATE</strong>:
My function looks like this:</p>

<pre><code>CREATE OR REPLACE FUNCTION APPEND_FIELD (sqlstr in varchar2, sep in varchar2 ) return varchar2 is
ret varchar2(4000) := '';
TYPE cur_typ IS REF CURSOR;
rec cur_typ;
field varchar2(4000);
begin
     OPEN rec FOR sqlstr;
     LOOP
         FETCH rec INTO field;
    	 EXIT WHEN rec%NOTFOUND;
         ret := ret || field || sep;
     END LOOP;
     if length(ret) = 0 then
          RETURN '';
     else
          RETURN substr(ret,1,length(ret)-length(sep));
     end if;
end;
</code></pre>
","<p>The fastest way it is to use the Oracle collect function. </p>

<p>You can also do this:</p>

<pre><code>select *
  2    from (
  3  select deptno,
  4         case when row_number() over (partition by deptno order by ename)=1
  5             then stragg(ename) over
  6                  (partition by deptno
  7                       order by ename
  8                         rows between unbounded preceding
  9                                  and unbounded following)
 10         end enames
 11    from emp
 12         )
 13   where enames is not null
</code></pre>

<p>Visit the site ask tom and search on 'stragg'  or 'string concatenation' . Lots of 
examples. There is also a not-documented oracle function to achieve your needs. </p>
"
504,208580,2,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>I think you can use anything for the ""ID"" as long as you're consistent. Including the table name is important to. I would suggest using a modeling tool like Erwin to enforce the naming conventions and standards so when writing queries it's easy to understand the relationships that may exist between tables. </p>

<p>What I mean by the first statement is, instead of ID you can use something else like 'recno'. So then this table would have a PK of invoice_recno and so on.</p>

<p>Cheers,
Ben</p>
"
505,208580,31,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>Theres been a nerd fight about this very thing in my company of late.  The advent of LINQ has made the redundant tablename+ID pattern even more obviously silly in my eyes.  I think most reasonable people will say that if you're hand writing your SQL in such a manner as that you have to specify table names to differentiate FKs then it's not only a savings on typing but it adds clarity to your SQL to use just the ID in that you can clearly see which is the PK and which is the FK.</p>

<p>ie.
LEFT JOIN Customers ON Employee.ID = Customer.EmployeeID</p>

<p>tells me not only that the two are linked but which is the PK and which is the FK</p>

<p>whereas in the old style you're forced to either look or hope that they were named well.</p>
"
510,208580,0,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>See the Interakt site's <a href=""http://www.interaktonline.com/Support/Articles/Details/Design+Your+Database-Database+Naming+Convention.html?id_art=24&amp;id_asc=221"" rel=""nofollow"">naming conventions</a> for a well thought out system of naming tables and columns. The method makes use of a suffix for each table (<code>_prd</code> for a product table, or <code>_ctg</code> for a category table) and appends that to each column in a given table. So the identity column for the products table would be <code>id_prd</code> and is therefore unique in the database.</p>

<p>They go one step further to help with understanding the foreign keys: The foreign key in the product table that refers to the category table would be <code>idctg_prd</code> so that it is obvious to which table it belong (<code>_prd</code> suffix) and to which table it refers (category).</p>

<p>Advantages are that there is no ambiguity with the identity columns in different tables, and that you can tell at a glance which columns a query is referring to by the column names.</p>
"
501,208580,1,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>For the column name in the database, I'd use ""InvoiceID"".</p>

<p>If I copy the fields into a unnamed struct via LINQ, I may name it ""ID"" there, if it's the only ID in the structure.</p>

<p>If the column is NOT going to be used in a foreign key, so that it's only used to uniquely identify a row for edit editing or deletion, I'll name it ""PK"".</p>
"
500,208580,8,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>It's not really important, you are likely to run into simalar problems in all naming conventions.</p>

<p>But it is important to be consistent so you don't have to look at the table definitions every time you write a query.</p>
"
499,208580,-2,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>You could use the following naming convention. It has its flaws but it solves your particular problems.</p>

<ol>
<li>Use short (3-4 characters) nicknames for the table names, i.e. Invoice - <code>inv</code>, InvoiceLines - <code>invl</code></li>
<li>Name the columns in the table using those nicknames, i.e. <code>inv_id</code>, <code>invl_id</code></li>
<li>For the reference columns use <code>invl_inv_id</code> for the names.</li>
</ol>

<p>this way you could say</p>

<pre><code>SELECT * FROM Invoice LEFT JOIN InvoiceLines ON inv_id = invl_inv_id
</code></pre>
"
498,208580,0,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>I definitely agree with including the table name in the ID field name, for exactly the reasons you give. Generally, this is the only field where I would include the table name.</p>
"
497,208580,6,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>For the sake of simplicity most people name the column on the table ID. If it has a foreign key reference on another table, then they explicity call it InvoiceID (to use your example) in the case of joins, you are aliasing the table anyway so the explicit inv.ID is still simpler than inv.InvoiceID</p>
"
502,208580,94,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>I always prefered ID to TableName + ID for the id column and then TableName + ID for a foreign key.  That way all tables have a the same name for the id field and there isn't a redundant description.  This seems simpler to me because all the tables have the same primary key field name.  </p>

<p>As far as joining tables and not knowing which Id field belongs to which table, in my opinion the query should be written to handle this situation.  Where I work, we always prefece the fields we use in a statement with the table/table alias.  </p>
"
503,208580,1,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>If you give each key a unique name, e.g. ""invoices.invoice_id"" instead of ""invoices.id"", then you can use the ""natural join"" and ""using"" operators with no worries. E.g.</p>

<pre><code>SELECT * FROM invoices NATURAL JOIN invoice_lines
SELECT * FROM invoices JOIN invoice_lines USING (invoice_id)
</code></pre>

<p>instead of</p>

<pre><code>SELECT * from invoices JOIN invoice_lines
    ON invoices.id = invoice_lines.invoice_id
</code></pre>

<p>SQL is verbose enough without making it more verbose.</p>
"
496,208580,0,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>I do hate the plain id name. I strongly prefer to always use the invoice_id or a variant thereof. I always know which table is the authoritative table for the id when I need to, but this confuses me</p>

<pre><code>SELECT * from Invoice inv, InvoiceLine inv_l where 
inv_l.InvoiceID = inv.ID 
SELECT * from Invoice inv, InvoiceLine inv_l where 
inv_l.ID = inv.InvoiceLineID 
SELECT * from Invoice inv, InvoiceLine inv_l where 
inv_l.ID = inv.InvoiceID 
SELECT * from Invoice inv, InvoiceLine inv_l where 
inv_l.InvoiceLineID = inv.ID
</code></pre>

<p>What's worst of all is the mix you mention, totally confusing. I've had to work with a database where almost always it was foo_id except in one of the most used ids. That was total hell.</p>
"
508,208580,0,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>I prefer DomainName || 'ID'.  (i.e. DomainName + ID)</p>

<p>DomainName is often, but not always, the same as TableName.  </p>

<p>The problem with ID all by itself is that it doesn't scale upwards.  Once you have about 200 tables,  each with a first column named ID, the data begins to look all alike.  If you always qualify ID with the table name,  that helps a little, but not that much.</p>

<p>DomainName &amp; ID can be used to name foreign keys as well as primary keys.  When foriegn keys are named after the column that they reference,  that can be of mnemonic assistance.  Formally, tying the name of a foreign key to the key it references is not necessary, since the referential integrity constrain will establish the reference. But it's awfully handy when it comes to reading queries and updates.  </p>

<p>Occasionally, DomainName || 'ID'   can't be used, because there would be two columns in the same table with the same name.  Example:  Employees.EmployeeID and Employees.SupervisorID.  In those cases,  I use RoleName || 'ID', as in the example.</p>

<p>Last but not least,  I use natural keys rather than synthetic keys when possible.  There are situations where natural keys are unavailable or untrustworthy,  but there are plenty of situations where the natural key is the right choice.  In those cases, I let the natural key take on the name it would naturally have.  This name often doesn't even have the letters, 'ID' in it. Example:  OrderNo  where No is an abbreviation for ""Number"".  </p>
"
509,208580,0,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>For each table I choose a tree letter shorthand(e.g. Employees => Emp)</p>

<p>That way a numeric autonumber primary key becomes <strong>nkEmp</strong>.</p>

<p>It is short, unique in the entire database and I know exactly its properties at a glance.</p>

<p>I keep the same names in SQL and all languages I use (mostly C#, Javascript, VB6).</p>
"
512,208580,1,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>FWIW, our new standard (which changes, uh, I mean ""evolves"", with every new project) is:</p>

<ul>
<li>Lower case database field names</li>
<li>Uppercase table names</li>
<li>Use underscores to separate words in the field name - convert these to Pascal case in code.</li>
<li><code>pk_</code> prefix means primary key</li>
<li><code>_id</code> suffix means an integer, auto-increment ID</li>
<li><code>fk_</code> prefix means foreign key (no suffix necessary)</li>
<li><code>_VW</code> suffix for views</li>
<li><code>is_</code> prefix for booleans</li>
</ul>

<p>So, a table named NAMES might have the fields <code>pk_name_id, first_name, last_name, is_alive,</code> and <code>fk_company</code> and a view called <code>LIVING_CUSTOMERS_VW</code>, defined like:</p>

<pre>
SELECT first_name, last_name
FROM CONTACT.NAMES
WHERE (is_alive = 'True')
</pre>

<p>As others have said, though, just about any scheme will work as long as it is consistent and doesn't unnecessarily obfuscate your meanings.</p>
"
507,208580,3,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>Coming at this from the perspective of a formal data dictionary, I would name the data element <code>invoice_ID</code>. Generally, a data element name will be unique in the data dictionary and ideally will have the same name throughout, though sometimes additional qualifying terms may be required based on context e.g. the data element named <code>employee_ID</code> could be used twice in the org chart and therefore qualified as <code>supervisor_employee_ID</code> and <code>subordinate_employee_ID</code> respectively. </p>

<p>Obviously, naming conventions are subjective and a matter of style. I've find ISO/IEC 11179 guidelines to be a useful starting point.</p>

<p>For the DBMS, I see tables as collections of entites (except those that only ever contain one row e.g. cofig table, table of constants, etc) e.g. the table where my <code>employee_ID</code> is the key would be named <code>Personnel</code>. So straight away the <code>TableNameID</code> convention doesn't work for me.</p>

<p>I've seen the <code>TableName.ID=PK TableNameID=FK</code> style used on large data models and have to say I find it slightly confusing: I much prefer an identifier's name be the same throughout i.e. does not change name based on which table it happens to appear in. Something to note is the aforementioned style seems to be used in the shops which add an <code>IDENTITY</code> (auto-increment) column to <em>every</em> table while shunning natural and compound keys in foreign keys. Those shops tend not to have formal data dictionaries nor build from data models. Again, this is merely a question of style and one to which I don't personally subscribe. So ultimately, it's not for me.</p>

<p>All that said, I can see a case for sometimes dropping the qualifier from the column name when the table's name provides a context for doing so e.g. the element named <code>employee_last_name</code> may become simply <code>last_name</code> in the <code>Personnel</code> table. The rationale here is that the domain is 'people's last names' and is more likely to be <code>UNION</code>ed with <code>last_name</code> columns <em>from</em> other tables rather than be used as a foreign key <em>in</em> another table, but then again... I might just change my mind, sometimes you can never tell. That's the thing: data modelling is part art, part science.</p>
"
506,208580,2,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>My vote is for InvoiceID for the table ID. I also use the same naming convention when it's used as a foreign key and use intelligent alias names in the queries.</p>

<pre><code> Select Invoice.InvoiceID, Lines.InvoiceLine, Customer.OrgName
 From Invoices Invoice
 Join InvoiceLines Lines on Lines.InvoiceID = Invoice.InvoiceID
 Join Customers Customer on Customer.CustomerID = Invoice.CustomerID
</code></pre>

<p>Sure, it's longer than some other examples. But smile. This is for posterity and someday, some poor junior coder is going to have to alter your masterpiece. In this example there is no ambiguity and as additional tables get added to the query, you'll be grateful for the verbosity.</p>
"
495,208580,28,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>We use <code>InvoiceID</code>, not <code>ID</code>.  It makes queries more readable -- when you see <code>ID</code> alone it could mean anything, especially when you alias the table to <code>i</code>.</p>
"
511,208580,1,66,sql,Naming of ID columns in database tables,"<p>I was wondering peoples opinions on the naming of ID columns in database tables.</p>

<p>If I have a table called Invoices with a primary key of an identity column I would call that column InvoiceID so that I would not conflict with other tables and it's obvious what it is.</p>

<p>Where I am workind current they have called all ID columns ID.</p>

<p>So they would do the following:</p>

<pre><code>Select  
    i.ID 
,   il.ID 
From
    Invoices i
    Left Join InvoiceLines il
        on i.ID = il.InvoiceID
</code></pre>

<p>Now, I see a few problems here:<br />
1. You would need to alias the columns on the select<br />
2. ID = InvoiceID does not fit in my brain<br />
3. If you did not alias the tables and referred to InvoiceID is it obvious what table it is on?</p>

<p>What are other peoples thoughts on the topic?</p>
","<p>What I do to keep things consistent for myself (where a table has a single column primary key used as the ID) is to name the primary key of the table <code>Table_pk</code>.  Anywhere I have a foreign key pointing to that tables primary key, I call the column <code>PrimaryKeyTable_fk</code>.  That way I know that if I have a <code>Customer_pk</code> in my Customer table and a <code>Customer_fk</code> in my Order table, I know that the Order table is referring to an entry in the Customer table.</p>

<p>To me, this makes sense especially for joins where I think it reads easier.</p>

<pre><code>SELECT * 
FROM Customer AS c
    INNER JOIN Order AS c ON c.Customer_pk = o.Customer_fk
</code></pre>
"
1207,542510,15,65,sql,How do I create a parameterized SQL query? Why Should I?,"<p>I've heard that ""everyone"" is using parameterized SQL queries to protect against SQL injection attacks without having to vailidate every piece of user input.</p>

<p>How do you do this?  Do you get this automatically when using stored procedures?</p>

<p>So my understanding this is non-parameterized:</p>

<pre><code>cmdText = String.Format(""SELECT foo FROM bar WHERE baz = '{0}'"", fuz)
</code></pre>

<p>Would this be parameterized?</p>

<pre><code>cmdText = String.Format(""EXEC foo_from_baz '{0}'"", fuz)
</code></pre>

<p>Or do I need to do somethng more extensive like this in order to protect myself from SQL injection?</p>

<pre><code>With command
    .Parameters.Count = 1
    .Parameters.Item(0).ParameterName = ""@baz""
    .Parameters.Item(0).Value = fuz
End With
</code></pre>

<p>Are there other advantages to using parameterized queries besides the security considerations?</p>

<p>Update:  This great article was linked in one of the questions references by Grotok.
<a href=""http://www.sommarskog.se/dynamic_sql.html"">http://www.sommarskog.se/dynamic_sql.html</a></p>
","<p>Definitely the second one.</p>

<p>Parametrized queries have two main advantages:</p>

<ul>
<li>Security: It is a good way to avoid <a href=""http://en.wikipedia.org/wiki/SQL_injection"">SQL Injection</a> vulnerabilities</li>
<li>Performance: If you regularly invoke the same query just with different parameters a parametrized query might allow the database to cache your queries which is a considerable source of performance gain.</li>
<li>Extra: You won't have to worry about date and time formatting issues in your database code. Similarly, if your code will ever run on machines with a non-English locale, you will not have problems with decimal points / decimal commas.</li>
</ul>
"
1203,542510,4,65,sql,How do I create a parameterized SQL query? Why Should I?,"<p>I've heard that ""everyone"" is using parameterized SQL queries to protect against SQL injection attacks without having to vailidate every piece of user input.</p>

<p>How do you do this?  Do you get this automatically when using stored procedures?</p>

<p>So my understanding this is non-parameterized:</p>

<pre><code>cmdText = String.Format(""SELECT foo FROM bar WHERE baz = '{0}'"", fuz)
</code></pre>

<p>Would this be parameterized?</p>

<pre><code>cmdText = String.Format(""EXEC foo_from_baz '{0}'"", fuz)
</code></pre>

<p>Or do I need to do somethng more extensive like this in order to protect myself from SQL injection?</p>

<pre><code>With command
    .Parameters.Count = 1
    .Parameters.Item(0).ParameterName = ""@baz""
    .Parameters.Item(0).Value = fuz
End With
</code></pre>

<p>Are there other advantages to using parameterized queries besides the security considerations?</p>

<p>Update:  This great article was linked in one of the questions references by Grotok.
<a href=""http://www.sommarskog.se/dynamic_sql.html"">http://www.sommarskog.se/dynamic_sql.html</a></p>
","<p>You want to go with your last example as this is the only one that is truly parametrized.  Besides security concerns (which are much more prevalent then you might think) it is best to let ADO.NET handle the parametrization as you cannot be sure if the value you are passing in requires single quotes around it or not without inspecting the <code>Type</code> of each parameter.</p>

<p>[Edit] Here is an example:</p>

<pre><code>SqlCommand command = new SqlCommand(
    ""select foo from bar where baz = @baz"",
    yourSqlConnection
);

SqlParameter parameter = new SqlParameter();
parameter.ParameterName = ""@baz"";
parameter.Value = ""xyz"";

command.Parameters.Add(parameter);
</code></pre>
"
1204,542510,60,65,sql,How do I create a parameterized SQL query? Why Should I?,"<p>I've heard that ""everyone"" is using parameterized SQL queries to protect against SQL injection attacks without having to vailidate every piece of user input.</p>

<p>How do you do this?  Do you get this automatically when using stored procedures?</p>

<p>So my understanding this is non-parameterized:</p>

<pre><code>cmdText = String.Format(""SELECT foo FROM bar WHERE baz = '{0}'"", fuz)
</code></pre>

<p>Would this be parameterized?</p>

<pre><code>cmdText = String.Format(""EXEC foo_from_baz '{0}'"", fuz)
</code></pre>

<p>Or do I need to do somethng more extensive like this in order to protect myself from SQL injection?</p>

<pre><code>With command
    .Parameters.Count = 1
    .Parameters.Item(0).ParameterName = ""@baz""
    .Parameters.Item(0).Value = fuz
End With
</code></pre>

<p>Are there other advantages to using parameterized queries besides the security considerations?</p>

<p>Update:  This great article was linked in one of the questions references by Grotok.
<a href=""http://www.sommarskog.se/dynamic_sql.html"">http://www.sommarskog.se/dynamic_sql.html</a></p>
","<p>Your EXEC example would NOT be parameterized.  You need parameterized queries (prepared statements in some circles) to prevent input like this from causing damage:</p>

<blockquote>
  <p>';DROP TABLE bar;--</p>
</blockquote>

<p>Try putting that in your fuz variable (or don't, if you value your bar table).  More subtle and damaging queries are possible as well.</p>

<p>Here's an example of how you do parameters with Sql Server:</p>

<pre><code>Public Function GetBarFooByBaz(ByVal Baz As String) As String
    Dim sql As String = ""SELECT foo FROM bar WHERE baz= @Baz""

    Using cn As New SqlConnection(""Your connection string here""), _
        cmd As New SqlCommand(sql, cn)

        cmd.Parameters.Add(""@Baz"", SqlDbType.VarChar, 50).Value = Baz
        Return cmd.ExecuteScalar().ToString()
    End Using
End Function
</code></pre>

<p>Stored procedures are sometimes credited with preventing SQL injection.  However, most of the time you still have to call them using query parameters or they don't help.  If you use stored procedures <em>exclusively</em>, then you can turn off permissions for SELECT, UPDATE, ALTER, CREATE, DELETE, etc (just about everything but EXEC) for the application user account and get some protection that way.</p>
"
1205,542510,1,65,sql,How do I create a parameterized SQL query? Why Should I?,"<p>I've heard that ""everyone"" is using parameterized SQL queries to protect against SQL injection attacks without having to vailidate every piece of user input.</p>

<p>How do you do this?  Do you get this automatically when using stored procedures?</p>

<p>So my understanding this is non-parameterized:</p>

<pre><code>cmdText = String.Format(""SELECT foo FROM bar WHERE baz = '{0}'"", fuz)
</code></pre>

<p>Would this be parameterized?</p>

<pre><code>cmdText = String.Format(""EXEC foo_from_baz '{0}'"", fuz)
</code></pre>

<p>Or do I need to do somethng more extensive like this in order to protect myself from SQL injection?</p>

<pre><code>With command
    .Parameters.Count = 1
    .Parameters.Item(0).ParameterName = ""@baz""
    .Parameters.Item(0).Value = fuz
End With
</code></pre>

<p>Are there other advantages to using parameterized queries besides the security considerations?</p>

<p>Update:  This great article was linked in one of the questions references by Grotok.
<a href=""http://www.sommarskog.se/dynamic_sql.html"">http://www.sommarskog.se/dynamic_sql.html</a></p>
","<p>Your command text need to be like:</p>

<pre><code>cmdText = ""SELECT foo FROM bar WHERE baz = ?""

cmdText = ""EXEC foo_from_baz ?""
</code></pre>

<p>Then add parameter values.  This way ensures that the value con only end up being used as a value, whereas with the other method if variable fuz is set to</p>

<pre><code>""x'; delete from foo where 'a' = 'a""
</code></pre>

<p>can you see what might happen?</p>
"
1206,542510,2,65,sql,How do I create a parameterized SQL query? Why Should I?,"<p>I've heard that ""everyone"" is using parameterized SQL queries to protect against SQL injection attacks without having to vailidate every piece of user input.</p>

<p>How do you do this?  Do you get this automatically when using stored procedures?</p>

<p>So my understanding this is non-parameterized:</p>

<pre><code>cmdText = String.Format(""SELECT foo FROM bar WHERE baz = '{0}'"", fuz)
</code></pre>

<p>Would this be parameterized?</p>

<pre><code>cmdText = String.Format(""EXEC foo_from_baz '{0}'"", fuz)
</code></pre>

<p>Or do I need to do somethng more extensive like this in order to protect myself from SQL injection?</p>

<pre><code>With command
    .Parameters.Count = 1
    .Parameters.Item(0).ParameterName = ""@baz""
    .Parameters.Item(0).Value = fuz
End With
</code></pre>

<p>Are there other advantages to using parameterized queries besides the security considerations?</p>

<p>Update:  This great article was linked in one of the questions references by Grotok.
<a href=""http://www.sommarskog.se/dynamic_sql.html"">http://www.sommarskog.se/dynamic_sql.html</a></p>
","<p>Most people would do this through a server side programming language library, like PHP's PDO or Perl DBI.</p>

<p>For instance, in PDO:</p>

<pre><code>$dbh=pdo_connect(); //you need a connection function, returns a pdo db connection

$sql='insert into squip values(null,?,?)';

$statement=$dbh-&gt;prepare($sql);

$data=array('my user supplied data','more stuff');

$statement-&gt;execute($data);

if($statement-&gt;rowCount()==1){/*it worked*/}
</code></pre>

<p>This takes care of escaping your data for database insertion.</p>

<p>One advantage is that you can repeat an insert many times with one prepared statement, gaining a speed advantage.</p>

<p>For instance, in the above query I could prepare the statement once, and then loop over creating the data array from a bunch of data and repeat the ->execute as many times as needed.</p>
"
624,272210,2,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>This is my normal preference:</p>

<pre><code>....SELECT column1
........,column2
....FROM table1
....WHERE column3 IN (
........SELECT TOP(1) column4
........FROM table2
........INNER JOIN table3
............ON table2.column1 = table3.column1
....)
</code></pre>

<p>Although stackoverflow messes up the formatting with an extra leading space, so I put in some periods so you can see the actual formatting...</p>
"
629,272210,5,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>SQL formatting is an area where there is a great deal of variance and disagreement... But fwiw, I like to focus on readability and think that whatever you do, consistently conforming to any rules that reduce readability is, as the old cliche goes, a ""foolish consistency""  ( ""Foolish consistency is a hobgoblin for simple minds"" ) </p>

<p>So, instead of calling them rules, here are some guidelines.
For each Major clause in a SQL statement (Select, Insert, Delete, From, Where, Having, Group BY, Order By, ... I may be missing a few) should be EASILY identifiable.  So I generally indent them at the highest level, all even with each other. Then within each clause, I indent the next logical sub structure evenly... and so on.. But I feel free to (and often do) change the pattern if in any individual case it would be more readable to do so... Complex Case statements are a good example.  Because anything that requires horizontal scrolling reduces readability enormously, I often write complex (nested) Case expressions on multiple lines.  When I do, I try to keep the beginning of such a statement hanging indent based on it's logical place in the SQL statement, and indent the rest of the statement lines  a few characters furthur... </p>

<p>SQL Database code has been around for a long time, since before computers had lower case, so there is a historical preference for upper casing keywords, but I prefer readability over tradition... (and every tool I use color codes the key words now anyway)</p>

<p>I also would use Table aliases to reduce the amount of text the eye has to scan in order to grok the structure of the query, as long as the aliases do not create confusion.  In a query with less than 3 or 4 tables, Single character aliases are fine, I often use first letter of the table if all ther tables start with a different letter...  again, whatever most contributes to readability. Finally, if your database supports it,  many of the keywords are optional, (like ""Inner"", ""Outer"", ""As"" for aliases, etc.)   ""Into"" (from Insert Into) is optional on Sql Server - but not on Oracle)  So be careful about using this if your code needs to be platform independant... </p>

<p>Your example, I would write as:</p>

<pre><code>Select column1, column2
From table1 T1
Where column3 In (Select Top(1) column4
                  From table2 T2
                     Join table3 T3
                         On T2.column1 = T3.column1)
</code></pre>

<p>Or</p>

<pre><code>Select column1, column2
From table1 T1
Where column3 In 
     (Select Top(1) column4
      From table2 T2
         Join table3 T3
            On T2.column1 = T3.column1)
</code></pre>

<p>If there many more columns on the select clause, I would indent the second and subsequent lines... I generally do NOT adhere to any strict (one column per row) kind of rule as scrolling veritcally is almost as bad for readability as scrolling horizontally is,  especially if only the first ten columns of the screen have any text in them)</p>

<pre><code>Select column1, column2, Col3, Col4, column5,
    column6, Column7, isNull(Column8, 'FedEx') Shipper,
    Case Upper(Column9) 
       When 'EAST'  Then 'JFK'
       When 'SOUTH' Then 'ATL'
       When 'WEST'  Then 'LAX'
       When 'NORTH' Then 'CHI' End HubPoint
From table1 T1
Where column3 In 
     (Select Top(1) column4
      From table2 T2
         Join table3 T3
            On T2.column1 = T3.column1)
</code></pre>

<p>Format the code in whatever manner makes it the most readable... </p>
"
627,272210,1,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>Well, of course it depends on the query.  </p>

<p>For simple queries, a highly formal indentation scheme is just more trouble than it's worth and can actually make the code <em>less</em> readable, not more.  But as complexity grows you need to start being more careful with how you structure the statement, to make sure it will be readable again later.</p>
"
626,272210,5,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>I like to have the different parts of my query line up vertically. I tend to use a tab size of 8 spaces for SQL which seems to work well.</p>

<pre><code>SELECT  column1, 
        column2
FROM    table1
WHERE   column3 IN
(
        SELECT TOP(1) column4
        FROM    table2
        INNER JOIN table3
        ON      table2.column1  = table3.column1
)
</code></pre>
"
625,272210,1,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>This is a matter of taste.</p>

<p>This is my preference.</p>

<pre><code>SELECT 
  column1
 ,column2
FROM
  table1
WHERE column3 IN (
                 SELECT TOP(1) column4
                 FROM 
                   table2
                   INNER JOIN table3
                 ON table2.column1 = table3.column1
                 )
</code></pre>
"
630,272210,14,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>I like jalbert's form of lining up the keywords on their right. I'd also add that I like the ANDs and ORs on the left (some people put them on the right.) In addition, I like to line up my equals signs when possible.</p>

<pre><code>
SELECT column1, 
       column2  
  FROM table1, table2 
 WHERE table1.column1 = table2.column4 
   AND table1.col5    = ""hi"" 
    OR table2.myfield = 678 
</code></pre>
"
623,272210,18,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>I like to have ""rivers"" of white space in the code. It makes it a little easier to scan.</p>

<pre><code>SELECT column1,
       column2
  FROM table1
 WHERE column3 IN (SELECT column4
                     FROM table2
                     JOIN table3
                       ON table2.column1 = table3.column1);
</code></pre>
"
622,272210,1,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>I don't know if there's a standard but I like to do it this way;</p>

<pre><code>SELECT column1, column2
  FROM table1
WHERE column3 IN
(
    SELECT TOP(1) column4
      FROM table2
    INNER JOIN table3
      ON table2.column1 = table3.column1
)
</code></pre>

<p>because I can read and analyze the SQL better.</p>
"
621,272210,4,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>I would format like this:</p>

<pre><code>SELECT
    column1, 
    column2
FROM 
    table1
WHERE 
    column3 IN (SELECT TOP(1) 
                    column4 
                FROM 
                    table2 
                    INNER JOIN table3 ON table2.column1 = table3.column1)
</code></pre>

<p>or like this:</p>

<pre><code>SELECT
    column1, 
    column2
FROM 
    table1
WHERE 
    column3 IN (SELECT TOP(1) column4 
                FROM table2 
                INNER JOIN table3 ON table2.column1 = table3.column1)
</code></pre>
"
620,272210,4,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>Of course, this comes down to personal preference.  And if in a team setting, it's something that should be agreed upon among the members for consistency's sake.  But this would be my preference:</p>

<pre><code>SELECT column1, column2
FROM   table1
WHERE  column3 IN(SELECT     TOP(1) column4
                  FROM       table2
                  INNER JOIN table3 ON
                             table2.column1 = table3.column1
                 )
</code></pre>
"
619,272210,1,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>What I usually do is,</p>

<pre><code>print(""SELECT column1, column2
       FROM table1
       WHERE column3 IN (SELECT TOP(1) column4
                         FROM table2 INNER JOIN 
                              table3 ON table2.column1 = table3.column1)"");
</code></pre>
"
618,272210,35,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<pre><code>SELECT column1
     , column2
FROM table1
WHERE column3 IN
(
	SELECT TOP(1) column4
	FROM table2
	INNER JOIN table3
	ON table2.column1 = table3.column1
)
</code></pre>

<p>I like to have all <strong>"","" in front</strong>, this way I never search them when an error at line X from the SQL editor.</p>

<p><hr/></p>

<h3>This is an example for those who do not use this type of writting SQL statement. Both contain an error of a missing comma.</h3>

<pre><code>SELECT sdcolumn123
 , dscolumn234
 , sdcolumn343
 , ffcolumn434
 , sdcolumn543
 , bvcolumn645
  vccolumn754
 , cccolumn834
 , vvcolumn954
 , cvcolumn104
FROM table1
WHERE column3 IN
(
	...
)

SELECT sdcolumn123, dscolumn234, asdcolumn345, dscolumn456, ascolumn554, gfcolumn645 sdcolumn754, fdcolumn845, sdcolumn954, fdcolumn1054
FROM table1
WHERE column3 IN
(
	...
)
</code></pre>

<p>I found easier and more quick at the first example. Hope this example show you more my point of view.</p>
"
617,272210,19,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>Not sure there is an accepted practice, but here's now how I'd do it:</p>

<pre><code>SELECT 
    column1, 
    column2 
FROM 
    table1 
WHERE 
    column3 IN 
    ( 
     SELECT TOP(1) 
         column4 
     FROM 
         table2 
         INNER JOIN 
         table3 
             ON table2.column1 = table3.column1 
    )
</code></pre>
"
616,272210,24,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<pre><code>SELECT column1, column2
FROM table
WHERE column3 IN (
    SELECT TOP(1) column4
    FROM table2
    INNER JOIN table3 ON table2.column1 = table3.column1
)
</code></pre>

<p>This is pretty short and easy to read.  I'd make adjustments if there were more columns selected or more join conditions.</p>
"
615,272210,10,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>This is my personal method.  Depending on the length of the join condition I sometimes indent it on the line below.</p>

<pre><code>SELECT
  column1,
  column2
FROM
  table1
WHERE
  column3 IN ( 
    SELECT TOP(1)
      column4
    FROM
      table2
      INNER JOIN table3 ON table2.column1 = table3.column1
  )


SELECT
  column1,
  column2
FROM
  table1
WHERE
  column3 IN ( 
    SELECT TOP(1)
      column4
    FROM
      table2
      INNER JOIN table3
        ON table2.column1 = table3.column1 -- for long ones
  )
</code></pre>
"
631,272210,7,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>I've written a code standard for our shop that is biased in the extreme towards readability/""discoverability"" (the latter being primarily useful in insert-select statements):</p>

<pre><code>SELECT 
    column1, 
    column2
FROM 
    table1
WHERE 
    column3 IN
    (
        SELECT TOP(1) 
            column4
        FROM 
            table2
            INNER JOIN table3 ON table2.column1 = table3.column1
    )
</code></pre>

<p>On more complex queries it becomes more obvious how this is useful:</p>

<pre><code>SELECT
    Column1,
    Column2,
    Function1
    (
        Column1,
        Column2
    ) as Function1,
    CASE
    WHEN Column1 = 1 THEN
        a
    ELSE
        B
    END as Case1       
FROM
    Table1 t1
    INNER JOIN Table2 t2 ON t1.column12 = t2.column21
WHERE
    (
        FilterClause1
        AND FilterClause2
    )
    OR
    (
        FilterClause3
        AND FilterClause4
    )
</code></pre>

<p>Once you move to systems with more than a single join in most of your queries, it has been my experience that using vertical space liberally is your best friend with complex SQL.</p>
"
632,272210,7,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>If you have a lengthy SQL statement that you'd like to reformat without all the typing and tabbing, you can slap it into <a href=""http://www.orafaq.com/cgi-bin/sqlformat/pp/utilities/sqlformatter.tpl"" rel=""nofollow"">this website</a> and get a nicely formatted result. You can experiment with various formats to see which makes your text the most readable.</p>

<p>Edit: I believe that <a href=""http://sqlformat.org/"" rel=""nofollow"">this</a> is the 2014 location of the SQL formatter.</p>
"
633,272210,2,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>I've just put it through my SQL prettifier and it came out like this....</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
    FROM table2
            INNER JOIN table3
            ON table2.column1 = table3.column1
)
</code></pre>

<p><a href=""http://extras.sqlservercentral.com/prettifier/prettifier.aspx"" rel=""nofollow"">http://extras.sqlservercentral.com/prettifier/prettifier.aspx</a></p>

<p>.....But I haven't worked out a way of getting colours into StackOverflow.</p>
"
628,272210,1,51,sql,SQL Statement indentation good practice,"<p>What is the accepted practice for indenting SQL statements?  For example, consider the following SQL statement:</p>

<pre><code>SELECT column1, column2
FROM table1
WHERE column3 IN
(
SELECT TOP(1) column4
FROM table2
INNER JOIN table3
ON table2.column1 = table3.column1
)
</code></pre>

<p>How should this be indented?  Many thanks.</p>
","<p>Yeah, this is pretty subjective...But here's my 2 cents:</p>

<pre><code>SELECT
   Column1,
   Column2
FROM Table1
WHERE 
   Column3 IN (
      SELECT Column4
      FROM Table2
      JOIN Table3 ON
         Table2.Column1 = Table3.Column1
   )
</code></pre>

<p>But, really, I'd probably rewrite it without the IN:</p>

<pre><code>SELECT
   Column1,
   Column2
FROM Table1
JOIN Table2 ON
   Table1.Column3 = Table2.Column4
JOIN Table3 ON
   Table2.Column1 = Table3.Column1
</code></pre>

<p>Basically, my rules are:</p>

<ul>
<li>Capitalize Keywords</li>
<li>Columns go on individual lines, but SELECT modifiers (SELECT TOP 100, SELECT DISTINCT, etc.) or single columns (SELECT 1, SELECT Id, SELECT *, etc.) go on same line</li>
<li>Join conditions indented underneath JOIN clause</li>
<li>Use JOIN for INNER JOIN (since it's the common one), and fully specify others (LEFT OUTER JOIN, FULL OUTER JOIN, etc.)</li>
<li>Open parens on same line, close paren on separate line. If you have an alias, the alias goes with close paren.</li>
</ul>
"
63,24200,2,50,sql,What's the fastest way to bulk insert a lot of data in SQL Server (C# client),"<p>I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.</p>

<p>I am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.</p>

<p>I have a simple table that looks like this: </p>

<pre><code> CREATE TABLE [BulkData](
 [ContainerId] [int] NOT NULL,
 [BinId] [smallint] NOT NULL,
 [Sequence] [smallint] NOT NULL,
 [ItemId] [int] NOT NULL,
 [Left] [smallint] NOT NULL,
 [Top] [smallint] NOT NULL,
 [Right] [smallint] NOT NULL,
 [Bottom] [smallint] NOT NULL,
 CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED 
 (
  [ContainerIdId] ASC,
  [BinId] ASC,
  [Sequence] ASC
))
</code></pre>

<p>I'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  </p>

<p>The %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.</p>

<p>Does it help any if I:</p>

<ol>
<li>Drop the Primary key while I am doing the inserting and recreate it later</li>
<li>Do inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small</li>
<li>Anything else?</li>
</ol>

<p>--
Based on the responses I have gotten, let me clarify a little bit:</p>

<p>Portman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?</p>

<p>Chopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.</p>

<p>Jason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.</p>
","<p>I'm not really a bright guy and I don't have a lot of experience with the SqlClient.SqlBulkCopy method but here's my 2 cents for what it's worth.  I hope it helps you and others (or at least causes people to call out my ignorance ;).</p>

<p>You will never match a raw file copy speed unless your database data file (mdf) is on a separate physical disk from your transaction log file (ldf).  Additionally, any clustered indexes would also need to be on a separate physical disk for a fairer comparison.</p>

<p>Your raw copy is not logging or maintaining a sort order of select fields (columns) for indexing purposes.</p>

<p>I agree with Portman on creating a nonclustered identity seed and changing your existing nonclustered index to a clustered index.</p>

<p>As far as what construct you're using on the clients...(data adapter, dataset, datatable, etc).  If your disk io on the server is at 100%, I don't think your time is best spent analyzing client constructs as they appear to be faster than the server can currently handle.</p>

<p>If you follow Portman's links about minimal logging, I wouldn't think surrounding your bulk copies in transactions would help a lot if any but I've been wrong many times in my life ;)</p>

<p>This won't necessarily help you right now but if you figure out your current issue, this next comment might help with the next bottleneck (network throughput) - especially if it's over the Internet...</p>

<p>Chopeen asked an interesting question too.  How did you determine to use 300 record count chunks to insert?  SQL Server has a default packet size (I believe it is 4096 bytes) and it would make sense to me to derive the size of your records and ensure that you are making efficient use of the packets transmitting between client and server.  (Note, you can change your packet size on your client code as opposed to the server option which would obviously change it for all server communications - probably not a good idea.)  For instance, if your record size results in 300 record batches requiring 4500 bytes, you will send 2 packets with the second packet being mostly wasted.  If batch record count was arbitrarily assigned, it might make sense to do some quick easy math.</p>

<p>From what I can tell (and remember about data type sizes) you have exactly 20 bytes for each record (if int=4 bytes and smallint=2 bytes).  If you are using 300 record count batches, then you are trying to send 300 x 20 = 6,000 bytes (plus I'm guessing a little overhead for the connection, etc).  You might be more efficient to send these up in 200 record count batches (200 x 20 = 4,000 + room for overhead) = 1 packet.  Then again, your bottleneck still appears to be the server's disk io.</p>

<p>I realize you're comparing a raw data transfer to the SqlBulkCopy with the same hardware/configuration but here's where I would go also if the challenge was mine:</p>

<p>This post probably won't help you anymore as it's rather old but I would next ask what your disk's RAID configuration is and what speed of disk are you using?  Try putting the log file on a drive that uses RAID 10 with a RAID 5 (ideally 1) on your data file.  This can help reduce a lot of spindle movement to different sectors on the disk and result in more time reading/writing instead of the unproductive ""moving"" state.  If you already separate your data and log files, do you have your index on a different physical disk drive from your data file (you can only do this with clustered indexes).  That would allow for not only concurrently updating logging information with data inserting but would allow index inserting (and any costly index page operations) to occur concurrently.</p>
"
62,24200,8,50,sql,What's the fastest way to bulk insert a lot of data in SQL Server (C# client),"<p>I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.</p>

<p>I am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.</p>

<p>I have a simple table that looks like this: </p>

<pre><code> CREATE TABLE [BulkData](
 [ContainerId] [int] NOT NULL,
 [BinId] [smallint] NOT NULL,
 [Sequence] [smallint] NOT NULL,
 [ItemId] [int] NOT NULL,
 [Left] [smallint] NOT NULL,
 [Top] [smallint] NOT NULL,
 [Right] [smallint] NOT NULL,
 [Bottom] [smallint] NOT NULL,
 CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED 
 (
  [ContainerIdId] ASC,
  [BinId] ASC,
  [Sequence] ASC
))
</code></pre>

<p>I'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  </p>

<p>The %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.</p>

<p>Does it help any if I:</p>

<ol>
<li>Drop the Primary key while I am doing the inserting and recreate it later</li>
<li>Do inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small</li>
<li>Anything else?</li>
</ol>

<p>--
Based on the responses I have gotten, let me clarify a little bit:</p>

<p>Portman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?</p>

<p>Chopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.</p>

<p>Jason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.</p>
","<p>My guess is that you'll see a dramatic improvement if you change that index to be <strong>nonclustered</strong>. This leaves you with two options:</p>

<ol>
<li>Change the index to nonclustered, and leave it as a heap table, without a clustered index</li>
<li>Change the index to nonclustered, but then add a surrogate key (like ""id"") and make it an identity, primary key, and clustered index</li>
</ol>

<p>Either one will speed up your inserts <strong>without</strong> noticeably slowing down your reads. </p>

<p>Think about it this way -- right now, you're telling SQL to do a bulk insert, but then you're asking SQL to reorder the entire table every table you add anything. With a nonclustered index, you'll add the records in whatever order they come in, and then build a separate index indicating their desired order. </p>
"
61,24200,3,50,sql,What's the fastest way to bulk insert a lot of data in SQL Server (C# client),"<p>I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.</p>

<p>I am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.</p>

<p>I have a simple table that looks like this: </p>

<pre><code> CREATE TABLE [BulkData](
 [ContainerId] [int] NOT NULL,
 [BinId] [smallint] NOT NULL,
 [Sequence] [smallint] NOT NULL,
 [ItemId] [int] NOT NULL,
 [Left] [smallint] NOT NULL,
 [Top] [smallint] NOT NULL,
 [Right] [smallint] NOT NULL,
 [Bottom] [smallint] NOT NULL,
 CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED 
 (
  [ContainerIdId] ASC,
  [BinId] ASC,
  [Sequence] ASC
))
</code></pre>

<p>I'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  </p>

<p>The %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.</p>

<p>Does it help any if I:</p>

<ol>
<li>Drop the Primary key while I am doing the inserting and recreate it later</li>
<li>Do inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small</li>
<li>Anything else?</li>
</ol>

<p>--
Based on the responses I have gotten, let me clarify a little bit:</p>

<p>Portman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?</p>

<p>Chopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.</p>

<p>Jason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.</p>
","<p><a href=""http://www.databasejournal.com/features/mssql/article.php/3391761"" rel=""nofollow"">BCP</a> - it's a pain to set up, but it's been around since the dawn of DBs and it's very very quick.</p>

<p>Unless you're inserting data in that order the 3-part index will really slow things.  Applying it later will really slow things too, but will be in a second step.</p>

<p>Compound keys in Sql are always quite slow, the bigger the key the slower.</p>
"
60,24200,1,50,sql,What's the fastest way to bulk insert a lot of data in SQL Server (C# client),"<p>I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.</p>

<p>I am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.</p>

<p>I have a simple table that looks like this: </p>

<pre><code> CREATE TABLE [BulkData](
 [ContainerId] [int] NOT NULL,
 [BinId] [smallint] NOT NULL,
 [Sequence] [smallint] NOT NULL,
 [ItemId] [int] NOT NULL,
 [Left] [smallint] NOT NULL,
 [Top] [smallint] NOT NULL,
 [Right] [smallint] NOT NULL,
 [Bottom] [smallint] NOT NULL,
 CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED 
 (
  [ContainerIdId] ASC,
  [BinId] ASC,
  [Sequence] ASC
))
</code></pre>

<p>I'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  </p>

<p>The %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.</p>

<p>Does it help any if I:</p>

<ol>
<li>Drop the Primary key while I am doing the inserting and recreate it later</li>
<li>Do inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small</li>
<li>Anything else?</li>
</ol>

<p>--
Based on the responses I have gotten, let me clarify a little bit:</p>

<p>Portman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?</p>

<p>Chopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.</p>

<p>Jason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.</p>
","<p>I think that it sounds like this could be done using <a href=""http://msdn.microsoft.com/en-us/library/ms141026.aspx"" rel=""nofollow"">SSIS packages</a>. They're similar to SQL 2000's DTS packages. I've used them to successfully transform everything from plain text CSV files, from existing SQL tables, and even from XLS files with 6-digit rows spanned across multiple worksheets. You could use C# to transform the data into an importable format (CSV, XLS, etc), then have your SQL server run a scheduled SSIS job to import the data.</p>

<p>It's pretty easy to create an SSIS package, there's a wizard built-into SQL Server's Enterprise Manager tool (labeled ""Import Data"" I think), and at the end of the wizard it gives you the option of saving it as an SSIS package. There's a bunch more info <a href=""http://technet.microsoft.com/en-us/sqlserver/bb671392.aspx"" rel=""nofollow"">on Technet</a> as well.</p>
"
59,24200,18,50,sql,What's the fastest way to bulk insert a lot of data in SQL Server (C# client),"<p>I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.</p>

<p>I am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.</p>

<p>I have a simple table that looks like this: </p>

<pre><code> CREATE TABLE [BulkData](
 [ContainerId] [int] NOT NULL,
 [BinId] [smallint] NOT NULL,
 [Sequence] [smallint] NOT NULL,
 [ItemId] [int] NOT NULL,
 [Left] [smallint] NOT NULL,
 [Top] [smallint] NOT NULL,
 [Right] [smallint] NOT NULL,
 [Bottom] [smallint] NOT NULL,
 CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED 
 (
  [ContainerIdId] ASC,
  [BinId] ASC,
  [Sequence] ASC
))
</code></pre>

<p>I'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  </p>

<p>The %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.</p>

<p>Does it help any if I:</p>

<ol>
<li>Drop the Primary key while I am doing the inserting and recreate it later</li>
<li>Do inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small</li>
<li>Anything else?</li>
</ol>

<p>--
Based on the responses I have gotten, let me clarify a little bit:</p>

<p>Portman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?</p>

<p>Chopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.</p>

<p>Jason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.</p>
","<p>You're already using <a href=""http://msdn.microsoft.com/en-us/library/system.data.sqlclient.sqlbulkcopy.aspx"">SqlBulkCopy</a>, which is a good start.</p>

<p>However, just using the SqlBulkCopy class does not necessarily mean that SQL will perform a bulk copy. In particular, there are a few requirements that must be met for SQL Server to perform an efficient bulk insert.</p>

<p>Further reading:</p>

<ul>
<li><a href=""http://msdn.microsoft.com/en-us/library/ms190422.aspx"">Prerequisites for Minimal Logging in Bulk Import</a></li>
<li><a href=""http://msdn.microsoft.com/en-us/library/ms190421.aspx"">Optimizing Bulk Import Performance</a></li>
</ul>

<p>Out of curiosity, why is your index set up like that? It seems like ContainerId/BinId/Sequence is <strong>much</strong> better suited to be a nonclustered index. Is there a particular reason you wanted this index to be clustered?</p>
"
58,24200,4,50,sql,What's the fastest way to bulk insert a lot of data in SQL Server (C# client),"<p>I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.</p>

<p>I am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.</p>

<p>I have a simple table that looks like this: </p>

<pre><code> CREATE TABLE [BulkData](
 [ContainerId] [int] NOT NULL,
 [BinId] [smallint] NOT NULL,
 [Sequence] [smallint] NOT NULL,
 [ItemId] [int] NOT NULL,
 [Left] [smallint] NOT NULL,
 [Top] [smallint] NOT NULL,
 [Right] [smallint] NOT NULL,
 [Bottom] [smallint] NOT NULL,
 CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED 
 (
  [ContainerIdId] ASC,
  [BinId] ASC,
  [Sequence] ASC
))
</code></pre>

<p>I'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  </p>

<p>The %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.</p>

<p>Does it help any if I:</p>

<ol>
<li>Drop the Primary key while I am doing the inserting and recreate it later</li>
<li>Do inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small</li>
<li>Anything else?</li>
</ol>

<p>--
Based on the responses I have gotten, let me clarify a little bit:</p>

<p>Portman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?</p>

<p>Chopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.</p>

<p>Jason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.</p>
","<p>Have you tried using transactions?</p>

<p>From what you describe, having the server committing 100% of the time to disk, it seems you are sending each row of data in an atomic SQL sentence thus forcing the server to commit (write to disk) every single row.</p>

<p>If you used transactions instead, the server would only commit <em>once</em> at the end of the transaction.</p>

<p>For further help: What method are you using for inserting data to the server? Updating a DataTable using a DataAdapter, or executing each sentence using a string?</p>
"
57,24200,0,50,sql,What's the fastest way to bulk insert a lot of data in SQL Server (C# client),"<p>I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.</p>

<p>I am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.</p>

<p>I have a simple table that looks like this: </p>

<pre><code> CREATE TABLE [BulkData](
 [ContainerId] [int] NOT NULL,
 [BinId] [smallint] NOT NULL,
 [Sequence] [smallint] NOT NULL,
 [ItemId] [int] NOT NULL,
 [Left] [smallint] NOT NULL,
 [Top] [smallint] NOT NULL,
 [Right] [smallint] NOT NULL,
 [Bottom] [smallint] NOT NULL,
 CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED 
 (
  [ContainerIdId] ASC,
  [BinId] ASC,
  [Sequence] ASC
))
</code></pre>

<p>I'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  </p>

<p>The %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.</p>

<p>Does it help any if I:</p>

<ol>
<li>Drop the Primary key while I am doing the inserting and recreate it later</li>
<li>Do inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small</li>
<li>Anything else?</li>
</ol>

<p>--
Based on the responses I have gotten, let me clarify a little bit:</p>

<p>Portman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?</p>

<p>Chopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.</p>

<p>Jason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.</p>
","<p>How about increasing the memory allocated to the server or the buffer size used by the server, if possible?</p>
"
56,24200,0,50,sql,What's the fastest way to bulk insert a lot of data in SQL Server (C# client),"<p>I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.</p>

<p>I am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.</p>

<p>I have a simple table that looks like this: </p>

<pre><code> CREATE TABLE [BulkData](
 [ContainerId] [int] NOT NULL,
 [BinId] [smallint] NOT NULL,
 [Sequence] [smallint] NOT NULL,
 [ItemId] [int] NOT NULL,
 [Left] [smallint] NOT NULL,
 [Top] [smallint] NOT NULL,
 [Right] [smallint] NOT NULL,
 [Bottom] [smallint] NOT NULL,
 CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED 
 (
  [ContainerIdId] ASC,
  [BinId] ASC,
  [Sequence] ASC
))
</code></pre>

<p>I'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  </p>

<p>The %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.</p>

<p>Does it help any if I:</p>

<ol>
<li>Drop the Primary key while I am doing the inserting and recreate it later</li>
<li>Do inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small</li>
<li>Anything else?</li>
</ol>

<p>--
Based on the responses I have gotten, let me clarify a little bit:</p>

<p>Portman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?</p>

<p>Chopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.</p>

<p>Jason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.</p>
","<p>Yes your ideas will help.<br />
Lean on option 1 if there are no reads happening while your loading.<br />
Lean on option 2 if you destination table is being queried during your processing.</p>

<p>@Andrew<br />
Question.  Your inserting in chunks of 300.  What is the total amount your inserting?  SQL server should be able to handle 300 plain old inserts very fast.</p>
"
135,46380,2,47,sql,Why doesn't Oracle tell you WHICH table or view does not exist?,"<p>If you've used Oracle, you've probably gotten the helpful message ""ORA-00942: Table or view does not exist"". Is there a legitimate technical reason the message doesn't include the name of the missing object? </p>

<p>Arguments about this being due to security sound like they were crafted by the TSA. If I'm an attacker, I'd know what table I just attempted to exploit, and be able to interpret this unhelpful message easily. If I'm a developer working with a complex join through several layers of application code, it's often very difficult to tell.</p>

<p>My guess is that when this error was originally implemented, someone neglected to add the object name, and now, people are afraid it will break compatibility to fix it. (Code doing silly things like parsing the error message will be confused if it changes.)</p>

<p>Is there a developer-friendly (as opposed to recruiting your DBA) way to determine the name of the missing table?</p>

<p><hr /></p>

<p>Although I've accepted an answer which is relevant to the topic, it doesn't really answer my question: <em>Why isn't the name part of the error message?</em> If anyone can come up with the real answer, I'll be happy to change my vote.</p>
","<p>@<a href=""#47143"" rel=""nofollow"">Matthew</a></p>

<p>Your query's a start, but it might not work when you have multiple schemas.  For example, if I log into our instance as myself, I have read access to all our tables.  But if I don't qualify the table name with the schema I'll get an ORA-00942 for tables without synonyms:</p>

<pre>
SQL> select * from tools; 
select * from tools 
              * 
ERROR at line 1: 
ORA-00942: table or view does not exist 
</pre>

<p>The table still shows up in all_tables though:</p>

<pre>
SQL> select owner, table_name from all_tables where table_name = 'TOOLS'; 

OWNER                          TABLE_NAME 
------------------------------ ------------------------------ 
APPLICATION                    TOOLS 
</pre>

<p>@erikson
Sorry that doesn't help much.  I'm with Mark - I used TOAD.</p>
"
136,46380,13,47,sql,Why doesn't Oracle tell you WHICH table or view does not exist?,"<p>If you've used Oracle, you've probably gotten the helpful message ""ORA-00942: Table or view does not exist"". Is there a legitimate technical reason the message doesn't include the name of the missing object? </p>

<p>Arguments about this being due to security sound like they were crafted by the TSA. If I'm an attacker, I'd know what table I just attempted to exploit, and be able to interpret this unhelpful message easily. If I'm a developer working with a complex join through several layers of application code, it's often very difficult to tell.</p>

<p>My guess is that when this error was originally implemented, someone neglected to add the object name, and now, people are afraid it will break compatibility to fix it. (Code doing silly things like parsing the error message will be confused if it changes.)</p>

<p>Is there a developer-friendly (as opposed to recruiting your DBA) way to determine the name of the missing table?</p>

<p><hr /></p>

<p>Although I've accepted an answer which is relevant to the topic, it doesn't really answer my question: <em>Why isn't the name part of the error message?</em> If anyone can come up with the real answer, I'll be happy to change my vote.</p>
","<p>SQL*Plus does tell you the table that doesn't exist. For example:</p>

<pre><code>SQL&gt; select
  2     *
  3  from
  4     user_tables a,
  5     non_existent_table b
  6  where
  7     a.table_name = b.table_name;
   non_existent_table b
   *
ERROR at line 5:
ORA-00942: table or view does not exist
</code></pre>

<p>Here it shows that the name of the missing table and the line number in the SQL statement where the error occurs.</p>

<p>Similarly, in a one-line SQL statement you can see the asterisk highlighting the name of the unknown table:</p>

<pre><code>SQL&gt; select * from user_tables a, non_existent_table b where a.table_name = b.table_name;
select * from user_tables a, non_existent_table b where a.table_name = b.table_name
                             *
ERROR at line 1:
ORA-00942: table or view does not exist
</code></pre>

<p>In terms of your question, I guess the reason the error message doesn't include the name of the table is that the error message itself needs to be static text. The line number and location in the line of the error is clearly passed back to SQL*Plus (somehow).</p>
"
132,46380,11,47,sql,Why doesn't Oracle tell you WHICH table or view does not exist?,"<p>If you've used Oracle, you've probably gotten the helpful message ""ORA-00942: Table or view does not exist"". Is there a legitimate technical reason the message doesn't include the name of the missing object? </p>

<p>Arguments about this being due to security sound like they were crafted by the TSA. If I'm an attacker, I'd know what table I just attempted to exploit, and be able to interpret this unhelpful message easily. If I'm a developer working with a complex join through several layers of application code, it's often very difficult to tell.</p>

<p>My guess is that when this error was originally implemented, someone neglected to add the object name, and now, people are afraid it will break compatibility to fix it. (Code doing silly things like parsing the error message will be confused if it changes.)</p>

<p>Is there a developer-friendly (as opposed to recruiting your DBA) way to determine the name of the missing table?</p>

<p><hr /></p>

<p>Although I've accepted an answer which is relevant to the topic, it doesn't really answer my question: <em>Why isn't the name part of the error message?</em> If anyone can come up with the real answer, I'll be happy to change my vote.</p>
","<p>You can set an EVENT in your parameter file (plain text or spfile) to force Oracle to dump a detailed trace file in the user_dump_dest, the object name might be in there, if not the SQL should be.</p>

<p>EVENT=""942 trace name errorstack level 12""</p>

<p>If you are using a plain text file you need to keep all your EVENT settings on consecutive lines. Not sure how that applied to spfile.</p>
"
133,46380,5,47,sql,Why doesn't Oracle tell you WHICH table or view does not exist?,"<p>If you've used Oracle, you've probably gotten the helpful message ""ORA-00942: Table or view does not exist"". Is there a legitimate technical reason the message doesn't include the name of the missing object? </p>

<p>Arguments about this being due to security sound like they were crafted by the TSA. If I'm an attacker, I'd know what table I just attempted to exploit, and be able to interpret this unhelpful message easily. If I'm a developer working with a complex join through several layers of application code, it's often very difficult to tell.</p>

<p>My guess is that when this error was originally implemented, someone neglected to add the object name, and now, people are afraid it will break compatibility to fix it. (Code doing silly things like parsing the error message will be confused if it changes.)</p>

<p>Is there a developer-friendly (as opposed to recruiting your DBA) way to determine the name of the missing table?</p>

<p><hr /></p>

<p>Although I've accepted an answer which is relevant to the topic, it doesn't really answer my question: <em>Why isn't the name part of the error message?</em> If anyone can come up with the real answer, I'll be happy to change my vote.</p>
","<p>If you are using a SQL browsing tool like TOAD or TORA it will help you with ORA errors by highlightling or pointing moving the cursor to where you made your error.</p>

<p>Copy and paste your SQL in to one of these tools to help. You may also find the analyse info available useful too.</p>
"
134,46380,4,47,sql,Why doesn't Oracle tell you WHICH table or view does not exist?,"<p>If you've used Oracle, you've probably gotten the helpful message ""ORA-00942: Table or view does not exist"". Is there a legitimate technical reason the message doesn't include the name of the missing object? </p>

<p>Arguments about this being due to security sound like they were crafted by the TSA. If I'm an attacker, I'd know what table I just attempted to exploit, and be able to interpret this unhelpful message easily. If I'm a developer working with a complex join through several layers of application code, it's often very difficult to tell.</p>

<p>My guess is that when this error was originally implemented, someone neglected to add the object name, and now, people are afraid it will break compatibility to fix it. (Code doing silly things like parsing the error message will be confused if it changes.)</p>

<p>Is there a developer-friendly (as opposed to recruiting your DBA) way to determine the name of the missing table?</p>

<p><hr /></p>

<p>Although I've accepted an answer which is relevant to the topic, it doesn't really answer my question: <em>Why isn't the name part of the error message?</em> If anyone can come up with the real answer, I'll be happy to change my vote.</p>
","<p>If its not a huge statement, then the easiest way is just to check the data dictionary,</p>

<pre><code>SQL&gt; select * from xx,abc;
select * from xx,abc
                 *
ERROR at line 1:
ORA-00942: table or view does not exist


SQL&gt; select owner,table_name from all_tables where table_name in ('XX','ABC');

OWNER                          TABLE_NAME
------------------------------ ------------------------------
MWATSON                        XX

SQL&gt;
</code></pre>

<p>This isn't ideal, but short of going and examining trace files, I'm not sure how else to do it.</p>
"
433,191640,5,39,sql,Get null == null in SQL,"<p>I wish to search a database table on a nullable column.  Sometimes the value I'm search for is itself NULL.  Since Null is equal to nothing, even NULL, saying</p>

<pre><code>where MYCOLUMN=SEARCHVALUE
</code></pre>

<p>will fail.  Right now I have to resort to</p>

<pre><code>where ((MYCOLUMN=SEARCHVALUE) OR (MYCOLUMN is NULL and SEARCHVALUE is NULL))
</code></pre>

<p>Is there a simpler way of saying that?</p>

<p>(I'm using Oracle if that matters)</p>
","<p>Another alternative, which is probably optimal from the executed query point of view, and <em>will be useful only if you are doing some kind of query generation</em> is to generate the exact query you need based on the search value.</p>

<p>Pseudocode follows.</p>

<pre><code>if (SEARCHVALUE IS NULL) {
    condition = 'MYCOLUMN IS NULL'
} else {
    condition = 'MYCOLUMN=SEARCHVALUE'
}
runQuery(query,condition)
</code></pre>
"
428,191640,1,39,sql,Get null == null in SQL,"<p>I wish to search a database table on a nullable column.  Sometimes the value I'm search for is itself NULL.  Since Null is equal to nothing, even NULL, saying</p>

<pre><code>where MYCOLUMN=SEARCHVALUE
</code></pre>

<p>will fail.  Right now I have to resort to</p>

<pre><code>where ((MYCOLUMN=SEARCHVALUE) OR (MYCOLUMN is NULL and SEARCHVALUE is NULL))
</code></pre>

<p>Is there a simpler way of saying that?</p>

<p>(I'm using Oracle if that matters)</p>
","<p>Try </p>

<pre><code>WHERE NVL(mycolumn,'NULL') = NVL(searchvalue,'NULL')
</code></pre>
"
429,191640,7,39,sql,Get null == null in SQL,"<p>I wish to search a database table on a nullable column.  Sometimes the value I'm search for is itself NULL.  Since Null is equal to nothing, even NULL, saying</p>

<pre><code>where MYCOLUMN=SEARCHVALUE
</code></pre>

<p>will fail.  Right now I have to resort to</p>

<pre><code>where ((MYCOLUMN=SEARCHVALUE) OR (MYCOLUMN is NULL and SEARCHVALUE is NULL))
</code></pre>

<p>Is there a simpler way of saying that?</p>

<p>(I'm using Oracle if that matters)</p>
","<p>Use NVL to replace null with some dummy value on both sides, as in:</p>

<pre><code>WHERE NVL(MYCOLUMN,0) = NVL(SEARCHVALUE,0)
</code></pre>
"
430,191640,11,39,sql,Get null == null in SQL,"<p>I wish to search a database table on a nullable column.  Sometimes the value I'm search for is itself NULL.  Since Null is equal to nothing, even NULL, saying</p>

<pre><code>where MYCOLUMN=SEARCHVALUE
</code></pre>

<p>will fail.  Right now I have to resort to</p>

<pre><code>where ((MYCOLUMN=SEARCHVALUE) OR (MYCOLUMN is NULL and SEARCHVALUE is NULL))
</code></pre>

<p>Is there a simpler way of saying that?</p>

<p>(I'm using Oracle if that matters)</p>
","<p>I don't know if it's simpler, but I've occasionally used
<pre><code>
WHERE ISNULL(MyColumn, -1) = ISNULL(SearchValue, -1)
</pre></code></p>

<p>Replacing ""-1"" with some value that is valid for the column type but also not likely to be actually found in the data.</p>

<p>NOTE: I use MS SQL, not Oracle, so not sure if ""ISNULL"" is valid.</p>
"
431,191640,61,39,sql,Get null == null in SQL,"<p>I wish to search a database table on a nullable column.  Sometimes the value I'm search for is itself NULL.  Since Null is equal to nothing, even NULL, saying</p>

<pre><code>where MYCOLUMN=SEARCHVALUE
</code></pre>

<p>will fail.  Right now I have to resort to</p>

<pre><code>where ((MYCOLUMN=SEARCHVALUE) OR (MYCOLUMN is NULL and SEARCHVALUE is NULL))
</code></pre>

<p>Is there a simpler way of saying that?</p>

<p>(I'm using Oracle if that matters)</p>
","<p>You can do the IsNull or NVL stuff, but it's just going to make the engine do more work.  You'll be calling functions to do column conversions which then have to have the results compared.</p>

<p>Use what you have</p>

<pre><code>where ((MYCOLUMN=SEARCHVALUE) OR (MYCOLUMN is NULL and SEARCHVALUE is NULL))
</code></pre>
"
432,191640,-1,39,sql,Get null == null in SQL,"<p>I wish to search a database table on a nullable column.  Sometimes the value I'm search for is itself NULL.  Since Null is equal to nothing, even NULL, saying</p>

<pre><code>where MYCOLUMN=SEARCHVALUE
</code></pre>

<p>will fail.  Right now I have to resort to</p>

<pre><code>where ((MYCOLUMN=SEARCHVALUE) OR (MYCOLUMN is NULL and SEARCHVALUE is NULL))
</code></pre>

<p>Is there a simpler way of saying that?</p>

<p>(I'm using Oracle if that matters)</p>
","<p>I would think that what you have is OK. You could maybe use:</p>

<pre><code>where NVL(MYCOLUMN, '') = NVL(SEARCHVALUE, '')
</code></pre>
"
434,191640,32,39,sql,Get null == null in SQL,"<p>I wish to search a database table on a nullable column.  Sometimes the value I'm search for is itself NULL.  Since Null is equal to nothing, even NULL, saying</p>

<pre><code>where MYCOLUMN=SEARCHVALUE
</code></pre>

<p>will fail.  Right now I have to resort to</p>

<pre><code>where ((MYCOLUMN=SEARCHVALUE) OR (MYCOLUMN is NULL and SEARCHVALUE is NULL))
</code></pre>

<p>Is there a simpler way of saying that?</p>

<p>(I'm using Oracle if that matters)</p>
","<p>@Andy Lester asserts that the original form of the query is more efficient than using NVL. I decided to test that assertion:</p>

<pre><code>    SQL&gt; DECLARE
      2    CURSOR B IS
      3       SELECT batch_id, equipment_id
      4         FROM batch;
      5    v_t1  NUMBER;
      6    v_t2  NUMBER;
      7    v_c1  NUMBER;
      8    v_c2  NUMBER;
      9    v_b   INTEGER;
     10  BEGIN
     11  -- Form 1 of the where clause
     12    v_t1 := dbms_utility.get_time;
     13    v_c1 := dbms_utility.get_cpu_time;
     14    FOR R IN B LOOP
     15       SELECT COUNT(*)
     16         INTO v_b
     17         FROM batch
     18        WHERE equipment_id = R.equipment_id OR (equipment_id IS NULL AND R.equipment_id IS NULL);
     19    END LOOP;
     20    v_t2 := dbms_utility.get_time;
     21    v_c2 := dbms_utility.get_cpu_time;
     22    dbms_output.put_line('For clause: WHERE equipment_id = R.equipment_id OR (equipment_id IS NULL AND R.equipment_id IS NULL)');
     23    dbms_output.put_line('CPU seconds used: '||(v_c2 - v_c1)/100);
     24    dbms_output.put_line('Elapsed time: '||(v_t2 - v_t1)/100);
     25  
     26  -- Form 2 of the where clause
     27    v_t1 := dbms_utility.get_time;
     28    v_c1 := dbms_utility.get_cpu_time;
     29    FOR R IN B LOOP
     30       SELECT COUNT(*)
     31         INTO v_b
     32         FROM batch
     33        WHERE NVL(equipment_id,'xxxx') = NVL(R.equipment_id,'xxxx');
     34    END LOOP;
     35    v_t2 := dbms_utility.get_time;
     36    v_c2 := dbms_utility.get_cpu_time;
     37    dbms_output.put_line('For clause: WHERE NVL(equipment_id,''xxxx'') = NVL(R.equipment_id,''xxxx'')');
     38    dbms_output.put_line('CPU seconds used: '||(v_c2 - v_c1)/100);
     39    dbms_output.put_line('Elapsed time: '||(v_t2 - v_t1)/100);
     40  END;
     41  /


    For clause: WHERE equipment_id = R.equipment_id OR (equipment_id IS NULL AND R.equipment_id IS NULL)
    CPU seconds used: 84.69
    Elapsed time: 84.8
    For clause: WHERE NVL(equipment_id,'xxxx') = NVL(R.equipment_id,'xxxx')
    CPU seconds used: 124
    Elapsed time: 124.01

    PL/SQL procedure successfully completed

    SQL&gt; select count(*) from batch;

  COUNT(*)
----------
     20903

SQL&gt;
</code></pre>

<p>I was kind of surprised to find out just how correct Andy is. It costs nearly 50% more to do the NVL solution. So, even though one piece of code might not look as tidy or elegant as another, it could be significantly more efficient.  I ran this procedure multiple times, and the results were nearly the same each time. Kudos to Andy...</p>
"
435,191640,2,39,sql,Get null == null in SQL,"<p>I wish to search a database table on a nullable column.  Sometimes the value I'm search for is itself NULL.  Since Null is equal to nothing, even NULL, saying</p>

<pre><code>where MYCOLUMN=SEARCHVALUE
</code></pre>

<p>will fail.  Right now I have to resort to</p>

<pre><code>where ((MYCOLUMN=SEARCHVALUE) OR (MYCOLUMN is NULL and SEARCHVALUE is NULL))
</code></pre>

<p>Is there a simpler way of saying that?</p>

<p>(I'm using Oracle if that matters)</p>
","<p>If an out-of-band value is possible:</p>

<pre><code>where coalesce(mycolumn, 'out-of-band') 
    = coalesce(searchvalue, 'out-of-band')
</code></pre>
"
436,191640,1,39,sql,Get null == null in SQL,"<p>I wish to search a database table on a nullable column.  Sometimes the value I'm search for is itself NULL.  Since Null is equal to nothing, even NULL, saying</p>

<pre><code>where MYCOLUMN=SEARCHVALUE
</code></pre>

<p>will fail.  Right now I have to resort to</p>

<pre><code>where ((MYCOLUMN=SEARCHVALUE) OR (MYCOLUMN is NULL and SEARCHVALUE is NULL))
</code></pre>

<p>Is there a simpler way of saying that?</p>

<p>(I'm using Oracle if that matters)</p>
","<p>This can also do the job in Oracle.</p>

<pre><code>WHERE MYCOLUMN || 'X'  = SEARCHVALUE || 'X'
</code></pre>

<p>There are some situations where it beats the IS NULL test with the OR.</p>

<p>I was also surprised that DECODE lets you check NULL against NULL.</p>

<pre><code>WITH 
TEST AS
(
    SELECT NULL A FROM DUAL
)
SELECT DECODE (A, NULL, 'NULL IS EQUAL', 'NULL IS NOT EQUAL')
FROM TEST
</code></pre>
"
261,119730,5,38,sql,How do I sort a VARCHAR column in SQL server that contains numbers?,"<p>I have a <code>VARCHAR</code> column in a <code>SQL Server 2000</code> database that can contain either letters or numbers. It depends on how the application is configured on the front-end for the customer. </p>

<p>When it does contain numbers, I want it to be sorted numerically, e.g. as ""1"", ""2"", ""10"" instead of ""1"", ""10"", ""2"". Fields containing just letters, or letters and numbers (such as 'A1') can be sorted alphabetically as normal. For example, this would be an acceptable sort order.</p>

<pre><code>1
2
10
A
B
B1
</code></pre>

<p>What is the best way to achieve this? </p>
","<pre><code>select
  Field1, Field2...
from
  Table1
order by
  isnumeric(Field1) desc,
  case when isnumeric(Field1) = 1 then cast(Field1 as int) else null end,
  Field1
</code></pre>

<p>This will return values in the order you gave in your question.</p>

<p>Performance won't be too great with all that casting going on, so another approach is to add another column to the table in which you store an integer copy of the data and then sort by that first and then the column in question. This will obviously require some changes to the logic that inserts or updates data in the table, to populate both columns. Either that, or put a trigger on the table to populate the second column whenever data is inserted or updated.</p>
"
263,119730,49,38,sql,How do I sort a VARCHAR column in SQL server that contains numbers?,"<p>I have a <code>VARCHAR</code> column in a <code>SQL Server 2000</code> database that can contain either letters or numbers. It depends on how the application is configured on the front-end for the customer. </p>

<p>When it does contain numbers, I want it to be sorted numerically, e.g. as ""1"", ""2"", ""10"" instead of ""1"", ""10"", ""2"". Fields containing just letters, or letters and numbers (such as 'A1') can be sorted alphabetically as normal. For example, this would be an acceptable sort order.</p>

<pre><code>1
2
10
A
B
B1
</code></pre>

<p>What is the best way to achieve this? </p>
","<p>One possible solution is to pad the numeric values with a character in front so that all are of the same string length.</p>

<p>Here is an example using that approach:</p>

<pre class=""lang-sql prettyprint-override""><code>select MyColumn
from MyTable
order by 
    case IsNumeric(MyColumn) 
        when 1 then Replicate('0', 100 - Len(MyColumn)) + MyColumn
        else MyColumn
    end
</code></pre>

<p>The <code>100</code> should be replaced with the actual length of that column.</p>
"
262,119730,2,38,sql,How do I sort a VARCHAR column in SQL server that contains numbers?,"<p>I have a <code>VARCHAR</code> column in a <code>SQL Server 2000</code> database that can contain either letters or numbers. It depends on how the application is configured on the front-end for the customer. </p>

<p>When it does contain numbers, I want it to be sorted numerically, e.g. as ""1"", ""2"", ""10"" instead of ""1"", ""10"", ""2"". Fields containing just letters, or letters and numbers (such as 'A1') can be sorted alphabetically as normal. For example, this would be an acceptable sort order.</p>

<pre><code>1
2
10
A
B
B1
</code></pre>

<p>What is the best way to achieve this? </p>
","<p>This seems to work:  </p>

<pre><code>select your_column  
from your_table  
order by   
case when isnumeric(your_column) = 1 then your_column else 999999999 end,  
your_column   
</code></pre>
"
260,119730,0,38,sql,How do I sort a VARCHAR column in SQL server that contains numbers?,"<p>I have a <code>VARCHAR</code> column in a <code>SQL Server 2000</code> database that can contain either letters or numbers. It depends on how the application is configured on the front-end for the customer. </p>

<p>When it does contain numbers, I want it to be sorted numerically, e.g. as ""1"", ""2"", ""10"" instead of ""1"", ""10"", ""2"". Fields containing just letters, or letters and numbers (such as 'A1') can be sorted alphabetically as normal. For example, this would be an acceptable sort order.</p>

<pre><code>1
2
10
A
B
B1
</code></pre>

<p>What is the best way to achieve this? </p>
","<pre><code>SELECT FIELD FROM TABLE
ORDER BY 
  isnumeric(FIELD) desc, 
  CASE ISNUMERIC(test) 
    WHEN 1 THEN CAST(CAST(test AS MONEY) AS INT)
    ELSE NULL 
  END,
  FIELD
</code></pre>

<p>As per <a href=""http://www.experts-exchange.com/Microsoft/Development/MS-SQL-Server/Q_23258510.html"" rel=""nofollow"">this link</a> you need to cast to MONEY then INT to avoid ordering '$' as a number.</p>
"
259,119730,8,38,sql,How do I sort a VARCHAR column in SQL server that contains numbers?,"<p>I have a <code>VARCHAR</code> column in a <code>SQL Server 2000</code> database that can contain either letters or numbers. It depends on how the application is configured on the front-end for the customer. </p>

<p>When it does contain numbers, I want it to be sorted numerically, e.g. as ""1"", ""2"", ""10"" instead of ""1"", ""10"", ""2"". Fields containing just letters, or letters and numbers (such as 'A1') can be sorted alphabetically as normal. For example, this would be an acceptable sort order.</p>

<pre><code>1
2
10
A
B
B1
</code></pre>

<p>What is the best way to achieve this? </p>
","<p>There are a few possible ways to do this.</p>

<p>One would be</p>

<pre><code>SELECT
 ...
ORDER BY
  CASE 
    WHEN ISNUMERIC(value) = 1 THEN CONVERT(INT, value) 
    ELSE 9999999 -- or something huge
  END,
  value
</code></pre>

<p>the first part of the ORDER BY converts everything to an int (with a huge value for non-numerics, to sort last) then the last part takes care of alphabetics.</p>

<p>Note that the performance of this query is probably at least moderately ghastly on large amounts of data.</p>
"
146,58940,0,33,sql,Access to Result sets from within Stored procedures Transact-SQL SQL Server,"<p>I'm using SQL Server 2005, and I would like to know how to access different result sets from within transact-sql. The following stored procedure returns two result sets, how do I access them from, for example, another stored procedure?</p>

<pre><code>CREATE PROCEDURE getOrder (@orderId as numeric) AS
BEGIN   
    select order_address, order_number from order_table where order_id = @orderId
    select item, number_of_items, cost from order_line where order_id = @orderId
END
</code></pre>

<p>I need to be able to iterate through both result sets individually.</p>

<p>EDIT: Just to clarify the question, I want to test the stored procedures. I have a set of stored procedures which are used from a VB.NET client, which return multiple result sets. These are not going to be changed to a table valued function, I can't in fact change the procedures at all. Changing the procedure is not an option.</p>

<p>The result sets returned by the procedures are not the same data types or number of columns.</p>
","<p>You could select them into temp tables or write table valued functions to return result sets. Are asking how to iterate through the result sets?</p>
"
147,58940,1,33,sql,Access to Result sets from within Stored procedures Transact-SQL SQL Server,"<p>I'm using SQL Server 2005, and I would like to know how to access different result sets from within transact-sql. The following stored procedure returns two result sets, how do I access them from, for example, another stored procedure?</p>

<pre><code>CREATE PROCEDURE getOrder (@orderId as numeric) AS
BEGIN   
    select order_address, order_number from order_table where order_id = @orderId
    select item, number_of_items, cost from order_line where order_id = @orderId
END
</code></pre>

<p>I need to be able to iterate through both result sets individually.</p>

<p>EDIT: Just to clarify the question, I want to test the stored procedures. I have a set of stored procedures which are used from a VB.NET client, which return multiple result sets. These are not going to be changed to a table valued function, I can't in fact change the procedures at all. Changing the procedure is not an option.</p>

<p>The result sets returned by the procedures are not the same data types or number of columns.</p>
","<p>There are two ways to do this easily. Either stick the results in a temp table and then reference the temp table from your sproc. The other alternative is to put the results into an XML variable that is used as an OUTPUT variable.</p>

<p>There are, however, pros and cons to both of these options. With a temporary table, you'll need to add code to the script that creates the calling procedure to create the temporary table before modifying the procedure. Also, you should clean up the temp table at the end of the procedure.</p>

<p>With the XML, it can be memory intensive and slow.</p>
"
148,58940,32,33,sql,Access to Result sets from within Stored procedures Transact-SQL SQL Server,"<p>I'm using SQL Server 2005, and I would like to know how to access different result sets from within transact-sql. The following stored procedure returns two result sets, how do I access them from, for example, another stored procedure?</p>

<pre><code>CREATE PROCEDURE getOrder (@orderId as numeric) AS
BEGIN   
    select order_address, order_number from order_table where order_id = @orderId
    select item, number_of_items, cost from order_line where order_id = @orderId
END
</code></pre>

<p>I need to be able to iterate through both result sets individually.</p>

<p>EDIT: Just to clarify the question, I want to test the stored procedures. I have a set of stored procedures which are used from a VB.NET client, which return multiple result sets. These are not going to be changed to a table valued function, I can't in fact change the procedures at all. Changing the procedure is not an option.</p>

<p>The result sets returned by the procedures are not the same data types or number of columns.</p>
","<p>The short answer is: you can't do it.</p>

<p>From T-SQL there is no way to access multiple results of a nested stored procedure call, without changing the stored procedure as others have suggested.</p>

<p>To be complete, if the procedure were returning a single result, you could insert it into a temp table or table variable with the following syntax:</p>

<pre><code>INSERT INTO #Table (...columns...)
EXEC MySproc ...parameters...
</code></pre>

<p>You can use the same syntax for a procedure that returns multiple results, but it will only process the first result, the rest will be discarded.</p>
"
149,58940,4,33,sql,Access to Result sets from within Stored procedures Transact-SQL SQL Server,"<p>I'm using SQL Server 2005, and I would like to know how to access different result sets from within transact-sql. The following stored procedure returns two result sets, how do I access them from, for example, another stored procedure?</p>

<pre><code>CREATE PROCEDURE getOrder (@orderId as numeric) AS
BEGIN   
    select order_address, order_number from order_table where order_id = @orderId
    select item, number_of_items, cost from order_line where order_id = @orderId
END
</code></pre>

<p>I need to be able to iterate through both result sets individually.</p>

<p>EDIT: Just to clarify the question, I want to test the stored procedures. I have a set of stored procedures which are used from a VB.NET client, which return multiple result sets. These are not going to be changed to a table valued function, I can't in fact change the procedures at all. Changing the procedure is not an option.</p>

<p>The result sets returned by the procedures are not the same data types or number of columns.</p>
","<p>Note that there's an extra, undocumented limitation to the INSERT INTO ... EXEC statement: it cannot be nested. That is, the stored proc that the EXEC calls (or any that it calls in turn) cannot itself do an INSERT INTO ... EXEC. It appears that there's a single scratchpad per process that accumulates the result, and if they're nested you'll get an error when the caller opens this up, and then the callee tries to open it again.</p>

<p>Matthieu, you'd need to maintain separate temp tables for each ""type"" of result. Also, if you're executing the same one multiple times, you might need to add an extra column to that result to indicate which call it resulted from.</p>
"
150,58940,2,33,sql,Access to Result sets from within Stored procedures Transact-SQL SQL Server,"<p>I'm using SQL Server 2005, and I would like to know how to access different result sets from within transact-sql. The following stored procedure returns two result sets, how do I access them from, for example, another stored procedure?</p>

<pre><code>CREATE PROCEDURE getOrder (@orderId as numeric) AS
BEGIN   
    select order_address, order_number from order_table where order_id = @orderId
    select item, number_of_items, cost from order_line where order_id = @orderId
END
</code></pre>

<p>I need to be able to iterate through both result sets individually.</p>

<p>EDIT: Just to clarify the question, I want to test the stored procedures. I have a set of stored procedures which are used from a VB.NET client, which return multiple result sets. These are not going to be changed to a table valued function, I can't in fact change the procedures at all. Changing the procedure is not an option.</p>

<p>The result sets returned by the procedures are not the same data types or number of columns.</p>
","<p>Sadly it is impossible to do this. The problem is, of course, that there is no SQL Syntax to allow it. It happens 'beneath the hood' of course, but you can't get at these other results in TSQL, only from the application via ODBC or whatever. </p>

<p>There is a way round it, as with most things. The trick is to use ole automation in TSQL to create an ADODB object which opens each resultset in turn and write the results to the tables you nominate (or do whatever you want with the resultsets). you can also do it in DMO if you enjoy pain. </p>
"
9,2840,32,32,sql,Paging SQL Server 2005 Results,"<p>How do I page results in SQL Server 2005?</p>

<p>I tried it in SQL Server 2000, but there was no reliable way to do this. I'm now wondering if SQL Server 2005 has any built in method?</p>

<p>What I mean by paging is, for example, if I list users by their username, I want to be able to only return the first 10 records, then the next 10 records and so on.</p>

<p>Any help would be much appreciated.</p>
","<p>You can use <code>the Row_Number()</code> function.
Its used as follows:</p>

<pre><code>SELECT Row_Number() OVER(ORDER BY UserName) As RowID, UserFirstName, UserLastName
FROM Users
</code></pre>

<p>From which it will yield a result set with a <code>RowID</code> field which you can use to page between.</p>

<pre><code>SELECT * 
FROM 
    ( SELECT Row_Number() OVER(ORDER BY UserName) As RowID, UserFirstName, UserLastName
      FROM Users 
    ) As RowResults
WHERE RowID Between 5 AND 10
</code></pre>

<p>etc</p>
"
13,2840,2,32,sql,Paging SQL Server 2005 Results,"<p>How do I page results in SQL Server 2005?</p>

<p>I tried it in SQL Server 2000, but there was no reliable way to do this. I'm now wondering if SQL Server 2005 has any built in method?</p>

<p>What I mean by paging is, for example, if I list users by their username, I want to be able to only return the first 10 records, then the next 10 records and so on.</p>

<p>Any help would be much appreciated.</p>
","<p>When I need to do paging, I typically use a temporary table as well.  You can use an output parameter to return the total number of records.  The case statements in the select allow you to sort the data on specific columns without needing to resort to dynamic SQL.</p>

<pre><code>--Declaration--

--Variables
@StartIndex INT,
@PageSize INT,
@SortColumn VARCHAR(50),
@SortDirection CHAR(3),
@Results INT OUTPUT

--Statements--
SELECT @Results = COUNT(ID) FROM Customers
WHERE FirstName LIKE '%a%'

SET @StartIndex = @StartIndex - 1 --Either do this here or in code, but be consistent
CREATE TABLE #Page(ROW INT IDENTITY(1,1) NOT NULL, id INT, sorting_1 SQL_VARIANT, sorting_2 SQL_VARIANT)
INSERT INTO #Page(ID, sorting_1, sorting_2)
SELECT TOP (@StartIndex + @PageSize)
    ID,
    CASE
    	WHEN @SortColumn='FirstName' AND @SortDirection='ASC' THEN CAST(FirstName AS SQL_VARIANT)
    	WHEN @SortColumn='LastName' AND @SortDirection='ASC' THEN CAST(LastName AS SQL_VARIANT)
    	ELSE NULL
    END AS sort_1,
    CASE
    	WHEN @SortColumn='FirstName' AND @SortDirection='DES' THEN CAST(FirstName AS SQL_VARIANT)
    	WHEN @SortColumn='LastName' AND @SortDirection='DES' THEN CAST(LastName AS SQL_VARIANT)
    	ELSE NULL
    END AS sort_2
FROM (
    SELECT
    	CustomerId AS ID,
    	FirstName,
    	LastName
    FROM Customers
    WHERE
    	FirstName LIKE '%a%'
) C
ORDER BY sort_1 ASC, sort_2 DESC, ID ASC;

SELECT
    ID,
    Customers.FirstName,
    Customers.LastName
FROM #Page
INNER JOIN Customers ON
    ID = Customers.CustomerId
WHERE ROW &gt; @StartIndex AND ROW &lt;= (@StartIndex + @PageSize)
ORDER BY ROW ASC

DROP TABLE #Page
</code></pre>
"
552,247090,19,32,sql,How to debug ORA-01775: looping chain of synonyms?,"<p>I'm familiar with the issue behind ORA-01775: looping chain of synonyms, but is there any trick to debugging it, or do I just have to ""create or replace"" my way out of it?  </p>

<p>Is there a way to query the schema or whatever to find out what the current definition of a public synonym is?  </p>

<p>Even more awesome would be a graphical tool, but at this point, anything would be helpful.</p>
","<p>The data dictionary table <code>DBA_SYNONYMS</code> has information about all the synonyms in a database.  So you can run the query</p>

<pre><code>SELECT table_owner, table_name, db_link
  FROM dba_synonyms 
 WHERE owner        = 'PUBLIC'
   AND synonym_name = &lt;&lt;synonym name&gt;&gt;
</code></pre>

<p>to see what the public synonym currently points at.</p>
"
553,247090,0,32,sql,How to debug ORA-01775: looping chain of synonyms?,"<p>I'm familiar with the issue behind ORA-01775: looping chain of synonyms, but is there any trick to debugging it, or do I just have to ""create or replace"" my way out of it?  </p>

<p>Is there a way to query the schema or whatever to find out what the current definition of a public synonym is?  </p>

<p>Even more awesome would be a graphical tool, but at this point, anything would be helpful.</p>
","<p><a href=""http://ora-01775.ora-code.com/"" rel=""nofollow"">http://ora-01775.ora-code.com/</a> suggests:</p>

<p><strong>ORA-01775</strong>:  looping chain of synonyms<br />
<em>Cause</em>:    Through a series of CREATE synonym statements, a synonym was defined that referred to itself. For example, the following definitions are circular:<br />
<code>CREATE SYNONYM s1 for s2 CREATE SYNONYM s2 for s3 CREATE SYNONYM s3 for s1</code><br />
<em>Action</em>:   Change one synonym definition so that it applies to a base table or view and retry the operation.</p>
"
554,247090,51,32,sql,How to debug ORA-01775: looping chain of synonyms?,"<p>I'm familiar with the issue behind ORA-01775: looping chain of synonyms, but is there any trick to debugging it, or do I just have to ""create or replace"" my way out of it?  </p>

<p>Is there a way to query the schema or whatever to find out what the current definition of a public synonym is?  </p>

<p>Even more awesome would be a graphical tool, but at this point, anything would be helpful.</p>
","<p>As it turns out, the problem wasn't actually a looping chain of synonyms, but the fact that the synonym was pointing to a view that did not exist.</p>

<p>Oracle apparently errors out as a looping chain in this condition.</p>
"
12,2840,13,32,sql,Paging SQL Server 2005 Results,"<p>How do I page results in SQL Server 2005?</p>

<p>I tried it in SQL Server 2000, but there was no reliable way to do this. I'm now wondering if SQL Server 2005 has any built in method?</p>

<p>What I mean by paging is, for example, if I list users by their username, I want to be able to only return the first 10 records, then the next 10 records and so on.</p>

<p>Any help would be much appreciated.</p>
","<p>If you're trying to get it in one statement (the total plus the paging).  You might need to explore SQL Server support for the partition by clause (windowing functions in ANSI SQL terms).  In Oracle the syntax is just like the example above using row_number(), but I have also added a partition by clause to get the total number of rows included with each row returned in the paging (total rows is 1,262):</p>

<pre><code>SELECT rn, total_rows, x.OWNER, x.object_name, x.object_type
  FROM (SELECT COUNT (*) OVER (PARTITION BY owner) AS TOTAL_ROWS,
               ROW_NUMBER () OVER (ORDER BY 1) AS rn, uo.*
          FROM all_objects uo
         WHERE owner = 'CSEIS') x
 WHERE rn BETWEEN 6 AND 10
</code></pre>

<p>Note that I have where owner = 'CSEIS' and my partition by is on owner.  So the results are:</p>

<pre><code>RN  TOTAL_ROWS  OWNER   OBJECT_NAME OBJECT_TYPE
6   1262    CSEIS   CG$BDS_MODIFICATION_TYPES   TRIGGER
7   1262    CSEIS   CG$AUS_MODIFICATION_TYPES   TRIGGER
8   1262    CSEIS   CG$BDR_MODIFICATION_TYPES   TRIGGER
9   1262    CSEIS   CG$ADS_MODIFICATION_TYPES   TRIGGER
10  1262    CSEIS   CG$BIS_LANGUAGES    TRIGGER
</code></pre>
"
11,2840,0,32,sql,Paging SQL Server 2005 Results,"<p>How do I page results in SQL Server 2005?</p>

<p>I tried it in SQL Server 2000, but there was no reliable way to do this. I'm now wondering if SQL Server 2005 has any built in method?</p>

<p>What I mean by paging is, for example, if I list users by their username, I want to be able to only return the first 10 records, then the next 10 records and so on.</p>

<p>Any help would be much appreciated.</p>
","<p>Here's what I do for paging:  All of my big queries that need to be paged are coded as inserts into a temp table.  The temp table has an identity field that will act in a similar manner to the row_number() mentioned above.  I store the number of rows in the temp table in an output parameter so the calling code knows how many total records there are.  The calling code also specifies which page it wants, and how many rows per page, which are selected out from the temp table.</p>

<p>The cool thing about doing it this way is that I also have an ""Export"" link that allows you to get all rows from the report returned as CSV above every grid in my application.  This link uses the same stored procedure: you just return the contents of the temp table instead of doing the paging logic.  This placates users who hate paging, and want to see <em>everything</em>, and want to sort it in a million different ways.</p>
"
10,2840,0,32,sql,Paging SQL Server 2005 Results,"<p>How do I page results in SQL Server 2005?</p>

<p>I tried it in SQL Server 2000, but there was no reliable way to do this. I'm now wondering if SQL Server 2005 has any built in method?</p>

<p>What I mean by paging is, for example, if I list users by their username, I want to be able to only return the first 10 records, then the next 10 records and so on.</p>

<p>Any help would be much appreciated.</p>
","<p>I believe you'd need to perform a separate query to accomplish that unfortionately.</p>

<p>I was able to accomplish this at my previous position using some help from this page:
<a href=""http://aspnet.4guysfromrolla.com/articles/031506-1.aspx"" rel=""nofollow"">Paging in DotNet 2.0</a></p>

<p>They also have it pulling a row count seperately.</p>"
955,443140,0,30,sql,Insert row in table for each id in another table,"<p>I tried searching here for a similar solution but didn't see one so I was wondering what is the best way to accomplish the following.</p>

<p>I have a table with 17 million + rows all have a unique ID.  We have recently created a new table that will be used in conjunction with the previous table where the foreign key of the new table is the unique id of the old table.</p>

<p>For ex.<br />
Table 1 - id, field1, field2, field3...
table 2 - table1.id, field1 ...</p>

<p>The problem is since we are migrating this into a live environment, we need to back fill table 2 with a row containing the id from table 1 for each row in table 1.
ex, table 1 - 1, test, null
table 2 now needs to have: 1, null, ...  and so on for each row that is in table1.  The main issue is that the ids are not all sequential in table 1 so we will have to read from table 1 and then insert based of the id of found into table 2.</p>

<p>Is there any easier way to go about this?
Thanks in advance
Joe</p>

<p>Also to clarify, table 2 will be new data and the only thing that it will contain from table 1 is the id to keep the foreign key relationship</p>

<p>Also this is sql server 2000</p>
","<p>With that many rows you may run into issues with transaction log space, and length of time running large insert transactions.</p>

<p>If run time is a constraint I'd seriously recommend using Bcp (or what ever tool is applicable depending on the platform)</p>

<p>Select out the id's from the original table, use that to build a Bcp file for the extension table, then Bcp it in.</p>

<p>You many find it more performant to Bcp in files of 10,000 records instead of one humungus file with 17,000,000 rows.</p>

<p>Also, you can do this in the back ground before go live, and write a t-sql job to pick up and that may have been inserted after you took the snapshop of id's.</p>
"
957,443140,35,30,sql,Insert row in table for each id in another table,"<p>I tried searching here for a similar solution but didn't see one so I was wondering what is the best way to accomplish the following.</p>

<p>I have a table with 17 million + rows all have a unique ID.  We have recently created a new table that will be used in conjunction with the previous table where the foreign key of the new table is the unique id of the old table.</p>

<p>For ex.<br />
Table 1 - id, field1, field2, field3...
table 2 - table1.id, field1 ...</p>

<p>The problem is since we are migrating this into a live environment, we need to back fill table 2 with a row containing the id from table 1 for each row in table 1.
ex, table 1 - 1, test, null
table 2 now needs to have: 1, null, ...  and so on for each row that is in table1.  The main issue is that the ids are not all sequential in table 1 so we will have to read from table 1 and then insert based of the id of found into table 2.</p>

<p>Is there any easier way to go about this?
Thanks in advance
Joe</p>

<p>Also to clarify, table 2 will be new data and the only thing that it will contain from table 1 is the id to keep the foreign key relationship</p>

<p>Also this is sql server 2000</p>
","<p>If I understand correctly, you want one record in table2 for each record in table1.
Also I believe that apart from the reference to table1, table2 should initially contain blank rows.</p>

<p>So assuming</p>

<pre><code>table1 (ID, field1, field2, ...)
table2 (ID, table1_ID, fieldA, fieldB,...)
-- where table1_ID is a reference to ID of table1
</code></pre>

<p>After creating table2 you can simply run this insert statement</p>

<pre><code>insert into table2(table1_ID) 
select ID from table1
</code></pre>
"
956,443140,3,30,sql,Insert row in table for each id in another table,"<p>I tried searching here for a similar solution but didn't see one so I was wondering what is the best way to accomplish the following.</p>

<p>I have a table with 17 million + rows all have a unique ID.  We have recently created a new table that will be used in conjunction with the previous table where the foreign key of the new table is the unique id of the old table.</p>

<p>For ex.<br />
Table 1 - id, field1, field2, field3...
table 2 - table1.id, field1 ...</p>

<p>The problem is since we are migrating this into a live environment, we need to back fill table 2 with a row containing the id from table 1 for each row in table 1.
ex, table 1 - 1, test, null
table 2 now needs to have: 1, null, ...  and so on for each row that is in table1.  The main issue is that the ids are not all sequential in table 1 so we will have to read from table 1 and then insert based of the id of found into table 2.</p>

<p>Is there any easier way to go about this?
Thanks in advance
Joe</p>

<p>Also to clarify, table 2 will be new data and the only thing that it will contain from table 1 is the id to keep the foreign key relationship</p>

<p>Also this is sql server 2000</p>
","<p>You need to read this article.</p>

<p><a href=""http://stackoverflow.com/questions/346659/what-are-the-most-common-sql-anti-patterns#346679"">http://stackoverflow.com/questions/346659/what-are-the-most-common-sql-anti-patterns#346679</a></p>

<blockquote>
  <p>The main issue is that the ids are not all sequential in table 1 so we will have to read from table 1 and then insert based of the id of found into table 2</p>
</blockquote>

<p>Yes, look at my answer in the above article and write a key-walking loop using Item #2.</p>

<p>Make sure when you write the insert statement, you provide a fieldlist - as I say in Item #1.</p>
"
689,304940,44,30,sql,How to choose returned column name in a SELECT FOR XML query?,"<p>MS SQL has a convenient workaround for concatenating a column value from multiple rows into one value:</p>

<pre><code>SELECT col1
 FROM table1
 WHERE col2 = 'x'
 ORDER by col3
 FOR XML path('')
</code></pre>

<p>and that returns a nice recordset:</p>

<pre><code>XML_F52E2B61-18A1-11d1-B105-00805F49916B                                     
---------------------------------------- 
&lt;col1&gt;Foo&lt;/col1&gt;&lt;col1&gt;Bar&lt;/col1&gt;
</code></pre>

<p>only the column name in the returned recordset is rather nasty!</p>

<p>The column name seems to include random elements (or a GUID), and hence I am reluctant to use it in my application (different instances or different servers might have another GUID).  Unfortunately I cannot use * to select the value, and due to the restrictions in the existing application I cannot iterate through returned columns, either...</p>

<p>Is there a way to force the column name in the returned recordset to something more sensible?</p>
","<p>That should do:</p>

<pre><code>select(
SELECT col1
 FROM table1
 WHERE col2 = 'x'
 ORDER by col3
 FOR XML path('')
) as myName
</code></pre>

<p>Not pretty but should give the result that you need</p>
"
954,443140,10,30,sql,Insert row in table for each id in another table,"<p>I tried searching here for a similar solution but didn't see one so I was wondering what is the best way to accomplish the following.</p>

<p>I have a table with 17 million + rows all have a unique ID.  We have recently created a new table that will be used in conjunction with the previous table where the foreign key of the new table is the unique id of the old table.</p>

<p>For ex.<br />
Table 1 - id, field1, field2, field3...
table 2 - table1.id, field1 ...</p>

<p>The problem is since we are migrating this into a live environment, we need to back fill table 2 with a row containing the id from table 1 for each row in table 1.
ex, table 1 - 1, test, null
table 2 now needs to have: 1, null, ...  and so on for each row that is in table1.  The main issue is that the ids are not all sequential in table 1 so we will have to read from table 1 and then insert based of the id of found into table 2.</p>

<p>Is there any easier way to go about this?
Thanks in advance
Joe</p>

<p>Also to clarify, table 2 will be new data and the only thing that it will contain from table 1 is the id to keep the foreign key relationship</p>

<p>Also this is sql server 2000</p>
","<p>I am not sure I am exactly following you, but would something like this work for you?</p>

<pre><code>INSERT INTO table2 ( SELECT field1, field2, field3... FROM table1 )
</code></pre>

<p>If I am understanding correctly you want a record in table2 for every record in table1.  This will do just that.  Just match up your fields in the select in the right order, and specify constants for any fields in table2 that you don't have in table1.</p>

<p>HTH.  Let me know if I am not understanding and Ill try to help again.</p>
"
241,105400,5,28,sql,What are indexes and how can I use them to optimize queries in my database?,"<p>I am maintaining a pretty sizable application and database and am noticing some poor database performance in a few of our stored procedures.</p>

<p>I always hear that ""adding an index"" can be done to help performance. I am certainly no DBA, and I do not understand what indexes are, why they help, and how to create them.</p>

<p>I basically need an indexes 101. </p>

<p>Can anyone give me resources so that I can learn?</p>
","<p>An index basically sorts your data on the given columns and then stores that order, so when you want to find an item, the database can optimize by using binary search (or some other optimized way of searching), rather than looking at each individual row.</p>

<p>Thus, if the amount of data you are searching through is large, you will absolutely want to add some indexes.</p>

<p>Most databases have a tool to explain how your query will work (for db2, it's db2expln, something similar probably for sqlserver), and a tool to suggest indexes and other optimizations (db2advis for db2, again probably something similar for sqlserver).</p>
"
242,105400,1,28,sql,What are indexes and how can I use them to optimize queries in my database?,"<p>I am maintaining a pretty sizable application and database and am noticing some poor database performance in a few of our stored procedures.</p>

<p>I always hear that ""adding an index"" can be done to help performance. I am certainly no DBA, and I do not understand what indexes are, why they help, and how to create them.</p>

<p>I basically need an indexes 101. </p>

<p>Can anyone give me resources so that I can learn?</p>
","<p>An index can be explained as a sorted list of the items in a register. It is very quick to lookup the position of the item in the register, by looking for it's key in the index. Next the the key in the index is a pointer to the position in the register where the rest of the record can be found.</p>

<p>You can have many indexes on a register, but the more you have, the slower inserting new records will be (because each index needs a new record as well - in a sorted order, which also adds time).</p>
"
243,105400,23,28,sql,What are indexes and how can I use them to optimize queries in my database?,"<p>I am maintaining a pretty sizable application and database and am noticing some poor database performance in a few of our stored procedures.</p>

<p>I always hear that ""adding an index"" can be done to help performance. I am certainly no DBA, and I do not understand what indexes are, why they help, and how to create them.</p>

<p>I basically need an indexes 101. </p>

<p>Can anyone give me resources so that I can learn?</p>
","<p>Think of an index similar to a card catalog in the library. An index keeps you from having to search through every isle or shelf for a book. Instead, you may be able to find the items you want from a commonly used field, such as and ID, Name, etc. When you build an index the database basically creates something separate that a query could hit to rather than scanning the entire table. You speed up the query by allowing it to search a smaller subset of data, or an optimized set of data. </p>
"
244,105400,1,28,sql,What are indexes and how can I use them to optimize queries in my database?,"<p>I am maintaining a pretty sizable application and database and am noticing some poor database performance in a few of our stored procedures.</p>

<p>I always hear that ""adding an index"" can be done to help performance. I am certainly no DBA, and I do not understand what indexes are, why they help, and how to create them.</p>

<p>I basically need an indexes 101. </p>

<p>Can anyone give me resources so that I can learn?</p>
","<p>Indices are created in an existing table to locate rows more quickly and efficiently. It is possible to create an index on one or more columns of a table, and each index is given a name. The users cannot see the indexes, they are just used to speed up queries.</p>

<p>Basically, your DBMS will create some sort of tree structure which points to the data (from one column) in a sorted manner. This way it is easier to search for data on that column(s).</p>

<p><a href=""http://en.wikipedia.org/wiki/Index%5F%28database%29"" rel=""nofollow"">http://en.wikipedia.org/wiki/Index_(database)</a></p>
"
245,105400,4,28,sql,What are indexes and how can I use them to optimize queries in my database?,"<p>I am maintaining a pretty sizable application and database and am noticing some poor database performance in a few of our stored procedures.</p>

<p>I always hear that ""adding an index"" can be done to help performance. I am certainly no DBA, and I do not understand what indexes are, why they help, and how to create them.</p>

<p>I basically need an indexes 101. </p>

<p>Can anyone give me resources so that I can learn?</p>
","<p>Indexes is a method which database systems use to quickly find data.  The real world analogy are indexes in books.  If an author/publisher does a good job at indexing their book, it becomes pretty easy for the reader to directly go to the page they want to read simply by looking at the index.  Same goes for a database.  If an index is created on a field, the database pre-sorts the data.  When a request is made on the data, the database uses the index to identify which location the data is stored in on the hard disk, and directly goes there.  If there are no indexes, the database needs to look at every record in order to find out if it meets the criteria(s) of your query.</p>

<p>A simple way to look at indexes is by thinking of a deck of cards.  A database which is not indexed is like a deck a cards which have been shuffled.  If you want to find the king of spades, you need to look at every card one by one to find it.  You might be lucky and it can be the first one, or you might be unlucky and it can be the last one.  </p>

<p>A database which is indexed, has all the cards in the deck ordered from ace to king and each suite is set aside in its own pile.  Looking for the king of spades is much simpler now because you simply need to look at the bottom of the pile of cards which contains the spades.</p>

<p>I hope this helps.  Be warned though that although indexes are necessary in a relational database system, they can counter productive if you write too many of them.  There's a ton of great articles on the web that you can read up on indexes.  I'd suggest doing some reading before you dive into them.</p>
"
246,105400,0,28,sql,What are indexes and how can I use them to optimize queries in my database?,"<p>I am maintaining a pretty sizable application and database and am noticing some poor database performance in a few of our stored procedures.</p>

<p>I always hear that ""adding an index"" can be done to help performance. I am certainly no DBA, and I do not understand what indexes are, why they help, and how to create them.</p>

<p>I basically need an indexes 101. </p>

<p>Can anyone give me resources so that I can learn?</p>
","<p>for mssql (and maybe others) the syntax looks like:</p>

<pre><code>create index &lt;indexname&gt; on &lt;tablename&gt;(&lt;column1&gt;[,&lt;column2&gt;...])
</code></pre>
"
247,105400,1,28,sql,What are indexes and how can I use them to optimize queries in my database?,"<p>I am maintaining a pretty sizable application and database and am noticing some poor database performance in a few of our stored procedures.</p>

<p>I always hear that ""adding an index"" can be done to help performance. I am certainly no DBA, and I do not understand what indexes are, why they help, and how to create them.</p>

<p>I basically need an indexes 101. </p>

<p>Can anyone give me resources so that I can learn?</p>
","<p>Some more index information!</p>

<p>Clustered indexes are the actual physical layout of the records in the table. Hence, you can only have one per table.</p>

<p>Nonclustered indexes are the aforementioned card catalog.  Sure, the books are arranged in a particular order, but you can arrange the cards in the catalog by book size, or maybe by number of pages, or by alphabetical last name.</p>

<p>Something to think about -- creating too many indexes is a common pitfall.  Every time your data gets updated your DB has to seek through that index and update it, inserting a record into every index on that table for that new row.  In transactional systems (think: NYSE's stock transactions!) that could be an application killer.</p>
"
248,105400,28,28,sql,What are indexes and how can I use them to optimize queries in my database?,"<p>I am maintaining a pretty sizable application and database and am noticing some poor database performance in a few of our stored procedures.</p>

<p>I always hear that ""adding an index"" can be done to help performance. I am certainly no DBA, and I do not understand what indexes are, why they help, and how to create them.</p>

<p>I basically need an indexes 101. </p>

<p>Can anyone give me resources so that I can learn?</p>
","<p>As a rule of thumb, indexes should be on any fields that you use in joins or where clauses (if they have enough different values to make using an index worthwhile, field with only a few possible values doesn't benefit from an index which is why it is pointless to try to index a bit field). </p>

<p>If your structure has formally created primary keys (which it should, I never create a table without a primary key), those are by definition indexed becasue a primary key is required to have a unique index on it. People often forget that they have to index the foreign keys becasue an index is not automatically created when you set up the foreign key relationsship.  Since the purpose of a foreign key is to give you a field to join on, most foreign keys should probably be indexed.</p>

<p>Indexes once created need to be maintained. If you have a lot of data change activity, they can get fragmented and slow performance and need to be refreshed. Read in Books online about indexes. You can also find the syntax for the create index statement there.</p>

<p>Indexes are a balancing act, every index you add usually will add time to data inserts, updates and deletes but can potentially speed up selects and joins in complex inserts, updates and deletes. There is no one formula for what are the best indexes although the rule of thumb above is a good place to start.</p>
"
249,105400,3,28,sql,What are indexes and how can I use them to optimize queries in my database?,"<p>I am maintaining a pretty sizable application and database and am noticing some poor database performance in a few of our stored procedures.</p>

<p>I always hear that ""adding an index"" can be done to help performance. I am certainly no DBA, and I do not understand what indexes are, why they help, and how to create them.</p>

<p>I basically need an indexes 101. </p>

<p>Can anyone give me resources so that I can learn?</p>
","<p>As previously stated, you can have a clustered index and multiple non-clustered indexes.  In SQL 2005, you can also add additional columns to a non-clustered index, which can improve performance where a few commonly retrieved columns are included with the index but not part of the key, which eliminates a trip to the table altogether.</p>

<p>Your #1 tool for determining what your SQL Server database is doing is the profiler.  You can profile entire workloads and then see what indexes it recommends.  You can also look at execution plans to see what effects an index has.</p>

<p>The too-many indexes problem is due to writing into a database, and having to update all the indexes which would have a record for that row.  If you're having read performance, it's probably not because of too many indexes, but too few, or too unsuitable.</p>
"
114,42620,18,27,sql,"SQL Server Views, blessing or curse?","<p>I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.</p>

<p>The database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.</p>

<p>Several years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.</p>

<p>In hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?</p>
","<p>You've answered your own question:</p>

<blockquote>
  <p>he was encouraging code reuse via copy-and-paste</p>
</blockquote>

<p>Reuse the code by creating a view.  If the view performs poorly, it will be much easier to track down than if you have the same poorly performing code in several places.</p>
"
123,42620,13,27,sql,"SQL Server Views, blessing or curse?","<p>I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.</p>

<p>The database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.</p>

<p>Several years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.</p>

<p>In hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?</p>
","<p>Not a big fan of views (Can't remember the last time I wrote one) but wouldn't ban them entirely either. If your database allows you to put indexes on the views and not just on the table, you can often improve performance a good bit which makes them better. If you are using views, make sure to look into indexing them.</p>

<p>I really only see the need for views for partitioning data and for extremely complex joins that are really critical to the application (thinking of financial reports here where starting from the same dataset for everything might be critical). I do know some reporting tools seem to prefer views over stored procs.</p>

<p>I am a big proponent of never returning more records or fields than you need in a specific instance and the overuse of views tends to make people return more fields (and in way too many cases, too many joins) than they need which wastes system resources. </p>

<p>I also tend to see that people who rely on views (not the developer of the view - the people who only use them) often don't understand the database very well (so they would get the joins wrong if not using the view) and that to me is critical to writing good code against the database. I want people to understand what they are asking the db to do, not rely on some magic black box of a view. That is all personal opinion of course, your mileage may vary.</p>

<p>Like BlaM I personally haven't found them easier to maintain than stored procs.</p>

<p>Edited in Oct 2010 to add:
Since I orginally wrote this, I have had occasion to work with a couple of databases designed by people who were addicted to using views. Even worse they used views that called views that called views (to the point where eventually we hit the limit of the number of tables that can be called). This was a performance nightmare. It took 8 minutes to get a simple count(*) of the records in one view and much longer to get data. If you use views, be very wary of using views that call other views. You will be building a system that will very probably not work under the normal performance load on production. In SQL Server you can only index views that do not call other views, so what ends up happening when you use views in a chain, is that the entire record set has to be built for each view and it is not until you get to the last one that the where clause criteria are applied. You may need to generate millions of records just to see three. You may join to the same table 6 times when you really only need to join to it once, you may return many many more columns than you need in the final results set. </p>
"
116,42620,1,27,sql,"SQL Server Views, blessing or curse?","<p>I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.</p>

<p>The database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.</p>

<p>Several years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.</p>

<p>In hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?</p>
","<p>We use views for all of our simple data exports to csv files. This simplifies the process of writing a package and embedding the sql within the package which becomes cumbersome and hard to debug against.</p>

<p>Using views, we can execute a view and see exactly what was exported, no cruft or unknowns. It greatly helps in troubleshooting problems with improper data exports and hides any complex joins behind the view. Granted, we use a very old legacy system from a TERMS based system that exports to sql, so the joins are a little more complex than usual.</p>
"
117,42620,2,27,sql,"SQL Server Views, blessing or curse?","<p>I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.</p>

<p>The database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.</p>

<p>Several years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.</p>

<p>In hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?</p>
","<p>Views are good for ad-hoc queries, the kind that a DBA does behind the scenes when he/she needs quick access to data to see what's going on with the system.</p>

<p>But they can be bad for production code.  Part of the reason is that it's sort of unpredictable what indexes you will need with a view, since the where clause can be different, and therefore hard to tune.  Also, you are generally returning a lot more data than is actually necesary for the individual queries that are using the view.  Each of these queries could be tightened up and tuned individually.</p>

<p>There are specific uses of views in cases of data partitioning that can be extremely useful, so I'm not saying they should avoided altogether.  I'm just saying that if a view can be replaced by a few stored procedures, you will be better off without the view.</p>
"
118,42620,28,27,sql,"SQL Server Views, blessing or curse?","<p>I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.</p>

<p>The database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.</p>

<p>Several years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.</p>

<p>In hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?</p>
","<p>There are some very good uses for views; I have used them a lot for tuning and for exposing less normalized sets of information, or for UNION-ing results from multiple selects into a single result set.</p>

<p>Obviously any programming tool can be used incorrectly, but I can't think of any times in my experience where a poorly tuned view has caused any kind of drawbacks from a performance standpoint, and the value they can provide by providing explicitly tuned selects and avoiding duplication of complex SQL code can be significant.</p>

<p>Incidentally, I have never been a fan of architectural ""rules"" that are based on keeping developers from hurting themselves.  These rules often have unintended side-effects -- the last place I worked didn't allow using NULLs in the database, because developers might forget to check for null.  This ended up forcing us to work around ""1/1/1900"" dates and  integers defaulted to ""0"" in all the software built against the databases, and introducing a litany of bugs caused by devs working around places where NULL was the appropriate value.</p>
"
119,42620,3,27,sql,"SQL Server Views, blessing or curse?","<p>I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.</p>

<p>The database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.</p>

<p>Several years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.</p>

<p>In hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?</p>
","<p>Like all power views have its own dark side. However you cannot blame views for when somebody writes bad performed code. Moreover views can limit the exposure of some columns and provide extra security.</p>
"
120,42620,0,27,sql,"SQL Server Views, blessing or curse?","<p>I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.</p>

<p>The database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.</p>

<p>Several years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.</p>

<p>In hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?</p>
","<p>Let's see if I can come up with a lame analogy ...</p>

<p>""I don't need a phillips screwdriver.  I carry a flat head and a grinder!""</p>

<p>Dismissing views out of hand will cause pain long term.  For one, it's easier to debug and modify a single view definition than it is to ship modified code.</p>
"
121,42620,4,27,sql,"SQL Server Views, blessing or curse?","<p>I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.</p>

<p>The database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.</p>

<p>Several years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.</p>

<p>In hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?</p>
","<p>One thing that hasn't been mentioned thus far is use of views to provide a logical picture of the data to end users for ad hoc reporting or similar.</p>

<p>This has two merits:</p>

<ol>
<li>To allow the user to single ""tables"" containing the data they expect rather requiring relatively non technical users to work out potentially complex joins (because the database is normalised)</li>
<li>It provides a means to allow some degree of ah hoc access without exposing the data or the structure to the end users.</li>
</ol>

<p>Even with non ad-hoc reporting its sometimes signicantly easier to provide a view to the reporting system that contains the relveant data, neatly separating production of data from presentation of same.</p>
"
122,42620,1,27,sql,"SQL Server Views, blessing or curse?","<p>I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.</p>

<p>The database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.</p>

<p>Several years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.</p>

<p>In hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?</p>
","<p>Some time ago I've tried to maintain code that used views built from views built from views... That was a pain in the a**, so I got a little allergic to views :)</p>

<p>I usually prefer working with tables directly, especially for web applications where speed is a main concern. When accessing tables directly you have the chance to tweak your SQL-Queries to achieve the best performance. ""Precompiled""/cached working plans might be one advantage of views, but in many cases just-in-time compilation with all given parameters and where clauses in consideration will result in faster processing over all.</p>

<p>However that does not rule out views totally, if used adequately. For example you can use a view with the ""users"" table joined with the ""users_status"" table to get an textual explanation for each status - if you need it. However if you don't need the explanation: use the ""users"" table, not the view. As always: Use your brain!</p>
"
115,42620,5,27,sql,"SQL Server Views, blessing or curse?","<p>I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.</p>

<p>The database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.</p>

<p>Several years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.</p>

<p>In hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?</p>
","<p>My current database was completely awash with countless small tables of no more than 5 rows each.  Well, I could count them but it was cluttered.  These tables simply held constant type values (think enum) and could very easily be combined into one table.  I then made views that simulated each of the tables I deleted to ensure backward compactability.  Worked great.</p>
"
294,135730,25,26,sql,"What are the different types of indexes, what are the benefits of each?","<p>What are the different types of indexes, what are the benefits of each?</p>

<p>I heard of covering and clustered indexes, are there more? Where would you use them?</p>
","<ul>
<li>Unique - Guarantees unique values for the column(or set of columns) included in the index</li>
<li>Covering - Includes all of the columns that are used in a particular query (or set of queries), allowing the database to use only the index and not actually have to look at the table data to retrieve the results</li>
<li>Clustered - This is way in which the actual data is ordered on the disk, which means if a query uses the clustered index for looking up the values, it does not have to take the additional step of looking up the actual table row for any data not included in the index.</li>
</ul>
"
298,135730,2,26,sql,"What are the different types of indexes, what are the benefits of each?","<p>What are the different types of indexes, what are the benefits of each?</p>

<p>I heard of covering and clustered indexes, are there more? Where would you use them?</p>
","<p>Oracle has various combinations of b-tree, bitmap, partitioned and non-partitioned, reverse byte, bitmap join, and domain indexes.</p>

<p>Here's a link to the 11gR1 documentation on the subject: <a href=""http://download.oracle.com/docs/cd/B28359_01/server.111/b28274/data_acc.htm#PFGRF004"" rel=""nofollow"">http://download.oracle.com/docs/cd/B28359_01/server.111/b28274/data_acc.htm#PFGRF004</a></p>
"
297,135730,4,26,sql,"What are the different types of indexes, what are the benefits of each?","<p>What are the different types of indexes, what are the benefits of each?</p>

<p>I heard of covering and clustered indexes, are there more? Where would you use them?</p>
","<p>PostgreSQL allows partial indexes, where only rows that match a predicate are indexed. For instance, you might want to index the customer table for only those records which are active. This might look something like:</p>

<pre><code>create index i on customers (id, name, whatever) where is_active is true;
</code></pre>

<p>If your index many columns, and you have many inactive customers, this can be a big win in terms of space (the index will be stored in fewer disk pages) and thus performance. To hit the index you need to, at a minimum, specify the predicate:</p>

<pre><code>select name from customers where is_active is true;
</code></pre>
"
295,135730,1,26,sql,"What are the different types of indexes, what are the benefits of each?","<p>What are the different types of indexes, what are the benefits of each?</p>

<p>I heard of covering and clustered indexes, are there more? Where would you use them?</p>
","<p>Different database systems have different names for the same type of index, so be careful with this.  For example, what SQL Server and Sybase call ""clustered index"" is called in Oracle an ""index-organised table"".</p>
"
296,135730,1,26,sql,"What are the different types of indexes, what are the benefits of each?","<p>What are the different types of indexes, what are the benefits of each?</p>

<p>I heard of covering and clustered indexes, are there more? Where would you use them?</p>
","<p>I suggest you search the blogs of Jason Massie (<a href=""http://statisticsio.com/"" rel=""nofollow"">http://statisticsio.com/</a>) and Brent Ozar (<a href=""http://www.brentozar.com/"" rel=""nofollow"">http://www.brentozar.com/</a>) for related info. They have some post about real-life scenario that deals with indexes.</p>
"
293,135730,4,26,sql,"What are the different types of indexes, what are the benefits of each?","<p>What are the different types of indexes, what are the benefits of each?</p>

<p>I heard of covering and clustered indexes, are there more? Where would you use them?</p>
","<p>I'll add a couple of index types</p>

<p>BITMAP   - when you have very low number of different possible values, very fast and doesn't take up much space</p>

<p>PARTITIONED  - allows the index to be partitioned based on some property usually advantageous on very large database objects for storage or performance reasons.</p>

<p>FUNCTION/EXPRESSION indexes - used to pre-calculate some value based on the table and store it in the index, a very simple example might be an index based on lower() or a substring function. </p>
"
292,135730,5,26,sql,"What are the different types of indexes, what are the benefits of each?","<p>What are the different types of indexes, what are the benefits of each?</p>

<p>I heard of covering and clustered indexes, are there more? Where would you use them?</p>
","<p><a href=""http://www.odetocode.com/Articles/70.aspx"">OdeToCode has a good article covering the basic differences</a></p>

<p>As it says in the article:</p>

<blockquote>
  <p>Proper indexes are crucial for good
  performance in large databases.
  Sometimes you can make up for a poorly
  written query with a good index, but
  it can be hard to make up for poor
  indexing with even the best queries.</p>
</blockquote>

<p>Quite true, too... If you're just starting out with it, I'd focus on clustered and composite indexes, since they'll probably be what you use the most.</p>
"
299,135730,0,26,sql,"What are the different types of indexes, what are the benefits of each?","<p>What are the different types of indexes, what are the benefits of each?</p>

<p>I heard of covering and clustered indexes, are there more? Where would you use them?</p>
","<p>SQL Server 2008 has <a href=""http://www.google.md/search?q=microsoft+sql+server+2008+filtered+indexes"" rel=""nofollow"">filtered indexes</a>, similar to PostgreSQL's <a href=""http://www.postgresql.org/docs/8.0/static/indexes-partial.html"" rel=""nofollow"">partial indexes</a>. Both allow to include in index only rows matching specified criteria.</p>

<p>The syntax is identical to PostgreSQL:</p>

<pre><code>create index i on Customers(name) where is_alive = cast(1 as bit);
</code></pre>
"
300,135730,2,26,sql,"What are the different types of indexes, what are the benefits of each?","<p>What are the different types of indexes, what are the benefits of each?</p>

<p>I heard of covering and clustered indexes, are there more? Where would you use them?</p>
","<p>Conventional wisdom suggests that index choice should be based on cardinality.  They'll say, </p>

<blockquote>
  <p>For a <em>low cardinality</em> column like GENDER, use bitmap.  For a <em>high cardinality</em> like LAST_NAME, use b-tree.</p>
</blockquote>

<p><strong>This is not the case with Oracle</strong>, where index choice should instead be based on the type of application (OLTP vs. OLAP).  DML on tables with bitmap indexes can cause serious lock contention.  On the other hand, the Oracle CBO can easily combine multiple bitmap indexes together, and bitmap indexes can be used to search for nulls.  As a general rule:</p>

<blockquote>
  <p>For an <em>OLTP</em> system with frequent DML and routine queries, use btree.  For an <em>OLAP</em> system with infrequent DML and adhoc queries, use bitmap.</p>
</blockquote>

<p>I'm not sure if this applies to other databases, comments are welcome.  The following articles discuss the subject further:</p>

<ul>
<li><a href=""http://www.oracle.com/technology/pub/articles/sharma_indexes.html"" rel=""nofollow"" title=""by Vivek Sharma"">Bitmap Index vs. B-tree Index: Which and When?</a> </li>
<li><a href=""http://www.dbazine.com/oracle/or-articles/jlewis3"" rel=""nofollow"" title=""by Jonathan Lewis"">Understanding Bitmap Indexes</a></li>
</ul>
"
756,347160,4,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>If you will need the deleted data sometimes, but not very often: you can <strong>move the records into a separate database</strong>/table (e.g. <code>users</code> and <code>users_deleted</code>, or better <code>somedb.users</code> and <code>somedb_deleted.users</code>).</p>

<p>This way, the data is still accessible through a query (although it won't be as simple as the normal one), yet it doesn't clutter the original database and you don't have to code around it.</p>
"
755,347160,0,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>It depends on the function of the database. Is it the <em>source of all truth</em>? If yes, then disable rather than delete, as it is easier to recover from bad operations (ie user error). If the database is feed from some upstream data source, delete then unused data. Any recreation/recovery can be done by the upstream system.</p>
"
743,347160,0,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>It's a judgment call, but I have ended up adding ""disabled"" columns on tables where I previously thought I could just delete row. I'd say most of the time you're safer adding a disabled column. This can get tricky with n:n relations however, so that's something to consider.</p>
"
745,347160,4,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>It depends. If it is disabled then it is easier to undelete / to see that someone actually deleted the record (for auditing).</p>

<p>You may also have a technical requirement to not delete records. For example, if you wanted to synchronize your database with another user by just sending changed records you wouldn't be able to do that if it was actually deleted.</p>
"
746,347160,0,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>It's probably best to add ""deleted"" column and offer users to undelete or purge deleted items.</p>
"
747,347160,4,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>You need to have it in functional requirements. If it is not said there explicitly you will have to figure out it yourself.</p>

<p>In most cases it is better to store such records in separate table. You then avoid various situations where one table refers another table and you need to decide should records in second table be treated as deleted as well or not.</p>
"
748,347160,20,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>Not deleting will create a new class of bugs for all future queries.  Don't forget that query writing is often done by power users (i.e. non-IT professionals), and junior developers.  So now every table that has invalid data marked only by a BIT active flag will need an additional AND in the WHERE clause for every query from now until forever.  This will help users fall into the pit of failure instead of the pit of success.  However, I strongly encourage you to implement these flag systems anyhow because without bad design, there is no need for maintenance developers to fix the numerous bugs it will create.</p>

<p>How valuable is it to have historical data in the table?  If the business if forward looking, having old data in the tables can just be a burden-- it cause problems when creating constraints (all constraints will have to be modified to exclude data you wish wasn't there).  Data quality assurance is complicated by having to continually re-identify what is ""old crap we are afraid to delete but never want to ever use or update again"" and new stuff we care about.</p>

<p>Is it being deleted because it was a mistake?  If the row corresponds to an entity in real life, maybe it is interesting to keep and set a ""vaporized"", ""dead"", ""left the building"" flag.  If you accidentally inserted a row that corresponds to no entity in real life, a DELETE is not a bad thing.  Are imaginary customers that never existed important to keep in the customer table?</p>

<p>And finally, personality plays a big role.  People can be packrats with data, too.  If a DBA keeps all his newspapers from 30 years back and don't like deleting data, maybe he should make sure he's making data design decisions based on the merits and not an irrelevant personal preference.</p>
"
749,347160,6,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>It's up to you and your requirements (some things get rather hard when records exist that...don't).</p>

<p>I will say that a boolean is a bad choice, though.  Make it a nullable timestamp.  It's pretty handy to know when something was deleted, especially when you deleted too much and want to undo part of the delete.</p>
"
757,347160,2,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>I'd like to note that there are (in most countries) use-cases where you can't delete records for legal reasons. Industry and data dependant of course. </p>

<p>In this case I believe the best practice guidleine is to shadow table the ""deleted"" data which gains you the benefits of actual deletion <a href=""http://stackoverflow.com/questions/347160/should-i-delete-or-disable-a-row-in-a-relational-database#answer-347195"">outlined by MatthewMartin</a> and by extension I have come to find this pattern frequently preferable to creating ""active"" bit-flags across my data-tables.</p>
"
754,347160,15,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>If you do use a deleted, visible, isactive, etc column, you can abstract away having to remember to use it by using views.</p>
"
753,347160,2,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>Unless you have a specific need for managing your own deletions, you are better off just deleting the rows.</p>
"
752,347160,3,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>Adding a ""DELETED"" column to your table and marking rows instead of deleting them creates a lot more work for you with little (if any) benefit.  Now, every time you write a query you have to remember to include ""WHERE DELETED IS NOT NULL"" (or whatever).</p>

<p>A better approach is to delete data when you need to delete data, and rely on your regular backup process to ensure that no data is ever lost.  If for some reason you need to keep some deleted data handy (for searches, maybe), you're better off just copying the data to a different table created for this purpose and then deleting the originals.</p>

<p>I've inherited many databases over the years, and this strategy of flagging records instead of deleting them is unfortunately very common, and (in my experience at least) always leads to major problems down the road.</p>
"
744,347160,20,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>It depends. (But you guessed that already, I'm sure.)  </p>

<p>In practice, the violation of proper usage here is almost always in the direction of deleting.  </p>

<p>The main bad consequence of deleting is how often there are dependent records in other tables whose referential integrity is lost when the parent record goes away.</p>

<p>One red herring used to defend deletion (which you've already dealt with properly by dismissing the issue of storage capacity), is expecting that it will make any noticeable difference in query efficiency.</p>

<p>There are too many cases where user or software issues cause someone to need to hit the big ""Undo"" button; if you delete, you're out of luck (at least without getting special help and aggravating people you'd rather be nice to.)</p>

<p>The terminology I usually use is ""Active"" and ""Inactive"".</p>

<p><hr /></p>

<p>A few more points to consider (by Totophil):</p>

<ol>
<li>Deleting a record in some databases will not automatically free up the disk space.</li>
<li>Purging any sensitive information that you no longer require helps avoiding security risks.</li>
<li><p>Data protection legislation might require your organisation under certain circumstances to purge any identifiable information about an individual. The legislation differs from country to country, some pointers:    </p>

<ul>
<li>EU <a href=""http://ec.europa.eu/justice_home/fsj/privacy/law/index_en.htm"">http://ec.europa.eu/justice_home/fsj/privacy/law/index_en.htm</a> </li>
<li>UK <a href=""http://www.ico.gov.uk/what_we_cover/data_protection.aspx"">http://www.ico.gov.uk/what_we_cover/data_protection.aspx</a></li>
<li>Estonia <a href=""http://www.riigiteataja.ee/ert/act.jsp?id=748829"">http://www.riigiteataja.ee/ert/act.jsp?id=748829</a></li>
</ul></li>
<li><p>On the other hand you might be required by law to keep certain information.</p></li>
</ol>
"
751,347160,17,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>After reading a book on temporal database design, I came to believe in the philosophy that every record of temporal significance needs to have at least 4 timestamp columns.  Those four are: created, deleted, start, end.  The created and deleted timestamps are fairly self-explanatory.  Your system shouldn't look at records where deleted is before now().  The start and end columns determine when the data applies to your system.  It's for keeping a history of changes.  If you need to update a record, you'd set it's end time to now(), copy it, update the copy, and set the copy's start time to now().  That way, when you need to look at the way something was historically, you can have the system figure it out.  You could also set the start to some point in the future to have a change take place automatically at that time, or set the end to a future time to have it automatically go away at that time.  Setting the created/deleted timestamps to the future doesn't really make sense...</p>
"
750,347160,1,25,sql,Should I delete or disable a row in a relational database?,"<p>In a brand new program where space isn't really that big a deal, is it better to delete a row or to disable a row by let's say a boolean ""Disabled"" and have the program just ignore it?</p>

<p>For example, if I wanted to remove a user from a program.</p>
","<p>This should be determined by the application needs.  I have done it both ways.  I have some applications that need to support undo as the cost of removing a row -- and the cascading deletes that are caused by that -- are too expensive to not have it.  Normally, though, the applications I have done require the user to confirm deletes, then just do as the user has asked.  In some cases, you must delete the data due to privacy concerns.  That is, if the user requests to be removed, you need to really remove it, not just mark it as not current.  In other cases (like tax-related transactions), there may be reasons to keep data in a non-current state until no longer required by law.  I have applications that fit in both categories.</p>

<p>Various strategies can be used in the case where you need to keep ""archival"" data.  Depending on whether it needs to be immediately available you can push it to archive tables that are either kept or backed up and cleaned out regularly.   If there is a need for undo you may want to keep it in the current table and just mark it by setting a flag.  It really depends on the complexity of your schema, the requirements of the application, and personal preference to some extent.</p>
"
853,377850,1,23,sql,Using GROUP_CONCAT on subquery in MySQL,"<p>I have a MySQL query in which I want to include a list of ID's from another table. On the website, people are able to add certain items, and people can then add those items to their favourites. I basically want to get the list of ID's of people who have favourited that item (this is a bit simplified, but this is what it boils down to).</p>

<p>Basically, I do something like this:</p>

<pre><code>SELECT *,
GROUP_CONCAT((SELECT userid FROM favourites WHERE itemid = items.id) SEPARATOR ',') AS idlist
FROM items
WHERE id = $someid
</code></pre>

<p>This way, I would be able to show who favourited some item, by splitting the idlist later on to an array in PHP further on in my code, however I am getting the following MySQL error:</p>

<blockquote>
  <p><em>1242 - Subquery returns more than 1 row</em> </p>
</blockquote>

<p>I thought that was kind of the point of using <code>GROUP_CONCAT</code> instead of, for example, <code>CONCAT</code>? Am I going about this the wrong way?</p>

<hr>

<p>Ok, thanks for the answers so far, that seems to work. However, there is a catch. Items are also considered to be a favourite if it was added by that user. So I would need an additional check to check if creator = userid. Can someone help me come up with a smart (and hopefully efficient) way to do this?</p>

<p>Thank you!</p>

<p>Edit: I just tried to do this:</p>

<pre><code>SELECT [...] LEFT JOIN favourites ON (userid = itemid OR creator = userid)
</code></pre>

<p>And <strong>idlist</strong> is empty. Note that if I use <code>INNER JOIN</code> instead of <code>LEFT JOIN</code> I get an empty result. Even though I am sure there are rows that meet the ON requirement.</p>
","<p>The purpose of GROUP_CONCAT is correct but the subquery is unnecessary and causing the problem. Try this instead:</p>

<pre><code>SELECT ITEMS.id,GROUP_CONCAT(FAVOURITES.UserId)
FROM FAVOURITES INNER JOIN ITEMS ON ITEMS.Id = FAVOURITES.ItemId
WHERE ITEMS.Id = $someid
GROUP BY ITEMS.ID
</code></pre>
"
852,377850,13,23,sql,Using GROUP_CONCAT on subquery in MySQL,"<p>I have a MySQL query in which I want to include a list of ID's from another table. On the website, people are able to add certain items, and people can then add those items to their favourites. I basically want to get the list of ID's of people who have favourited that item (this is a bit simplified, but this is what it boils down to).</p>

<p>Basically, I do something like this:</p>

<pre><code>SELECT *,
GROUP_CONCAT((SELECT userid FROM favourites WHERE itemid = items.id) SEPARATOR ',') AS idlist
FROM items
WHERE id = $someid
</code></pre>

<p>This way, I would be able to show who favourited some item, by splitting the idlist later on to an array in PHP further on in my code, however I am getting the following MySQL error:</p>

<blockquote>
  <p><em>1242 - Subquery returns more than 1 row</em> </p>
</blockquote>

<p>I thought that was kind of the point of using <code>GROUP_CONCAT</code> instead of, for example, <code>CONCAT</code>? Am I going about this the wrong way?</p>

<hr>

<p>Ok, thanks for the answers so far, that seems to work. However, there is a catch. Items are also considered to be a favourite if it was added by that user. So I would need an additional check to check if creator = userid. Can someone help me come up with a smart (and hopefully efficient) way to do this?</p>

<p>Thank you!</p>

<p>Edit: I just tried to do this:</p>

<pre><code>SELECT [...] LEFT JOIN favourites ON (userid = itemid OR creator = userid)
</code></pre>

<p>And <strong>idlist</strong> is empty. Note that if I use <code>INNER JOIN</code> instead of <code>LEFT JOIN</code> I get an empty result. Even though I am sure there are rows that meet the ON requirement.</p>
","<p>You can't access variables in the outer scope in such queries (can't use <code>items.id</code> there). You should rather try something like</p>

<pre><code>SELECT
    items.name,
    items.color,
    CONCAT(favourites.userid) as idlist
FROM
    items
INNER JOIN favourites ON items.id = favourites.itemid
WHERE
    items.id = $someid
GROUP BY
    items.name,
    items.color;
</code></pre>

<p>Expand the list of fields as needed (name, color...).</p>
"
854,377850,2,23,sql,Using GROUP_CONCAT on subquery in MySQL,"<p>I have a MySQL query in which I want to include a list of ID's from another table. On the website, people are able to add certain items, and people can then add those items to their favourites. I basically want to get the list of ID's of people who have favourited that item (this is a bit simplified, but this is what it boils down to).</p>

<p>Basically, I do something like this:</p>

<pre><code>SELECT *,
GROUP_CONCAT((SELECT userid FROM favourites WHERE itemid = items.id) SEPARATOR ',') AS idlist
FROM items
WHERE id = $someid
</code></pre>

<p>This way, I would be able to show who favourited some item, by splitting the idlist later on to an array in PHP further on in my code, however I am getting the following MySQL error:</p>

<blockquote>
  <p><em>1242 - Subquery returns more than 1 row</em> </p>
</blockquote>

<p>I thought that was kind of the point of using <code>GROUP_CONCAT</code> instead of, for example, <code>CONCAT</code>? Am I going about this the wrong way?</p>

<hr>

<p>Ok, thanks for the answers so far, that seems to work. However, there is a catch. Items are also considered to be a favourite if it was added by that user. So I would need an additional check to check if creator = userid. Can someone help me come up with a smart (and hopefully efficient) way to do this?</p>

<p>Thank you!</p>

<p>Edit: I just tried to do this:</p>

<pre><code>SELECT [...] LEFT JOIN favourites ON (userid = itemid OR creator = userid)
</code></pre>

<p>And <strong>idlist</strong> is empty. Note that if I use <code>INNER JOIN</code> instead of <code>LEFT JOIN</code> I get an empty result. Even though I am sure there are rows that meet the ON requirement.</p>
","<p>I think you may have the ""userid = itemid"" wrong, shouldn't it be like this:</p>

<pre><code>SELECT ITEMS.id,GROUP_CONCAT(FAVOURITES.UserId) AS IdList
FROM FAVOURITES 
INNER JOIN ITEMS ON (ITEMS.Id = FAVOURITES.ItemId OR FAVOURITES.UserId = ITEMS.Creator)
WHERE ITEMS.Id = $someid
GROUP BY ITEMS.ID
</code></pre>
"
656,288620,5,23,sql,What GOOD tools are available for generating ERD from a SQL Server Database?,"<p>I am trying to generate an Entity Relationship Diagram from an existing MS SQLServer 2005 database. What tools are available? Specifically,I am not only interested in ERD's more directly I am looking for a tool to help quickly learning and analysing a medium size (schema wise not really row wise) database structure.</p>
","<p>The database reverse engineering feature of microsoft Visio are excellent for pulling the schema out of a database and developing from there. I'd investigate that avenue if you haven't already.</p>
"
657,288620,2,23,sql,What GOOD tools are available for generating ERD from a SQL Server Database?,"<p>I am trying to generate an Entity Relationship Diagram from an existing MS SQLServer 2005 database. What tools are available? Specifically,I am not only interested in ERD's more directly I am looking for a tool to help quickly learning and analysing a medium size (schema wise not really row wise) database structure.</p>
","<p>I've used Visio and had some good results with that.  One thing I do though too is to use the visual designers (Database Diagrams) built into SQL Server GUI.  When you drop the tables in there, it automatically includes the foreign keys.  You can just include the tables you want at this point to focus in.</p>

<p>All of these tools though anticipate the foreign keys pre-existing.</p>
"
658,288620,1,23,sql,What GOOD tools are available for generating ERD from a SQL Server Database?,"<p>I am trying to generate an Entity Relationship Diagram from an existing MS SQLServer 2005 database. What tools are available? Specifically,I am not only interested in ERD's more directly I am looking for a tool to help quickly learning and analysing a medium size (schema wise not really row wise) database structure.</p>
","<p>I've been happy with <a href=""http://sourceforge.net/projects/dbdesigner-fork"" rel=""nofollow"">DBDesigner4</a>.</p>
"
659,288620,0,23,sql,What GOOD tools are available for generating ERD from a SQL Server Database?,"<p>I am trying to generate an Entity Relationship Diagram from an existing MS SQLServer 2005 database. What tools are available? Specifically,I am not only interested in ERD's more directly I am looking for a tool to help quickly learning and analysing a medium size (schema wise not really row wise) database structure.</p>
","<p>You can also generate an ERD from Microsoft Visual Studio 2005.</p>
"
1101,504060,11,21,sql,Oracle Delete Rows Matching On Multiple Values,"<p>I want to do something like:</p>

<pre><code>DELETE FROM student WHERE
student.course, student.major IN
(SELECT schedule.course, schedule.major FROM schedule)
</code></pre>

<p>However, it seems that you can only use one column with the IN operator. Is that true? Seems like a query like this should be possible.</p>
","<p>You could also use the EXISTS clause:</p>

<pre><code>DELETE FROM student WHERE
EXISTS
(
  SELECT 1 FROM schedule 
  WHERE schedule.course=student.course 
  AND schedule.major=student.major
)
</code></pre>
"
1100,504060,3,21,sql,Oracle Delete Rows Matching On Multiple Values,"<p>I want to do something like:</p>

<pre><code>DELETE FROM student WHERE
student.course, student.major IN
(SELECT schedule.course, schedule.major FROM schedule)
</code></pre>

<p>However, it seems that you can only use one column with the IN operator. Is that true? Seems like a query like this should be possible.</p>
","<p>In Oracle, you can do a delete from an in-line view, but it generally needs a foreign key that ensures that a row from the table from which the row is deleted cannot be represented by more than one row in the view.</p>

<pre><code>create table parent (id number primary key);
create table child (id number primary key, parent_id number references parent);
insert into parent values(1);
insert into child values(2,1);
delete from (select * from parent p, child c where c.parent_id = p.id);
</code></pre>
"
1099,504060,2,21,sql,Oracle Delete Rows Matching On Multiple Values,"<p>I want to do something like:</p>

<pre><code>DELETE FROM student WHERE
student.course, student.major IN
(SELECT schedule.course, schedule.major FROM schedule)
</code></pre>

<p>However, it seems that you can only use one column with the IN operator. Is that true? Seems like a query like this should be possible.</p>
","<p>The syntax below works in SQLServer <strike> but I believe it is a standard sql </strike>
but as pointed out in comments this is non standard implementation and is not currently supported in Oracle.</p>

<p>I will leave it for reference</p>

<pre><code>delete s
from 
    student s 
    inner join schedule sch
    on s.course=sch.course 
    and s.major = sch.major
</code></pre>
"
1098,504060,7,21,sql,Oracle Delete Rows Matching On Multiple Values,"<p>I want to do something like:</p>

<pre><code>DELETE FROM student WHERE
student.course, student.major IN
(SELECT schedule.course, schedule.major FROM schedule)
</code></pre>

<p>However, it seems that you can only use one column with the IN operator. Is that true? Seems like a query like this should be possible.</p>
","<pre><code>DELETE FROM student WHERE
(student.course, student.major) IN
(SELECT schedule.course, schedule.major FROM schedule)
</code></pre>

<p>Put parens around your terms in the where clause. Cheers!</p>
"
1097,504060,35,21,sql,Oracle Delete Rows Matching On Multiple Values,"<p>I want to do something like:</p>

<pre><code>DELETE FROM student WHERE
student.course, student.major IN
(SELECT schedule.course, schedule.major FROM schedule)
</code></pre>

<p>However, it seems that you can only use one column with the IN operator. Is that true? Seems like a query like this should be possible.</p>
","<p>No, you just need parentheses:</p>

<pre><code>DELETE FROM student WHERE
(student.course, student.major) IN
(SELECT schedule.course, schedule.major FROM schedule)
</code></pre>
"
0,120,9,21,sql,ASP.NET Site Maps,"<p>Has anyone got experience creating <strong>SQL-based ASP.NET</strong> site-map providers?</p>

<p>I've got the default XML file <code>web.sitemap</code> working properly with my Menu and <strong>SiteMapPath</strong> controls, but I'll need a way for the users of my site to create and modify pages dynamically.</p>

<p>I need to tie page viewing permissions into the standard <code>ASP.NET</code> membership system as well.</p>
","<p>The Jeff Prosise version from MSDN magazine works pretty well, but it has a few flaws:</p>

<p><code>AddNode</code> freaks out with links to external sites on your menu (www.google.com, etc.)</p>

<p>Here's my fix in <code>BuildSiteMap()</code>:</p>

<pre><code>SiteMapNode node = GetSiteMapNodeFromReader(reader);
string url = node.Url;
if (url.Contains("":""))
{
    string garbage = Guid.NewGuid().ToString();  // SiteMapNode needs unique URLs
    node.Url = ""~/dummy_"" + garbage + "".aspx"";
    AddNode(node, _root);
    node.Url = url;
}
else
{
    AddNode(node, _root);
}
</code></pre>

<p><code>SQLDependency</code> caching is cool, but if you don't want to make a trip to the DB everytime your menu loads (to check to see if the dependency has changed) and your menus don't change very often, then why not use <code>HttpRuntime.Cache</code> instead?</p>

<pre><code>public override SiteMapNode RootNode
{
    get
    {
        SiteMapNode temp = (SiteMapNode)HttpRuntime.Cache[""SomeKeyName""];
        if (temp == null)
        {
            temp = BuildSiteMap();
            HttpRuntime.Cache.Insert(""SomeKeyName"", temp, null, DateTime.Now.AddHours(1), Cache.NoSlidingExpiration);
        }
        return temp;
    }
}
</code></pre>
"
44,21280,20,20,sql,Am I missing something about LINQ?,"<p>I seem to be missing something about LINQ.  To me, it looks like it's taking some of the elements of SQL that I like the least and moving them into the C# language and using them for other things.</p>

<p>I mean, I could see the benefit of using SQL-like statements on things other than databases.  But if I wanted to write SQL, well, why not just write SQL and keep it out of C#?  What am I missing here?</p>
","<p>Before:</p>

<pre><code>// Init Movie
m_ImageArray = new Image[K_NB_IMAGE];

Stream l_ImageStream = null;
Bitmap l_Bitmap = null;

// get a reference to the current assembly
Assembly l_Assembly = Assembly.GetExecutingAssembly();

// get a list of resource names from the manifest
string[] l_ResourceName = l_Assembly.GetManifestResourceNames();

foreach (string l_Str in l_ResourceName)
{
    if (l_Str.EndsWith("".png""))
    {
        // attach to stream to the resource in the manifest
        l_ImageStream = l_Assembly.GetManifestResourceStream(l_Str);
        if (!(null == l_ImageStream))
        {
            // create a new bitmap from this stream and 
            // add it to the arraylist
            l_Bitmap = Bitmap.FromStream(l_ImageStream) as Bitmap;
            if (!(null == l_Bitmap))
            {
                int l_Index = Convert.ToInt32(l_Str.Substring(l_Str.Length - 6, 2));
                l_Index -= 1;
                if (l_Index &lt; 0) l_Index = 0;
                if (l_Index &gt; K_NB_IMAGE) l_Index = K_NB_IMAGE;
                m_ImageArray[l_Index] = l_Bitmap;
            }
            l_Bitmap = null;
            l_ImageStream.Close();
            l_ImageStream = null;
        } // if
    } // if
} // foreach
</code></pre>

<p>After:</p>

<pre><code>Assembly l_Assembly = Assembly.GetExecutingAssembly();

//Linq is the tops
m_ImageList = l_Assembly.GetManifestResourceNames()
    .Where(a =&gt; a.EndsWith("".png""))
    .OrderBy(b =&gt; b)
    .Select(c =&gt; l_Assembly.GetManifestResourceStream(c))
    .Where(d =&gt; d != null)  //ImageStream not null
    .Select(e =&gt; Bitmap.FromStream(e))
    .Where(f =&gt; f != null)  //Bitmap not null
    .ToList();
</code></pre>

<p>Or, alternatively (<em>query syntax</em>):</p>

<pre><code>Assembly l_Assembly = Assembly.GetExecutingAssembly();

//Linq is the tops
m_ImageList = (
    from resource in l_Assembly.GetManifestResourceNames()
    where resource.EndsWith("".png"")
    orderby resource
    let imageStream = l_Assembly.GetManifestResourceStream(resource)
    where imageStream != null
    let bitmap = Bitmap.FromStream(imageStream)
    where bitmap != null)
    .ToList();
</code></pre>
"
40,21280,2,20,sql,Am I missing something about LINQ?,"<p>I seem to be missing something about LINQ.  To me, it looks like it's taking some of the elements of SQL that I like the least and moving them into the C# language and using them for other things.</p>

<p>I mean, I could see the benefit of using SQL-like statements on things other than databases.  But if I wanted to write SQL, well, why not just write SQL and keep it out of C#?  What am I missing here?</p>
","<p>The point is that LINQ integrates your queries into your primary programming language, allowing your IDE to provide you with some facilities (Intellisense and debug support, for example) that you otherwise would not have, and to allow the compiler to type-check your SQL code (which is impossible with a normal string query).</p>
"
41,21280,39,20,sql,Am I missing something about LINQ?,"<p>I seem to be missing something about LINQ.  To me, it looks like it's taking some of the elements of SQL that I like the least and moving them into the C# language and using them for other things.</p>

<p>I mean, I could see the benefit of using SQL-like statements on things other than databases.  But if I wanted to write SQL, well, why not just write SQL and keep it out of C#?  What am I missing here?</p>
","<p>LINQ is not about SQL. LINQ is about being apply functional programming paradigmns on objects.</p>

<p>LINQ to SQL is an ORM built ontop of the LINQ foundation, but LINQ is much more. I don't use LINQ to SQL, yet I use LINQ all the time.</p>

<p>Take the task of finding the intersection of two lists:</p>

<p>Before LINQ, this tasks requires writing a nested foreach that iterates the small list once for every item in the big list O(N*M), and takes about 10 lines of code.</p>

<pre><code>foreach (int number in list1)
{
    foreach (int number2 in list2)
    {
        if (number2 == number)
        {
            returnList.add(number2);
        }
    }
}
</code></pre>

<p>Using LINQ, it does the same thing in one line of code:</p>

<pre><code>var results = list1.Intersect(list2);
</code></pre>

<p>You'll notice that doesn't look like LINQ, yet it is. You don't need to use the expression syntax if you don't want to.</p>
"
42,21280,5,20,sql,Am I missing something about LINQ?,"<p>I seem to be missing something about LINQ.  To me, it looks like it's taking some of the elements of SQL that I like the least and moving them into the C# language and using them for other things.</p>

<p>I mean, I could see the benefit of using SQL-like statements on things other than databases.  But if I wanted to write SQL, well, why not just write SQL and keep it out of C#?  What am I missing here?</p>
","<p>So the really, really big deal about LINQ has nothing to do with Linq to SQL. It's about the enhancements it brought to the C# language itself.</p>
"
43,21280,5,20,sql,Am I missing something about LINQ?,"<p>I seem to be missing something about LINQ.  To me, it looks like it's taking some of the elements of SQL that I like the least and moving them into the C# language and using them for other things.</p>

<p>I mean, I could see the benefit of using SQL-like statements on things other than databases.  But if I wanted to write SQL, well, why not just write SQL and keep it out of C#?  What am I missing here?</p>
","<p>LINQ is not just an ORM system, as Jonathan pointed out it brings a lot of functional programming elements to C#. And it lets you do a lot of ""database-y"" things in regular C# code. It's difficult to explain just how incredibly powerful that can be. Consider how much having solid, well designed generic data structures (such as list, stack, dictionary/hash, etc.) included in common frameworks has improved the state of development in modern languages. Precisely because using these data structures is very common and reducing the intellectual overhead of using them is a huge benefit. LINQ doesn't do anything you can't do yourself, but it makes a lot of operations a lot more straightforward and a lot easier.</p>

<p>Consider the time-honored example of removing duplicates from a non-ordered list. In a lower level language like C or C++ you'd probably have to sort the list and maintain two indices into the list as you removed dupes. In a language with hashes (Java, C#, Javascript, Perl, etc.) you could create a hash where the keys are the unique values, then extract the keys into a new list. With LINQ you could just do this:</p>

<pre><code>int[] data = { 0, 1, 3, 3, 7, 8, 0, 9, 2, 1 };

var uniqueData = data.GroupBy(i =&gt; i).Select(g =&gt; g.Key);
</code></pre>
"
377,161960,1,19,sql,"If I stop a long running query, does it rollback?","<p>A query that is used to loop through <b>17 millions records to remove duplicates</b>  has been running now for about <b>16 hours</b> and I wanted to know if the query is stopped right now if it will finalize the delete statements or if it has been deleting while running this query? Indeed, if I do stop it, does it finalize the deletes or rolls back?</p>

<p>I have found that when I do a </p>

<pre><code> select count(*) from myTable
</code></pre>

<p>That the rows that it returns (while doing this query) is about 5 less than what the starting row count was. Obviously the server resources are extremely poor, so does that mean that this process has taken 16 hours to find 5 duplicates (when there are actually thousands), and this could be running for days?</p>

<p>This query took 6 seconds on 2000 rows of test data, and it works great on that set of data, so I figured it would take 15 hours for the complete set.</p>

<p>Any ideas?</p>

<p>Below is the query:</p>

<pre><code>--Declare the looping variable
DECLARE @LoopVar char(10)


    DECLARE
     --Set private variables that will be used throughout
      @long DECIMAL,
      @lat DECIMAL,
      @phoneNumber char(10),
      @businessname varchar(64),
      @winner char(10)

    SET @LoopVar = (SELECT MIN(RecordID) FROM MyTable)

    WHILE @LoopVar is not null
    BEGIN

      --initialize the private variables (essentially this is a .ctor)
      SELECT 
        @long = null,
        @lat = null,
        @businessname = null,
        @phoneNumber = null,
        @winner = null

      -- load data from the row declared when setting @LoopVar  
      SELECT
        @long = longitude,
        @lat = latitude,
        @businessname = BusinessName,
        @phoneNumber = Phone
      FROM MyTable
      WHERE RecordID = @LoopVar

      --find the winning row with that data. The winning row means 
      SELECT top 1 @Winner = RecordID
      FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
      ORDER BY
        CASE WHEN webAddress is not null THEN 1 ELSE 2 END,
        CASE WHEN caption1 is not null THEN 1 ELSE 2 END,
        CASE WHEN caption2 is not null THEN 1 ELSE 2 END,
        RecordID

      --delete any losers.
      DELETE FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
        AND @winner != RecordID

      -- prep the next loop value to go ahead and perform the next duplicate query.
      SET @LoopVar = (SELECT MIN(RecordID) 
    FROM MyTable
    WHERE @LoopVar &lt; RecordID)
    END
</code></pre>
","<h2>Implicit transactions</h2>

<p><strong>If no 'Implicit transactions' has been set, then each iteration in your loop committed the changes.</strong></p>

<p>It is possible for any SQL Server to be set with 'Implicit transactions'. This is a database setting (by default is OFF). You can also have implicit transactions in the properties of a particular query inside of Management Studio (right click in query pane>options), by default settings in the client, or a SET statement.</p>

<pre><code>SET IMPLICIT_TRANSACTIONS ON;
</code></pre>

<p>Either way, if this was the case, you would still need to execute an explicit COMMIT/ROLLBACK regardless of interruption of the query execution.</p>

<p><hr /></p>

<p><strong>Implicit transactions reference:</strong></p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ms188317.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms188317.aspx</a></p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ms190230.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms190230.aspx</a></p>
"
1189,534240,1,19,sql,MSSQL Select statement with incremental integer column... not from a table,"<p>I need, if possible, a t-sql query that, returning the values from an arbitrary table, also returns a incremental integer column with value = 1 for the first row, 2 for the second, and so on.</p>

<p>This column does not actually resides in any table, and must be strictly incremental, because the ORDER BY clause could sort the rows of the table and I want the incremental row in perfect shape always...</p>

<p>Thanks in advance.</p>

<p>--EDIT
Sorry, forgot to mention, must run on SQL Server 2000</p>
","<p>Try ROW_NUMBER()</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ms186734.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms186734.aspx</a></p>

<p>Example:</p>

<pre><code>SELECT
  col1,
  col2,
  ROW_NUMBER() OVER (ORDER BY col1) AS rownum
FROM tbl
</code></pre>
"
369,161960,-1,19,sql,"If I stop a long running query, does it rollback?","<p>A query that is used to loop through <b>17 millions records to remove duplicates</b>  has been running now for about <b>16 hours</b> and I wanted to know if the query is stopped right now if it will finalize the delete statements or if it has been deleting while running this query? Indeed, if I do stop it, does it finalize the deletes or rolls back?</p>

<p>I have found that when I do a </p>

<pre><code> select count(*) from myTable
</code></pre>

<p>That the rows that it returns (while doing this query) is about 5 less than what the starting row count was. Obviously the server resources are extremely poor, so does that mean that this process has taken 16 hours to find 5 duplicates (when there are actually thousands), and this could be running for days?</p>

<p>This query took 6 seconds on 2000 rows of test data, and it works great on that set of data, so I figured it would take 15 hours for the complete set.</p>

<p>Any ideas?</p>

<p>Below is the query:</p>

<pre><code>--Declare the looping variable
DECLARE @LoopVar char(10)


    DECLARE
     --Set private variables that will be used throughout
      @long DECIMAL,
      @lat DECIMAL,
      @phoneNumber char(10),
      @businessname varchar(64),
      @winner char(10)

    SET @LoopVar = (SELECT MIN(RecordID) FROM MyTable)

    WHILE @LoopVar is not null
    BEGIN

      --initialize the private variables (essentially this is a .ctor)
      SELECT 
        @long = null,
        @lat = null,
        @businessname = null,
        @phoneNumber = null,
        @winner = null

      -- load data from the row declared when setting @LoopVar  
      SELECT
        @long = longitude,
        @lat = latitude,
        @businessname = BusinessName,
        @phoneNumber = Phone
      FROM MyTable
      WHERE RecordID = @LoopVar

      --find the winning row with that data. The winning row means 
      SELECT top 1 @Winner = RecordID
      FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
      ORDER BY
        CASE WHEN webAddress is not null THEN 1 ELSE 2 END,
        CASE WHEN caption1 is not null THEN 1 ELSE 2 END,
        CASE WHEN caption2 is not null THEN 1 ELSE 2 END,
        RecordID

      --delete any losers.
      DELETE FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
        AND @winner != RecordID

      -- prep the next loop value to go ahead and perform the next duplicate query.
      SET @LoopVar = (SELECT MIN(RecordID) 
    FROM MyTable
    WHERE @LoopVar &lt; RecordID)
    END
</code></pre>
","<p>I'm pretty sure that is a negatory. Otherwise what would the point of transactions be?</p>
"
370,161960,7,19,sql,"If I stop a long running query, does it rollback?","<p>A query that is used to loop through <b>17 millions records to remove duplicates</b>  has been running now for about <b>16 hours</b> and I wanted to know if the query is stopped right now if it will finalize the delete statements or if it has been deleting while running this query? Indeed, if I do stop it, does it finalize the deletes or rolls back?</p>

<p>I have found that when I do a </p>

<pre><code> select count(*) from myTable
</code></pre>

<p>That the rows that it returns (while doing this query) is about 5 less than what the starting row count was. Obviously the server resources are extremely poor, so does that mean that this process has taken 16 hours to find 5 duplicates (when there are actually thousands), and this could be running for days?</p>

<p>This query took 6 seconds on 2000 rows of test data, and it works great on that set of data, so I figured it would take 15 hours for the complete set.</p>

<p>Any ideas?</p>

<p>Below is the query:</p>

<pre><code>--Declare the looping variable
DECLARE @LoopVar char(10)


    DECLARE
     --Set private variables that will be used throughout
      @long DECIMAL,
      @lat DECIMAL,
      @phoneNumber char(10),
      @businessname varchar(64),
      @winner char(10)

    SET @LoopVar = (SELECT MIN(RecordID) FROM MyTable)

    WHILE @LoopVar is not null
    BEGIN

      --initialize the private variables (essentially this is a .ctor)
      SELECT 
        @long = null,
        @lat = null,
        @businessname = null,
        @phoneNumber = null,
        @winner = null

      -- load data from the row declared when setting @LoopVar  
      SELECT
        @long = longitude,
        @lat = latitude,
        @businessname = BusinessName,
        @phoneNumber = Phone
      FROM MyTable
      WHERE RecordID = @LoopVar

      --find the winning row with that data. The winning row means 
      SELECT top 1 @Winner = RecordID
      FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
      ORDER BY
        CASE WHEN webAddress is not null THEN 1 ELSE 2 END,
        CASE WHEN caption1 is not null THEN 1 ELSE 2 END,
        CASE WHEN caption2 is not null THEN 1 ELSE 2 END,
        RecordID

      --delete any losers.
      DELETE FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
        AND @winner != RecordID

      -- prep the next loop value to go ahead and perform the next duplicate query.
      SET @LoopVar = (SELECT MIN(RecordID) 
    FROM MyTable
    WHERE @LoopVar &lt; RecordID)
    END
</code></pre>
","<p>Your query is not wrapped in a transaction, so it won't rollback the changes already made by the individual delete statements.</p>

<p>I specifically tested this myself on my own SQL Server using the following query, and the ApplicationLog table was empty even though I cancelled the query:</p>

<pre><code>declare @count int
select @count = 5
WHILE @count &gt; 0
BEGIN
  print @count
  delete from applicationlog;
  waitfor time '20:00';
  select @count = @count -1
END
</code></pre>

<p>However your query is likely to take many days or weeks, much longer then 15 hours.  Your estimate that you can process 2000 records every 6 seconds is wrong because each iteration in your while loop will take significantly longer with 17 million rows then it does with 2000 rows.  So unless your query takes significantly less then a second for 2000 rows, it will take days for all 17 million.</p>

<p>You should ask a new question on how you can delete duplicate rows efficiently.</p>
"
371,161960,24,19,sql,"If I stop a long running query, does it rollback?","<p>A query that is used to loop through <b>17 millions records to remove duplicates</b>  has been running now for about <b>16 hours</b> and I wanted to know if the query is stopped right now if it will finalize the delete statements or if it has been deleting while running this query? Indeed, if I do stop it, does it finalize the deletes or rolls back?</p>

<p>I have found that when I do a </p>

<pre><code> select count(*) from myTable
</code></pre>

<p>That the rows that it returns (while doing this query) is about 5 less than what the starting row count was. Obviously the server resources are extremely poor, so does that mean that this process has taken 16 hours to find 5 duplicates (when there are actually thousands), and this could be running for days?</p>

<p>This query took 6 seconds on 2000 rows of test data, and it works great on that set of data, so I figured it would take 15 hours for the complete set.</p>

<p>Any ideas?</p>

<p>Below is the query:</p>

<pre><code>--Declare the looping variable
DECLARE @LoopVar char(10)


    DECLARE
     --Set private variables that will be used throughout
      @long DECIMAL,
      @lat DECIMAL,
      @phoneNumber char(10),
      @businessname varchar(64),
      @winner char(10)

    SET @LoopVar = (SELECT MIN(RecordID) FROM MyTable)

    WHILE @LoopVar is not null
    BEGIN

      --initialize the private variables (essentially this is a .ctor)
      SELECT 
        @long = null,
        @lat = null,
        @businessname = null,
        @phoneNumber = null,
        @winner = null

      -- load data from the row declared when setting @LoopVar  
      SELECT
        @long = longitude,
        @lat = latitude,
        @businessname = BusinessName,
        @phoneNumber = Phone
      FROM MyTable
      WHERE RecordID = @LoopVar

      --find the winning row with that data. The winning row means 
      SELECT top 1 @Winner = RecordID
      FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
      ORDER BY
        CASE WHEN webAddress is not null THEN 1 ELSE 2 END,
        CASE WHEN caption1 is not null THEN 1 ELSE 2 END,
        CASE WHEN caption2 is not null THEN 1 ELSE 2 END,
        RecordID

      --delete any losers.
      DELETE FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
        AND @winner != RecordID

      -- prep the next loop value to go ahead and perform the next duplicate query.
      SET @LoopVar = (SELECT MIN(RecordID) 
    FROM MyTable
    WHERE @LoopVar &lt; RecordID)
    END
</code></pre>
","<p>no, sql server will not roll back the deletes it has already performed if you stop query execution. oracle requires an explicit committal of action queries or the data gets rolled back, but not mssql.</p>

<p>with sql server it will not roll back unless you are specifically running in the context of a transaction and you rollback that transaction, or the connection closes without the transaction having been committed. but i don't see a transaction context in your above query.</p>

<p>you could also try re-structuring your query to make the deletes a little more efficient, but essentially if the specs of your box are not up to snuff then you might be stuck waiting it out.</p>

<p>going forward, you should create a unique index on the table to keep yourself from having to go through this again. </p>
"
372,161960,0,19,sql,"If I stop a long running query, does it rollback?","<p>A query that is used to loop through <b>17 millions records to remove duplicates</b>  has been running now for about <b>16 hours</b> and I wanted to know if the query is stopped right now if it will finalize the delete statements or if it has been deleting while running this query? Indeed, if I do stop it, does it finalize the deletes or rolls back?</p>

<p>I have found that when I do a </p>

<pre><code> select count(*) from myTable
</code></pre>

<p>That the rows that it returns (while doing this query) is about 5 less than what the starting row count was. Obviously the server resources are extremely poor, so does that mean that this process has taken 16 hours to find 5 duplicates (when there are actually thousands), and this could be running for days?</p>

<p>This query took 6 seconds on 2000 rows of test data, and it works great on that set of data, so I figured it would take 15 hours for the complete set.</p>

<p>Any ideas?</p>

<p>Below is the query:</p>

<pre><code>--Declare the looping variable
DECLARE @LoopVar char(10)


    DECLARE
     --Set private variables that will be used throughout
      @long DECIMAL,
      @lat DECIMAL,
      @phoneNumber char(10),
      @businessname varchar(64),
      @winner char(10)

    SET @LoopVar = (SELECT MIN(RecordID) FROM MyTable)

    WHILE @LoopVar is not null
    BEGIN

      --initialize the private variables (essentially this is a .ctor)
      SELECT 
        @long = null,
        @lat = null,
        @businessname = null,
        @phoneNumber = null,
        @winner = null

      -- load data from the row declared when setting @LoopVar  
      SELECT
        @long = longitude,
        @lat = latitude,
        @businessname = BusinessName,
        @phoneNumber = Phone
      FROM MyTable
      WHERE RecordID = @LoopVar

      --find the winning row with that data. The winning row means 
      SELECT top 1 @Winner = RecordID
      FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
      ORDER BY
        CASE WHEN webAddress is not null THEN 1 ELSE 2 END,
        CASE WHEN caption1 is not null THEN 1 ELSE 2 END,
        CASE WHEN caption2 is not null THEN 1 ELSE 2 END,
        RecordID

      --delete any losers.
      DELETE FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
        AND @winner != RecordID

      -- prep the next loop value to go ahead and perform the next duplicate query.
      SET @LoopVar = (SELECT MIN(RecordID) 
    FROM MyTable
    WHERE @LoopVar &lt; RecordID)
    END
</code></pre>
","<p>As a loop your query will struggle to scale well, even with appropriate indexes. The query should be rewritten to a single statement, as per the suggestions in <a href=""http://stackoverflow.com/questions/150891/sql-query-remove-duplicates-with-caveats"">your previous question</a> on this.</p>

<p>If you're not running it explicitly within a transaction it will only roll back the executing statement.</p>
"
374,161960,1,19,sql,"If I stop a long running query, does it rollback?","<p>A query that is used to loop through <b>17 millions records to remove duplicates</b>  has been running now for about <b>16 hours</b> and I wanted to know if the query is stopped right now if it will finalize the delete statements or if it has been deleting while running this query? Indeed, if I do stop it, does it finalize the deletes or rolls back?</p>

<p>I have found that when I do a </p>

<pre><code> select count(*) from myTable
</code></pre>

<p>That the rows that it returns (while doing this query) is about 5 less than what the starting row count was. Obviously the server resources are extremely poor, so does that mean that this process has taken 16 hours to find 5 duplicates (when there are actually thousands), and this could be running for days?</p>

<p>This query took 6 seconds on 2000 rows of test data, and it works great on that set of data, so I figured it would take 15 hours for the complete set.</p>

<p>Any ideas?</p>

<p>Below is the query:</p>

<pre><code>--Declare the looping variable
DECLARE @LoopVar char(10)


    DECLARE
     --Set private variables that will be used throughout
      @long DECIMAL,
      @lat DECIMAL,
      @phoneNumber char(10),
      @businessname varchar(64),
      @winner char(10)

    SET @LoopVar = (SELECT MIN(RecordID) FROM MyTable)

    WHILE @LoopVar is not null
    BEGIN

      --initialize the private variables (essentially this is a .ctor)
      SELECT 
        @long = null,
        @lat = null,
        @businessname = null,
        @phoneNumber = null,
        @winner = null

      -- load data from the row declared when setting @LoopVar  
      SELECT
        @long = longitude,
        @lat = latitude,
        @businessname = BusinessName,
        @phoneNumber = Phone
      FROM MyTable
      WHERE RecordID = @LoopVar

      --find the winning row with that data. The winning row means 
      SELECT top 1 @Winner = RecordID
      FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
      ORDER BY
        CASE WHEN webAddress is not null THEN 1 ELSE 2 END,
        CASE WHEN caption1 is not null THEN 1 ELSE 2 END,
        CASE WHEN caption2 is not null THEN 1 ELSE 2 END,
        RecordID

      --delete any losers.
      DELETE FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
        AND @winner != RecordID

      -- prep the next loop value to go ahead and perform the next duplicate query.
      SET @LoopVar = (SELECT MIN(RecordID) 
    FROM MyTable
    WHERE @LoopVar &lt; RecordID)
    END
</code></pre>
","<p>I inherited a system which had logic something like yours implemented in SQL.   In our case, we were trying to link together rows using fuzzy matching that had similar names/addresses, etc, and that logic was done purely in SQL.   At the time I inherited it we had about 300,000 rows in the table and according to the timings, we calculated it would take A YEAR to match them all.</p>

<p>As an experiment to see how much faster I could do it outside of SQL, I wrote a program to dump the db table into flat files, read the flat files into a C++ program, build my own indexes, and do the fuzzy logic there, then reimport the flat files into the database.   What took A YEAR in SQL took about 30 seconds in the C++ app.</p>

<p>So, my advice is, don't even try what you are doing in SQL.   Export, process, re-import.</p>
"
375,161960,0,19,sql,"If I stop a long running query, does it rollback?","<p>A query that is used to loop through <b>17 millions records to remove duplicates</b>  has been running now for about <b>16 hours</b> and I wanted to know if the query is stopped right now if it will finalize the delete statements or if it has been deleting while running this query? Indeed, if I do stop it, does it finalize the deletes or rolls back?</p>

<p>I have found that when I do a </p>

<pre><code> select count(*) from myTable
</code></pre>

<p>That the rows that it returns (while doing this query) is about 5 less than what the starting row count was. Obviously the server resources are extremely poor, so does that mean that this process has taken 16 hours to find 5 duplicates (when there are actually thousands), and this could be running for days?</p>

<p>This query took 6 seconds on 2000 rows of test data, and it works great on that set of data, so I figured it would take 15 hours for the complete set.</p>

<p>Any ideas?</p>

<p>Below is the query:</p>

<pre><code>--Declare the looping variable
DECLARE @LoopVar char(10)


    DECLARE
     --Set private variables that will be used throughout
      @long DECIMAL,
      @lat DECIMAL,
      @phoneNumber char(10),
      @businessname varchar(64),
      @winner char(10)

    SET @LoopVar = (SELECT MIN(RecordID) FROM MyTable)

    WHILE @LoopVar is not null
    BEGIN

      --initialize the private variables (essentially this is a .ctor)
      SELECT 
        @long = null,
        @lat = null,
        @businessname = null,
        @phoneNumber = null,
        @winner = null

      -- load data from the row declared when setting @LoopVar  
      SELECT
        @long = longitude,
        @lat = latitude,
        @businessname = BusinessName,
        @phoneNumber = Phone
      FROM MyTable
      WHERE RecordID = @LoopVar

      --find the winning row with that data. The winning row means 
      SELECT top 1 @Winner = RecordID
      FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
      ORDER BY
        CASE WHEN webAddress is not null THEN 1 ELSE 2 END,
        CASE WHEN caption1 is not null THEN 1 ELSE 2 END,
        CASE WHEN caption2 is not null THEN 1 ELSE 2 END,
        RecordID

      --delete any losers.
      DELETE FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
        AND @winner != RecordID

      -- prep the next loop value to go ahead and perform the next duplicate query.
      SET @LoopVar = (SELECT MIN(RecordID) 
    FROM MyTable
    WHERE @LoopVar &lt; RecordID)
    END
</code></pre>
","<p>I think this query would be much more efficient if it was re-written using a single-pass algorithm using a cursor.  You would order you cursor table by longitude,latitude,BusinessName AND @phoneNumber. Youd step through the rows one at a time. If a row has the same longitude, latitude, businessname, and phonenumber as the previous row, then delete it. </p>
"
376,161960,1,19,sql,"If I stop a long running query, does it rollback?","<p>A query that is used to loop through <b>17 millions records to remove duplicates</b>  has been running now for about <b>16 hours</b> and I wanted to know if the query is stopped right now if it will finalize the delete statements or if it has been deleting while running this query? Indeed, if I do stop it, does it finalize the deletes or rolls back?</p>

<p>I have found that when I do a </p>

<pre><code> select count(*) from myTable
</code></pre>

<p>That the rows that it returns (while doing this query) is about 5 less than what the starting row count was. Obviously the server resources are extremely poor, so does that mean that this process has taken 16 hours to find 5 duplicates (when there are actually thousands), and this could be running for days?</p>

<p>This query took 6 seconds on 2000 rows of test data, and it works great on that set of data, so I figured it would take 15 hours for the complete set.</p>

<p>Any ideas?</p>

<p>Below is the query:</p>

<pre><code>--Declare the looping variable
DECLARE @LoopVar char(10)


    DECLARE
     --Set private variables that will be used throughout
      @long DECIMAL,
      @lat DECIMAL,
      @phoneNumber char(10),
      @businessname varchar(64),
      @winner char(10)

    SET @LoopVar = (SELECT MIN(RecordID) FROM MyTable)

    WHILE @LoopVar is not null
    BEGIN

      --initialize the private variables (essentially this is a .ctor)
      SELECT 
        @long = null,
        @lat = null,
        @businessname = null,
        @phoneNumber = null,
        @winner = null

      -- load data from the row declared when setting @LoopVar  
      SELECT
        @long = longitude,
        @lat = latitude,
        @businessname = BusinessName,
        @phoneNumber = Phone
      FROM MyTable
      WHERE RecordID = @LoopVar

      --find the winning row with that data. The winning row means 
      SELECT top 1 @Winner = RecordID
      FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
      ORDER BY
        CASE WHEN webAddress is not null THEN 1 ELSE 2 END,
        CASE WHEN caption1 is not null THEN 1 ELSE 2 END,
        CASE WHEN caption2 is not null THEN 1 ELSE 2 END,
        RecordID

      --delete any losers.
      DELETE FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
        AND @winner != RecordID

      -- prep the next loop value to go ahead and perform the next duplicate query.
      SET @LoopVar = (SELECT MIN(RecordID) 
    FROM MyTable
    WHERE @LoopVar &lt; RecordID)
    END
</code></pre>
","<p>DELETES that have been performed up to this point will not be rolled back.</p>

<p><hr /></p>

<p>As the original author of the <a href=""http://stackoverflow.com/questions/150891/sql-query-remove-duplicates-with-caveats#150967"">code in question</a>, and having issued the caveat that performance will be dependant on indexes, I would propose the following items to speed this up.</p>

<p>RecordId better be PRIMARY KEY.  I don't mean IDENTITY, I mean PRIMARY KEY.  Confirm this using sp_help</p>

<p>Some index should be used in evaluating this query.  Figure out which of these four columns has the least repeats and index that...</p>

<pre><code>SELECT *
FROM MyTable
WHERE @long = longitude
  AND @lat = latitude
  AND @businessname = BusinessName
  AND @phoneNumber = Phone
</code></pre>

<p>Before and After adding this index, check the query plan to see if index scanning has been added.</p>
"
1190,534240,36,19,sql,MSSQL Select statement with incremental integer column... not from a table,"<p>I need, if possible, a t-sql query that, returning the values from an arbitrary table, also returns a incremental integer column with value = 1 for the first row, 2 for the second, and so on.</p>

<p>This column does not actually resides in any table, and must be strictly incremental, because the ORDER BY clause could sort the rows of the table and I want the incremental row in perfect shape always...</p>

<p>Thanks in advance.</p>

<p>--EDIT
Sorry, forgot to mention, must run on SQL Server 2000</p>
","<p>For SQL 2005 and up</p>

<pre><code>SELECT ROW_NUMBER() OVER( ORDER BY SomeColumn ) AS 'rownumber',*
    FROM YourTable
</code></pre>

<p>for 2000 you need to do something like this</p>

<pre><code>SELECT IDENTITY(INT, 1,1) AS Rank ,VALUE
INTO #Ranks FROM YourTable WHERE 1=0

INSERT INTO #Ranks
SELECT SomeColumn  FROM YourTable
ORDER BY SomeColumn 

SELECT * FROM #Ranks
Order By Ranks
</code></pre>

<p>see also here  <a href=""http://wiki.lessthandot.com/index.php/Row_Number"">Row Number</a></p>
"
373,161960,2,19,sql,"If I stop a long running query, does it rollback?","<p>A query that is used to loop through <b>17 millions records to remove duplicates</b>  has been running now for about <b>16 hours</b> and I wanted to know if the query is stopped right now if it will finalize the delete statements or if it has been deleting while running this query? Indeed, if I do stop it, does it finalize the deletes or rolls back?</p>

<p>I have found that when I do a </p>

<pre><code> select count(*) from myTable
</code></pre>

<p>That the rows that it returns (while doing this query) is about 5 less than what the starting row count was. Obviously the server resources are extremely poor, so does that mean that this process has taken 16 hours to find 5 duplicates (when there are actually thousands), and this could be running for days?</p>

<p>This query took 6 seconds on 2000 rows of test data, and it works great on that set of data, so I figured it would take 15 hours for the complete set.</p>

<p>Any ideas?</p>

<p>Below is the query:</p>

<pre><code>--Declare the looping variable
DECLARE @LoopVar char(10)


    DECLARE
     --Set private variables that will be used throughout
      @long DECIMAL,
      @lat DECIMAL,
      @phoneNumber char(10),
      @businessname varchar(64),
      @winner char(10)

    SET @LoopVar = (SELECT MIN(RecordID) FROM MyTable)

    WHILE @LoopVar is not null
    BEGIN

      --initialize the private variables (essentially this is a .ctor)
      SELECT 
        @long = null,
        @lat = null,
        @businessname = null,
        @phoneNumber = null,
        @winner = null

      -- load data from the row declared when setting @LoopVar  
      SELECT
        @long = longitude,
        @lat = latitude,
        @businessname = BusinessName,
        @phoneNumber = Phone
      FROM MyTable
      WHERE RecordID = @LoopVar

      --find the winning row with that data. The winning row means 
      SELECT top 1 @Winner = RecordID
      FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
      ORDER BY
        CASE WHEN webAddress is not null THEN 1 ELSE 2 END,
        CASE WHEN caption1 is not null THEN 1 ELSE 2 END,
        CASE WHEN caption2 is not null THEN 1 ELSE 2 END,
        RecordID

      --delete any losers.
      DELETE FROM MyTable
      WHERE @long = longitude
        AND @lat = latitude
        AND @businessname = BusinessName
        AND @phoneNumber = Phone
        AND @winner != RecordID

      -- prep the next loop value to go ahead and perform the next duplicate query.
      SET @LoopVar = (SELECT MIN(RecordID) 
    FROM MyTable
    WHERE @LoopVar &lt; RecordID)
    END
</code></pre>
","<p>If you don't do anything explicit about transactions then the connection will be in <a href=""http://msdn.microsoft.com/en-us/library/ms187878.aspx"" rel=""nofollow"">autocommit transactions</a> mode. In this mode every SQL statement is considered a transaction.</p>

<p>The question is whether this means the individual SQL statements are transactions and are therefore being committed as you go, or whether the outer WHILE loop counts as a transaction.</p>

<p>There doesn't seem to be any discussion of this in the description of the WHILE construct on <a href=""http://msdn.microsoft.com/en-us/library/ms178642.aspx"" rel=""nofollow"">MSDN</a>.  However, since a WHILE statement can't directly modify the database it would seem logical that it <strong>doesn't</strong> start an auto-commit transaction.</p>
"
1191,534240,-1,19,sql,MSSQL Select statement with incremental integer column... not from a table,"<p>I need, if possible, a t-sql query that, returning the values from an arbitrary table, also returns a incremental integer column with value = 1 for the first row, 2 for the second, and so on.</p>

<p>This column does not actually resides in any table, and must be strictly incremental, because the ORDER BY clause could sort the rows of the table and I want the incremental row in perfect shape always...</p>

<p>Thanks in advance.</p>

<p>--EDIT
Sorry, forgot to mention, must run on SQL Server 2000</p>
","<p>It is ugly and performs badly, but technically this works on any table with at least one unique field AND works in SQL 2000.</p>

<pre><code>SELECT (SELECT COUNT(*) FROM myTable T1 WHERE T1.UniqueField&lt;=T2.UniqueField) as RowNum, T2.OtherField
FROM myTable T2
ORDER By T2.UniqueField
</code></pre>

<p>Note: If you use this approach and add a WHERE clause to the outer SELECT, you have to added it to the inner SELECT also if you want the numbers to be continuous.</p>
"
276,125400,4,17,sql,Generic LINQ query predicate?,"<p>Not sure if this is possible or if I'm expressing correctly what I'm looking for, but I have the following piece of code in my library repeatedly and would like to practice some DRY. 
I have set of SQL Server tables that I'm querying based on a simple user-supplied search field ala Google. I'm using LINQ to compose the final query based on what's in the search string. I'm looking for a way to use generics and passed in lambda functions to create a reusable routine out of this: </p>

<pre><code>string[] arrayOfQueryTerms = getsTheArray();

var somequery = from q in dataContext.MyTable
                select q;

if (arrayOfQueryTerms.Length == 1)
{
    somequery = somequery.Where&lt;MyTableEntity&gt;(
        e =&gt; e.FieldName.StartsWith(arrayOfQueryTerms[0]));
}
else
{
    foreach(string queryTerm in arrayOfQueryTerms)
    {
        if (!String.IsNullOrEmpty(queryTerm))
        {
            somequery = somequery 
                        .Where&lt;MyTableEntity&gt;(
                            e =&gt; e.FieldName.Contains(queryTerm));
        }
    }
}
</code></pre>

<p>I was hoping to create a generic method with signature that looks something like:</p>

<pre><code>private IQueryable&lt;T&gt; getQuery(
    T MyTableEntity, string[] arrayOfQueryTerms, Func&lt;T, bool&gt; predicate)
</code></pre>

<p>I'm using the same search strategy across all my tables, so the only thing that really differs from usage to usage is the MyTable &amp; MyTableEntity searched and the FieldName searched. Does this make sense? Is there a way with LINQ to dynamically pass in the name of the field to query in the where clause? Or can I pass in this as a predicate lambda?</p>

<pre><code>e =&gt; e.FieldName.Contains(queryTerm)
</code></pre>

<p>I realize there a million and a half ways to do this in SQL, probably easier, but I'd love to keep everything in the LINQ family for this one. Also, I feel that generics should be handy for a problem like this. Any ideas?</p>
","<p>You might want to look at expression trees:</p>

<pre><code>IQueryable&lt;T&gt; getQuery&lt;T&gt;(T myTableEntity, string[] arrayOfQueryTerms, Expression&lt;Func&lt;T, bool&gt;&gt; predicate)
 { var fieldOrProperty = getMemberInfo(predicate);
   /* ... */
 }

MemberInfo getmemberInfo&lt;T&gt;(Expression&lt;Func&lt;T,bool&gt; expr)
 { var memberExpr = expr as MemberExpression;
   if (memberExpr != null) return memberExpr.Member;
   throw new ArgumentException();
 }

var q = getQuery&lt;FooTable&gt;(foo, new[]{""Bar"",""Baz""}, x=&gt;x.FieldName);
</code></pre>
"
583,262450,3,17,sql,Why is using '*' to build a view bad?,"<p>Why is using '*' to build a view bad ?</p>

<p>Suppose that you have a complex join and all fields may be used somewhere.</p>

<p>Then you just have to chose fields needed.</p>

<pre><code>SELECT field1, field2 FROM aview WHERE ...
</code></pre>

<p>The view ""aview"" could be <code>SELECT table1.*, table2.* ... FROM table1 INNER JOIN table2 ...</code></p>

<p>We have a problem if 2 fields have the same name in table1 and table2.</p>

<p>Is this only the reason why using '*' in a view is bad?</p>

<p>With '*', you may use the view in a different context because the information is there.</p>

<p>What am I missing ?</p>

<p>Regards</p>
","<p>It's because you don't always need every variable, and also to make sure that you are thinking about what you specifically need.</p>

<p>There's no point getting all the hashed passwords out of the database when building a list of users on your site for instance, so a select * would be unproductive.</p>
"
591,262450,2,17,sql,Why is using '*' to build a view bad?,"<p>Why is using '*' to build a view bad ?</p>

<p>Suppose that you have a complex join and all fields may be used somewhere.</p>

<p>Then you just have to chose fields needed.</p>

<pre><code>SELECT field1, field2 FROM aview WHERE ...
</code></pre>

<p>The view ""aview"" could be <code>SELECT table1.*, table2.* ... FROM table1 INNER JOIN table2 ...</code></p>

<p>We have a problem if 2 fields have the same name in table1 and table2.</p>

<p>Is this only the reason why using '*' in a view is bad?</p>

<p>With '*', you may use the view in a different context because the information is there.</p>

<p>What am I missing ?</p>

<p>Regards</p>
","<p>I think it depends on the language you are using. I prefer to use select * when the language or DB driver returns a dict(Python, Perl, etc.) or associative array(PHP) of the results. It makes your code alot easier to understand if you are referring to the columns by name instead of as an index in an array.</p>
"
592,262450,12,17,sql,Why is using '*' to build a view bad?,"<p>Why is using '*' to build a view bad ?</p>

<p>Suppose that you have a complex join and all fields may be used somewhere.</p>

<p>Then you just have to chose fields needed.</p>

<pre><code>SELECT field1, field2 FROM aview WHERE ...
</code></pre>

<p>The view ""aview"" could be <code>SELECT table1.*, table2.* ... FROM table1 INNER JOIN table2 ...</code></p>

<p>We have a problem if 2 fields have the same name in table1 and table2.</p>

<p>Is this only the reason why using '*' in a view is bad?</p>

<p>With '*', you may use the view in a different context because the information is there.</p>

<p>What am I missing ?</p>

<p>Regards</p>
","<p>These other answers all have good points, but on SQL server at least they also have some wrong points.  Try this:</p>

<pre><code>create table temp (i int, j int)
go
create view vtemp as select * from temp
go
insert temp select 1, 1
go
alter table temp add k int
go
insert temp select 1, 1, 1
go
select * from vtemp
</code></pre>

<p>SQL Server doesn't learn about the ""new"" column when it is added.  Depending on what you want this could be a good thing or a bad thing, but either way it's probably not good to depend on it.  So avoiding it just seems like a good idea.</p>

<p>To me this weird behavior is the most compelling reason to avoid select * in views.</p>

<p>The comments have taught me that MySQL has similar behavior and Oracle does not (it will learn about changes to the table).  This inconsistency to me is all the more reason not to use select * in views.</p>
"
277,125400,0,17,sql,Generic LINQ query predicate?,"<p>Not sure if this is possible or if I'm expressing correctly what I'm looking for, but I have the following piece of code in my library repeatedly and would like to practice some DRY. 
I have set of SQL Server tables that I'm querying based on a simple user-supplied search field ala Google. I'm using LINQ to compose the final query based on what's in the search string. I'm looking for a way to use generics and passed in lambda functions to create a reusable routine out of this: </p>

<pre><code>string[] arrayOfQueryTerms = getsTheArray();

var somequery = from q in dataContext.MyTable
                select q;

if (arrayOfQueryTerms.Length == 1)
{
    somequery = somequery.Where&lt;MyTableEntity&gt;(
        e =&gt; e.FieldName.StartsWith(arrayOfQueryTerms[0]));
}
else
{
    foreach(string queryTerm in arrayOfQueryTerms)
    {
        if (!String.IsNullOrEmpty(queryTerm))
        {
            somequery = somequery 
                        .Where&lt;MyTableEntity&gt;(
                            e =&gt; e.FieldName.Contains(queryTerm));
        }
    }
}
</code></pre>

<p>I was hoping to create a generic method with signature that looks something like:</p>

<pre><code>private IQueryable&lt;T&gt; getQuery(
    T MyTableEntity, string[] arrayOfQueryTerms, Func&lt;T, bool&gt; predicate)
</code></pre>

<p>I'm using the same search strategy across all my tables, so the only thing that really differs from usage to usage is the MyTable &amp; MyTableEntity searched and the FieldName searched. Does this make sense? Is there a way with LINQ to dynamically pass in the name of the field to query in the where clause? Or can I pass in this as a predicate lambda?</p>

<pre><code>e =&gt; e.FieldName.Contains(queryTerm)
</code></pre>

<p>I realize there a million and a half ways to do this in SQL, probably easier, but I'd love to keep everything in the LINQ family for this one. Also, I feel that generics should be handy for a problem like this. Any ideas?</p>
","<p>I recently had to do this same thing. You will need <a href=""http://talesfromthebleedingedge.blogspot.com/2008/10/linq-to-entities-dynamic-linq-to.html"" rel=""nofollow"">Dynamic Linq</a> <a href=""http://talesfromthebleedingedge.blogspot.com/2008/10/linq-to-entities-dynamic-linq-to.html"" rel=""nofollow"">here</a> is a way to keep this strongly typed. </p>
"
593,262450,2,17,sql,Why is using '*' to build a view bad?,"<p>Why is using '*' to build a view bad ?</p>

<p>Suppose that you have a complex join and all fields may be used somewhere.</p>

<p>Then you just have to chose fields needed.</p>

<pre><code>SELECT field1, field2 FROM aview WHERE ...
</code></pre>

<p>The view ""aview"" could be <code>SELECT table1.*, table2.* ... FROM table1 INNER JOIN table2 ...</code></p>

<p>We have a problem if 2 fields have the same name in table1 and table2.</p>

<p>Is this only the reason why using '*' in a view is bad?</p>

<p>With '*', you may use the view in a different context because the information is there.</p>

<p>What am I missing ?</p>

<p>Regards</p>
","<p>No one else seems to have mentioned it, but within SQL Server you can also set up your view with the <a href=""http://msdn.microsoft.com/en-us/library/ms173846.aspx"" rel=""nofollow"">schemabinding</a> attribute. </p>

<p>This prevents modifications to any of the base tables (including dropping them) that would affect the view definition. </p>

<p>This may be useful to you for some situations. I realise that I haven't exactly answered your question, but thought I would highlight it nonetheless.</p>
"
589,262450,2,17,sql,Why is using '*' to build a view bad?,"<p>Why is using '*' to build a view bad ?</p>

<p>Suppose that you have a complex join and all fields may be used somewhere.</p>

<p>Then you just have to chose fields needed.</p>

<pre><code>SELECT field1, field2 FROM aview WHERE ...
</code></pre>

<p>The view ""aview"" could be <code>SELECT table1.*, table2.* ... FROM table1 INNER JOIN table2 ...</code></p>

<p>We have a problem if 2 fields have the same name in table1 and table2.</p>

<p>Is this only the reason why using '*' in a view is bad?</p>

<p>With '*', you may use the view in a different context because the information is there.</p>

<p>What am I missing ?</p>

<p>Regards</p>
","<p>It's generally a bad idea to use *. Some code certification engines mark this as a warning and advise you to explicitly refer only the necessary columns. The use of * can lead to performance louses as you might only need some columns and not all. But, on the other hand, there are some cases where the use of * is ideal. Imagine that, no matter what, using the example you provided, for this view (aview) you would always need all the columns in these tables. In the future, when a column is added, you wouldn't need to alter the view. This can be good or bad depending the case you are dealing with. </p>
"
594,262450,3,17,sql,Why is using '*' to build a view bad?,"<p>Why is using '*' to build a view bad ?</p>

<p>Suppose that you have a complex join and all fields may be used somewhere.</p>

<p>Then you just have to chose fields needed.</p>

<pre><code>SELECT field1, field2 FROM aview WHERE ...
</code></pre>

<p>The view ""aview"" could be <code>SELECT table1.*, table2.* ... FROM table1 INNER JOIN table2 ...</code></p>

<p>We have a problem if 2 fields have the same name in table1 and table2.</p>

<p>Is this only the reason why using '*' in a view is bad?</p>

<p>With '*', you may use the view in a different context because the information is there.</p>

<p>What am I missing ?</p>

<p>Regards</p>
","<p>A SQL query is basically a functional unit designed by a programmer for use in some context. For long-term stability and supportability (possibly by someone other than you) everything in a functional unit should be there for a purpose, and it should be reasonably evident (or documented) why it's there - especially every element of data.</p>

<p>If I were to come along two years from now with the need or desire to alter your query, I would expect to grok it pretty thoroughly before I would be confident that I could mess with it. Which means I would need to understand why all the columns are called out. (This is even more obviously true if you are trying to reuse the query in more than one context. Which is problematic in general, for similar reasons.) If I were to see columns in the output that I couldn't relate to some purpose, I'd be pretty sure that I didn't understand what it did, and why, and what the consequences would be of changing it.</p>
"
590,262450,3,17,sql,Why is using '*' to build a view bad?,"<p>Why is using '*' to build a view bad ?</p>

<p>Suppose that you have a complex join and all fields may be used somewhere.</p>

<p>Then you just have to chose fields needed.</p>

<pre><code>SELECT field1, field2 FROM aview WHERE ...
</code></pre>

<p>The view ""aview"" could be <code>SELECT table1.*, table2.* ... FROM table1 INNER JOIN table2 ...</code></p>

<p>We have a problem if 2 fields have the same name in table1 and table2.</p>

<p>Is this only the reason why using '*' in a view is bad?</p>

<p>With '*', you may use the view in a different context because the information is there.</p>

<p>What am I missing ?</p>

<p>Regards</p>
","<p>Using <code>SELECT *</code> within the view does not incur much of a performance overhead if columns aren't used outside the view - the optimizer will optimize them out; <code>SELECT * FROM TheView</code> can perhaps waste bandwidth, just like any time you pull more columns across a network connection.</p>

<p>In fact, I have found that views which link almost all the columns from a number of huge tables in my datawarehouse have not introduced any performance issues at all, even through relatively few of those columns are requested from outside the view.  The optimizer handles that well and is able to push the external filter criteria down into the view very well.</p>

<p>However, for all the reasons given above, I very rarely use <code>SELECT *</code>.</p>

<p>I have some business processes where a number of CTEs are built on top of each other, effectively building derived columns from derived columns from derived columns (which will hopefully one day being refactored as the business rationalizes and simplifies these calculations), and in that case, I need all the columns to drop through each time, and I use <code>SELECT *</code> - but <code>SELECT *</code> is not used at the base layer, only in between the first CTE and the last.</p>
"
584,262450,31,17,sql,Why is using '*' to build a view bad?,"<p>Why is using '*' to build a view bad ?</p>

<p>Suppose that you have a complex join and all fields may be used somewhere.</p>

<p>Then you just have to chose fields needed.</p>

<pre><code>SELECT field1, field2 FROM aview WHERE ...
</code></pre>

<p>The view ""aview"" could be <code>SELECT table1.*, table2.* ... FROM table1 INNER JOIN table2 ...</code></p>

<p>We have a problem if 2 fields have the same name in table1 and table2.</p>

<p>Is this only the reason why using '*' in a view is bad?</p>

<p>With '*', you may use the view in a different context because the information is there.</p>

<p>What am I missing ?</p>

<p>Regards</p>
","<p>I don't think there's much in software that is ""just bad"", but there's plenty of stuff that is misused in bad ways :-)</p>

<p>The example you give is a reason why * might not give you what you expect, and I think there are others.  For example, if the underlying tables change, maybe columns are added or removed, a view that uses * will continue to be valid, but might break any applications that use it.  If your view had named the columns explicitly then there was more chance that someone would spot the problem when making the schema change.</p>

<p><strike>On the other hand, you might actually <em>want</em> your view to blithely
accept all changes to the underlying tables, in which case a * would
be just what you want.</strike></p>

<p><em>Update:</em> I don't know if the OP had a specific database vendor in mind, but it is now clear that my last remark does not hold true for all types.  I am indebted to user12861 and Jonny Leeds for pointing this out, and sorry it's taken over 6 years for me to edit my answer.</p>
"
585,262450,3,17,sql,Why is using '*' to build a view bad?,"<p>Why is using '*' to build a view bad ?</p>

<p>Suppose that you have a complex join and all fields may be used somewhere.</p>

<p>Then you just have to chose fields needed.</p>

<pre><code>SELECT field1, field2 FROM aview WHERE ...
</code></pre>

<p>The view ""aview"" could be <code>SELECT table1.*, table2.* ... FROM table1 INNER JOIN table2 ...</code></p>

<p>We have a problem if 2 fields have the same name in table1 and table2.</p>

<p>Is this only the reason why using '*' in a view is bad?</p>

<p>With '*', you may use the view in a different context because the information is there.</p>

<p>What am I missing ?</p>

<p>Regards</p>
","<p>Once upon a time, I created a view against a table in another database (on the same server) with</p>

<pre><code>Select * From dbname..tablename
</code></pre>

<p>Then one day, a column was added to the targetted table.  The view started returning totally incorrect results until it was redeployed.</p>

<p><hr /></p>

<p>Totally incorrect : no rows.</p>

<p>This was on Sql Server 2000.</p>

<p>I speculate that this is because of syscolumns values that the view had captured, even though I used *.</p>
"
274,125400,6,17,sql,Generic LINQ query predicate?,"<p>Not sure if this is possible or if I'm expressing correctly what I'm looking for, but I have the following piece of code in my library repeatedly and would like to practice some DRY. 
I have set of SQL Server tables that I'm querying based on a simple user-supplied search field ala Google. I'm using LINQ to compose the final query based on what's in the search string. I'm looking for a way to use generics and passed in lambda functions to create a reusable routine out of this: </p>

<pre><code>string[] arrayOfQueryTerms = getsTheArray();

var somequery = from q in dataContext.MyTable
                select q;

if (arrayOfQueryTerms.Length == 1)
{
    somequery = somequery.Where&lt;MyTableEntity&gt;(
        e =&gt; e.FieldName.StartsWith(arrayOfQueryTerms[0]));
}
else
{
    foreach(string queryTerm in arrayOfQueryTerms)
    {
        if (!String.IsNullOrEmpty(queryTerm))
        {
            somequery = somequery 
                        .Where&lt;MyTableEntity&gt;(
                            e =&gt; e.FieldName.Contains(queryTerm));
        }
    }
}
</code></pre>

<p>I was hoping to create a generic method with signature that looks something like:</p>

<pre><code>private IQueryable&lt;T&gt; getQuery(
    T MyTableEntity, string[] arrayOfQueryTerms, Func&lt;T, bool&gt; predicate)
</code></pre>

<p>I'm using the same search strategy across all my tables, so the only thing that really differs from usage to usage is the MyTable &amp; MyTableEntity searched and the FieldName searched. Does this make sense? Is there a way with LINQ to dynamically pass in the name of the field to query in the where clause? Or can I pass in this as a predicate lambda?</p>

<pre><code>e =&gt; e.FieldName.Contains(queryTerm)
</code></pre>

<p>I realize there a million and a half ways to do this in SQL, probably easier, but I'd love to keep everything in the LINQ family for this one. Also, I feel that generics should be handy for a problem like this. Any ideas?</p>
","<p>What it sounds like is you want basically a conditional predicate builder.. </p>

<p>I hope you can mold this into something you are looking for, good luck!</p>

<p><a href=""http://www.albahari.com/nutshell/predicatebuilder.aspx"">http://www.albahari.com/nutshell/predicatebuilder.aspx</a></p>
"
588,262450,18,17,sql,Why is using '*' to build a view bad?,"<p>Why is using '*' to build a view bad ?</p>

<p>Suppose that you have a complex join and all fields may be used somewhere.</p>

<p>Then you just have to chose fields needed.</p>

<pre><code>SELECT field1, field2 FROM aview WHERE ...
</code></pre>

<p>The view ""aview"" could be <code>SELECT table1.*, table2.* ... FROM table1 INNER JOIN table2 ...</code></p>

<p>We have a problem if 2 fields have the same name in table1 and table2.</p>

<p>Is this only the reason why using '*' in a view is bad?</p>

<p>With '*', you may use the view in a different context because the information is there.</p>

<p>What am I missing ?</p>

<p>Regards</p>
","<p>Although many of the comments here are very good and reference one common problem of using wildcards in queries, such as causing errors or different results if the underlying tables change, another issue that hasn't been covered is optimization.  A query that pulls every column of a table tends to not be quite as efficient as a query that pulls only those columns you actually need.  Granted, there are those times when you need every column and it's a major PIA having to reference them all, especially in a large table, but if you only need a subset, why bog down your query with more columns than you need.</p>
"
587,262450,15,17,sql,Why is using '*' to build a view bad?,"<p>Why is using '*' to build a view bad ?</p>

<p>Suppose that you have a complex join and all fields may be used somewhere.</p>

<p>Then you just have to chose fields needed.</p>

<pre><code>SELECT field1, field2 FROM aview WHERE ...
</code></pre>

<p>The view ""aview"" could be <code>SELECT table1.*, table2.* ... FROM table1 INNER JOIN table2 ...</code></p>

<p>We have a problem if 2 fields have the same name in table1 and table2.</p>

<p>Is this only the reason why using '*' in a view is bad?</p>

<p>With '*', you may use the view in a different context because the information is there.</p>

<p>What am I missing ?</p>

<p>Regards</p>
","<p>Another reason why ""<code>*</code>"" is risky, not only in views but in queries, is that columns can change name or change position in the underlying tables.  Using a wildcard means that your view accommodates such changes easily without needing to be changed.  But if your application references columns by position in the result set, or if you use a dynamic language that returns result sets keyed by column name, you could experience problems that are hard to debug.</p>

<p>I avoid using the wildcard at all times.  That way if a column changes name, I get an error in the view or query immediately, and I know where to fix it.  If a column changes position in the underlying table, specifying the order of the columns in the view or query compensates for this.</p>
"
586,262450,11,17,sql,Why is using '*' to build a view bad?,"<p>Why is using '*' to build a view bad ?</p>

<p>Suppose that you have a complex join and all fields may be used somewhere.</p>

<p>Then you just have to chose fields needed.</p>

<pre><code>SELECT field1, field2 FROM aview WHERE ...
</code></pre>

<p>The view ""aview"" could be <code>SELECT table1.*, table2.* ... FROM table1 INNER JOIN table2 ...</code></p>

<p>We have a problem if 2 fields have the same name in table1 and table2.</p>

<p>Is this only the reason why using '*' in a view is bad?</p>

<p>With '*', you may use the view in a different context because the information is there.</p>

<p>What am I missing ?</p>

<p>Regards</p>
","<p>Using '*' for anything production is bad. It's great for one-off queries, but in production code you should always be as explicit as possible.</p>

<p>For views in particular, if the underlying tables have columns added or removed, the view will either be wrong or broken until it is recompiled.</p>
"
275,125400,14,17,sql,Generic LINQ query predicate?,"<p>Not sure if this is possible or if I'm expressing correctly what I'm looking for, but I have the following piece of code in my library repeatedly and would like to practice some DRY. 
I have set of SQL Server tables that I'm querying based on a simple user-supplied search field ala Google. I'm using LINQ to compose the final query based on what's in the search string. I'm looking for a way to use generics and passed in lambda functions to create a reusable routine out of this: </p>

<pre><code>string[] arrayOfQueryTerms = getsTheArray();

var somequery = from q in dataContext.MyTable
                select q;

if (arrayOfQueryTerms.Length == 1)
{
    somequery = somequery.Where&lt;MyTableEntity&gt;(
        e =&gt; e.FieldName.StartsWith(arrayOfQueryTerms[0]));
}
else
{
    foreach(string queryTerm in arrayOfQueryTerms)
    {
        if (!String.IsNullOrEmpty(queryTerm))
        {
            somequery = somequery 
                        .Where&lt;MyTableEntity&gt;(
                            e =&gt; e.FieldName.Contains(queryTerm));
        }
    }
}
</code></pre>

<p>I was hoping to create a generic method with signature that looks something like:</p>

<pre><code>private IQueryable&lt;T&gt; getQuery(
    T MyTableEntity, string[] arrayOfQueryTerms, Func&lt;T, bool&gt; predicate)
</code></pre>

<p>I'm using the same search strategy across all my tables, so the only thing that really differs from usage to usage is the MyTable &amp; MyTableEntity searched and the FieldName searched. Does this make sense? Is there a way with LINQ to dynamically pass in the name of the field to query in the where clause? Or can I pass in this as a predicate lambda?</p>

<pre><code>e =&gt; e.FieldName.Contains(queryTerm)
</code></pre>

<p>I realize there a million and a half ways to do this in SQL, probably easier, but I'd love to keep everything in the LINQ family for this one. Also, I feel that generics should be handy for a problem like this. Any ideas?</p>
","<p>It sounds like you're looking for Dynamic Linq. Take a look <a href=""http://weblogs.asp.net/scottgu/archive/2008/01/07/dynamic-linq-part-1-using-the-linq-dynamic-query-library.aspx"" rel=""nofollow"">here</a>. This allows you to pass strings as arguments to the query methods, like:</p>

<pre><code>var query = dataSource.Where(""CategoryID == 2 &amp;&amp; UnitPrice &gt; 3"")
                      .OrderBy(""SupplierID"");
</code></pre>

<p>Edit: Another set of posts on this subject, using C# 4's Dynamic support: <a href=""http://weblogs.asp.net/davidfowler/archive/2010/08/04/dynamic-linq-a-little-more-dynamic.aspx"" rel=""nofollow"">Part 1</a> and <a href=""http://weblogs.asp.net/davidfowler/archive/2010/08/19/dynamic-linq-part-2-evolution.aspx"" rel=""nofollow"">Part 2</a>.</p>
"
76,31500,3,15,sql,"Do indexes work with ""IN"" clause","<p>If I have a query like:</p>

<pre><code>Select EmployeeId 
From Employee 
Where EmployeeTypeId IN (1,2,3)
</code></pre>

<p>and I have an index on the <code>EmployeeTypeId</code> field, does SQL server still use that index?</p>
","<p>Unless technology has improved in ways I can't imagine of late, the ""IN"" query shown will produce a result that's effectively the OR-ing of three result sets, one for each of the values in the ""IN"" list. The IN clause becomes an equality condition for each of the list and will use an index if appropriate. In the case of unique IDs and a large enough table then I'd expect the optimiser to use an index.</p>

<p>If the items in the list were to be non-unique however, and I guess in the example that a ""TypeId"" is a foreign key, then I'm more interested in the distribution. I'm wondering if the optimiser will check the stats for each value in the list? Say it checks the first value and finds it's in 20% of the rows (of a large enough table to matter). It'll probably table scan. But will the same query plan be used for the other two, even if they're unique?</p>

<p>It's probably moot - something like an Employee table is likely to be small enough that it will stay cached in memory and you probably wouldn't notice a difference between that and indexed retrieval anyway.</p>

<p>And lastly, while I'm preaching, beware the query in the IN clause: it's often a quick way to get something working and (for me at least) can be a good way to express the requirement, but it's almost always better restated as a join. Your optimiser may be smart enough to spot this, but then again it may not. If you don't currently performance-check against production data volumes, do so - in these days of cost-based optimisation you can't be certain of the query plan until you have a full load and representative statistics. If you can't, then be prepared for surprises in production...</p>
"
77,31500,1,15,sql,"Do indexes work with ""IN"" clause","<p>If I have a query like:</p>

<pre><code>Select EmployeeId 
From Employee 
Where EmployeeTypeId IN (1,2,3)
</code></pre>

<p>and I have an index on the <code>EmployeeTypeId</code> field, does SQL server still use that index?</p>
","<p>@Mike: Thanks for the detailed analysis. There are definately some interesting points you make there. The example I posted is somewhat trivial but the basis of the question came from using NHibernate.</p>

<p>With NHibernate, you can write a clause like this:</p>

<pre><code>int[] employeeIds = new int[]{1, 5, 23463, 32523};
NHibernateSession.CreateCriteria(typeof(Employee))
.Add(Restrictions.InG(""EmployeeId"",employeeIds))
</code></pre>

<p>NHibernate then generates a query which looks like  </p>

<pre><code>select * from employee where employeeid in (1, 5, 23463, 32523)
</code></pre>

<p>So as you and others have pointed out, it looks like there are going to be times where an index will be used or a table scan will happen, but you can't really determine that until runtime.</p>
"
74,31500,10,15,sql,"Do indexes work with ""IN"" clause","<p>If I have a query like:</p>

<pre><code>Select EmployeeId 
From Employee 
Where EmployeeTypeId IN (1,2,3)
</code></pre>

<p>and I have an index on the <code>EmployeeTypeId</code> field, does SQL server still use that index?</p>
","<p>Yeah, that's right.  If your employee table has 10,000 records, and only 5 records have employeetypeID in (1,2,3), then it will most likely use the index to fetch the records.  However, if it finds that 9,000 records have the employeeIDType in (1,2,3), then it would most likely just do a table scan to get the corresponding EmployeeIDs, as it's faster just to run through the whole table than to go to each branch of the index tree and look at the records individually.  </p>

<p>SQL Server does a lot of stuff to try and optimize how the queries run.  However, sometimes it doesn't get the right answer.  If you know that SQL Server isn't using the index, by looking at the execution plan in query analyzer, you can tell the query engine to use a specific index with the following change to your query.</p>

<pre><code>Select EmployeeId From Employee WITH (Index(Index_EmployeeTypeId )) Where EmployeeTypeId IN (1,2,3)
</code></pre>

<p>Assuming the index you have on the EmployeeTypeId field is named Index_EmployeeTypeId. </p>
"
73,31500,4,15,sql,"Do indexes work with ""IN"" clause","<p>If I have a query like:</p>

<pre><code>Select EmployeeId 
From Employee 
Where EmployeeTypeId IN (1,2,3)
</code></pre>

<p>and I have an index on the <code>EmployeeTypeId</code> field, does SQL server still use that index?</p>
","<p>Usually it would, unless the IN clause covers too much of the table, and then it will do a table scan.  Best way to find out in your specific case would be to run it in the query analyzer, and check out the execution plan.</p>
"
75,31500,2,15,sql,"Do indexes work with ""IN"" clause","<p>If I have a query like:</p>

<pre><code>Select EmployeeId 
From Employee 
Where EmployeeTypeId IN (1,2,3)
</code></pre>

<p>and I have an index on the <code>EmployeeTypeId</code> field, does SQL server still use that index?</p>
","<blockquote>
  <p>So there's the potential for an ""IN"" clause to run a table scan, but the optimizer will 
  try and work out the best way to deal with it?</p>
</blockquote>

<p>Whether an index is used doesn't so much vary on the type of query as much of the type and distribution of data in the table(s), how up-to-date your table statistics are, and the actual datatype of the column.</p>

<p>The other posters are correct that an index will be used over a table scan if:</p>

<ul>
<li>The query won't access more than a certain percent of the rows indexed (say ~10% but should vary between DBMS's).</li>
<li>Alternatively, if there are a lot of rows, but relatively few unique values in the column, it also may be faster to do a table scan.</li>
</ul>

<p>The other variable that might not be that obvious is making sure that the datatypes of the values being compared are the same. In PostgreSQL, I don't think that indexes will be used if you're filtering on a float but your column is made up of ints. There are also some operators that don't support index use (again, in PostgreSQL, the ILIKE operator is like this).</p>

<p>As noted though, always check the query analyser when in doubt and your DBMS's documentation is your friend.</p>
"
1143,525610,12,15,sql,How to remove diagramming support objects from SQL Server?,"<p>I need to remove diagramming support tables, stored procs, views, etc from SQL Servrer using TSQL script.   </p>

<p>Is there such a script available?  </p>

<p>SQL 2005 and 2008.</p>
","<p>You can drop the objects, but a user will be prompted to recreate them when they click the diagrams node.</p>

<p>Objects:</p>

<ul>
<li>sp_upgraddiagrams</li>
<li>sp_helpdiagrams</li>
<li>sp_helpdiagramdefinition</li>
<li>sp_creatediagram</li>
<li>sp_renamediagram</li>
<li>sp_alterdiagram</li>
<li>sp_dropdiagram</li>
<li>fn_diagramobjects</li>
<li>sysdiagrams</li>
<li>dt_properties (?)</li>
</ul>
"
924,430830,15,14,sql,Prevent mutually recursive execution of triggers?,"<p>Suppose you have the tables <code>Presentations</code> and <code>Events</code>. When a presentation is saved and contains basic event information, such as location and date, an event will be created automatically using a trigger. (I'm afraid it's impossible for technical reasons to simply keep the data at one place and use a view.) In addition, when changing this information later on in the presentation, the trigger will copy the updates over to the event as well, like so:</p>

<pre><code>CREATE TRIGGER update_presentations
ON Presentations
AFTER UPDATE
AS
BEGIN
    UPDATE Events
    SET Events.Date = Presentations.Date,
        Events.Location = Presentations.Location
    FROM Presentations INNER JOIN Events ON Presentations.EventID = Events.ID
    WHERE Presentations.ID IN (SELECT ID FROM inserted)
END
</code></pre>

<p>Now, the customer wants it so that, if a user ever changes the information in the <em>event</em>, it should go back to the presentation as well. For obvious reasons, I can't do the reverse:</p>

<pre><code>CREATE TRIGGER update_events
ON Events
AFTER UPDATE
AS
BEGIN
    UPDATE Presentations
    SET Presentations.Date = Events.Date,
        Presentations.Location = Events.Location
    FROM Events INNER JOIN Presentations ON Events.PresentationID = Presentations.ID
    WHERE Events.ID IN (SELECT ID FROM inserted)
END
</code></pre>

<p>After all, this would cause each trigger to fire after each other. What I could do is add a column <code>last_edit_by</code> to both tables, containing a user ID. If filled by the trigger with a special invalid ID (say, by making all user IDs of actual persons positive, but user IDs of scripts negative), I could use that as an exit condition:</p>

<pre><code>    AND last_edit_by &gt;= 0
</code></pre>

<p>This might work, but what I'd like to do is indicate to the SQL server that, within a transaction, a trigger should only fire once. Is there a way to check this? Or perhaps to check that a table has already been affected by a trigger?</p>

<p><hr /></p>

<p><strong>Answer</strong> thanks to Steve Robbins:</p>

<p>Just wrap the potentially nested <code>UPDATE</code> statements in an IF condition checking for <code>trigger_nestlevel()</code>. For example:</p>

<pre><code>CREATE TRIGGER update_presentations
ON Presentations
AFTER UPDATE
AS
BEGIN
    IF trigger_nestlevel() &lt; 2
        UPDATE Events
        SET Events.Date = Presentations.Date,
            Events.Location = Presentations.Location
        FROM Presentations INNER JOIN Events ON Presentations.EventID = Events.ID
        WHERE Presentations.ID IN (SELECT ID FROM inserted)
END
</code></pre>

<p>Note that <code>trigger_nestlevel()</code> appears to be 1-based, not 0-based. If you want each of the two triggers to execute once, but not more often, just check for <code>trigger_nestlevel() &lt; 3</code> in both triggers.</p>
","<p>I'm not sure about doing it per transaction, but do you need nested triggers switched on for other parts? If you switch them off on the server then a trigger won't fire from another trigger updating a table.</p>

<p>EDIT (answer from the comments): <strong>You will need to alter trigger A to use <a href=""http://msdn.microsoft.com/en-us/library/ms182737.aspx"">TRIGGER_NESTLEVEL</a></strong> </p>
"
176,76350,1,12,sql,Free/cheap PowerDesigner alternative?,"<p>We are using PowerDesigner at work for database modelling. But there is a hell of a price tag on that piece of software. And frankly, all I use is physical diagrams for MS SQL, which is about 1% of what PD knows.</p>

<p>Are there any good alternatives? I know about Visio and MS SQL Diagrams, but looking for other options.</p>
","<p>Well there's another alternative. Use it for more than just making tables! Exploit it, get your money's worth. You've already paid for it, you could drop the maintenance and just use it as-is. Anyways, something to ponder.</p>
"
1171,528830,-1,12,sql,"SQL sort by version ""number"", a string of varying length","<p>I'm trying to create an SQL query that will order the results by a version number (e.g. 1.1, 4.5.10, etc.)</p>

<p>Here's what I tried:</p>

<pre><code>SELECT * FROM Requirements 
    WHERE Requirements.Release NOT LIKE '%Obsolete%' 
    ORDER BY Requirements.ReqNum
</code></pre>

<p>Now, the ReqNum field is a string field and unfortunately I can't change it to a float or something like that because I have requirement numbers like <code>162.1.11</code>.</p>

<p>When I get the results back, I'll get ordering like this:</p>

<pre><code>1.1
1.10
1.11
1.3
</code></pre>

<p><strong>How can I write a query that will sort by lexicographic order?</strong> </p>

<p>... or,</p>

<p><strong>How can I correctly sort the data?</strong></p>

<p>Thanks for the input in advance!</p>
","<p>I would do as Joel Coehoorn said. Then to re-arrange your data structure you don't have to manually do it. You can write a simple script that will do the job for all 600 records.</p>
"
177,76350,12,12,sql,Free/cheap PowerDesigner alternative?,"<p>We are using PowerDesigner at work for database modelling. But there is a hell of a price tag on that piece of software. And frankly, all I use is physical diagrams for MS SQL, which is about 1% of what PD knows.</p>

<p>Are there any good alternatives? I know about Visio and MS SQL Diagrams, but looking for other options.</p>
","<p><a href=""http://www.sqlpower.ca/page/architect"">Power*Architect</a> is the way to go.  It's free, open source, and does a really great job helping you build your ERDs.  Plus, it works on Windows, Linux, and OSX.</p>
"
1172,528830,3,12,sql,"SQL sort by version ""number"", a string of varying length","<p>I'm trying to create an SQL query that will order the results by a version number (e.g. 1.1, 4.5.10, etc.)</p>

<p>Here's what I tried:</p>

<pre><code>SELECT * FROM Requirements 
    WHERE Requirements.Release NOT LIKE '%Obsolete%' 
    ORDER BY Requirements.ReqNum
</code></pre>

<p>Now, the ReqNum field is a string field and unfortunately I can't change it to a float or something like that because I have requirement numbers like <code>162.1.11</code>.</p>

<p>When I get the results back, I'll get ordering like this:</p>

<pre><code>1.1
1.10
1.11
1.3
</code></pre>

<p><strong>How can I write a query that will sort by lexicographic order?</strong> </p>

<p>... or,</p>

<p><strong>How can I correctly sort the data?</strong></p>

<p>Thanks for the input in advance!</p>
","<p>You could split up the string (you already know the delimiters: ""."") with CHARINDEX / SUBSTR and ORDER BY the different parts. Do it in a function or do it part by part.</p>

<p>It won't be pretty and it won't be fast: so if you need fast queries, follow Tony or Joel.</p>
"
463,202440,0,12,sql,How hard is it to incorporate full text search with SQL Server?,"<p>I am building a C#/ASP.NET app with an SQL backend. I am on deadline and finishing up my pages, out of left field one of my designers incorporated a full text search on one of my pages. My ""searches"" up until this point have been filters, being able to narrow a result set by certain factors and column values. </p>

<p>Being that I'm on deadline (you know 3 hours sleep a night, at the point where I am looking like something the cat ate and threw up), I was expecting this page to be very similar to be others and I'm trying to decide whether or not to make a stink. I have never done a full text search on a page before.... is this a mountain to climb or is there a simple solution?</p>

<p>thank you. </p>
","<p>""How hard is it"" is a tough question to answer. For example, someone who's already done it 10 times will probably reckon it's a snap. All I can really say is that you're likely to find it a lot easier if you use something like <a href=""http://sourceforge.net/projects/nlucene"" rel=""nofollow"">NLucene</a> rather than rolling your own.</p>
"
464,202440,2,12,sql,How hard is it to incorporate full text search with SQL Server?,"<p>I am building a C#/ASP.NET app with an SQL backend. I am on deadline and finishing up my pages, out of left field one of my designers incorporated a full text search on one of my pages. My ""searches"" up until this point have been filters, being able to narrow a result set by certain factors and column values. </p>

<p>Being that I'm on deadline (you know 3 hours sleep a night, at the point where I am looking like something the cat ate and threw up), I was expecting this page to be very similar to be others and I'm trying to decide whether or not to make a stink. I have never done a full text search on a page before.... is this a mountain to climb or is there a simple solution?</p>

<p>thank you. </p>
","<p>Full text search in SQL Server is really easy, a bit of configuration and a slight tweak on the queryside and you are good to go!  I have done it for clients in under 20 minutes before, being familiar with the process</p>

<p>Here is the <a href=""http://msdn.microsoft.com/en-us/library/ms142571.aspx"" rel=""nofollow"">2008 MSDN article</a>, links go out to the 2005 versions from there</p>
"
465,202440,27,12,sql,How hard is it to incorporate full text search with SQL Server?,"<p>I am building a C#/ASP.NET app with an SQL backend. I am on deadline and finishing up my pages, out of left field one of my designers incorporated a full text search on one of my pages. My ""searches"" up until this point have been filters, being able to narrow a result set by certain factors and column values. </p>

<p>Being that I'm on deadline (you know 3 hours sleep a night, at the point where I am looking like something the cat ate and threw up), I was expecting this page to be very similar to be others and I'm trying to decide whether or not to make a stink. I have never done a full text search on a page before.... is this a mountain to climb or is there a simple solution?</p>

<p>thank you. </p>
","<p>First off, you need to enabled Full text Searching indexing on the production servers, so if thats not in scope, your not going to want to go with this.</p>

<p>However, if that's already ready to go, full text searching is relatively simple.</p>

<p>T-SQL has 4 predicates used for full text search:</p>

<ul>
<li>FREETEXT</li>
<li>FREETEXTTABLE</li>
<li>CONTAINS</li>
<li>CONTAINSTABLE</li>
</ul>

<p>FREETEXT is the simplest, and can be done like this:</p>

<pre><code>SELECT UserName
FROM Tbl_Users
WHERE FREETEXT (UserName, 'bob' )

Results:

JimBob
Little Bobby Tables
</code></pre>

<p>FREETEXTTABLE works the same as FreeTEXT, except it returns the results as a table.</p>

<p>The real power of T-SQL's full text search comes from the CONTAINS (and CONTAINSTABLE) predicate...This one is huge, so I'll just paste its usage in:</p>

<pre><code>CONTAINS
    ( { column | * } , '&lt; contains_search_condition &gt;' 
    ) 

&lt; contains_search_condition &gt; ::= 
        { &lt; simple_term &gt; 
        | &lt; prefix_term &gt; 
        | &lt; generation_term &gt; 
        | &lt; proximity_term &gt; 
        | &lt; weighted_term &gt; 
        } 
        | { ( &lt; contains_search_condition &gt; ) 
        { AND | AND NOT | OR } &lt; contains_search_condition &gt; [ ...n ] 
        } 

&lt; simple_term &gt; ::= 
    word | "" phrase ""

&lt; prefix term &gt; ::= 
    { ""word * "" | ""phrase * "" }

&lt; generation_term &gt; ::= 
    FORMSOF ( INFLECTIONAL , &lt; simple_term &gt; [ ,...n ] ) 

&lt; proximity_term &gt; ::= 
    { &lt; simple_term &gt; | &lt; prefix_term &gt; } 
    { { NEAR | ~ } { &lt; simple_term &gt; | &lt; prefix_term &gt; } } [ ...n ] 

&lt; weighted_term &gt; ::= 
    ISABOUT 
        ( { { 
                &lt; simple_term &gt; 
                | &lt; prefix_term &gt; 
                | &lt; generation_term &gt; 
                | &lt; proximity_term &gt; 
                } 
            [ WEIGHT ( weight_value ) ] 
            } [ ,...n ] 
        )
</code></pre>

<p>This means you can write queries such as:</p>

<pre><code>SELECT UserName
FROM Tbl_Users
WHERE CONTAINS(UserName, '""little*"" NEAR tables')

Results:

Little Bobby Tables
</code></pre>

<p>Good luck :)</p>
"
466,202440,2,12,sql,How hard is it to incorporate full text search with SQL Server?,"<p>I am building a C#/ASP.NET app with an SQL backend. I am on deadline and finishing up my pages, out of left field one of my designers incorporated a full text search on one of my pages. My ""searches"" up until this point have been filters, being able to narrow a result set by certain factors and column values. </p>

<p>Being that I'm on deadline (you know 3 hours sleep a night, at the point where I am looking like something the cat ate and threw up), I was expecting this page to be very similar to be others and I'm trying to decide whether or not to make a stink. I have never done a full text search on a page before.... is this a mountain to climb or is there a simple solution?</p>

<p>thank you. </p>
","<p>I have used dtSearch before for adding full text searching to files and databases, and their stuff is pretty cheap and easy to use. </p>

<p>Short of adding all that and configuring SQL, This script will search through all columns in a database and tell you what columns contain the values you are looking for. I know its not the ""proper"" solution, but may buy you some time. </p>

<pre><code>/*This script will find any text value in the database*/
/*Output will be directed to the Messages window. Don't forget to look there!!!*/

SET NOCOUNT ON
DECLARE @valuetosearchfor varchar(128), @objectOwner varchar(64)
SET @valuetosearchfor = '%staff%' --should be formatted as a like search 
SET @objectOwner = 'dbo'

DECLARE @potentialcolumns TABLE (id int IDENTITY, sql varchar(4000))

INSERT INTO @potentialcolumns (sql)
SELECT 
    ('if exists (select 1 from [' +
    [tabs].[table_schema] + '].[' +
    [tabs].[table_name] + 
    '] (NOLOCK) where [' + 
    [cols].[column_name] + 
    '] like ''' + @valuetosearchfor + ''' ) print ''SELECT * FROM [' +
    [tabs].[table_schema] + '].[' +
    [tabs].[table_name] + 
    '] (NOLOCK) WHERE [' + 
    [cols].[column_name] + 
    '] LIKE ''''' + @valuetosearchfor + '''''' +
    '''') as 'sql'
FROM information_schema.columns cols
    INNER JOIN information_schema.tables tabs
    	ON cols.TABLE_CATALOG = tabs.TABLE_CATALOG
    		AND cols.TABLE_SCHEMA = tabs.TABLE_SCHEMA
    		AND cols.TABLE_NAME = tabs.TABLE_NAME
WHERE cols.data_type IN ('char', 'varchar', 'nvchar', 'nvarchar','text','ntext')
    AND	tabs.table_schema = @objectOwner
    AND tabs.TABLE_TYPE = 'BASE TABLE'
ORDER BY tabs.table_catalog, tabs.table_name, cols.ordinal_position

DECLARE @count int
SET @count = (SELECT MAX(id) FROM @potentialcolumns)
PRINT 'Found ' + CAST(@count as varchar) + ' potential columns.'
PRINT 'Beginning scan...'
PRINT ''
PRINT 'These columns contain the values being searched for...'
PRINT ''
DECLARE @iterator int, @sql varchar(4000)
SET @iterator = 1
WHILE @iterator &lt;= (SELECT Max(id) FROM @potentialcolumns)
BEGIN
    SET @sql = (SELECT [sql] FROM @potentialcolumns where [id] = @iterator)
    IF (@sql IS NOT NULL) and (RTRIM(LTRIM(@sql)) &lt;&gt; '')
    BEGIN
    	--SELECT @sql --use when checking sql output
    	EXEC (@sql)
    END
    SET @iterator = @iterator + 1
END

PRINT ''
PRINT 'Scan completed'
</code></pre>
"
467,202440,1,12,sql,How hard is it to incorporate full text search with SQL Server?,"<p>I am building a C#/ASP.NET app with an SQL backend. I am on deadline and finishing up my pages, out of left field one of my designers incorporated a full text search on one of my pages. My ""searches"" up until this point have been filters, being able to narrow a result set by certain factors and column values. </p>

<p>Being that I'm on deadline (you know 3 hours sleep a night, at the point where I am looking like something the cat ate and threw up), I was expecting this page to be very similar to be others and I'm trying to decide whether or not to make a stink. I have never done a full text search on a page before.... is this a mountain to climb or is there a simple solution?</p>

<p>thank you. </p>
","<p>I've been there. It works like a charm until you start to consider scalability and advanced search functionalities like search over multiple columns with giving each one different weight values.</p>

<p>For example, the only way to search over <strong>Title</strong> and <strong>Summary</strong> columns is to have a computed column with <code>SearchColumn = CONCAT(Title, Summary)</code> and index over <code>SearchColumn</code>. Weighting? <code>SearchColumn = CONCAT(CONCAT(Title,Title), Summary)</code> something like that. ;) Filtering? Forget about it.</p>
"
1175,528830,1,12,sql,"SQL sort by version ""number"", a string of varying length","<p>I'm trying to create an SQL query that will order the results by a version number (e.g. 1.1, 4.5.10, etc.)</p>

<p>Here's what I tried:</p>

<pre><code>SELECT * FROM Requirements 
    WHERE Requirements.Release NOT LIKE '%Obsolete%' 
    ORDER BY Requirements.ReqNum
</code></pre>

<p>Now, the ReqNum field is a string field and unfortunately I can't change it to a float or something like that because I have requirement numbers like <code>162.1.11</code>.</p>

<p>When I get the results back, I'll get ordering like this:</p>

<pre><code>1.1
1.10
1.11
1.3
</code></pre>

<p><strong>How can I write a query that will sort by lexicographic order?</strong> </p>

<p>... or,</p>

<p><strong>How can I correctly sort the data?</strong></p>

<p>Thanks for the input in advance!</p>
","<p>This would work if you're using Microsoft SQL Server:</p>

<pre><code>create function fnGetVersion (@v AS varchar(50)) returns bigint as
begin
declare @n as bigint;
declare @i as int;
select @n = 0;
select @i = charindex('.',@v);
while(@i &gt; 0)
begin
    select @n = @n * 1000;
    select @n = @n + cast(substring(@v,1,@i-1) as bigint); 
    select @v = substring(@v,@i+1,len(@v)-@i);
    select @i = charindex('.',@v);
end
return @n * 1000 + cast(@v as bigint);
end
</code></pre>

<p>Test by running this command:</p>

<pre><code>select dbo.fnGetVersion('1.2.3.4')
</code></pre>

<p>That would return the number 1002003004 wich is perfectly sortable.  Is you need 9.0.1 to be bigger than 2.1.2.3 then you would need to change the logic slightly.  In my example 9.0.1 would be sorted before 2.1.2.3.</p>
"
1170,528830,3,12,sql,"SQL sort by version ""number"", a string of varying length","<p>I'm trying to create an SQL query that will order the results by a version number (e.g. 1.1, 4.5.10, etc.)</p>

<p>Here's what I tried:</p>

<pre><code>SELECT * FROM Requirements 
    WHERE Requirements.Release NOT LIKE '%Obsolete%' 
    ORDER BY Requirements.ReqNum
</code></pre>

<p>Now, the ReqNum field is a string field and unfortunately I can't change it to a float or something like that because I have requirement numbers like <code>162.1.11</code>.</p>

<p>When I get the results back, I'll get ordering like this:</p>

<pre><code>1.1
1.10
1.11
1.3
</code></pre>

<p><strong>How can I write a query that will sort by lexicographic order?</strong> </p>

<p>... or,</p>

<p><strong>How can I correctly sort the data?</strong></p>

<p>Thanks for the input in advance!</p>
","<p>If you don't re-design the table as Joel Coehoorn sensibly suggests, then you need to re-format the version numbers to a string that sorts as you require, e.g.</p>

<ul>
<li>1.1 -> 0001.0001.0000</li>
<li>162.1.11 -> 0162.0001.0011</li>
</ul>

<p>This could be done by a function, or using a computed/virtual column if your DBMS has these.  Then you can use that function or column in the ORDER BY clause.</p>
"
1169,528830,22,12,sql,"SQL sort by version ""number"", a string of varying length","<p>I'm trying to create an SQL query that will order the results by a version number (e.g. 1.1, 4.5.10, etc.)</p>

<p>Here's what I tried:</p>

<pre><code>SELECT * FROM Requirements 
    WHERE Requirements.Release NOT LIKE '%Obsolete%' 
    ORDER BY Requirements.ReqNum
</code></pre>

<p>Now, the ReqNum field is a string field and unfortunately I can't change it to a float or something like that because I have requirement numbers like <code>162.1.11</code>.</p>

<p>When I get the results back, I'll get ordering like this:</p>

<pre><code>1.1
1.10
1.11
1.3
</code></pre>

<p><strong>How can I write a query that will sort by lexicographic order?</strong> </p>

<p>... or,</p>

<p><strong>How can I correctly sort the data?</strong></p>

<p>Thanks for the input in advance!</p>
","<p>For best results, refactor version number storage so that each section has it's own column: MajorVersion, MinorVersion, Revision, Build.  Then the ordering problem suddenly becomes trivial.  You can also build a computed column for easy retrieval of the full string.</p>
"
1081,495700,5,12,sql,Can we write a sub function or procedure inside another stored procedure - SQL Server,"<p>I want to check if SQL Server(2000/05/08) has the ability to write a nested stored procedure, what I meant is - WRITING a Sub Function/procedure inside another stored procedure. NOT calling another SP. </p>

<p>Why I was thinking about it is- One of my SP is having a repeated lines of code and that is specific to only this SP.So if we have this nested SP feature then I can declare another sub/local procedure inside my main SP and put all the repeating lines in that. and I can call that local sp in my main SP. I remember such feature is available in Oracle SPs.</p>

<p>If SQL server is also having this feature, can someone please explain some more details about it or provide a link where I can find documentation.</p>

<p>Thanks in advance
Sai</p>
","<p>It does not have that feature. It is hard to see what real benefit such a feature would provide, apart from stopping the code in the nested SPROC from being called from elsewhere.</p>
"
1173,528830,0,12,sql,"SQL sort by version ""number"", a string of varying length","<p>I'm trying to create an SQL query that will order the results by a version number (e.g. 1.1, 4.5.10, etc.)</p>

<p>Here's what I tried:</p>

<pre><code>SELECT * FROM Requirements 
    WHERE Requirements.Release NOT LIKE '%Obsolete%' 
    ORDER BY Requirements.ReqNum
</code></pre>

<p>Now, the ReqNum field is a string field and unfortunately I can't change it to a float or something like that because I have requirement numbers like <code>162.1.11</code>.</p>

<p>When I get the results back, I'll get ordering like this:</p>

<pre><code>1.1
1.10
1.11
1.3
</code></pre>

<p><strong>How can I write a query that will sort by lexicographic order?</strong> </p>

<p>... or,</p>

<p><strong>How can I correctly sort the data?</strong></p>

<p>Thanks for the input in advance!</p>
","<p>I've had the same problem, though mine was with apartment numbers like A1, A2, A3, A10, A11, etc, that they wanted to sort ""right"".  If splitting up the version number into separate columns doesn't work, try this PL/SQL.  It takes a string like A1 or A10and expands it into A0000001, A0000010, etc, so it sorts nicely.  Just call this in ORDER BY clause, like</p>

<p>select apt_num
from apartment
order by PAD(apt_num)</p>

<pre><code>function pad(inString IN VARCHAR2)
   return VARCHAR2

--This function pads the numbers in a alphanumeric string.
--It is particularly useful in sorting, things like ""A1, A2, A10""
--which would sort like ""A1, A10, A2"" in a standard ""ORDER BY name"" clause
--but by calling ""ORDER BY pkg_sort.pad(name)"" it will sort as ""A1, A2, A10"" because this
--function will convert it to ""A00000000000000000001, A00000000000000000002, A00000000000000000010"" 
--(but since this is in the order by clause, it will
--not be displayed.

--currently, the charTemplate variable pads the number to 20 digits, so anything up to 99999999999999999999 
--will work correctly.
--to increase the size, just change the charTemplate variable.  If the number is larger than 20 digits, it will just
--appear without padding.


   is
      outString VARCHAR2(255);
      numBeginIndex NUMBER;
      numLength NUMBER;
      stringLength NUMBER;
      i NUMBER;
      thisChar VARCHAR2(6);
      charTemplate VARCHAR2(20) := '00000000000000000000';
      charTemplateLength NUMBER := 20;


   BEGIN
      outString := null;
      numBeginIndex := -1;
      numLength := 0;
      stringLength := length(inString);

      --loop through each character, get that character
      FOR i IN 1..(stringLength) LOOP
         thisChar := substr(inString, i, 1);

         --if this character is a number
         IF (FcnIsNumber(thisChar)) THEN

            --if we haven't started a number yet
            IF (numBeginIndex = -1) THEN
               numBeginIndex := i;
               numLength := 1;

            --else if we're in a number, increase the length
            ELSE 
               numLength := numLength + 1;
            END IF;

            --if this is the last character, we have to append the number
            IF (i = stringLength) THEN
               outString:= FcnConcatNumber(inString, outString, numBeginIndex, numLength, charTemplate, charTemplateLength);
            END IF;

         --else this is a character
         ELSE

            --if we were previously in a number, concat that and reset the numBeginIndex
            IF (numBeginIndex != -1) THEN
               outString:= FcnConcatNumber(inString, outString, numBeginIndex, numLength, charTemplate, charTemplateLength);
               numBeginIndex := -1;
               numLength := 0;
            END IF;

            --concat the character
            outString := outString || thisChar;
         END IF;
      END LOOP;

      RETURN outString;

   --any exception, just return the original string
   EXCEPTION WHEN OTHERS THEN
      RETURN inString;

   END;
</code></pre>
"
1082,495700,2,12,sql,Can we write a sub function or procedure inside another stored procedure - SQL Server,"<p>I want to check if SQL Server(2000/05/08) has the ability to write a nested stored procedure, what I meant is - WRITING a Sub Function/procedure inside another stored procedure. NOT calling another SP. </p>

<p>Why I was thinking about it is- One of my SP is having a repeated lines of code and that is specific to only this SP.So if we have this nested SP feature then I can declare another sub/local procedure inside my main SP and put all the repeating lines in that. and I can call that local sp in my main SP. I remember such feature is available in Oracle SPs.</p>

<p>If SQL server is also having this feature, can someone please explain some more details about it or provide a link where I can find documentation.</p>

<p>Thanks in advance
Sai</p>
","<p>I don't recommend doing this as each time it is created a new execution plan must be calculated, but YES, it definitely can be done (Everything is possible, but not always recommended).</p>

<p>Here is an example:</p>

<pre><code>CREATE PROC [dbo].[sp_helloworld]
AS
BEGIN
    SELECT 'Hello World'
    DECLARE @sSQL VARCHAR(1000)
    SET @sSQL = 'CREATE PROC [dbo].[sp_helloworld2]
    		AS
    		BEGIN
    			SELECT ''Hello World 2''
    		END'
    EXEC (@sSQL)

    EXEC [sp_helloworld2];
    DROP PROC [sp_helloworld2];
END
</code></pre>

<p>You will get the warning</p>

<pre><code>The module 'sp_helloworld' depends on the missing object 'sp_helloworld2'.
The module will still be created; however, it cannot run successfully until
the object exists.
</code></pre>

<p>You can bypass this warning by using EXEC('sp_helloworld2') above.</p>

<p>But if you call EXEC [sp_helloworld] you will get the results</p>

<pre><code>Hello World
Hello World 2
</code></pre>
"
173,76350,1,12,sql,Free/cheap PowerDesigner alternative?,"<p>We are using PowerDesigner at work for database modelling. But there is a hell of a price tag on that piece of software. And frankly, all I use is physical diagrams for MS SQL, which is about 1% of what PD knows.</p>

<p>Are there any good alternatives? I know about Visio and MS SQL Diagrams, but looking for other options.</p>
","<p>I just use SQL Server using the diagrams folder. The designer is pretty simple to use, and can be used to generate tables fairly quickly. Considering it's free with the software, I don't see the issue.</p>
"
1179,528830,2,12,sql,"SQL sort by version ""number"", a string of varying length","<p>I'm trying to create an SQL query that will order the results by a version number (e.g. 1.1, 4.5.10, etc.)</p>

<p>Here's what I tried:</p>

<pre><code>SELECT * FROM Requirements 
    WHERE Requirements.Release NOT LIKE '%Obsolete%' 
    ORDER BY Requirements.ReqNum
</code></pre>

<p>Now, the ReqNum field is a string field and unfortunately I can't change it to a float or something like that because I have requirement numbers like <code>162.1.11</code>.</p>

<p>When I get the results back, I'll get ordering like this:</p>

<pre><code>1.1
1.10
1.11
1.3
</code></pre>

<p><strong>How can I write a query that will sort by lexicographic order?</strong> </p>

<p>... or,</p>

<p><strong>How can I correctly sort the data?</strong></p>

<p>Thanks for the input in advance!</p>
","<p>If you are in SQL Server land...</p>

<pre><code>DECLARE @string varchar(40)
SET @string = '1.2.3.4'
SELECT PARSENAME(@string, 1), PARSENAME(@string, 2), PARSENAME(@string, 3), PARSENAME(@string, 4)
</code></pre>

<p>Results:
4, 3, 2, 1</p>

<p>Useful for parsing IP Addresses and other dotted items, such as a version number.  (You can use REPLACE() to convert items into dotted notation too... e.g. 1-2-3-4 -> 1.2.3.4)</p>
"
1178,528830,0,12,sql,"SQL sort by version ""number"", a string of varying length","<p>I'm trying to create an SQL query that will order the results by a version number (e.g. 1.1, 4.5.10, etc.)</p>

<p>Here's what I tried:</p>

<pre><code>SELECT * FROM Requirements 
    WHERE Requirements.Release NOT LIKE '%Obsolete%' 
    ORDER BY Requirements.ReqNum
</code></pre>

<p>Now, the ReqNum field is a string field and unfortunately I can't change it to a float or something like that because I have requirement numbers like <code>162.1.11</code>.</p>

<p>When I get the results back, I'll get ordering like this:</p>

<pre><code>1.1
1.10
1.11
1.3
</code></pre>

<p><strong>How can I write a query that will sort by lexicographic order?</strong> </p>

<p>... or,</p>

<p><strong>How can I correctly sort the data?</strong></p>

<p>Thanks for the input in advance!</p>
","<p>For the all-in-one-query purists, assuming Oracle, some instr/substr/decode/to_number voodoo can solve it:</p>

<pre><code>SELECT *
FROM Requirements
WHERE Release NOT LIKE '%Obsolete%'
ORDER BY
    to_number(
      substr( reqnum, 1, instr( reqnum, '.' ) - 1 )
    )
  , to_number(
      substr( 
          reqnum
        , instr( reqnum, '.' ) + 1 -- start: after first occurance
        , decode( 
              instr( reqnum, '.', 1, 2 )
            , 0, length( reqnum )
            , instr( reqnum, '.', 1, 2 ) - 1 
          ) -- second occurance (or end)
          - instr( reqnum, '.', 1, 1) -- length: second occurance (or end) less first
      )
    )
  , to_number(
      decode( 
          instr( reqnum, '.', 1, 2 )
        , 0, null
        , substr( 
              reqnum
            , instr( reqnum, '.', 1, 2 ) + 1 -- start: after second occurance
            , decode( 
                  instr( reqnum, '.', 1, 3 )
                , 0, length( reqnum )
                , instr( reqnum, '.', 1, 3 ) - 1 
              ) -- third occurance (or end)
              - instr( reqnum, '.', 1, 2) -- length: third occurance (or end) less second
          ) 
      )
    )
  , to_number(
      decode( 
          instr( reqnum, '.', 1, 3 )
        , 0, null
        , substr( 
              reqnum
            , instr( reqnum, '.', 1, 3 ) + 1 -- start: after second occurance
            , decode( 
                  instr( reqnum, '.', 1, 4 )
                , 0, length( reqnum )
                , instr( reqnum, '.', 1, 4 ) - 1 
              ) -- fourth occurance (or end)
              - instr( reqnum, '.', 1, 3) -- length: fourth occurance (or end) less third
          ) 
      )
    )
;
</code></pre>

<p>I suspect there are plenty of caveats including:</p>

<ul>
<li>assumption of the presence of minor version (second)</li>
<li>limited to four versions as specified in question's comments</li>
</ul>
"
1083,495700,1,12,sql,Can we write a sub function or procedure inside another stored procedure - SQL Server,"<p>I want to check if SQL Server(2000/05/08) has the ability to write a nested stored procedure, what I meant is - WRITING a Sub Function/procedure inside another stored procedure. NOT calling another SP. </p>

<p>Why I was thinking about it is- One of my SP is having a repeated lines of code and that is specific to only this SP.So if we have this nested SP feature then I can declare another sub/local procedure inside my main SP and put all the repeating lines in that. and I can call that local sp in my main SP. I remember such feature is available in Oracle SPs.</p>

<p>If SQL server is also having this feature, can someone please explain some more details about it or provide a link where I can find documentation.</p>

<p>Thanks in advance
Sai</p>
","<p>I agree with andynormancx that there doesn't seem to be much point in doing this.</p>

<p>If you really want the shared code to be contained inside the SP then you could probably cobble something together with <a href=""http://msdn.microsoft.com/en-us/library/ms180188.aspx"" rel=""nofollow"">GOTO</a> or dynamic SQL, but doing it properly with a separate SP or UDF would be better in almost every way.</p>
"
1176,528830,0,12,sql,"SQL sort by version ""number"", a string of varying length","<p>I'm trying to create an SQL query that will order the results by a version number (e.g. 1.1, 4.5.10, etc.)</p>

<p>Here's what I tried:</p>

<pre><code>SELECT * FROM Requirements 
    WHERE Requirements.Release NOT LIKE '%Obsolete%' 
    ORDER BY Requirements.ReqNum
</code></pre>

<p>Now, the ReqNum field is a string field and unfortunately I can't change it to a float or something like that because I have requirement numbers like <code>162.1.11</code>.</p>

<p>When I get the results back, I'll get ordering like this:</p>

<pre><code>1.1
1.10
1.11
1.3
</code></pre>

<p><strong>How can I write a query that will sort by lexicographic order?</strong> </p>

<p>... or,</p>

<p><strong>How can I correctly sort the data?</strong></p>

<p>Thanks for the input in advance!</p>
","<p>Ok, if high performance is an issue then your only option is to change your values into something numeric.</p>

<p>However, if this is a low usage query then you can just split your numbers and order by those.</p>

<p>This query assumes just major and minor version numbers and that they contain just numbers.</p>

<pre><code>SELECT
    *
FROM
    Requirements
WHERE
    Requirements.Release NOT LIKE '%Obsolete%'
ORDER BY
    CONVERT(int, RIGHT(REPLICATE('0', 10) + LEFT(Requirements.ReqNum, CHARINDEX('.', Requirements.ReqNum)-1), 10)),
    CONVERT(int, SUBSTRING(Requirements.ReqNum, CHARINDEX('.', Requirements.ReqNum )+1, LEN(Requirements.ReqNum) - CHARINDEX('.', Requirements.ReqNum )))
</code></pre>
"
1174,528830,0,12,sql,"SQL sort by version ""number"", a string of varying length","<p>I'm trying to create an SQL query that will order the results by a version number (e.g. 1.1, 4.5.10, etc.)</p>

<p>Here's what I tried:</p>

<pre><code>SELECT * FROM Requirements 
    WHERE Requirements.Release NOT LIKE '%Obsolete%' 
    ORDER BY Requirements.ReqNum
</code></pre>

<p>Now, the ReqNum field is a string field and unfortunately I can't change it to a float or something like that because I have requirement numbers like <code>162.1.11</code>.</p>

<p>When I get the results back, I'll get ordering like this:</p>

<pre><code>1.1
1.10
1.11
1.3
</code></pre>

<p><strong>How can I write a query that will sort by lexicographic order?</strong> </p>

<p>... or,</p>

<p><strong>How can I correctly sort the data?</strong></p>

<p>Thanks for the input in advance!</p>
","<p>Here is an example query that extracts the string.  You should be able to use this in either the UPDATE refactoring of the database, or simply in your query as-is.  However, I'm not sure how it is on time; just something to watch out and test for.</p>

<pre><code>SELECT SUBSTRING_INDEX(""1.5.32"",'.',1) AS MajorVersion,
  SUBSTRING_INDEX(SUBSTRING_INDEX(""1.5.32"",'.',-2),'.',1) AS MinorVersion,
  SUBSTRING_INDEX(""1.5.32"",'.',-1) AS Revision;
</code></pre>

<p>this will return:</p>

<pre><code>MajorVersion | MinorVersion | Revision
1            | 5            | 32
</code></pre>
"
1177,528830,2,12,sql,"SQL sort by version ""number"", a string of varying length","<p>I'm trying to create an SQL query that will order the results by a version number (e.g. 1.1, 4.5.10, etc.)</p>

<p>Here's what I tried:</p>

<pre><code>SELECT * FROM Requirements 
    WHERE Requirements.Release NOT LIKE '%Obsolete%' 
    ORDER BY Requirements.ReqNum
</code></pre>

<p>Now, the ReqNum field is a string field and unfortunately I can't change it to a float or something like that because I have requirement numbers like <code>162.1.11</code>.</p>

<p>When I get the results back, I'll get ordering like this:</p>

<pre><code>1.1
1.10
1.11
1.3
</code></pre>

<p><strong>How can I write a query that will sort by lexicographic order?</strong> </p>

<p>... or,</p>

<p><strong>How can I correctly sort the data?</strong></p>

<p>Thanks for the input in advance!</p>
","<p>The following function will take a version number and format each level out to 3 digits:</p>

<p>Usage:</p>

<pre><code>select * from TableX order by dbo.fn_VersionPad(VersionCol1)
</code></pre>

<p>Function:</p>

<pre><code>CREATE FUNCTION [dbo].[fn_VersionPad]
(
    @version varchar(20)
)
RETURNS varchar(20)
AS
BEGIN
    /*
        Purpose:  Pads multi-level Version Number sections to 3 digits
        Example:  1.2.3.4
        Returns:  001.002.003.004
    */

    declare @verPad varchar(20)
    declare @i int
    declare @digits int

    set @verPad = ''

    set @i = len(@version)
    set @digits = 0

    while @i &gt; 0
    begin
        if (substring(@version, @i, 1) = '.')
        begin
            while (@digits &lt; 3)
            begin
                -- Pad version level to 3 digits
                set @verPad = '0' + @verPad
                set @digits = @digits + 1
            end

            set @digits = -1
        end

        set @verPad = substring(@version, @i, 1) + @verPad

        set @i = @i - 1
        set @digits = @digits + 1
    end

    while (@digits &lt; 3)
    begin
        -- Pad version level to 3 digits
        set @verPad = '0' + @verPad
        set @digits = @digits + 1
    end

    return @verPad
END
</code></pre>
"
174,76350,0,12,sql,Free/cheap PowerDesigner alternative?,"<p>We are using PowerDesigner at work for database modelling. But there is a hell of a price tag on that piece of software. And frankly, all I use is physical diagrams for MS SQL, which is about 1% of what PD knows.</p>

<p>Are there any good alternatives? I know about Visio and MS SQL Diagrams, but looking for other options.</p>
","<p>You might want to look at https://www.xcase.com/demo.php. It's not free, but it's quite a bit cheaper than PowerDesigner, as far as I can tell. I've used earlier versions, but lately I've had easy access to Visio, so have continued with that instead of investing in xCase.</p>
"
175,76350,0,12,sql,Free/cheap PowerDesigner alternative?,"<p>We are using PowerDesigner at work for database modelling. But there is a hell of a price tag on that piece of software. And frankly, all I use is physical diagrams for MS SQL, which is about 1% of what PD knows.</p>

<p>Are there any good alternatives? I know about Visio and MS SQL Diagrams, but looking for other options.</p>
","<p>The version of Visio that comes with VS Enterprise Architect has a forward-engineer feature that will generate SQL.  There is also a type library for the modelling engine, but (on older versions at least) it won't extract certain items such as comments.  However, the generated SQL has the comments in a fairly simple structure that does facilitate parsing the generated SQL.</p>

<p>You can get older versions of VS enterprise architect on E-bay for not very much money (I think mine cost about 250).</p>

<p>One caveat for reverse-engineers is that all pre-VS2005 visio DB modelling engines will not play nicely with the SQL Server 2005 native client.  You need to either script out the database and re-load it on a SQL2000 server (dealing with SQL2005 specific features such as schemas is left as an exercise for the reader) or get a more recent version.</p>
"
1086,495700,3,12,sql,Can we write a sub function or procedure inside another stored procedure - SQL Server,"<p>I want to check if SQL Server(2000/05/08) has the ability to write a nested stored procedure, what I meant is - WRITING a Sub Function/procedure inside another stored procedure. NOT calling another SP. </p>

<p>Why I was thinking about it is- One of my SP is having a repeated lines of code and that is specific to only this SP.So if we have this nested SP feature then I can declare another sub/local procedure inside my main SP and put all the repeating lines in that. and I can call that local sp in my main SP. I remember such feature is available in Oracle SPs.</p>

<p>If SQL server is also having this feature, can someone please explain some more details about it or provide a link where I can find documentation.</p>

<p>Thanks in advance
Sai</p>
","<p>Oracle's PL/SQL is something of a special case, being a language heavily based on Ada, rather than simple DML with some procedural constructs bolted on. Whether or not you think this is a good idea probably depends on your appetite for procedural code in your DBMS and your liking for learning complex new languages.</p>

<p>The idea of a subroutine, to reduce duplication or otherwise, is largely foreign to other database platforms in my experience (Oracle, MS SQL, Sybase, MySQL, SQLite in the main).</p>

<p>While the SQL-building proc would work, I think John's right in suggesting that you don't use his otherwise-correct answer!</p>

<p>You don't say what form your repeated lines take, so I'll offer three potential alternatives, starting with the simplest:</p>

<ol>
<li><p>Do nothing. Accept that procedural
SQL is a primitive language lacking
so many ""essential"" constructs that
you wouldn't use it at all if it
wasn't the only option.</p></li>
<li><p>Move your procedural operations outside of the DBMS and execute them in code written in a more sophisticated language. Consider ways in which your architecture could be adjusted to extract business logic from your data storage platform (hey, why not redesign the whole thing!)</p></li>
<li><p>If the repetition is happening in DML, SELECTs in particular, consider introducing views to slim down the queries.</p></li>
<li><p>Write code to generate, as part of your build process, the stored procedures. That way if the repeated lines ever need to change, you can change them in one place and automatically generate the repetition.</p></li>
</ol>

<p>That's <a href=""http://people.csail.mit.edu/paulfitz/spanish/script.html"" rel=""nofollow"">four</a>. I thought of another one as I was typing; consider it a bonus.</p>
"
1085,495700,0,12,sql,Can we write a sub function or procedure inside another stored procedure - SQL Server,"<p>I want to check if SQL Server(2000/05/08) has the ability to write a nested stored procedure, what I meant is - WRITING a Sub Function/procedure inside another stored procedure. NOT calling another SP. </p>

<p>Why I was thinking about it is- One of my SP is having a repeated lines of code and that is specific to only this SP.So if we have this nested SP feature then I can declare another sub/local procedure inside my main SP and put all the repeating lines in that. and I can call that local sp in my main SP. I remember such feature is available in Oracle SPs.</p>

<p>If SQL server is also having this feature, can someone please explain some more details about it or provide a link where I can find documentation.</p>

<p>Thanks in advance
Sai</p>
","<p>Thank you all for your replies!
I'm better off then creating one more SP with the repeating code and call that, which is the best way interms of performance and look wise.</p>
"
1084,495700,1,12,sql,Can we write a sub function or procedure inside another stored procedure - SQL Server,"<p>I want to check if SQL Server(2000/05/08) has the ability to write a nested stored procedure, what I meant is - WRITING a Sub Function/procedure inside another stored procedure. NOT calling another SP. </p>

<p>Why I was thinking about it is- One of my SP is having a repeated lines of code and that is specific to only this SP.So if we have this nested SP feature then I can declare another sub/local procedure inside my main SP and put all the repeating lines in that. and I can call that local sp in my main SP. I remember such feature is available in Oracle SPs.</p>

<p>If SQL server is also having this feature, can someone please explain some more details about it or provide a link where I can find documentation.</p>

<p>Thanks in advance
Sai</p>
","<p>John's sp_helloworld does work, but here's the reason why you don't see this done more often.</p>

<p>There is a very large performance impact when a stored procedure is compiled.  There's a Microsoft article on troubleshooting performance problems caused by a large number of recompiles, because this really slows your system down quite a bit:</p>

<p><a href=""http://support.microsoft.com/kb/243586"" rel=""nofollow"">http://support.microsoft.com/kb/243586</a></p>

<p>Instead of creating the stored procedure, you're better off just creating a string variable with the T-SQL you want to call, and then repeatedly executing that string variable.</p>

<p>Don't get me wrong - that's a pretty bad performance idea too, but it's better than creating stored procedures on the fly.  If you can persist this code in a permanent stored procedure or function and eliminate the recompile delays, SQL Server can build a single execution plan for the code once and then reuse that plan very quickly.</p>
"
911,418960,3,11,sql,Managing and debugging SQL queries in MS Access,"<p>MS Access has limited capabilities to manage raw SQL queries: the editor is quite bad, no syntax highlighting, it reformats your raw SQL into a long string and you can't insert comments.</p>

<p>Debugging complex SQL queries is a pain as well: either you have to split it into many smaller queries that become difficult to manage when your schema changes or you end-up with a giant query that is a nightmare to debug and update.</p>

<p>How do you manage your complex SQL queries in MS Access and how do you debug them?</p>

<p><strong>Edit</strong><br />
At the moment, I'm mostly just using <a href=""http://notepad-plus.sourceforge.net/uk/site.htm"">Notepad++</a> for some syntax colouring and <a href=""http://www.wangz.net/"">SQL Pretty Printer</a> for reformatting sensibly the raw SQL from Access.<br />
Using an external repository is useful but keeping there's always the risk of getting the two versions out of sync and you still have to remove comments before trying the query in Access...</p>
","<p>If you're doing really complex queries in MS Access, I would consider keeping a repository of those queries somewhere outside of the Access database itself... for instance, in a .sql file that you can then edit in an editor like Intype that will provide syntax highlighting.  It'll require you to update queries in both places, but you may end up finding it handy to have an ""official"" spot for it that is formatted and highlighted correctly.</p>

<p>Or, if at all possible, switch to SQL Server 2005 Express Edition, which is also free and will provide you the features you desire through the SQL Management Studio (also free).</p>
"
912,418960,1,11,sql,Managing and debugging SQL queries in MS Access,"<p>MS Access has limited capabilities to manage raw SQL queries: the editor is quite bad, no syntax highlighting, it reformats your raw SQL into a long string and you can't insert comments.</p>

<p>Debugging complex SQL queries is a pain as well: either you have to split it into many smaller queries that become difficult to manage when your schema changes or you end-up with a giant query that is a nightmare to debug and update.</p>

<p>How do you manage your complex SQL queries in MS Access and how do you debug them?</p>

<p><strong>Edit</strong><br />
At the moment, I'm mostly just using <a href=""http://notepad-plus.sourceforge.net/uk/site.htm"">Notepad++</a> for some syntax colouring and <a href=""http://www.wangz.net/"">SQL Pretty Printer</a> for reformatting sensibly the raw SQL from Access.<br />
Using an external repository is useful but keeping there's always the risk of getting the two versions out of sync and you still have to remove comments before trying the query in Access...</p>
","<p>Similar to <strong>recursive,</strong> I use an external editor to write my queries. I use Notepad++ with the Light Explorer extension for maintaining several scripts at a time, and Notepad2 for one-off scripts. (I'm kind of partial to Scintilla-based editors.)</p>

<p>Another option is to use the free SQL Server Management Studio Express, which comes with SQL Server Express. <em>(EDIT: Sorry, <strong>EdgarVerona</strong>, I didn't notice you mentioned this already!)</em> I normally use it to write SQL queries instead of using Access, because I typically use ODBC to link to a SQL Server back end anyway. Beware that the differences in the syntax of T-SQL, used by SQL Server, and Jet SQL, used by Access MDB's, are sometimes substantial.</p>
"
913,418960,3,11,sql,Managing and debugging SQL queries in MS Access,"<p>MS Access has limited capabilities to manage raw SQL queries: the editor is quite bad, no syntax highlighting, it reformats your raw SQL into a long string and you can't insert comments.</p>

<p>Debugging complex SQL queries is a pain as well: either you have to split it into many smaller queries that become difficult to manage when your schema changes or you end-up with a giant query that is a nightmare to debug and update.</p>

<p>How do you manage your complex SQL queries in MS Access and how do you debug them?</p>

<p><strong>Edit</strong><br />
At the moment, I'm mostly just using <a href=""http://notepad-plus.sourceforge.net/uk/site.htm"">Notepad++</a> for some syntax colouring and <a href=""http://www.wangz.net/"">SQL Pretty Printer</a> for reformatting sensibly the raw SQL from Access.<br />
Using an external repository is useful but keeping there's always the risk of getting the two versions out of sync and you still have to remove comments before trying the query in Access...</p>
","<p>Debugging is more of a challenge. If a single column is off, that's usually pretty easy to fix. But I'm assuming you have more complex debugging tasks that you need to perform.</p>

<p>When flummoxed, I typically start debugging with the <code>FROM</code> clause. I trace back to all the tables and sub-queries that comprise the larger query, and make sure that the joins are properly defined.</p>

<p>Then I check my <code>WHERE</code> clause. I run lots of simple queries on the tables, and on the sub-queries that I've already checked or that I already trust, and make sure that when I run the larger query, I'm getting what I expect with the <code>WHERE</code> conditions in place. I double-check the <code>JOIN</code> conditions at the same time.</p>

<p>I double-check my column definitions to make sure I'm retrieving what I really want to see, especially if the formulas involved are complicated. If you have something complicated like a coordinated subquery in a column definition</p>

<p>Then I check to see if I'm grouping data properly, making sure that ""<code>DISTINCT</code>""'s and ""<code>UNION</code>""'s without <code>UNION ALL</code> don't remove necessary duplicates.</p>

<p>I don't think I've ever encountered a SQL query that couldn't be broken down this way. I'm not always as methodical as this, but it's a good way to start breaking down a real stumper.</p>

<p><hr /></p>

<p>One thing I could recommend when you write your queries is this: <strong>Never use <code>SELECT *</code> in production code.</strong> Selecting all columns this way is a maintenance nightmare, and it leads to big problems when your underlying schemas change. You should always write out each and every column if you're writing SQL code that you'll be maintaining in the future. I saved myself a lot of time and worry just by getting rid of ""<code>SELECT *</code>""'s in my projects.</p>

<p>The downside to this is that those extra columns won't appear automatically in queries that refer to ""<code>SELECT *</code>"" queries. But you should be aware of how your queries are related to each other, anyway, and if you need the extra columns, you can go back and add them.</p>

<p><hr /></p>

<p>There is some hassle involved in maintaining a code repository, but if you have versioning software, the hassle is more than worth it. I've heard of ways of versioning SQL code written in Access databases, but unfortunately, I've never used them.</p>
"
914,418960,1,11,sql,Managing and debugging SQL queries in MS Access,"<p>MS Access has limited capabilities to manage raw SQL queries: the editor is quite bad, no syntax highlighting, it reformats your raw SQL into a long string and you can't insert comments.</p>

<p>Debugging complex SQL queries is a pain as well: either you have to split it into many smaller queries that become difficult to manage when your schema changes or you end-up with a giant query that is a nightmare to debug and update.</p>

<p>How do you manage your complex SQL queries in MS Access and how do you debug them?</p>

<p><strong>Edit</strong><br />
At the moment, I'm mostly just using <a href=""http://notepad-plus.sourceforge.net/uk/site.htm"">Notepad++</a> for some syntax colouring and <a href=""http://www.wangz.net/"">SQL Pretty Printer</a> for reformatting sensibly the raw SQL from Access.<br />
Using an external repository is useful but keeping there's always the risk of getting the two versions out of sync and you still have to remove comments before trying the query in Access...</p>
","<p>Are you talking here about what MS-Access calls 'queries' and SQL call 'views' or about the 'MS-Access pass-through' queries which are SQL queries? Someone could get easily lost! My solution is the following</p>

<ol>
<li>free SQL Server Management
Studio Express, where I will
elaborate and test my queries</li>
<li>a query table on the client
side, with one field for the query
name (<code>id_Query</code>) and another one
(<code>queryText</code>, memo type) for the
query itself.</li>
</ol>

<p>I then have a small function <code>getSQLQuery</code> in my VBA code to be used when I need to execute a query (either returning a recordset or not):</p>

<pre><code>Dim myQuery as string, _
    rsADO as ADODB.recorset

rsADO = new ADODB.recordset
myQuery = getSQLQuery(myId_Query)

'if my query retunrs a recordset'
set rsADO = myADOConnection.Execute myQuery
'or, if no recordset is to be returned'
myADOConnection.Execute myQuery
</code></pre>

<p>For views, it is even possible to keep them on the server side and to refer to them from the client side</p>

<pre><code>set rsADO = myADOConnection.execute ""dbo.myViewName""
</code></pre>
"
915,418960,-6,11,sql,Managing and debugging SQL queries in MS Access,"<p>MS Access has limited capabilities to manage raw SQL queries: the editor is quite bad, no syntax highlighting, it reformats your raw SQL into a long string and you can't insert comments.</p>

<p>Debugging complex SQL queries is a pain as well: either you have to split it into many smaller queries that become difficult to manage when your schema changes or you end-up with a giant query that is a nightmare to debug and update.</p>

<p>How do you manage your complex SQL queries in MS Access and how do you debug them?</p>

<p><strong>Edit</strong><br />
At the moment, I'm mostly just using <a href=""http://notepad-plus.sourceforge.net/uk/site.htm"">Notepad++</a> for some syntax colouring and <a href=""http://www.wangz.net/"">SQL Pretty Printer</a> for reformatting sensibly the raw SQL from Access.<br />
Using an external repository is useful but keeping there's always the risk of getting the two versions out of sync and you still have to remove comments before trying the query in Access...</p>
","<p>I guess I don't write complex SQL, because I don't have a problem with the Access SQL editor most of the time. This is because, for the most part, I use the QBE to write the SQL and only dip into the SQL view to do the things the QBE doesn't support (such as non-equi joins, some forms of subqueries, UNION, etc.). This is not to say that I don't have any SQL that is very hard to work with, but that's mostly because it's HIDEOUSLY BADLY WRITTEN, and that's <em>my</em> fault, not Access's fault. I have one horrid, appalling saved QueryDef in an app that's been in production since 1997 that has SQL that's 11,934 characters. And, yes, it's awful to troubleshoot. And nearly any edit I make to it breaks something. But that's because IT'S BAD SQL.</p>

<p>Why anyone would want to write their SQL by hand as a general rule, I can't say. For anything but the most trivial SQL, it seems to me like more trouble than it's worth.</p>

<p>This kind of thing seems to me like another case of people resisting the default Access way of doing things. Almost always, this comes about with users experienced in other programming environments who are too impatient to try things the way Access does them by default. The end result is usually unhappy for everybody.</p>
"
969,444820,4,11,sql,Left outer join on two columns performance issue,"<p>I'm using a SQL query that is similar to the following form:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.person_uid = table2.person_uid
AND table1.period = table2.period
</code></pre>

<p>And it's either way too slow or something's deadlocking because it takes at least 4 minutes to return.  If I were to change it to this:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.person_uid = table2.person_uid
WHERE table1.period = table2.period
</code></pre>

<p>then it works fine (albeit not returning the right number of columns).  Is there any way to speed this up?</p>

<p><strong>UPDATE</strong>:  It does the same thing if I switch the last two lines of the latter query:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.period = table2.period
WHERE table1.person_uid = table2.person_uid
</code></pre>

<p><strong>UPDATE 2:</strong>  These are actually views that I'm joining.  Unfortunately, they're on a database I don't have control over, so I can't (easily) make any changes to the indexing.  I am inclined to agree that this is an indexing issue though.  I'll wait a little while before accepting an answer in case there's some magical way to tune this query that I don't know about.  Otherwise, I'll accept one of the current answers and try to figure out another way to do what I want to do.  Thanks for everybody's help so far.</p>
","<p>Anything anyone tells you based on the information you provided is a guess.</p>

<p>Look at the execution plan for the query.  If you don't see a reason for the slowness in the plan, the post the plan here.</p>

<p><a href=""http://download.oracle.com/docs/cd/B28359_01/server.111/b28274/ex_plan.htm#PFGRF009"" rel=""nofollow"">http://download.oracle.com/docs/cd/B28359_01/server.111/b28274/ex_plan.htm#PFGRF009</a></p>
"
968,444820,2,11,sql,Left outer join on two columns performance issue,"<p>I'm using a SQL query that is similar to the following form:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.person_uid = table2.person_uid
AND table1.period = table2.period
</code></pre>

<p>And it's either way too slow or something's deadlocking because it takes at least 4 minutes to return.  If I were to change it to this:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.person_uid = table2.person_uid
WHERE table1.period = table2.period
</code></pre>

<p>then it works fine (albeit not returning the right number of columns).  Is there any way to speed this up?</p>

<p><strong>UPDATE</strong>:  It does the same thing if I switch the last two lines of the latter query:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.period = table2.period
WHERE table1.person_uid = table2.person_uid
</code></pre>

<p><strong>UPDATE 2:</strong>  These are actually views that I'm joining.  Unfortunately, they're on a database I don't have control over, so I can't (easily) make any changes to the indexing.  I am inclined to agree that this is an indexing issue though.  I'll wait a little while before accepting an answer in case there's some magical way to tune this query that I don't know about.  Otherwise, I'll accept one of the current answers and try to figure out another way to do what I want to do.  Thanks for everybody's help so far.</p>
","<p>In a left join you'd be scanning table1 for each unique combination of (person_uid,period) then searching table2 for all corresponding records there.  If table2 doesn't have an appropriate index, this can involve scanning the whole of that table too.</p>

<p>My best guess, without seeing an execution plan, is that the first query (the only one which seems to be correct) is having to table scan table2 as well as table1.</p>

<p>As you say that you can't change the indexes, you need to change the query.  As far as I can tell, there is only one realistic alternative...</p>

<pre><code>SELECT
   col1, col2
FROM
   table2
FULL OUTER JOIN
   table1
      ON table1.person_uid = table2.person_uid
      AND table1.period = table2.period
WHERE
   table1.person_uid IS NOT NULL
</code></pre>

<p>The hope here is that you scan table2 for each unique combination of (person_uid, period), but make use of indexes on table1.  (As opposed to scanning table1 and making use of indexes on table2, which what I expected from your query.)</p>

<p>If table1 doesn't have appropriate indexes, however, you'll be very unlikely to see any performance improvement at all...</p>

<p>Dems.</p>
"
910,418960,11,11,sql,Managing and debugging SQL queries in MS Access,"<p>MS Access has limited capabilities to manage raw SQL queries: the editor is quite bad, no syntax highlighting, it reformats your raw SQL into a long string and you can't insert comments.</p>

<p>Debugging complex SQL queries is a pain as well: either you have to split it into many smaller queries that become difficult to manage when your schema changes or you end-up with a giant query that is a nightmare to debug and update.</p>

<p>How do you manage your complex SQL queries in MS Access and how do you debug them?</p>

<p><strong>Edit</strong><br />
At the moment, I'm mostly just using <a href=""http://notepad-plus.sourceforge.net/uk/site.htm"">Notepad++</a> for some syntax colouring and <a href=""http://www.wangz.net/"">SQL Pretty Printer</a> for reformatting sensibly the raw SQL from Access.<br />
Using an external repository is useful but keeping there's always the risk of getting the two versions out of sync and you still have to remove comments before trying the query in Access...</p>
","<p>For debugging, I edit them in a separate text editor that lets me format them sensibly.  When I find I need to make changes, I edit the version in the text editor, and paste it back to Access, never editing the version in Access.</p>

<p>Still a major PITA.</p>
"
967,444820,5,11,sql,Left outer join on two columns performance issue,"<p>I'm using a SQL query that is similar to the following form:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.person_uid = table2.person_uid
AND table1.period = table2.period
</code></pre>

<p>And it's either way too slow or something's deadlocking because it takes at least 4 minutes to return.  If I were to change it to this:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.person_uid = table2.person_uid
WHERE table1.period = table2.period
</code></pre>

<p>then it works fine (albeit not returning the right number of columns).  Is there any way to speed this up?</p>

<p><strong>UPDATE</strong>:  It does the same thing if I switch the last two lines of the latter query:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.period = table2.period
WHERE table1.person_uid = table2.person_uid
</code></pre>

<p><strong>UPDATE 2:</strong>  These are actually views that I'm joining.  Unfortunately, they're on a database I don't have control over, so I can't (easily) make any changes to the indexing.  I am inclined to agree that this is an indexing issue though.  I'll wait a little while before accepting an answer in case there's some magical way to tune this query that I don't know about.  Otherwise, I'll accept one of the current answers and try to figure out another way to do what I want to do.  Thanks for everybody's help so far.</p>
","<p>I think you need to understand why the last two are not the same query as the first one. If you do a left join and then add a where clause referncing a field in the table on the right side of the join (the one which may not always have a record to match the first table), then you have effectively changed the join to an inner join. There is one exception to this and that is if you reference something like</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.person_uid = table2.person_uid
WHERE table2.person_uid is null
</code></pre>

<p>In this case you asking for the record which don't have a record in the second table. But other than this special case, you are changing the left join to an inner join if you refence a field in table2 in the where clause.</p>

<p>If your query is not fast enough, I would look at your indexing.</p>
"
966,444820,16,11,sql,Left outer join on two columns performance issue,"<p>I'm using a SQL query that is similar to the following form:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.person_uid = table2.person_uid
AND table1.period = table2.period
</code></pre>

<p>And it's either way too slow or something's deadlocking because it takes at least 4 minutes to return.  If I were to change it to this:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.person_uid = table2.person_uid
WHERE table1.period = table2.period
</code></pre>

<p>then it works fine (albeit not returning the right number of columns).  Is there any way to speed this up?</p>

<p><strong>UPDATE</strong>:  It does the same thing if I switch the last two lines of the latter query:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.period = table2.period
WHERE table1.person_uid = table2.person_uid
</code></pre>

<p><strong>UPDATE 2:</strong>  These are actually views that I'm joining.  Unfortunately, they're on a database I don't have control over, so I can't (easily) make any changes to the indexing.  I am inclined to agree that this is an indexing issue though.  I'll wait a little while before accepting an answer in case there's some magical way to tune this query that I don't know about.  Otherwise, I'll accept one of the current answers and try to figure out another way to do what I want to do.  Thanks for everybody's help so far.</p>
","<p>Bear in mind that statements 2 and 3 are different to the first one.</p>

<p>How?  Well, you're doing a left outer join and your WHERE clause isn't taking that into account (like the ON clause does).  At a minimum, try:</p>

<pre><code>SELECT col1, col2
FROM table1, table2
WHERE table1.person_uid = table2.person_uid (+)
AND table1.period = table2.period (+)
</code></pre>

<p>and see if you get the same performance issue.</p>

<p>What indexes do you have on these tables?  Is this relationship defined by a foreign key constraint?</p>

<p>What you probably need is a composite index on both person_uid and period (on both tables).</p>
"
965,444820,2,11,sql,Left outer join on two columns performance issue,"<p>I'm using a SQL query that is similar to the following form:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.person_uid = table2.person_uid
AND table1.period = table2.period
</code></pre>

<p>And it's either way too slow or something's deadlocking because it takes at least 4 minutes to return.  If I were to change it to this:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.person_uid = table2.person_uid
WHERE table1.period = table2.period
</code></pre>

<p>then it works fine (albeit not returning the right number of columns).  Is there any way to speed this up?</p>

<p><strong>UPDATE</strong>:  It does the same thing if I switch the last two lines of the latter query:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.period = table2.period
WHERE table1.person_uid = table2.person_uid
</code></pre>

<p><strong>UPDATE 2:</strong>  These are actually views that I'm joining.  Unfortunately, they're on a database I don't have control over, so I can't (easily) make any changes to the indexing.  I am inclined to agree that this is an indexing issue though.  I'll wait a little while before accepting an answer in case there's some magical way to tune this query that I don't know about.  Otherwise, I'll accept one of the current answers and try to figure out another way to do what I want to do.  Thanks for everybody's help so far.</p>
","<p>Do these tables have indexes on the columns you're joining?  Install Oracle's free SQLDeveloper product and use it to do an ""explain"" on that query and see if it's doing sequential scans of both tables.</p>
"
887,403420,10,11,sql,Convert XSD into SQL relational tables,"<p>Is there something available that could help me convert a XSD into SQL relational tables? The XSD is rather big (in my world anyway) and I could save time and boring typing if something pushed me ahead rather than starting from scratch.</p>

<p>The XSD is <a href=""http://www.grip.no/kjemikalier/XMLstandardformat/hmsdatablad.xsd"">here</a> if you want to have a look. It's a standardized/localized format to exchange MSDS.</p>
","<p>Altova's <a href=""http://www.altova.com/features_database.html"">XML Spy</a> has a feature that will generate SQL DDL Script from an XSD file. XML Spy will cost you some money though.</p>

<p>Interestingly enough, a developer used a really clever trick of using an XSLT translation to create the DDL script from an XSD file. They have outlined it in two parts <a href=""http://annlewkowicz.blogspot.com/2007/03/create-ddl-from-dataset-xsd-file.html"">here</a> and <a href=""http://annlewkowicz.blogspot.com/2008/01/create-ddl-from-xsd-file-part-ii.html"">here</a>.</p>

<p>I might have to try this out myself for future use...</p>

<p>EDIT: Just found this question asked previously <a href=""http://stackoverflow.com/questions/138575/how-can-i-create-database-tables-from-xsd-files"">here</a>...</p>
"
964,444820,3,11,sql,Left outer join on two columns performance issue,"<p>I'm using a SQL query that is similar to the following form:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.person_uid = table2.person_uid
AND table1.period = table2.period
</code></pre>

<p>And it's either way too slow or something's deadlocking because it takes at least 4 minutes to return.  If I were to change it to this:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.person_uid = table2.person_uid
WHERE table1.period = table2.period
</code></pre>

<p>then it works fine (albeit not returning the right number of columns).  Is there any way to speed this up?</p>

<p><strong>UPDATE</strong>:  It does the same thing if I switch the last two lines of the latter query:</p>

<pre><code>SELECT col1, col2
FROM table1
LEFT OUTER JOIN table2
ON table1.period = table2.period
WHERE table1.person_uid = table2.person_uid
</code></pre>

<p><strong>UPDATE 2:</strong>  These are actually views that I'm joining.  Unfortunately, they're on a database I don't have control over, so I can't (easily) make any changes to the indexing.  I am inclined to agree that this is an indexing issue though.  I'll wait a little while before accepting an answer in case there's some magical way to tune this query that I don't know about.  Otherwise, I'll accept one of the current answers and try to figure out another way to do what I want to do.  Thanks for everybody's help so far.</p>
","<p>Do you have covering indexes on <code>person_uid</code> and <code>period</code> for both tables?</p>

<p>If not, add them and try again.</p>

<p>Take a look at the execution plan and see what the query is actually doing.</p>

<p>Also: What are the datatypes of the fields? Are they the same in both tables? An implicit cast can really slow things down.</p>
"
291,135530,1,10,sql,Will my index be used if all columns are not used?,"<p>I have an index on columns A, B, C, D of table T</p>

<p>I have a query that pulls from T with A, B, C in the WHERE clause.</p>

<p>Will the index be used or will a separate index be needed that only includes A, B, C?</p>
","<p>Here's another ""it depends"" answer... it also depends on how large your table is...</p>

<p>I agree with everyone else who has mentioned checking the execution plan to verify whether or not your index is being used.  </p>

<p>Here are a couple of articles on reading an execution plan that you should find useful:</p>

<p><a href=""http://www.sqlservercentral.com/articles/Administering/executionplans/1345/"" rel=""nofollow"">http://www.sqlservercentral.com/articles/Administering/executionplans/1345/</a>
<a href=""http://www.codeproject.com/KB/database/sql-tuning-tutorial-1.aspx"" rel=""nofollow"">http://www.codeproject.com/KB/database/sql-tuning-tutorial-1.aspx</a></p>

<p>There's also a good article on seeks vs. scans that I'd recommend:
<a href=""http://blogs.msdn.com/craigfr/archive/2006/06/26/647852.aspx"" rel=""nofollow"">http://blogs.msdn.com/craigfr/archive/2006/06/26/647852.aspx</a></p>

<p>There are a log of good articles on Craig Freedman's blog, here's another one you should find useful.  This article is about some of the factors SQL Server uses to determine which index to use... </p>

<p><a href=""http://blogs.msdn.com/craigfr/archive/2006/07/13/664902.aspx"" rel=""nofollow"">http://blogs.msdn.com/craigfr/archive/2006/07/13/664902.aspx</a></p>

<p>Take care!
Jeff</p>
"
290,135530,6,10,sql,Will my index be used if all columns are not used?,"<p>I have an index on columns A, B, C, D of table T</p>

<p>I have a query that pulls from T with A, B, C in the WHERE clause.</p>

<p>Will the index be used or will a separate index be needed that only includes A, B, C?</p>
","<p>David B is right that you should check the execution plan to verify the index is being used.</p>

<blockquote>Will the index be used or will a separate index be needed that only includes A, B, C?</blockquote>

<p>To answer this last part of the question, which I think is the core underlying topic (as opposed to the immediate solution), there is <em>almost</em> never a reason to index a subset of your indexed columns.  If your index is (A, B, C, D), a WHERE against (A, B, C) will most likely result in an index <strong>seek</strong>, which is the ideal situation -- the index includes all the information the engine needs to go directly to the result set.  I believe this is holds true for numeric types and for equality tests in string types, though it can break down with LIKE '%'s).  On the other hand, if your WHERE only referenced D, you would most likely end up with an index <strong>scan</strong>, which would mean that the SQL engine would have to scan across all combinations of A, B, and C, and then check whether D met your criteria before deciding whether to add the row to the result set.  On a particularly large table, when I found myself having to do a lot of queries against column ""D"", I added an additional index for D only, and saw about 90% performance improvement.</p>

<p>Edit: I should also recommend using the Database Engine Tuning Advisor in SQL Management Studio.  It will tell you if your table isn't indexed ideally for the query you want to run.</p>
"
289,135530,1,10,sql,Will my index be used if all columns are not used?,"<p>I have an index on columns A, B, C, D of table T</p>

<p>I have a query that pulls from T with A, B, C in the WHERE clause.</p>

<p>Will the index be used or will a separate index be needed that only includes A, B, C?</p>
","<p>Generally speaking yes it will be, all modern databases are clever enough to do this.  There are exceptions, for example if the statistics on the table show that the volume of data in it is sufficiently small that a full table read will be more efficient then the index will be discounted, but as a rule you can rely on it where appropriate.</p>

<p>Consequently you can take advantage of this when designing your indexes.  Say for example I have a table which contains A, B, C as key values and colums Y and Z containing data which I know will be retrieved often by the statements  </p>

<p>SELECT Y FROM table WHERE A = alpha and B = beta and C = gamma </p>

<p>SELECT Z FROM table WHERE A = alpha and B = beta and C = gamma </p>

<p>The I will generally create an index on A,B,C,X,Z - assuming that X and Z are some reasonably small field.  The reason for this is that I know the access pathway in the statements above will use use the index, and <em>as the data I want to retrieve is already in the index read</em> then no separate read of the block of data required to retrieve the table data itself will be needed.  This strategy can dramatically speed up data retrieval in some circumstances.  Of course you pay for it in update costs and disk space so you need to understand what your database is doing before applying it, but as in most databases reads dramatically outnumber writes it's generally well worth the consideration.</p>
"
288,135530,2,10,sql,Will my index be used if all columns are not used?,"<p>I have an index on columns A, B, C, D of table T</p>

<p>I have a query that pulls from T with A, B, C in the WHERE clause.</p>

<p>Will the index be used or will a separate index be needed that only includes A, B, C?</p>
","<p>Start with the simple equals lookup (WHERE A=1 and B='Red' and C=287) yes the index will (most likely) be used. The index will be used first to help the optimizer ""guess"" the number of rows that will match the selection, and then second, to actually access those rows. </p>

<p>In response to David B's comment about the ""like"" predicate, SQLServer may still use the index, it depends on what you're selecting. For example, if you're selecting a count(*) then SQLServer would likely scan the index and count the hits that match the where clause since the index is smaller and would require fewer IOs to scan. And it may decide to do that even if you're selecting some columns from the base table, depending on how selective SQLServer feels the index is.</p>
"
287,135530,4,10,sql,Will my index be used if all columns are not used?,"<p>I have an index on columns A, B, C, D of table T</p>

<p>I have a query that pulls from T with A, B, C in the WHERE clause.</p>

<p>Will the index be used or will a separate index be needed that only includes A, B, C?</p>
","<p>If in doubt, take a look at the <a href=""http://msdn.microsoft.com/en-us/library/aa178303(SQL.80).aspx"" rel=""nofollow"">execution plan</a>.</p>
"
286,135530,2,10,sql,Will my index be used if all columns are not used?,"<p>I have an index on columns A, B, C, D of table T</p>

<p>I have a query that pulls from T with A, B, C in the WHERE clause.</p>

<p>Will the index be used or will a separate index be needed that only includes A, B, C?</p>
","<p>The fact that the index contains a column which is not used in your query will not prevent it from being used.</p>

<p>That's not to say that it definitely <strong>will</strong> be used, it may be ignored for a different reason (perhaps because one or more other indexes are more useful).</p>

<p>As always, take a squizz at the estimated execution plan to see what is likely to happen.</p>
"
285,135530,1,10,sql,Will my index be used if all columns are not used?,"<p>I have an index on columns A, B, C, D of table T</p>

<p>I have a query that pulls from T with A, B, C in the WHERE clause.</p>

<p>Will the index be used or will a separate index be needed that only includes A, B, C?</p>
","<p>The index will be used, yes.  It's fairly smart about which indexes will produce a more optimal query plan, and it should have no trouble with that.</p>

<p>As with this sort of thing, don't take my word for it - benchmark it.  Create a table, fill it with representative data, query it, index it, and query it again.</p>
"
284,135530,6,10,sql,Will my index be used if all columns are not used?,"<p>I have an index on columns A, B, C, D of table T</p>

<p>I have a query that pulls from T with A, B, C in the WHERE clause.</p>

<p>Will the index be used or will a separate index be needed that only includes A, B, C?</p>
","<p>It depends!</p>

<pre><code>WHERE A like '%x%'
  and B = 1
  and C = 1
//
WHERE A = 1
  OR B = 1
  OR C = 1
//
WHERE DateAdd(dd, 1, A) = '2008-01-01'
  AND B = 1
  AND C = 1
</code></pre>

<p>These will not rely on the index, because the index is not useful.</p>

<p>Click on ""display estimated execution plan"" to confirm potential index usage.</p>
"
283,135530,4,10,sql,Will my index be used if all columns are not used?,"<p>I have an index on columns A, B, C, D of table T</p>

<p>I have a query that pulls from T with A, B, C in the WHERE clause.</p>

<p>Will the index be used or will a separate index be needed that only includes A, B, C?</p>
","<p>in Oracle databases it will if you reference the leading index columns. ie the columns declared first..</p>

<p>so in your case yes the index would be used.  and could be check be using an explain plan.</p>

<p>if MS SQLSERVER is different (and i suspect it might) you'll need a new answer.</p>

<p><strong>Edit:</strong>
Should also mention it will only <strong>consider</strong> the index for use.. that does not necessarily mean it WILL use it.</p>

<p><strong>Edit2:</strong>
Oracle 11g now has an option that will allow it to skip columns in an index.</p>
"
6,1970,2,10,sql,What language do you use for PostgreSQL triggers and stored procedures?,"<p>PostgreSQL is interesting in that it supports several languages for writing stored procedures.  Which one do you use, and why?</p>
","<p>PL/Ruby because I use Ruby every day anyway.</p>
"
21,6340,0,10,sql,Multiple foreign keys?,"<p>I've got a table that is supposed to track days and costs for shipping product from one vendor to another. We (brilliantly :p) stored both the shipping vendors (FedEx, UPS) with the product handling vendors (Think... Dunder Mifflin) in a ""VENDOR"" table. So, I have three columns in my SHIPPING_DETAILS table that all reference VENDOR.no. For some reason MySQL isn't letting me define all three as foreign keys. Any ideas?</p>

<pre><code>CREATE TABLE SHIPPING_GRID(  
    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'Unique ID for each row',  
    shipping_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the shipping vendor (vendors_type must be 3)',  
    start_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the vendor being shipped from',  
    end_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to the VENDOR.no for the vendor being shipped to',  
    shipment_duration INT(1) DEFAULT 1 COMMENT 'Duration in whole days shipment will take',  
    price FLOAT(5,5) NOT NULL COMMENT 'Price in US dollars per shipment lbs (down to 5 decimal places)',  
    is_flat_rate TINYINT(1) DEFAULT 0 COMMENT '1 if is flat rate regardless of weight, 0 if price is by lbs',  
    INDEX (shipping_vendor_no),  
    INDEX (start_vendor_no),  
    INDEX (end_vendor_no),  
    FOREIGN KEY (shipping_vendor_no) REFERENCES VENDOR (no),  
    FOREIGN KEY (start_vendor_no) REFERENCES VENDOR (no),  
    FOREIGN KEY (end_vendor_no) REFERENCES VENDOR (no)  
) TYPE = INNODB;
</code></pre>

<p><em>Edited to remove double primary key definition...</em></p>

<hr>

<p>Yeah, unfortunately that didn't fix it though. Now I'm getting:</p>

<blockquote>
  <p>Can't create table
  './<em>REMOVED MY DB NAME</em>/SHIPPING_GRID.frm'
  (errno: 150)</p>
</blockquote>

<p>Doing a phpinfo() tells me this for mysql:</p>

<blockquote>
  <p>Client API version    5.0.45</p>
</blockquote>

<p>Yes, the VENDOR.no is type int(6).</p>
","<blockquote>
  <p>Can you provide the definition of the
  VENDOR table</p>
</blockquote>

<p>I figured it out. The VENDOR table was MyISAM... (edited your answer to tell me to make them both INNODB ;) )</p>

<p>(any reason <em>not</em> to just switch the VENDOR type over to INNODB?)</p>
"
611,271730,0,10,sql,How to select maximum 3 items per users in MySQL?,"<p>I run a website where users can post items (e.g. pictures). The items are stored in a MySQL database. </p>

<p>I want to query for the last ten posted items BUT with the constraint of a maximum of 3 items can come from any single user. </p>

<p>What is the best way of doing it? My preferred solution is a constraint that is put on the SQL query requesting the last ten items. But ideas on how to set up the database design is very welcome.</p>

<p>Thanks in advance!</p>

<p>BR</p>
","<p>I would first select 10 distinct users, then selecting images from each of those users with a LIMIT 3, possibly by a union of all those and limit that to 10.</p>

<p>That would atleast narrow down the data you need to process to a fair amount.</p>
"
612,271730,4,10,sql,How to select maximum 3 items per users in MySQL?,"<p>I run a website where users can post items (e.g. pictures). The items are stored in a MySQL database. </p>

<p>I want to query for the last ten posted items BUT with the constraint of a maximum of 3 items can come from any single user. </p>

<p>What is the best way of doing it? My preferred solution is a constraint that is put on the SQL query requesting the last ten items. But ideas on how to set up the database design is very welcome.</p>

<p>Thanks in advance!</p>

<p>BR</p>
","<p>It's pretty easy with a correlated sub-query:</p>

<pre><code>SELECT `img`.`id` , `img`.`userid`
FROM `img`
WHERE 3 &gt; (
SELECT count( * )
FROM `img` AS `img1`
WHERE `img`.`userid` = `img1`.`userid`
AND `img`.`id` &gt; `img1`.`id` )
ORDER BY `img`.`id` DESC
LIMIT 10
</code></pre>

<p>The query assumes that larger <code>id</code> means added later</p>

<p>Correlated sub-queries are a powerful tool! :-)</p>
"
22,10190,8,10,sql,How to return a page of results from SQL?,"<p>Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.</p>

<p>What's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?</p>

<p>Does LINQ simplify the solution?</p>
","<p>On MS SQL Server 2005 and above, <a href=""http://msdn.microsoft.com/en-us/library/ms186734.aspx"" rel=""nofollow"">ROW_NUMBER()</a> seems to work:</p>

<p><a href=""http://blogs.x2line.com/al/archive/2005/11/18/1323.aspx"" rel=""nofollow"">T-SQL: Paging with ROW_NUMBER()</a></p>

<pre><code>DECLARE @PageNum AS INT;
DECLARE @PageSize AS INT;
SET @PageNum = 2;
SET @PageSize = 10;

WITH OrdersRN AS
(
    SELECT ROW_NUMBER() OVER(ORDER BY OrderDate, OrderID) AS RowNum
          ,OrderID
          ,OrderDate
          ,CustomerID
          ,EmployeeID
      FROM dbo.Orders
)

SELECT * 
  FROM OrdersRN
 WHERE RowNum BETWEEN (@PageNum - 1) * @PageSize + 1 
                  AND @PageNum * @PageSize
 ORDER BY OrderDate
         ,OrderID;
</code></pre>
"
5,1970,2,10,sql,What language do you use for PostgreSQL triggers and stored procedures?,"<p>PostgreSQL is interesting in that it supports several languages for writing stored procedures.  Which one do you use, and why?</p>
","<p>For anything really small/simple or that doesn't require a lot of string manipulation or logic, I use plpgsql, because it's fast.  For more complex things, I use plperl, because I like it.</p>
"
4,1970,4,10,sql,What language do you use for PostgreSQL triggers and stored procedures?,"<p>PostgreSQL is interesting in that it supports several languages for writing stored procedures.  Which one do you use, and why?</p>
","<p>I write pretty much everything in plpgsql, but I'm also a database guy first and foremost, so it generally suits me better than any other language. But there's plenty of things that it doesn't do very well, in which case another language such as plperl or plpython is a good bet. Of course, if speed is a serious concern, C is the way to go.</p>
"
3,1970,2,10,sql,What language do you use for PostgreSQL triggers and stored procedures?,"<p>PostgreSQL is interesting in that it supports several languages for writing stored procedures.  Which one do you use, and why?</p>
","<p>Skype uses <strong>PostgreSQL</strong> together with python, and they have improved PL/Python to it's current state so I would doubt that python support is far behind perl. They have written queuing/replication system on top of those bindings, after all :-) </p>

<p>Take a look: <a href=""http://wiki.postgresql.org/wiki/Skytools"" rel=""nofollow"">Wiki Skytools</a></p>

<blockquote>
  <p>From a quick look in documentation, python seems to have less
  documentation than perl bindings, but I would suggest to just stick
  with language you are most comfortable with.</p>
</blockquote>
"
2,1970,5,10,sql,What language do you use for PostgreSQL triggers and stored procedures?,"<p>PostgreSQL is interesting in that it supports several languages for writing stored procedures.  Which one do you use, and why?</p>
","<p>I have only really used PL/pgSQL, but that was because I needed a few stored procedures relatively fast and didn't want to add extra modules to the server.</p>

<p>Longer term, I would probably use PL/Perl or PL/Python, as I use perl for quick scripting and have been looking at python for a while now.</p>

<p>One thing I have found is that there is a lack of good documentation for that on the PostgreSQL site. The manuals were thorough as a reference, but did not work well as a tutorial to help show people how it should be done.</p>

<p>That, combined with a very good debugging environment, meant that my first experience of writing procedures involved looking at weird syntax errors for a long time.</p>

<p>If someone knows of a good site with tutorials etc for PostgreSQL programming, I would love to get a link to it.</p>
"
388,177970,8,10,sql,Is there a way to get DateTime value from timestamp type column?,"<p>I need a select from table which does not have column that tells when row was inserted, only <code>timestamp</code> column (values like: 0x0000000000530278). Some data was imported to the table yesterday and now I need to find out what exactly was imported :(</p>

<p>Is there a way to do it using only <code>timestamp</code> info? <a href=""http://www.sqlhacks.com/index.php/Dates/Timestamp"">Here</a> I found that:</p>

<ul>
<li>Timestamp is a 8 bytes sequential Hex number, that has nothing to do with neither the date nor the time.</li>
<li>To get the current value of timestamp, use: @@DBTS.</li>
</ul>

<p>Perhaps there is a way to find what was <code>timestamp</code> value around specific time? That would help to form a select. Or maybe there is a well known solution?</p>
","<p>The timestamp datatype in SQL Server 2005 is a synonym of rowversion and is just a number that is automatically incremented with each row update.</p>

<p>You can cast it to bigint to see its value.</p>

<p>To get what you want for new or updated rows, you should propably add another datetime column (lastupdate) and a trigger to update that column with each update.</p>

<p>For rows that have already been inserted in the past I don't think that you can do something to find the exact time.</p>
"
389,177970,0,10,sql,Is there a way to get DateTime value from timestamp type column?,"<p>I need a select from table which does not have column that tells when row was inserted, only <code>timestamp</code> column (values like: 0x0000000000530278). Some data was imported to the table yesterday and now I need to find out what exactly was imported :(</p>

<p>Is there a way to do it using only <code>timestamp</code> info? <a href=""http://www.sqlhacks.com/index.php/Dates/Timestamp"">Here</a> I found that:</p>

<ul>
<li>Timestamp is a 8 bytes sequential Hex number, that has nothing to do with neither the date nor the time.</li>
<li>To get the current value of timestamp, use: @@DBTS.</li>
</ul>

<p>Perhaps there is a way to find what was <code>timestamp</code> value around specific time? That would help to form a select. Or maybe there is a well known solution?</p>
","<p>I think your best bet is to restore a backup from before the inserts and compare the backuped table with the current table. </p>
"
390,177970,3,10,sql,Is there a way to get DateTime value from timestamp type column?,"<p>I need a select from table which does not have column that tells when row was inserted, only <code>timestamp</code> column (values like: 0x0000000000530278). Some data was imported to the table yesterday and now I need to find out what exactly was imported :(</p>

<p>Is there a way to do it using only <code>timestamp</code> info? <a href=""http://www.sqlhacks.com/index.php/Dates/Timestamp"">Here</a> I found that:</p>

<ul>
<li>Timestamp is a 8 bytes sequential Hex number, that has nothing to do with neither the date nor the time.</li>
<li>To get the current value of timestamp, use: @@DBTS.</li>
</ul>

<p>Perhaps there is a way to find what was <code>timestamp</code> value around specific time? That would help to form a select. Or maybe there is a well known solution?</p>
","<p>I'm afraid it's not possible to convert/cast a TIMESTAMP to a DATETIME. 
They have entirely different uses and implementations that are incompatible.</p>

<p>See this link
<a href=""http://www.sqlteam.com/article/timestamps-vs-datetime-data-types"" rel=""nofollow"">http://www.sqlteam.com/article/timestamps-vs-datetime-data-types</a></p>

<p>Books on-line also says <a href=""http://msdn.microsoft.com/en-us/library/aa260631.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/aa260631.aspx</a></p>

<blockquote>
  <p>The SQL Server timestamp data type has
  nothing to do with times or dates. SQL
  Server timestamps are binary numbers
  that indicate the relative sequence in
  which data modifications took place in
  a database. The timestamp data type
  was originally implemented to support
  the SQL Server recovery algorithms.</p>
</blockquote>
"
391,177970,18,10,sql,Is there a way to get DateTime value from timestamp type column?,"<p>I need a select from table which does not have column that tells when row was inserted, only <code>timestamp</code> column (values like: 0x0000000000530278). Some data was imported to the table yesterday and now I need to find out what exactly was imported :(</p>

<p>Is there a way to do it using only <code>timestamp</code> info? <a href=""http://www.sqlhacks.com/index.php/Dates/Timestamp"">Here</a> I found that:</p>

<ul>
<li>Timestamp is a 8 bytes sequential Hex number, that has nothing to do with neither the date nor the time.</li>
<li>To get the current value of timestamp, use: @@DBTS.</li>
</ul>

<p>Perhaps there is a way to find what was <code>timestamp</code> value around specific time? That would help to form a select. Or maybe there is a well known solution?</p>
","<p>The Transact-SQL timestamp data type is a binary data type with no time-related values.</p>

<p>So to answer your question: <em>Is there a way to get DateTime value from timestamp type column?</em></p>

<p>The answer is: <em>No</em></p>
"
392,177970,3,10,sql,Is there a way to get DateTime value from timestamp type column?,"<p>I need a select from table which does not have column that tells when row was inserted, only <code>timestamp</code> column (values like: 0x0000000000530278). Some data was imported to the table yesterday and now I need to find out what exactly was imported :(</p>

<p>Is there a way to do it using only <code>timestamp</code> info? <a href=""http://www.sqlhacks.com/index.php/Dates/Timestamp"">Here</a> I found that:</p>

<ul>
<li>Timestamp is a 8 bytes sequential Hex number, that has nothing to do with neither the date nor the time.</li>
<li>To get the current value of timestamp, use: @@DBTS.</li>
</ul>

<p>Perhaps there is a way to find what was <code>timestamp</code> value around specific time? That would help to form a select. Or maybe there is a well known solution?</p>
","<p>Another answer to you question:</p>

<p>If the timestamp column is the only resource for you recovery (no backups etc) you may try to use the following logic </p>

<p><em>Timestamp is simply a value of a counter that is incremented for each insert or update operation that is performed on a table that contains a timestamp column</em>.</p>

<p>If the data import that happened yesterday was one insert of several records you may see a sequence of numbers in the timestamp column like e.g:</p>

<pre><code>0x00000000000007D1
0x00000000000007D2
0x00000000000007D3
0x00000000000007D4
0x00000000000007D5
</code></pre>

<p>The most recent sequence can be your added data (of course it is not guarantied)
You con combine that knowledge with other things (like auto-increment column if you use them) to identify the records you are interested in.</p>
"
393,177970,0,10,sql,Is there a way to get DateTime value from timestamp type column?,"<p>I need a select from table which does not have column that tells when row was inserted, only <code>timestamp</code> column (values like: 0x0000000000530278). Some data was imported to the table yesterday and now I need to find out what exactly was imported :(</p>

<p>Is there a way to do it using only <code>timestamp</code> info? <a href=""http://www.sqlhacks.com/index.php/Dates/Timestamp"">Here</a> I found that:</p>

<ul>
<li>Timestamp is a 8 bytes sequential Hex number, that has nothing to do with neither the date nor the time.</li>
<li>To get the current value of timestamp, use: @@DBTS.</li>
</ul>

<p>Perhaps there is a way to find what was <code>timestamp</code> value around specific time? That would help to form a select. Or maybe there is a well known solution?</p>
","<p>To identify new rows by timestamp you need to keep track of the timestamps that were there beforehand.  In a pinch you could:</p>

<ul>
<li>Restore a previous version somewhere else.</li>
<li>Copy the data from both tables into a scratch database.</li>
<li>Identify the inserted data from the timestamps present in one but not the other.</li>
</ul>

<p>With a minor risk of false positives if anything else has been going on in the DB this will get you a reasonably good difference.  </p>

<p>For a more robust check you could calculate MD5 or SHA-1 hashes with <a href=""http://msdn.microsoft.com/en-us/library/ms174415(SQL.90).aspx"" rel=""nofollow"">Hashbytes</a> on the row contents to give you a difference with a very low probability of collision (see this wikipedia article on <a href=""http://en.wikipedia.org/wiki/Birthday_attack"" rel=""nofollow"">Birthday attacks</a> for a discussion of this problem).</p>
"
170,71920,6,10,sql,How to implement a Digg-like algorithm?,"<p>How to implement a website with a recommendation system similar to stackoverflow/digg/reddit? I.e., users submit content and the website needs to calculate some sort of ""hotness"" according to how popular the item is. The flow is as follows:</p>

<ul>
<li>Users submit content</li>
<li>Other users view and vote on the content (assume 90% of the users only views content and 10% actively votes up or down on content)</li>
<li>New content is continuously submitted</li>
</ul>

<p>How do I implement an algorithm that calculates the ""hotness"" of a submitted item, preferably in real-time? Are there any best-practices or design patterns?</p>

<p>I would assume that the algorithm takes the following into consideration:</p>

<ul>
<li>When an item was submitted</li>
<li>When each vote was cast</li>
<li>When the item was viewed</li>
</ul>

<p>E.g. an item that gets a constant trickle of votes would stay somewhat ""hot"" constantly while an item that receives a burst of votes when it is first submitted will jump to the top of the ""hotness""-list but then fall down as the votes stop coming in.</p>

<p>(I am using a MySQL+PHP but I am interested in general design patterns).</p>
","<p>You could use something similar to the <a href=""http://redflavor.com/reddit.cf.algorithm.png"">Reddit algorithm</a> - the basic principle of which is you compute a value for a post based on the time it was posted and the score. What's neat about the Reddit algorithm is that you only need recompute the value when the score of a post changes. When you want to display your front page, you just get the top n posts from your database based on that score. As time goes on the scores will naturally increase, so you don't have to do any special processing to remove items from the front page.</p>
"
171,71920,4,10,sql,How to implement a Digg-like algorithm?,"<p>How to implement a website with a recommendation system similar to stackoverflow/digg/reddit? I.e., users submit content and the website needs to calculate some sort of ""hotness"" according to how popular the item is. The flow is as follows:</p>

<ul>
<li>Users submit content</li>
<li>Other users view and vote on the content (assume 90% of the users only views content and 10% actively votes up or down on content)</li>
<li>New content is continuously submitted</li>
</ul>

<p>How do I implement an algorithm that calculates the ""hotness"" of a submitted item, preferably in real-time? Are there any best-practices or design patterns?</p>

<p>I would assume that the algorithm takes the following into consideration:</p>

<ul>
<li>When an item was submitted</li>
<li>When each vote was cast</li>
<li>When the item was viewed</li>
</ul>

<p>E.g. an item that gets a constant trickle of votes would stay somewhat ""hot"" constantly while an item that receives a burst of votes when it is first submitted will jump to the top of the ""hotness""-list but then fall down as the votes stop coming in.</p>

<p>(I am using a MySQL+PHP but I am interested in general design patterns).</p>
","<p>On my own site, I assign each entry a unique integer from a monotonically increasing series (newer posts get higher numbers). Each up vote increases the number by one, and each down vote decreases it by one (you can tweak these values, of course). Then, simply sort by the number to display the 'hottest' entries.</p>
"
23,10190,1,10,sql,How to return a page of results from SQL?,"<p>Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.</p>

<p>What's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?</p>

<p>Does LINQ simplify the solution?</p>
","<p>Actually, LINQ has Skip and Take methods which can be combined to choose which records are fetched.</p>

<p>Check those out.</p>

<p>For DB: <a href=""http://www.singingeels.com/Articles/Pagination_In_SQL_Server_2005.aspx"" rel=""nofollow"">Pagination In SQL Server 2005</a></p>
"
7,1970,2,10,sql,What language do you use for PostgreSQL triggers and stored procedures?,"<p>PostgreSQL is interesting in that it supports several languages for writing stored procedures.  Which one do you use, and why?</p>
","<p>I use PL/pgSQL for most everything, and if there is something it can't do I write functions in PL/Python (which rocks).  You can also use PL/Java, PL/Perl, PL/PHP.</p>

<p>I would say Python is probably the best all around one because Python is on just about every linux system. Perl would be second with Python beating it because of the easier reading syntax.</p>
"
942,438610,20,10,sql,How do I write a query that outputs the row number as a column?,"<p>How do I write a query that outputs the row number as a column? This is DB2 SQL on an iSeries.</p>

<p>eg if I have</p>

<p>table Beatles:</p>

<pre><code>John
Paul
George
Ringo
</code></pre>

<p>and I want to write a statement, without writing a procedure or view if possible, that gives me</p>

<pre><code>1 John
2 Paul
3 George
4 Ringo
</code></pre>
","<pre><code>SELECT ROW_NUMBER() OVER (ORDER BY beatle_name ASC) AS ROWID, * FROM beatles
</code></pre>
"
27,10190,3,10,sql,How to return a page of results from SQL?,"<p>Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.</p>

<p>What's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?</p>

<p>Does LINQ simplify the solution?</p>
","<p>LINQ combined with lambda expressions and anonymous classes in .Net 3.5 <em>hugely</em> simplifies this sort of thing.</p>

<p>Querying the database:</p>

<pre><code>var customers = from c in db.customers
                join p in db.purchases on c.CustomerID equals p.CustomerID
                where p.purchases &gt; 5
                select c;
</code></pre>

<p>Number of records per page:</p>

<pre><code>customers = customers.Skip(pageNum * pageSize).Take(pageSize);
</code></pre>

<p>Sorting by any column:</p>

<pre><code>customers = customers.OrderBy(c =&gt; c.LastName);
</code></pre>

<p>Getting only selected fields from server:</p>

<pre><code>var customers = from c in db.customers
                join p in db.purchases on c.CustomerID equals p.CustomerID
                where p.purchases &gt; 5
                select new
                {
                    CustomerID = c.CustomerID,
                    FirstName = c.FirstName,
                    LastName = c.LastName
                };
</code></pre>

<p>This creates a statically-typed anonymous class in which you can access its properties:</p>

<pre><code>var firstCustomer = customer.First();
int id = firstCustomer.CustomerID;
</code></pre>

<p>Results from queries are lazy-loaded by default, so you aren't talking to the database until you actually need the data. LINQ in .Net also greatly simplifies updates by keeping a datacontext of any changes you have made, and only updating the fields which you change.</p>
"
28,10190,0,10,sql,How to return a page of results from SQL?,"<p>Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.</p>

<p>What's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?</p>

<p>Does LINQ simplify the solution?</p>
","<p>There is a discussion about this <a href=""http://www.4guysfromrolla.com/webtech/042606-1.shtml"" rel=""nofollow"">Here</a></p>

<p>The technique gets page number 100,000 from a 150,000 line database in 78ms</p>

<blockquote>
  <p>Using optimizer knowledge and SET ROWCOUNT, the first EmployeeID in the page that is requested is stored in a local variable for a starting point. Next, SET ROWCOUNT to the maximum number of records that is requested in @maximumRows. This allows paging the result set in a much more efficient manner. Using this method also takes advantage of pre-existing indexes on the table as it goes directly to the base table and not to a locally created table. </p>
</blockquote>

<p>I am afraid I am not able to judge if it is better than the current accepted answer.</p>
"
610,271730,2,10,sql,How to select maximum 3 items per users in MySQL?,"<p>I run a website where users can post items (e.g. pictures). The items are stored in a MySQL database. </p>

<p>I want to query for the last ten posted items BUT with the constraint of a maximum of 3 items can come from any single user. </p>

<p>What is the best way of doing it? My preferred solution is a constraint that is put on the SQL query requesting the last ten items. But ideas on how to set up the database design is very welcome.</p>

<p>Thanks in advance!</p>

<p>BR</p>
","<p>This is difficult because MySQL does not support the LIMIT clause on sub-queries. If it did, this would be rather trivial... But alas, here is my nave approach:</p>

<pre><code>SELECT
  i.UserId,
  i.ImageId
FROM
  UserSuppliedImages i
WHERE
  /* second valid ImageId */
  ImageId = (
    SELECT MAX(ImageId)
    FROM UserSuppliedImages
    WHERE UserId = i.UserId
  )
  OR
  /* second valid ImageId */
  ImageId = (
    SELECT MAX(ImageId)
    FROM   UserSuppliedImages
    WHERE UserId = i.UserId
      AND ImageId &lt; (
        SELECT MAX(ImageId)
        FROM UserSuppliedImages
        WHERE UserId = i.UserId
      )
    )
  /* you get the picture... 
     the more ""per user"" images you want, the more complex this will get */
LIMIT 10;
</code></pre>

<p>You did not comment on having a preferred result order, so this selects the latest images (assuming <code>ImageId</code> is an ascending auto-incrementing value).</p>

<p>For comparison, on SQL Server the same would look like this:</p>

<pre><code>SELECT TOP 10
  img.ImageId,
  img.ImagePath,
  img.UserId
FROM
  UserSuppliedImages img
WHERE
  ImageId IN (
    SELECT TOP 3 ImageId
    FROM UserSuppliedImages 
    WHERE UserId = img.UserId
  )
</code></pre>
"
26,10190,1,10,sql,How to return a page of results from SQL?,"<p>Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.</p>

<p>What's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?</p>

<p>Does LINQ simplify the solution?</p>
","<p>There are a few solutions which I use with MS SQL 2005.</p>

<p>One of them is ROW<em>NUMBER(). But, personally, I don't like ROW</em>NUMBER() because it doesn't work for big results (DB which I work on is really big -- over 1TB data running thousands of queries in second -- you know -- big social networking site).</p>

<p>Here are my favourite solution.</p>

<p>I will use kind of pseudo code of T-SQL.</p>

<p>Let's find 2nd page of users sorted by forename, surname, where each page has 10 records.</p>

<pre><code>@page = 2 -- input parameter
@size = 10 -- can be optional input parameter

if @page &lt; 1 then begin
    @page = 1 -- check page number
end
@start = (@page-1) * @size + 1 -- @page starts at record no @start

-- find the beginning of page @page
SELECT TOP (@start)
    @forename = forename,
    @surname = surname
    @id = id
FROM
    users
ORDER BY
    forename,
    surname,
    id -- to keep correct order in case of have two John Smith.

-- select @size records starting from @start
SELECT TOP (@size)
    id,
    forename,
    surname
FROM
    users
WHERE
    (forename = @forename and surname = @surname and id &gt;= @id) -- the same name and surname, but bigger id
    OR (forename = @forename and surname &gt; @surname) -- the same name, but bigger surname, id doesn't matter
    OR (forename &gt; @forename) -- bigger forename, the rest doesn't matter
ORDER BY
    forename,
    surname,
    id
</code></pre>
"
25,10190,6,10,sql,How to return a page of results from SQL?,"<p>Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.</p>

<p>What's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?</p>

<p>Does LINQ simplify the solution?</p>
","<p>I'd recommend either using LINQ, or try to copy what it does. I've got an app where I use the LINQ Take and Skip methods to retrieve paged data. The code looks something like this:</p>

<pre><code>MyDataContext db = new MyDataContext();
var results = db.Products
    .Skip((pageNumber - 1) * pageSize)
    .Take(pageSize);
</code></pre>

<p>Running SQL Server Profiler reveals that LINQ is converting this query into SQL similar to:</p>

<pre><code>SELECT [ProductId], [Name], [Cost], and so on...
FROM (
    SELECT [ProductId], [Name], [Cost], [ROW_NUMBER]
    FROM (
       SELECT ROW_NUMBER() OVER (ORDER BY [Name]) AS [ROW_NUMBER], 
           [ProductId], [Name], [Cost]
       FROM [Products]
    )
    WHERE [ROW_NUMBER] BETWEEN 10 AND 20
)
ORDER BY [ROW_NUMBER]
</code></pre>

<p>In plain English:<br />
1. Filter your rows and use the ROW_NUMBER function to add row numbers in the order you want.<br />
2. Filter (1) to return only the row numbers you want on your page.<br />
3. Sort (2) by the row number, which is the same as the order you wanted (in this case, by Name).</p>
"
24,10190,1,10,sql,How to return a page of results from SQL?,"<p>Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.</p>

<p>What's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?</p>

<p>Does LINQ simplify the solution?</p>
","<p>Oracle Solution:</p>

<pre><code>select * from (
    select a.*, rownum rnum from (
        YOUR_QUERY_GOES_HERE -- including the order by
    ) a
    where rownum &lt;= MAX_ROW
 ) where rnum &gt;= MIN_ROW
</code></pre>
"
19,6340,7,10,sql,Multiple foreign keys?,"<p>I've got a table that is supposed to track days and costs for shipping product from one vendor to another. We (brilliantly :p) stored both the shipping vendors (FedEx, UPS) with the product handling vendors (Think... Dunder Mifflin) in a ""VENDOR"" table. So, I have three columns in my SHIPPING_DETAILS table that all reference VENDOR.no. For some reason MySQL isn't letting me define all three as foreign keys. Any ideas?</p>

<pre><code>CREATE TABLE SHIPPING_GRID(  
    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'Unique ID for each row',  
    shipping_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the shipping vendor (vendors_type must be 3)',  
    start_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the vendor being shipped from',  
    end_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to the VENDOR.no for the vendor being shipped to',  
    shipment_duration INT(1) DEFAULT 1 COMMENT 'Duration in whole days shipment will take',  
    price FLOAT(5,5) NOT NULL COMMENT 'Price in US dollars per shipment lbs (down to 5 decimal places)',  
    is_flat_rate TINYINT(1) DEFAULT 0 COMMENT '1 if is flat rate regardless of weight, 0 if price is by lbs',  
    INDEX (shipping_vendor_no),  
    INDEX (start_vendor_no),  
    INDEX (end_vendor_no),  
    FOREIGN KEY (shipping_vendor_no) REFERENCES VENDOR (no),  
    FOREIGN KEY (start_vendor_no) REFERENCES VENDOR (no),  
    FOREIGN KEY (end_vendor_no) REFERENCES VENDOR (no)  
) TYPE = INNODB;
</code></pre>

<p><em>Edited to remove double primary key definition...</em></p>

<hr>

<p>Yeah, unfortunately that didn't fix it though. Now I'm getting:</p>

<blockquote>
  <p>Can't create table
  './<em>REMOVED MY DB NAME</em>/SHIPPING_GRID.frm'
  (errno: 150)</p>
</blockquote>

<p>Doing a phpinfo() tells me this for mysql:</p>

<blockquote>
  <p>Client API version    5.0.45</p>
</blockquote>

<p>Yes, the VENDOR.no is type int(6).</p>
","<p>You defined the primary key twice. Try:</p>

<pre><code>CREATE TABLE SHIPPING_GRID(  
    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'Unique ID for each row',  
    shipping_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the shipping vendor (vendors_type must be 3)',  
    start_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the vendor being shipped from',  
    end_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to the VENDOR.no for the vendor being shipped to',  
    shipment_duration INT(1) DEFAULT 1 COMMENT 'Duration in whole days shipment will take',  
    price FLOAT(5,5) NOT NULL COMMENT 'Price in US dollars per shipment lbs (down to 5 decimal places)',  
    is_flat_rate TINYINT(1) DEFAULT 0 COMMENT '1 if is flat rate regardless of weight, 0 if price is by lbs',  
    INDEX (shipping_vendor_no),  
    INDEX (start_vendor_no),  
    INDEX (end_vendor_no),  
    FOREIGN KEY (shipping_vendor_no) REFERENCES VENDOR (no),  
    FOREIGN KEY (start_vendor_no) REFERENCES VENDOR (no),  
    FOREIGN KEY (end_vendor_no) REFERENCES VENDOR (no)  
) TYPE = INNODB;
</code></pre>

<p>The VENDOR primary key must be INT(6), and both tables must be of type InnoDB.</p>
"
20,6340,0,10,sql,Multiple foreign keys?,"<p>I've got a table that is supposed to track days and costs for shipping product from one vendor to another. We (brilliantly :p) stored both the shipping vendors (FedEx, UPS) with the product handling vendors (Think... Dunder Mifflin) in a ""VENDOR"" table. So, I have three columns in my SHIPPING_DETAILS table that all reference VENDOR.no. For some reason MySQL isn't letting me define all three as foreign keys. Any ideas?</p>

<pre><code>CREATE TABLE SHIPPING_GRID(  
    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'Unique ID for each row',  
    shipping_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the shipping vendor (vendors_type must be 3)',  
    start_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the vendor being shipped from',  
    end_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to the VENDOR.no for the vendor being shipped to',  
    shipment_duration INT(1) DEFAULT 1 COMMENT 'Duration in whole days shipment will take',  
    price FLOAT(5,5) NOT NULL COMMENT 'Price in US dollars per shipment lbs (down to 5 decimal places)',  
    is_flat_rate TINYINT(1) DEFAULT 0 COMMENT '1 if is flat rate regardless of weight, 0 if price is by lbs',  
    INDEX (shipping_vendor_no),  
    INDEX (start_vendor_no),  
    INDEX (end_vendor_no),  
    FOREIGN KEY (shipping_vendor_no) REFERENCES VENDOR (no),  
    FOREIGN KEY (start_vendor_no) REFERENCES VENDOR (no),  
    FOREIGN KEY (end_vendor_no) REFERENCES VENDOR (no)  
) TYPE = INNODB;
</code></pre>

<p><em>Edited to remove double primary key definition...</em></p>

<hr>

<p>Yeah, unfortunately that didn't fix it though. Now I'm getting:</p>

<blockquote>
  <p>Can't create table
  './<em>REMOVED MY DB NAME</em>/SHIPPING_GRID.frm'
  (errno: 150)</p>
</blockquote>

<p>Doing a phpinfo() tells me this for mysql:</p>

<blockquote>
  <p>Client API version    5.0.45</p>
</blockquote>

<p>Yes, the VENDOR.no is type int(6).</p>
","<p>I ran the code here, and the error message showed (and it is right!) that you are setting <em>id</em> field twice as primary key. </p>"
172,71920,1,10,sql,How to implement a Digg-like algorithm?,"<p>How to implement a website with a recommendation system similar to stackoverflow/digg/reddit? I.e., users submit content and the website needs to calculate some sort of ""hotness"" according to how popular the item is. The flow is as follows:</p>

<ul>
<li>Users submit content</li>
<li>Other users view and vote on the content (assume 90% of the users only views content and 10% actively votes up or down on content)</li>
<li>New content is continuously submitted</li>
</ul>

<p>How do I implement an algorithm that calculates the ""hotness"" of a submitted item, preferably in real-time? Are there any best-practices or design patterns?</p>

<p>I would assume that the algorithm takes the following into consideration:</p>

<ul>
<li>When an item was submitted</li>
<li>When each vote was cast</li>
<li>When the item was viewed</li>
</ul>

<p>E.g. an item that gets a constant trickle of votes would stay somewhat ""hot"" constantly while an item that receives a burst of votes when it is first submitted will jump to the top of the ""hotness""-list but then fall down as the votes stop coming in.</p>

<p>(I am using a MySQL+PHP but I am interested in general design patterns).</p>
","<p>I developed an social bookmarking site, <a href=""http://www.sites-favoritos.com"" rel=""nofollow"">Sites Favoritos</a>, and used a complex algoritm:</p>

<ol>
<li>First, the votes are finite, an user only have a limited number of votes, and the number of votes depends on the user points. To earn points each user must add links that get positive votes.</li>
<li>Then, users can vote -3,-2,-1,1,2 or 3 votes for each link. As the votes are limited, each user will vote only on those links that they like.</li>
<li>To prevent user to vote only on links for the same user, creating support groups, the points each vote adds to the link depends on a racio between total votes and votes to links of the owner of the voted link. If you always vote on the same users links, your votes will lose value.</li>
<li>Votes lose value with time.</li>
<li>New links from users who don't have points (new users) will have a starting 0 points. New links from older users will have points depending on their points. Ranging from +3 to -infinite. Links from users with negative points will have negative starting points, links from users with positive points will have positive starting points.</li>
</ol>

<p>Users will get random points when their links are voted. Positive votes give positive points, negative votes for negative points.</p>
"
1,1970,3,10,sql,What language do you use for PostgreSQL triggers and stored procedures?,"<p>PostgreSQL is interesting in that it supports several languages for writing stored procedures.  Which one do you use, and why?</p>
","<p>When I wrote my first trigger it was in Perl because that was the language used in the example I found but the last triggers I wrote where in Python because I'm more comfortable with that.</p>

<p>I think programmer comfort is my main reason to choose python but I think Perl is still better supported.</p>"
941,438610,1,10,sql,How do I write a query that outputs the row number as a column?,"<p>How do I write a query that outputs the row number as a column? This is DB2 SQL on an iSeries.</p>

<p>eg if I have</p>

<p>table Beatles:</p>

<pre><code>John
Paul
George
Ringo
</code></pre>

<p>and I want to write a statement, without writing a procedure or view if possible, that gives me</p>

<pre><code>1 John
2 Paul
3 George
4 Ringo
</code></pre>
","<p>Check out the row_number() function; you should be able to do this in DB2 via:</p>

<pre><code>SELECT row_number(), first_name FROM beatles
</code></pre>

<p>I'm almost certain this is not part of the SQL standard though, so it is not likely to be portable should that ever be an issue.</p>
"
97,36760,22,9,sql,"SQL Query, Count with 0 count","<p>I have three tables: page, attachment, page-attachment</p>

<p>I have data like this:</p>

<pre><code>page
ID    NAME
1     first page
2     second page
3     third page
4     fourth page

attachment
ID    NAME
1     foo.word
2     test.xsl
3     mm.ppt

page-attachment
ID    PAGE-ID   ATTACHMENT-ID
1     2         1
2     2         2
3     3         3
</code></pre>

<p>I would like to get the number of attachments per page <strong>also when that number is 0</strong>. I have tried with: </p>

<pre><code>select page.name, count(page-attachment.id) as attachmentsnumber 
from page 
    inner join page-attachment on page.id=page-id 
group by page.id
</code></pre>

<p>I am getting this output: </p>

<pre><code>NAME        ATTACHMENTSNUMBER
second page  2
third page   1
</code></pre>

<p>I would like to get this output:</p>

<pre><code>NAME        ATTACHMENTSNUMBER
first page   0
second page  2
third page   1
fourth page  0
</code></pre>

<p>How do I get the 0 part?</p>
","<p>Change your ""inner join"" to a ""left outer join"", which means ""get me all the rows on the left of the join, even if there isn't a matching row on the right.""</p>

<pre><code>select page.name, count(page-attachment.id) as attachmentsnumber 
from page 
    left outer join page-attachment on page.id=page-id 
group by page.name
</code></pre>
"
98,36760,1,9,sql,"SQL Query, Count with 0 count","<p>I have three tables: page, attachment, page-attachment</p>

<p>I have data like this:</p>

<pre><code>page
ID    NAME
1     first page
2     second page
3     third page
4     fourth page

attachment
ID    NAME
1     foo.word
2     test.xsl
3     mm.ppt

page-attachment
ID    PAGE-ID   ATTACHMENT-ID
1     2         1
2     2         2
3     3         3
</code></pre>

<p>I would like to get the number of attachments per page <strong>also when that number is 0</strong>. I have tried with: </p>

<pre><code>select page.name, count(page-attachment.id) as attachmentsnumber 
from page 
    inner join page-attachment on page.id=page-id 
group by page.id
</code></pre>

<p>I am getting this output: </p>

<pre><code>NAME        ATTACHMENTSNUMBER
second page  2
third page   1
</code></pre>

<p>I would like to get this output:</p>

<pre><code>NAME        ATTACHMENTSNUMBER
first page   0
second page  2
third page   1
fourth page  0
</code></pre>

<p>How do I get the 0 part?</p>
","<p>You want a left join, instead of an inner join, as that allows records to not exist.</p>
"
1153,526460,2,9,sql,AutoIncrement fields on databases without autoincrement field,"<p>In MS Sql Server is easy create autoincrement fields. In my systems I stopped to use autoincrement fields for primary keys, and now I use Guid's. It was awesome, I've got a lot of advantages with that change. But in another non-primary key fields, I really was needing implement a ""soft autoincrement"". It's because my system is DB independent, so I create the autoinc value programatically in c#. </p>

<p>I would like about solutions for autoincrement fields on databases without autoincrement, what the solution that your use and why? There is some Sql Ansi statement about this? and generating directly from my c#, is a better solution?</p>

<p>PS: I know that <em>select max(id)+1 from table</em> it's not really concurrent friendly...</p>
","<p>I think your question is actually quite a good one. However, it is easy to get lost trying to come up with a SQL only solution. In reality you will want the optimization and transaction safety afforded by using the database implementations of the autoincrement types.</p>

<p>If you need to abstract out the implementation of the autoincrement operator, why not create a stored procedure to return your autoincrement value. Most SQL dialects access stored procedures in relatively the same way and it should be more portable. Then you can create database specific autoincrement logic when you create the sproc - eliminating the need to change many statements to be vendor specific.</p>

<p>Done this way, your inserts could be as simple as:</p>

<pre><code>INSERT INTO foo (id, name, rank, serial_number)
 VALUES (getNextFooId(), 'bar', 'fooRank', 123456);
</code></pre>

<p>Then define getNextFooId() in a database specific way when the database is being initialized.</p>
"
99,36760,1,9,sql,"SQL Query, Count with 0 count","<p>I have three tables: page, attachment, page-attachment</p>

<p>I have data like this:</p>

<pre><code>page
ID    NAME
1     first page
2     second page
3     third page
4     fourth page

attachment
ID    NAME
1     foo.word
2     test.xsl
3     mm.ppt

page-attachment
ID    PAGE-ID   ATTACHMENT-ID
1     2         1
2     2         2
3     3         3
</code></pre>

<p>I would like to get the number of attachments per page <strong>also when that number is 0</strong>. I have tried with: </p>

<pre><code>select page.name, count(page-attachment.id) as attachmentsnumber 
from page 
    inner join page-attachment on page.id=page-id 
group by page.id
</code></pre>

<p>I am getting this output: </p>

<pre><code>NAME        ATTACHMENTSNUMBER
second page  2
third page   1
</code></pre>

<p>I would like to get this output:</p>

<pre><code>NAME        ATTACHMENTSNUMBER
first page   0
second page  2
third page   1
fourth page  0
</code></pre>

<p>How do I get the 0 part?</p>
","<p>LEFT join is your friend.
To learn more about different join types refer to <a href=""http://en.wikipedia.org/wiki/Join_"" rel=""nofollow"">http://en.wikipedia.org/wiki/Join_</a>(SQL)</p>
"
100,36760,7,9,sql,"SQL Query, Count with 0 count","<p>I have three tables: page, attachment, page-attachment</p>

<p>I have data like this:</p>

<pre><code>page
ID    NAME
1     first page
2     second page
3     third page
4     fourth page

attachment
ID    NAME
1     foo.word
2     test.xsl
3     mm.ppt

page-attachment
ID    PAGE-ID   ATTACHMENT-ID
1     2         1
2     2         2
3     3         3
</code></pre>

<p>I would like to get the number of attachments per page <strong>also when that number is 0</strong>. I have tried with: </p>

<pre><code>select page.name, count(page-attachment.id) as attachmentsnumber 
from page 
    inner join page-attachment on page.id=page-id 
group by page.id
</code></pre>

<p>I am getting this output: </p>

<pre><code>NAME        ATTACHMENTSNUMBER
second page  2
third page   1
</code></pre>

<p>I would like to get this output:</p>

<pre><code>NAME        ATTACHMENTSNUMBER
first page   0
second page  2
third page   1
fourth page  0
</code></pre>

<p>How do I get the 0 part?</p>
","<p>Here's another solution using sub-querying.</p>

<pre><code>SELECT
  p.name,
  (
    SELECT COUNT(*) FROM [page-attachment] pa
    WHERE pa.[PAGE-ID] = p.id
  ) as attachmentsnumber
FROM page p
</code></pre>
"
422,189680,6,9,sql,Database localization,"<p>i am looking for opinions if the following problem maybe has a better/different/common solution:</p>

<p><hr /></p>

<p>I have a database for products which contains the names of the products in english (the default language of this application) and i need translations of the names if available.</p>

<p>Currently i have this setup:</p>

<p>A product table</p>

<pre><code>CREATE TABLE products
(
  id serial NOT NULL,
  ""name"" character varying(255) NOT NULL,
  CONSTRAINT products_pkey PRIMARY KEY (id)
)
</code></pre>

<p>and a product localization table</p>

<pre><code>CREATE TABLE products_l10n
(
  product_id serial NOT NULL,
  ""language"" character(2) NOT NULL,
  ""name"" character varying(255) NOT NULL,
  CONSTRAINT products_l10n_pkey PRIMARY KEY (product_id, language),
  CONSTRAINT products_l10n_product_id_fkey FOREIGN KEY (product_id)
      REFERENCES products (id) MATCH SIMPLE
      ON UPDATE CASCADE ON DELETE CASCADE
)
</code></pre>

<p>and i use the following query to retrieve a list of localized products (german in this case) with fallback to the default english names:</p>

<pre><code>SELECT p.id, COALESCE(pl.name, p.name) 
from products p LEFT 
JOIN products_l10n pl ON p.id = pl.product_id AND language = 'de';
</code></pre>

<p>The SQL code is in postgres dialect. Data is stored as UTF-8.</p>
","<p>Looks good to me.  The one thing I might change is the way you handle languages: that should probably be a separate table.  Thus, you would have:</p>

<pre><code>CREATE TABLE products_l10n
(
  product_id serial NOT NULL,
  language_id int NOT NULL,
  ""name"" character varying(255) NOT NULL,
  CONSTRAINT products_l10n_pkey PRIMARY KEY (product_id, language),
  CONSTRAINT products_l10n_product_id_fkey FOREIGN KEY (product_id)
      REFERENCES products (id) MATCH SIMPLE
      ON UPDATE CASCADE ON DELETE CASCADE
  CONSTRAINT products_l10n_language_id_fkey FOREIGN KEY (language_id)
      REFERENCES languages (id) MATCH SIMPLE
      ON UPDATE CASCADE ON DELETE CASCADE
)

CREATE TABLE languages
)
  id serial not null
  ""language"" character(2) NOT NULL
)
</code></pre>

<p>Besides that, I think you've got just about the best possible solution.</p>
"
53,22570,2,9,sql,What's a good way to check if two datetimes are on the same calendar day in TSQL?,"<p>Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.</p>

<p>In this case, merging the function code back into the query seems impractical.</p>

<p>I think I am missing something simple here.</p>

<p>Here's the function for reference.</p>

<pre><code>if not exists (select * from dbo.sysobjects 
              where id = object_id(N'dbo.f_MakeDate') and               
              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))
  exec('create function dbo.f_MakeDate() returns int as 
         begin declare @retval int return @retval end')
go

alter function dbo.f_MakeDate
(
    @Day datetime, 
    @Hour int, 
    @Minute int
)
returns datetime
as

/*

Creates a datetime using the year-month-day portion of @Day, and the 
@Hour and @Minute provided

*/

begin

declare @retval datetime
set @retval = cast(
    cast(datepart(m, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(d, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(yyyy, @Day) as varchar(4)) + 
    ' ' + 
    cast(@Hour as varchar(2)) + 
    ':' + 
    cast(@Minute as varchar(2)) as datetime)
return @retval
end

go
</code></pre>

<p>To complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:</p>

<pre><code>where 
dbo.f_MakeDate(dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight
</code></pre>

<p>[Edit]</p>

<p>I'm incorporating @Todd's suggestion:</p>

<pre><code>where datediff(day, dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0
</code></pre>

<p>My misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.</p>

<p>But the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.</p>
","<p>Eric Z Beard:</p>

<blockquote>
  <p>I do store all dates in GMT. Here's the use case: something happened at 11:00 PM EST on the 1st, which is the 2nd GMT. I want to see activity for the 1st, and I am in EST so I will want to see the 11PM activity. If I just compared raw GMT datetimes, I would miss things. Each row in the report can represent an activity from a different time zone.</p>
</blockquote>

<p>Right, but when you say you're interested in activity for Jan 1st 2008 EST:</p>

<pre><code>SELECT @activityDateMidnight = '1/1/2008', @activityDateTZ = 'EST'
</code></pre>

<p>you just need to convert <em>that</em> to GMT (I'm ignoring the complication of querying for the day before EST goes to EDT, or vice versa):</p>

<pre><code>Table: TimeZone
Fields: TimeZone, Offset
Values: EST, -4

--Multiply by -1, since we're converting EST to GMT.
--Offsets are to go from GMT to EST.
SELECT @activityGmtBegin = DATEADD(hh, Offset * -1, @activityDateMidnight)
FROM TimeZone
WHERE TimeZone = @activityDateTZ
</code></pre>

<p>which should give you '1/1/2008 4:00 AM'. Then, you can just search in GMT:</p>

<pre><code>SELECT * FROM EventTable
WHERE 
   EventTime &gt;= @activityGmtBegin --1/1/2008 4:00 AM
   AND EventTime &lt; (@activityGmtBegin + 1) --1/2/2008 4:00 AM
</code></pre>

<p>The event in question is stored with a GMT EventTime of 1/2/2008 3:00 AM. You don't even need the TimeZone in the EventTable (for this purpose, at least). </p>

<p>Since EventTime is not in a function, this is a straight index scan - which should be pretty efficient. Make EventTime your clustered index, and it'll fly. ;)</p>

<p>Personally, I'd have the app convert the search time into GMT before running the query.</p>
"
423,189680,0,9,sql,Database localization,"<p>i am looking for opinions if the following problem maybe has a better/different/common solution:</p>

<p><hr /></p>

<p>I have a database for products which contains the names of the products in english (the default language of this application) and i need translations of the names if available.</p>

<p>Currently i have this setup:</p>

<p>A product table</p>

<pre><code>CREATE TABLE products
(
  id serial NOT NULL,
  ""name"" character varying(255) NOT NULL,
  CONSTRAINT products_pkey PRIMARY KEY (id)
)
</code></pre>

<p>and a product localization table</p>

<pre><code>CREATE TABLE products_l10n
(
  product_id serial NOT NULL,
  ""language"" character(2) NOT NULL,
  ""name"" character varying(255) NOT NULL,
  CONSTRAINT products_l10n_pkey PRIMARY KEY (product_id, language),
  CONSTRAINT products_l10n_product_id_fkey FOREIGN KEY (product_id)
      REFERENCES products (id) MATCH SIMPLE
      ON UPDATE CASCADE ON DELETE CASCADE
)
</code></pre>

<p>and i use the following query to retrieve a list of localized products (german in this case) with fallback to the default english names:</p>

<pre><code>SELECT p.id, COALESCE(pl.name, p.name) 
from products p LEFT 
JOIN products_l10n pl ON p.id = pl.product_id AND language = 'de';
</code></pre>

<p>The SQL code is in postgres dialect. Data is stored as UTF-8.</p>
","<p>Looks decent to me.</p>

<p>Obviously you should put the localized name into a Unicode column, which you could opt to put the English default into an ASCII field (assuming the database supports that).  It may be best to just do Unicode throughout and ""forget"" about it.</p>
"
1151,526460,1,9,sql,AutoIncrement fields on databases without autoincrement field,"<p>In MS Sql Server is easy create autoincrement fields. In my systems I stopped to use autoincrement fields for primary keys, and now I use Guid's. It was awesome, I've got a lot of advantages with that change. But in another non-primary key fields, I really was needing implement a ""soft autoincrement"". It's because my system is DB independent, so I create the autoinc value programatically in c#. </p>

<p>I would like about solutions for autoincrement fields on databases without autoincrement, what the solution that your use and why? There is some Sql Ansi statement about this? and generating directly from my c#, is a better solution?</p>

<p>PS: I know that <em>select max(id)+1 from table</em> it's not really concurrent friendly...</p>
","<p>The traditional solution is to have a table of ids  that look something like this</p>

<pre><code>CREATE TABLE ids (
  tablename VARCHAR(32) NOT NULL PRIMARY KEY,
  nextid INTEGER
)
</code></pre>

<p>which s populated with one row per table when you create the database.</p>

<p>You then do a select to get the next next id for the table you are inserting into, increment it and then update the table with the new id. Obviously, there are locking issues here, but for databases with moderate insert rates it works well. And it is completely portable.</p>
"
1150,526460,1,9,sql,AutoIncrement fields on databases without autoincrement field,"<p>In MS Sql Server is easy create autoincrement fields. In my systems I stopped to use autoincrement fields for primary keys, and now I use Guid's. It was awesome, I've got a lot of advantages with that change. But in another non-primary key fields, I really was needing implement a ""soft autoincrement"". It's because my system is DB independent, so I create the autoinc value programatically in c#. </p>

<p>I would like about solutions for autoincrement fields on databases without autoincrement, what the solution that your use and why? There is some Sql Ansi statement about this? and generating directly from my c#, is a better solution?</p>

<p>PS: I know that <em>select max(id)+1 from table</em> it's not really concurrent friendly...</p>
","<p>Most databases that don't have autoincrement fields like SQL Server (I'm thinking Oracle specifically) have sequences where you ask the Sequence for the next number.  No matter how many people are requesting numbers at the same time everyone gets a unique number.</p>
"
426,189680,0,9,sql,Database localization,"<p>i am looking for opinions if the following problem maybe has a better/different/common solution:</p>

<p><hr /></p>

<p>I have a database for products which contains the names of the products in english (the default language of this application) and i need translations of the names if available.</p>

<p>Currently i have this setup:</p>

<p>A product table</p>

<pre><code>CREATE TABLE products
(
  id serial NOT NULL,
  ""name"" character varying(255) NOT NULL,
  CONSTRAINT products_pkey PRIMARY KEY (id)
)
</code></pre>

<p>and a product localization table</p>

<pre><code>CREATE TABLE products_l10n
(
  product_id serial NOT NULL,
  ""language"" character(2) NOT NULL,
  ""name"" character varying(255) NOT NULL,
  CONSTRAINT products_l10n_pkey PRIMARY KEY (product_id, language),
  CONSTRAINT products_l10n_product_id_fkey FOREIGN KEY (product_id)
      REFERENCES products (id) MATCH SIMPLE
      ON UPDATE CASCADE ON DELETE CASCADE
)
</code></pre>

<p>and i use the following query to retrieve a list of localized products (german in this case) with fallback to the default english names:</p>

<pre><code>SELECT p.id, COALESCE(pl.name, p.name) 
from products p LEFT 
JOIN products_l10n pl ON p.id = pl.product_id AND language = 'de';
</code></pre>

<p>The SQL code is in postgres dialect. Data is stored as UTF-8.</p>
","<p>The only complicating factor that others have not mentioned is code sets - will you be able to handle Hebrew, Arabic, Russian, Chinese, Japanese?  If everything is Unicode, you only have to worry about GB18030 (Chinese), which is (IIUC) a superset of Unicode.</p>
"
425,189680,1,9,sql,Database localization,"<p>i am looking for opinions if the following problem maybe has a better/different/common solution:</p>

<p><hr /></p>

<p>I have a database for products which contains the names of the products in english (the default language of this application) and i need translations of the names if available.</p>

<p>Currently i have this setup:</p>

<p>A product table</p>

<pre><code>CREATE TABLE products
(
  id serial NOT NULL,
  ""name"" character varying(255) NOT NULL,
  CONSTRAINT products_pkey PRIMARY KEY (id)
)
</code></pre>

<p>and a product localization table</p>

<pre><code>CREATE TABLE products_l10n
(
  product_id serial NOT NULL,
  ""language"" character(2) NOT NULL,
  ""name"" character varying(255) NOT NULL,
  CONSTRAINT products_l10n_pkey PRIMARY KEY (product_id, language),
  CONSTRAINT products_l10n_product_id_fkey FOREIGN KEY (product_id)
      REFERENCES products (id) MATCH SIMPLE
      ON UPDATE CASCADE ON DELETE CASCADE
)
</code></pre>

<p>and i use the following query to retrieve a list of localized products (german in this case) with fallback to the default english names:</p>

<pre><code>SELECT p.id, COALESCE(pl.name, p.name) 
from products p LEFT 
JOIN products_l10n pl ON p.id = pl.product_id AND language = 'de';
</code></pre>

<p>The SQL code is in postgres dialect. Data is stored as UTF-8.</p>
","<p>The only variation I can offer is that you may also want to include country/dialect possibility; eg, instead of just English (en), use English US (en-US).  That way you can account for variations all the way (eg, British spellings, French Canadian probably has differences from the French spoken in France, etc).</p>
"
424,189680,1,9,sql,Database localization,"<p>i am looking for opinions if the following problem maybe has a better/different/common solution:</p>

<p><hr /></p>

<p>I have a database for products which contains the names of the products in english (the default language of this application) and i need translations of the names if available.</p>

<p>Currently i have this setup:</p>

<p>A product table</p>

<pre><code>CREATE TABLE products
(
  id serial NOT NULL,
  ""name"" character varying(255) NOT NULL,
  CONSTRAINT products_pkey PRIMARY KEY (id)
)
</code></pre>

<p>and a product localization table</p>

<pre><code>CREATE TABLE products_l10n
(
  product_id serial NOT NULL,
  ""language"" character(2) NOT NULL,
  ""name"" character varying(255) NOT NULL,
  CONSTRAINT products_l10n_pkey PRIMARY KEY (product_id, language),
  CONSTRAINT products_l10n_product_id_fkey FOREIGN KEY (product_id)
      REFERENCES products (id) MATCH SIMPLE
      ON UPDATE CASCADE ON DELETE CASCADE
)
</code></pre>

<p>and i use the following query to retrieve a list of localized products (german in this case) with fallback to the default english names:</p>

<pre><code>SELECT p.id, COALESCE(pl.name, p.name) 
from products p LEFT 
JOIN products_l10n pl ON p.id = pl.product_id AND language = 'de';
</code></pre>

<p>The SQL code is in postgres dialect. Data is stored as UTF-8.</p>
","<p>Looks good - similar to my preferred localization technique - what about wide characters (Japanese)?  We always used nvarchar to handle that.</p>

<p>What we actually found, however in our international purchasing operation, was that there was no consistency across international boundaries on products, since the suppliers in each country were different, so we internationalized/localized our interface, but the databases were completely distinct.</p>
"
55,22570,1,9,sql,What's a good way to check if two datetimes are on the same calendar day in TSQL?,"<p>Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.</p>

<p>In this case, merging the function code back into the query seems impractical.</p>

<p>I think I am missing something simple here.</p>

<p>Here's the function for reference.</p>

<pre><code>if not exists (select * from dbo.sysobjects 
              where id = object_id(N'dbo.f_MakeDate') and               
              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))
  exec('create function dbo.f_MakeDate() returns int as 
         begin declare @retval int return @retval end')
go

alter function dbo.f_MakeDate
(
    @Day datetime, 
    @Hour int, 
    @Minute int
)
returns datetime
as

/*

Creates a datetime using the year-month-day portion of @Day, and the 
@Hour and @Minute provided

*/

begin

declare @retval datetime
set @retval = cast(
    cast(datepart(m, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(d, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(yyyy, @Day) as varchar(4)) + 
    ' ' + 
    cast(@Hour as varchar(2)) + 
    ':' + 
    cast(@Minute as varchar(2)) as datetime)
return @retval
end

go
</code></pre>

<p>To complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:</p>

<pre><code>where 
dbo.f_MakeDate(dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight
</code></pre>

<p>[Edit]</p>

<p>I'm incorporating @Todd's suggestion:</p>

<pre><code>where datediff(day, dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0
</code></pre>

<p>My misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.</p>

<p>But the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.</p>
","<p>Eric Z Beard:</p>

<blockquote>
  <p>the activity date is meant to indicate the local time zone, but not a specific one</p>
</blockquote>

<p>Okay - back to the drawing board. Try this:</p>

<pre><code>where t.TheDateINeedToCheck BETWEEN (
    dateadd(hh, (tz.Offset + ISNULL(ds.LocalTimeZone, 0)) * -1, @ActivityDate)
    AND
    dateadd(hh, (tz.Offset + ISNULL(ds.LocalTimeZone, 0)) * -1, (@ActivityDate + 1))
)
</code></pre>

<p>which will translate the @ActivityDate to local time, and compare against that. That's your best chance for using an index, though I'm not sure it'll work - you should try it and check the query plan.</p>

<p>The next option would be an indexed view, with an indexed, computed TimeINeedToCheck <em>in local time</em>. Then you just go back to:</p>

<pre><code>where v.TheLocalDateINeedToCheck BETWEEN @ActivityDate AND (@ActivityDate + 1)
</code></pre>

<p>which would definitely use the index - though you have a slight overhead on INSERT and UPDATE then.</p>
"
54,22570,0,9,sql,What's a good way to check if two datetimes are on the same calendar day in TSQL?,"<p>Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.</p>

<p>In this case, merging the function code back into the query seems impractical.</p>

<p>I think I am missing something simple here.</p>

<p>Here's the function for reference.</p>

<pre><code>if not exists (select * from dbo.sysobjects 
              where id = object_id(N'dbo.f_MakeDate') and               
              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))
  exec('create function dbo.f_MakeDate() returns int as 
         begin declare @retval int return @retval end')
go

alter function dbo.f_MakeDate
(
    @Day datetime, 
    @Hour int, 
    @Minute int
)
returns datetime
as

/*

Creates a datetime using the year-month-day portion of @Day, and the 
@Hour and @Minute provided

*/

begin

declare @retval datetime
set @retval = cast(
    cast(datepart(m, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(d, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(yyyy, @Day) as varchar(4)) + 
    ' ' + 
    cast(@Hour as varchar(2)) + 
    ':' + 
    cast(@Minute as varchar(2)) as datetime)
return @retval
end

go
</code></pre>

<p>To complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:</p>

<pre><code>where 
dbo.f_MakeDate(dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight
</code></pre>

<p>[Edit]</p>

<p>I'm incorporating @Todd's suggestion:</p>

<pre><code>where datediff(day, dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0
</code></pre>

<p>My misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.</p>

<p>But the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.</p>
","<p>@Eric: No you won't miss anything. If you want to see what happened at 11pm EST, you look for things that happened at the corresponding time in GMT. If all the records are converted into GMT before saving, it shouldn't matter. So long as you convert the requested time (i.e. 11pm) to GMT before using it in the query.</p>
"
1152,526460,14,9,sql,AutoIncrement fields on databases without autoincrement field,"<p>In MS Sql Server is easy create autoincrement fields. In my systems I stopped to use autoincrement fields for primary keys, and now I use Guid's. It was awesome, I've got a lot of advantages with that change. But in another non-primary key fields, I really was needing implement a ""soft autoincrement"". It's because my system is DB independent, so I create the autoinc value programatically in c#. </p>

<p>I would like about solutions for autoincrement fields on databases without autoincrement, what the solution that your use and why? There is some Sql Ansi statement about this? and generating directly from my c#, is a better solution?</p>

<p>PS: I know that <em>select max(id)+1 from table</em> it's not really concurrent friendly...</p>
","<p>The mechanism to generate unique id values <strong>must not</strong> be subject to transaction isolation.  This is required for the database to generate a distinct value for each client, better than the trick of <code>SELECT MAX(id)+1 FROM table</code>, which results in a race condition if two clients try to allocate new <code>id</code> values concurrently.</p>

<p>You can't simulate this operation using standard SQL queries (unless you use table locks or <em>serializable</em> transactions).  It has to be a mechanism built into the database engine.</p>

<p>ANSI SQL did not describe an operation to generate unique values for surrogate keys until SQL:2003.  Before that, there was no standard for auto-incrementing columns, so nearly every brand of RDBMS provided some proprietary solution.  Naturally they vary a lot, and there's no way to use them in a simple, database-independent manner.</p>

<ul>
<li>MySQL has the <code>AUTO_INCREMENT</code> column option, or <code>SERIAL</code> pseudo-datatype which is equivalent to <code>BIGINT UNSIGNED AUTO_INCREMENT</code>;</li>
<li>Microsoft SQL Server has the <code>IDENTITY</code> column option and <code>NEWSEQUENTIALID()</code> which is something between auto-increment and GUID;</li>
<li>Oracle has a <code>SEQUENCE</code> object;</li>
<li>PostgreSQL has a <code>SEQUENCE</code> object, or <code>SERIAL</code> pseudo-datatype which implicitly creates a sequence object according to a naming convention;</li>
<li>InterBase/Firebird has a <code>GENERATOR</code> object which is pretty much like a <code>SEQUENCE</code> in Oracle;  Firebird 2.1 supports <code>SEQUENCE</code> too;</li>
<li>SQLite treats any integer declared as your primary key as implicitly auto-incrementing;</li>
<li>DB2 UDB has just about everything: <code>SEQUENCE</code> objects, or you can declare columns with the ""<code>GEN_ID</code>"" option.</li>
</ul>

<p>All these mechanisms operate outside transaction isolation, ensuring that concurrent clients get unique values.  Also in all cases there is a way to query the most recently generated value <em>for your current session</em>.  There has to be, so you can use it to insert rows in a child table.</p>
"
45,22570,4,9,sql,What's a good way to check if two datetimes are on the same calendar day in TSQL?,"<p>Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.</p>

<p>In this case, merging the function code back into the query seems impractical.</p>

<p>I think I am missing something simple here.</p>

<p>Here's the function for reference.</p>

<pre><code>if not exists (select * from dbo.sysobjects 
              where id = object_id(N'dbo.f_MakeDate') and               
              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))
  exec('create function dbo.f_MakeDate() returns int as 
         begin declare @retval int return @retval end')
go

alter function dbo.f_MakeDate
(
    @Day datetime, 
    @Hour int, 
    @Minute int
)
returns datetime
as

/*

Creates a datetime using the year-month-day portion of @Day, and the 
@Hour and @Minute provided

*/

begin

declare @retval datetime
set @retval = cast(
    cast(datepart(m, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(d, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(yyyy, @Day) as varchar(4)) + 
    ' ' + 
    cast(@Hour as varchar(2)) + 
    ':' + 
    cast(@Minute as varchar(2)) as datetime)
return @retval
end

go
</code></pre>

<p>To complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:</p>

<pre><code>where 
dbo.f_MakeDate(dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight
</code></pre>

<p>[Edit]</p>

<p>I'm incorporating @Todd's suggestion:</p>

<pre><code>where datediff(day, dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0
</code></pre>

<p>My misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.</p>

<p>But the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.</p>
","<pre><code>where
year(date1) = year(date2)
and month(date1) = month(date2)
and day(date1) = day(date2)
</code></pre>
"
48,22570,10,9,sql,What's a good way to check if two datetimes are on the same calendar day in TSQL?,"<p>Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.</p>

<p>In this case, merging the function code back into the query seems impractical.</p>

<p>I think I am missing something simple here.</p>

<p>Here's the function for reference.</p>

<pre><code>if not exists (select * from dbo.sysobjects 
              where id = object_id(N'dbo.f_MakeDate') and               
              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))
  exec('create function dbo.f_MakeDate() returns int as 
         begin declare @retval int return @retval end')
go

alter function dbo.f_MakeDate
(
    @Day datetime, 
    @Hour int, 
    @Minute int
)
returns datetime
as

/*

Creates a datetime using the year-month-day portion of @Day, and the 
@Hour and @Minute provided

*/

begin

declare @retval datetime
set @retval = cast(
    cast(datepart(m, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(d, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(yyyy, @Day) as varchar(4)) + 
    ' ' + 
    cast(@Hour as varchar(2)) + 
    ':' + 
    cast(@Minute as varchar(2)) as datetime)
return @retval
end

go
</code></pre>

<p>To complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:</p>

<pre><code>where 
dbo.f_MakeDate(dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight
</code></pre>

<p>[Edit]</p>

<p>I'm incorporating @Todd's suggestion:</p>

<pre><code>where datediff(day, dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0
</code></pre>

<p>My misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.</p>

<p>But the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.</p>
","<p>You pretty much have to keep the left side of your where clause clean. So, normally, you'd do something like:</p>

<pre><code>WHERE MyDateTime &gt;= @activityDateMidnight 
      AND MyDateTime &lt; (@activityDateMidnight + 1)
</code></pre>

<p>(Some folks prefer DATEADD(d, 1, @activityDateMidnight) instead - but it's the same thing).</p>

<p>The TimeZone table complicates matter a bit though. It's a little unclear from your snippet, but it looks like t.TheDateInTable is in GMT with a Time Zone identifier, and that you're then adding the offset to compare against @activityDateMidnight - which is in local time. I'm not sure what ds.LocalTimeZone is, though.</p>

<p>If that's the case, then you need to get @activityDateMidnight into GMT instead.</p>
"
50,22570,0,9,sql,What's a good way to check if two datetimes are on the same calendar day in TSQL?,"<p>Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.</p>

<p>In this case, merging the function code back into the query seems impractical.</p>

<p>I think I am missing something simple here.</p>

<p>Here's the function for reference.</p>

<pre><code>if not exists (select * from dbo.sysobjects 
              where id = object_id(N'dbo.f_MakeDate') and               
              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))
  exec('create function dbo.f_MakeDate() returns int as 
         begin declare @retval int return @retval end')
go

alter function dbo.f_MakeDate
(
    @Day datetime, 
    @Hour int, 
    @Minute int
)
returns datetime
as

/*

Creates a datetime using the year-month-day portion of @Day, and the 
@Hour and @Minute provided

*/

begin

declare @retval datetime
set @retval = cast(
    cast(datepart(m, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(d, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(yyyy, @Day) as varchar(4)) + 
    ' ' + 
    cast(@Hour as varchar(2)) + 
    ':' + 
    cast(@Minute as varchar(2)) as datetime)
return @retval
end

go
</code></pre>

<p>To complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:</p>

<pre><code>where 
dbo.f_MakeDate(dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight
</code></pre>

<p>[Edit]</p>

<p>I'm incorporating @Todd's suggestion:</p>

<pre><code>where datediff(day, dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0
</code></pre>

<p>My misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.</p>

<p>But the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.</p>
","<p>You're spoilt for choice in terms of options here. If you are using Sybase or SQL Server 2008 you can create variables of type date and assign them your datetime values. The database engine gets rid of the time for you. Here's a quick and dirty test to illustrate (Code is in Sybase dialect):</p>

<pre><code>declare @date1 date
declare @date2 date
set @date1='2008-1-1 10:00'
set @date2='2008-1-1 22:00'
if @date1=@date2
    print 'Equal'
else
    print 'Not equal'
</code></pre>

<p>For SQL 2005 and earlier what you can do is convert the date to a varchar in a format that does not have the time component. For instance the following returns 2008.08.22</p>

<pre><code>select convert(varchar,'2008-08-22 18:11:14.133',102)
</code></pre>

<p>The 102 part specifies the formatting (Books online can list for you all the available formats)</p>

<p>So, what you can do is write a function that takes a datetime and extracts the date element and discards the time. Like so:</p>

<pre><code>create function MakeDate (@InputDate datetime) returns datetime as
begin
    return cast(convert(varchar,@InputDate,102) as datetime);
end
</code></pre>

<p>You can then use the function for companions</p>

<pre><code>Select * from Orders where dbo.MakeDate(OrderDate) = dbo.MakeDate(DeliveryDate)
</code></pre>
"
51,22570,0,9,sql,What's a good way to check if two datetimes are on the same calendar day in TSQL?,"<p>Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.</p>

<p>In this case, merging the function code back into the query seems impractical.</p>

<p>I think I am missing something simple here.</p>

<p>Here's the function for reference.</p>

<pre><code>if not exists (select * from dbo.sysobjects 
              where id = object_id(N'dbo.f_MakeDate') and               
              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))
  exec('create function dbo.f_MakeDate() returns int as 
         begin declare @retval int return @retval end')
go

alter function dbo.f_MakeDate
(
    @Day datetime, 
    @Hour int, 
    @Minute int
)
returns datetime
as

/*

Creates a datetime using the year-month-day portion of @Day, and the 
@Hour and @Minute provided

*/

begin

declare @retval datetime
set @retval = cast(
    cast(datepart(m, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(d, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(yyyy, @Day) as varchar(4)) + 
    ' ' + 
    cast(@Hour as varchar(2)) + 
    ':' + 
    cast(@Minute as varchar(2)) as datetime)
return @retval
end

go
</code></pre>

<p>To complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:</p>

<pre><code>where 
dbo.f_MakeDate(dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight
</code></pre>

<p>[Edit]</p>

<p>I'm incorporating @Todd's suggestion:</p>

<pre><code>where datediff(day, dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0
</code></pre>

<p>My misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.</p>

<p>But the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.</p>
","<p>I would use the dayofyear function of datepart:</p>

<pre><code>
Select *
from mytable
where datepart(dy,date1) = datepart(dy,date2)
and
year(date1) = year(date2) --assuming you want the same year too
</code></pre>

<p>See the datepart reference <a href=""http://www.tizag.com/sqlTutorial/sqldatepart.php"" rel=""nofollow"">here</a>.</p>
"
780,350860,0,9,sql,How bad is ignoring Oracle DUP_VAL_ON_INDEX exception?,"<p>I have a table where I'm recording if a user has viewed an object at least once, hence:</p>

<pre><code> HasViewed
     ObjectID  number (FK to Object table)
     UserId    number (FK to Users table)
</code></pre>

<p>Both fields are NOT NULL and together form the Primary Key.</p>

<p>My question is, since I don't care how many times someone has viewed an object (after the first), I have two options for handling inserts.</p>

<ul>
<li>Do a SELECT count(*) ... and if no records are found, insert a new record.</li>
<li>Always just insert a record, and if it throws a DUP_VAL_ON_INDEX exceptions (indicating that there already was such a record), just ignore it.</li>
</ul>

<p>What's the downside of choosing the second option?</p>

<p>UPDATE:</p>

<p>I guess the best way to put it is : ""Is the overhead caused by the exception worse than the overhead caused by the initial select?""</p>
","<p>Usually, exception handling is slower; however if it would happen only seldom, then you would avoid the overhead of the query.<br>
I think it mainly depends on the frequency of the exception, but if performance is important, I would suggest some benchmarking with both approaches.</p>

<p>Generally speaking, treating common events as exception is a bad smell; for this reason you could see also from another point of view.<br>
If it is an exception, then it should be treated as an exception - and your approach is correct.<br>
If it is a common event, then you should try to explicitly handle it - and then checking if the record is already inserted.</p>
"
781,350860,13,9,sql,How bad is ignoring Oracle DUP_VAL_ON_INDEX exception?,"<p>I have a table where I'm recording if a user has viewed an object at least once, hence:</p>

<pre><code> HasViewed
     ObjectID  number (FK to Object table)
     UserId    number (FK to Users table)
</code></pre>

<p>Both fields are NOT NULL and together form the Primary Key.</p>

<p>My question is, since I don't care how many times someone has viewed an object (after the first), I have two options for handling inserts.</p>

<ul>
<li>Do a SELECT count(*) ... and if no records are found, insert a new record.</li>
<li>Always just insert a record, and if it throws a DUP_VAL_ON_INDEX exceptions (indicating that there already was such a record), just ignore it.</li>
</ul>

<p>What's the downside of choosing the second option?</p>

<p>UPDATE:</p>

<p>I guess the best way to put it is : ""Is the overhead caused by the exception worse than the overhead caused by the initial select?""</p>
","<p>I would normally just insert and trap the DUP_VAL_ON_INDEX exception, as this is the simplest to code.  This is more efficient than checking for existence before inserting.  I don't consider doing this a ""bad smell"" (horrible phrase!) because the exception we handle is raised by Oracle - it's not like raising your own exceptions as a flow-control mechanism.</p>

<p>Thanks to Igor's comment I have now run two different benchamrks on this: (1) where all insert attempts except the first are duplicates, (2) where all inserts are not duplicates.  Reality will lie somewhere between the two cases.</p>

<p>Note: tests performed on Oracle 10.2.0.3.0.</p>

<p><strong>Case 1: Mostly duplicates</strong></p>

<p>It seems that the most efficient approach (by a significant factor) is to check for existence WHILE inserting:</p>

<pre><code>prompt 1) Check DUP_VAL_ON_INDEX
begin
   for i in 1..1000 loop
      begin
         insert into hasviewed values(7782,20);
      exception
         when dup_val_on_index then
            null;
      end;
   end loop
   rollback;
end;
/

prompt 2) Test if row exists before inserting
declare
   dummy integer;
begin
   for i in 1..1000 loop
      select count(*) into dummy
      from hasviewed
      where objectid=7782 and userid=20;
      if dummy = 0 then
         insert into hasviewed values(7782,20);
      end if;
   end loop;
   rollback;
end;
/

prompt 3) Test if row exists while inserting
begin
   for i in 1..1000 loop
      insert into hasviewed
      select 7782,20 from dual
      where not exists (select null
                        from hasviewed
                        where objectid=7782 and userid=20);
   end loop;
   rollback;
end;
/
</code></pre>

<p>Results (after running once to avoid parsing overheads):</p>

<pre><code>1) Check DUP_VAL_ON_INDEX

PL/SQL procedure successfully completed.

Elapsed: 00:00:00.54
2) Test if row exists before inserting

PL/SQL procedure successfully completed.

Elapsed: 00:00:00.59
3) Test if row exists while inserting

PL/SQL procedure successfully completed.

Elapsed: 00:00:00.20
</code></pre>

<p><strong>Case 2: no duplicates</strong></p>

<pre><code>prompt 1) Check DUP_VAL_ON_INDEX
begin
   for i in 1..1000 loop
      begin
         insert into hasviewed values(7782,i);
      exception
         when dup_val_on_index then
            null;
      end;
   end loop
   rollback;
end;
/

prompt 2) Test if row exists before inserting
declare
   dummy integer;
begin
   for i in 1..1000 loop
      select count(*) into dummy
      from hasviewed
      where objectid=7782 and userid=i;
      if dummy = 0 then
         insert into hasviewed values(7782,i);
      end if;
   end loop;
   rollback;
end;
/

prompt 3) Test if row exists while inserting
begin
   for i in 1..1000 loop
      insert into hasviewed
      select 7782,i from dual
      where not exists (select null
                        from hasviewed
                        where objectid=7782 and userid=i);
   end loop;
   rollback;
end;
/
</code></pre>

<p>Results:</p>

<pre><code>1) Check DUP_VAL_ON_INDEX

PL/SQL procedure successfully completed.

Elapsed: 00:00:00.15
2) Test if row exists before inserting

PL/SQL procedure successfully completed.

Elapsed: 00:00:00.76
3) Test if row exists while inserting

PL/SQL procedure successfully completed.

Elapsed: 00:00:00.71
</code></pre>

<p>In this case DUP_VAL_ON_INDEX wins by a mile.  Note the ""select before insert"" is the slowest in both cases.</p>

<p>So it appears that you should choose option 1 or 3 according to the relative likelihood of inserts being or not being duplicates.  </p>
"
779,350860,1,9,sql,How bad is ignoring Oracle DUP_VAL_ON_INDEX exception?,"<p>I have a table where I'm recording if a user has viewed an object at least once, hence:</p>

<pre><code> HasViewed
     ObjectID  number (FK to Object table)
     UserId    number (FK to Users table)
</code></pre>

<p>Both fields are NOT NULL and together form the Primary Key.</p>

<p>My question is, since I don't care how many times someone has viewed an object (after the first), I have two options for handling inserts.</p>

<ul>
<li>Do a SELECT count(*) ... and if no records are found, insert a new record.</li>
<li>Always just insert a record, and if it throws a DUP_VAL_ON_INDEX exceptions (indicating that there already was such a record), just ignore it.</li>
</ul>

<p>What's the downside of choosing the second option?</p>

<p>UPDATE:</p>

<p>I guess the best way to put it is : ""Is the overhead caused by the exception worse than the overhead caused by the initial select?""</p>
","<p>Try this?</p>

<pre><code>SELECT 1
FROM TABLE
WHERE OBJECTID = 'PRON_172.JPG' AND
      USERID='JCURRAN'
</code></pre>

<p>It should return 1, if there is one there, otherwise NULL.</p>

<p>In your case, it looks safe to ignore, but for performance, one should avoid exceptions on the common path.  A question to ask, ""How common will the exceptions be?""
Few enough to ignore? or so many another method should be used?</p>
"
52,22570,0,9,sql,What's a good way to check if two datetimes are on the same calendar day in TSQL?,"<p>Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.</p>

<p>In this case, merging the function code back into the query seems impractical.</p>

<p>I think I am missing something simple here.</p>

<p>Here's the function for reference.</p>

<pre><code>if not exists (select * from dbo.sysobjects 
              where id = object_id(N'dbo.f_MakeDate') and               
              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))
  exec('create function dbo.f_MakeDate() returns int as 
         begin declare @retval int return @retval end')
go

alter function dbo.f_MakeDate
(
    @Day datetime, 
    @Hour int, 
    @Minute int
)
returns datetime
as

/*

Creates a datetime using the year-month-day portion of @Day, and the 
@Hour and @Minute provided

*/

begin

declare @retval datetime
set @retval = cast(
    cast(datepart(m, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(d, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(yyyy, @Day) as varchar(4)) + 
    ' ' + 
    cast(@Hour as varchar(2)) + 
    ':' + 
    cast(@Minute as varchar(2)) as datetime)
return @retval
end

go
</code></pre>

<p>To complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:</p>

<pre><code>where 
dbo.f_MakeDate(dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight
</code></pre>

<p>[Edit]</p>

<p>I'm incorporating @Todd's suggestion:</p>

<pre><code>where datediff(day, dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0
</code></pre>

<p>My misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.</p>

<p>But the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.</p>
","<p>Regarding timezones, yet one more reason to store all dates in a single timezone (preferably UTC). Anyway, I think the answers using datediff, datepart and the different built-in date functions are your best bet.</p>
"
46,22570,34,9,sql,What's a good way to check if two datetimes are on the same calendar day in TSQL?,"<p>Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.</p>

<p>In this case, merging the function code back into the query seems impractical.</p>

<p>I think I am missing something simple here.</p>

<p>Here's the function for reference.</p>

<pre><code>if not exists (select * from dbo.sysobjects 
              where id = object_id(N'dbo.f_MakeDate') and               
              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))
  exec('create function dbo.f_MakeDate() returns int as 
         begin declare @retval int return @retval end')
go

alter function dbo.f_MakeDate
(
    @Day datetime, 
    @Hour int, 
    @Minute int
)
returns datetime
as

/*

Creates a datetime using the year-month-day portion of @Day, and the 
@Hour and @Minute provided

*/

begin

declare @retval datetime
set @retval = cast(
    cast(datepart(m, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(d, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(yyyy, @Day) as varchar(4)) + 
    ' ' + 
    cast(@Hour as varchar(2)) + 
    ':' + 
    cast(@Minute as varchar(2)) as datetime)
return @retval
end

go
</code></pre>

<p>To complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:</p>

<pre><code>where 
dbo.f_MakeDate(dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight
</code></pre>

<p>[Edit]</p>

<p>I'm incorporating @Todd's suggestion:</p>

<pre><code>where datediff(day, dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0
</code></pre>

<p>My misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.</p>

<p>But the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.</p>
","<p>This is much more concise:</p>

<pre><code>where 
  datediff(day, date1, date2) = 0
</code></pre>
"
47,22570,1,9,sql,What's a good way to check if two datetimes are on the same calendar day in TSQL?,"<p>Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.</p>

<p>In this case, merging the function code back into the query seems impractical.</p>

<p>I think I am missing something simple here.</p>

<p>Here's the function for reference.</p>

<pre><code>if not exists (select * from dbo.sysobjects 
              where id = object_id(N'dbo.f_MakeDate') and               
              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))
  exec('create function dbo.f_MakeDate() returns int as 
         begin declare @retval int return @retval end')
go

alter function dbo.f_MakeDate
(
    @Day datetime, 
    @Hour int, 
    @Minute int
)
returns datetime
as

/*

Creates a datetime using the year-month-day portion of @Day, and the 
@Hour and @Minute provided

*/

begin

declare @retval datetime
set @retval = cast(
    cast(datepart(m, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(d, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(yyyy, @Day) as varchar(4)) + 
    ' ' + 
    cast(@Hour as varchar(2)) + 
    ':' + 
    cast(@Minute as varchar(2)) as datetime)
return @retval
end

go
</code></pre>

<p>To complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:</p>

<pre><code>where 
dbo.f_MakeDate(dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight
</code></pre>

<p>[Edit]</p>

<p>I'm incorporating @Todd's suggestion:</p>

<pre><code>where datediff(day, dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0
</code></pre>

<p>My misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.</p>

<p>But the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.</p>
","<p>this will remove time component from a date for you:  </p>

<pre><code>select dateadd(d, datediff(d, 0, current_timestamp), 0)
</code></pre>
"
778,350860,1,9,sql,How bad is ignoring Oracle DUP_VAL_ON_INDEX exception?,"<p>I have a table where I'm recording if a user has viewed an object at least once, hence:</p>

<pre><code> HasViewed
     ObjectID  number (FK to Object table)
     UserId    number (FK to Users table)
</code></pre>

<p>Both fields are NOT NULL and together form the Primary Key.</p>

<p>My question is, since I don't care how many times someone has viewed an object (after the first), I have two options for handling inserts.</p>

<ul>
<li>Do a SELECT count(*) ... and if no records are found, insert a new record.</li>
<li>Always just insert a record, and if it throws a DUP_VAL_ON_INDEX exceptions (indicating that there already was such a record), just ignore it.</li>
</ul>

<p>What's the downside of choosing the second option?</p>

<p>UPDATE:</p>

<p>I guess the best way to put it is : ""Is the overhead caused by the exception worse than the overhead caused by the initial select?""</p>
","<p>I don't think there is a downside to your second option.  I think it's a perfectly valid use of the named exception, plus it avoids the lookup overhead.</p>
"
301,137630,0,9,sql,Encapsulating SQL in a named_scope,"<p>I was wondering if there was a way to use ""find_by_sql"" within a named_scope. I'd like to treat custom sql as named_scope so I can chain it to my existing named_scopes. It would also be good for optimizing a sql snippet I use frequently.</p>
","<p>sure why not </p>

<p>:named_scope :conditions => [ your sql ]</p>
"
302,137630,10,9,sql,Encapsulating SQL in a named_scope,"<p>I was wondering if there was a way to use ""find_by_sql"" within a named_scope. I'd like to treat custom sql as named_scope so I can chain it to my existing named_scopes. It would also be good for optimizing a sql snippet I use frequently.</p>
","<p>While you can put any SQL you like in the conditions of a named scope, if you then call <code>find_by_sql</code> then the 'scopes' get thrown away.</p>

<p>Given:</p>

<pre><code>class Item
  # Anything you can put in an sql WHERE you can put here
  named_scope :mine, :conditions=&gt;'user_id = 12345 and IS_A_NINJA() = 1'
end
</code></pre>

<p>This works (it just sticks the SQL string in there - if you have more than one they get joined with AND)</p>

<pre><code>Item.mine.find :all
=&gt; SELECT * FROM items WHERE ('user_id' = 887 and IS_A_NINJA() = 1)
</code></pre>

<p>However, this doesn't</p>

<pre><code>Items.mine.find_by_sql 'select * from items limit 1'
=&gt; select * from items limit 1
</code></pre>

<p>So the answer is ""No"". If you think about what has to happen behind the scenes then this makes a lot of sense. In order to build the SQL rails has to know how it fits together.<br />
When you create normal queries, the <code>select</code>, <code>joins</code>, <code>conditions</code>, etc are all broken up into distinct pieces. Rails knows that it can add things to the conditions without affecting everything else (which is how <code>with_scope</code> and <code>named_scope</code> work).</p>

<p>With <code>find_by_sql</code> however, you just give rails a big string. It doesn't know what goes where, so it's not safe for it to go in and add the things it would need to add for the scopes to work.</p>
"
49,22570,3,9,sql,What's a good way to check if two datetimes are on the same calendar day in TSQL?,"<p>Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.</p>

<p>In this case, merging the function code back into the query seems impractical.</p>

<p>I think I am missing something simple here.</p>

<p>Here's the function for reference.</p>

<pre><code>if not exists (select * from dbo.sysobjects 
              where id = object_id(N'dbo.f_MakeDate') and               
              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))
  exec('create function dbo.f_MakeDate() returns int as 
         begin declare @retval int return @retval end')
go

alter function dbo.f_MakeDate
(
    @Day datetime, 
    @Hour int, 
    @Minute int
)
returns datetime
as

/*

Creates a datetime using the year-month-day portion of @Day, and the 
@Hour and @Minute provided

*/

begin

declare @retval datetime
set @retval = cast(
    cast(datepart(m, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(d, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(yyyy, @Day) as varchar(4)) + 
    ' ' + 
    cast(@Hour as varchar(2)) + 
    ':' + 
    cast(@Minute as varchar(2)) as datetime)
return @retval
end

go
</code></pre>

<p>To complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:</p>

<pre><code>where 
dbo.f_MakeDate(dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight
</code></pre>

<p>[Edit]</p>

<p>I'm incorporating @Todd's suggestion:</p>

<pre><code>where datediff(day, dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0
</code></pre>

<p>My misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.</p>

<p>But the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.</p>
","<p>Make sure to read <a href=""http://blogs.lessthandot.com/index.php/DataMgmt/DataDesign/only-in-a-database-can-you-get-1000-impr"" rel=""nofollow"">Only In A Database Can You Get 1000% + Improvement By Changing A Few Lines Of Code</a> so that you are sure that the optimizer can utilize the index effectively when messing with dates</p>
"
91,32360,0,8,sql,1:1 Foreign Key Constraints,"<p>How do you specify that a foreign key constraint should be a 1:1 relationship in transact sql? Is declaring the column UNIQUE enough? Below is my existing code.!</p>

<pre><code>CREATE TABLE [dbo].MyTable(
    [MyTablekey] INT IDENTITY(1,1) NOT FOR REPLICATION NOT NULL,
    [OtherTableKey] INT NOT NULL UNIQUE
        CONSTRAINT [FK_MyTable_OtherTable] FOREIGN KEY REFERENCES [dbo].[OtherTable]([OtherTableKey]),
    ...
    CONSTRAINT [PK_MyTable] PRIMARY KEY CLUSTERED 
    (
        [MyTableKey] ASC
    ) WITH (PAD_INDEX  = OFF, STATISTICS_NORECOMPUTE  = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS  = ON, ALLOW_PAGE_LOCKS  = ON) ON [PRIMARY]
) ON [PRIMARY]
GO
</code></pre>
","<p>Based on your code above, the unique constraint would be enough given that the for every primary key you have in the table, the unique constrained column is also unique.  Also, this assumes that in [OtherTable], the [OtherTableKey] column is the primary key of that table.</p>
"
636,277900,0,8,sql,How can I run sql server stored procedures in parallel?,"<p>I want to do something like:</p>

<pre><code>exec sproc1 and sproc2 at the same time
when they are both finished exec sproc3
</code></pre>

<p>I can do this in dts.
Is there a way to do it in transact sql?
Or is there a way to do it with a batch script (eg vbs or powershell)?</p>
","<p>You can use SSIS.  The benefits of this are that the package can be stored in the SQL Server and easily scheduled there.</p>

<p>From PowerShell or just about any external scripting language, you can use the SQL command line osql or sqlcmd.  This technique can also be used to schedule it on the SQL Server by shelling out using xp_cmdshell also.</p>
"
1009,461580,0,8,sql,Persistence solutions for C++ (with a SQL database)?,"<p>I'm wondering what kind of persistence solutions are there for C++ with a SQL database? In addition to doing things with custom SQL (and encapsulating the data access to DAOs or something similar), are there some other (more general) solutions?</p>

<p>Like some general libraries or frameworks (something like Hibernate &amp; co for Java and .NET) or something else? (Something that I haven't even thought of can also be welcome to be suggested)</p>

<p>EDIT: Yep, I was searching more for an ORM solution or something similar to handle sql queries and the relationships between tables and objects than for the db engine itself. Thanks for all the answers anyway!</p>
","<p>I use MYSQL or SQLite.</p>

<p>MYSQL: Provides a server based DB that your application must dynamically connect to.<br />
SQLite:Provides an in memory or file base DB.</p>

<p>Using the in memory DB is useful for quick development as setting up and configuring a DB server just for a single project is a big task. But once you have a DB server up and running it's just as easy to sue that.</p>

<p>In memory DB is useful for holding small DB such as configuration etc.
While for larger data sets a DB server is probably more practical.</p>

<p>Download from here: <a href=""http://dev.mysql.com/"" rel=""nofollow"">http://dev.mysql.com/</a><br />
Download from here: <a href=""http://www.sqlite.org/"" rel=""nofollow"">http://www.sqlite.org/</a>  </p>
"
321,139670,6,8,sql,Data in a table with carriage return?,"<p>In SQL SERVER Is it possible to store data with carriage return in a table and then retrieve it back again with carriage return.</p>

<p>Eg:</p>

<pre><code>insert into table values ('test1 

test2

test3

test4');
</code></pre>

<p>When I retrieve it, I get the message in a line </p>

<p>test1  test2  test3  test4</p>

<p>The carriage return is treated as a single character.</p>

<p>Is there way to get the carriage returns or its just the way its going to be stored?</p>

<p>Thanks for the help guys!!!</p>

<p>Edit: I should have explained this before. I get the data from the web development (asp .net) and I just insert it into the table. I might not be doing any data manipulation.. just insert.</p>

<p>I return the data to the app development (C++) and may be some data or report viewer.</p>

<p>I don't want to manipulate on the data.</p>
","<pre><code>insert into table values 
('test1' + CHAR(10) + 'test2' + CHAR(10) + 'test3' + CHAR(10) + 'test4')
</code></pre>

<p>should do it. To see the effect, switch the query result window to plain text output.</p>

<p>Regards</p>
"
320,139670,0,8,sql,Data in a table with carriage return?,"<p>In SQL SERVER Is it possible to store data with carriage return in a table and then retrieve it back again with carriage return.</p>

<p>Eg:</p>

<pre><code>insert into table values ('test1 

test2

test3

test4');
</code></pre>

<p>When I retrieve it, I get the message in a line </p>

<p>test1  test2  test3  test4</p>

<p>The carriage return is treated as a single character.</p>

<p>Is there way to get the carriage returns or its just the way its going to be stored?</p>

<p>Thanks for the help guys!!!</p>

<p>Edit: I should have explained this before. I get the data from the web development (asp .net) and I just insert it into the table. I might not be doing any data manipulation.. just insert.</p>

<p>I return the data to the app development (C++) and may be some data or report viewer.</p>

<p>I don't want to manipulate on the data.</p>
","<p>Is this result in your HTML or in Query analyser?  If it's in HTML, have a look at the source code and it might appear correct there, in which case you'd have to replace the crlf characters with <code>&lt;br /&gt;</code> tags.</p>

<p>I'm also thinking that there used to be attributes you could add to an HTML textarea to force it to send carriage returns in certain ways -- soft or hard?  I haven't looked that up, perhaps someone could do that.</p>

<p>But SQL Server does save the two characters in my experience.  In fact I did exactly as you described here a few days ago using SQL 2005 and each line break has two unprintable characters.</p>
"
319,139670,4,8,sql,Data in a table with carriage return?,"<p>In SQL SERVER Is it possible to store data with carriage return in a table and then retrieve it back again with carriage return.</p>

<p>Eg:</p>

<pre><code>insert into table values ('test1 

test2

test3

test4');
</code></pre>

<p>When I retrieve it, I get the message in a line </p>

<p>test1  test2  test3  test4</p>

<p>The carriage return is treated as a single character.</p>

<p>Is there way to get the carriage returns or its just the way its going to be stored?</p>

<p>Thanks for the help guys!!!</p>

<p>Edit: I should have explained this before. I get the data from the web development (asp .net) and I just insert it into the table. I might not be doing any data manipulation.. just insert.</p>

<p>I return the data to the app development (C++) and may be some data or report viewer.</p>

<p>I don't want to manipulate on the data.</p>
","<p>IIRC, using chr(13) + chr(10) should works.</p>

<pre><code>insert into table values ('test1' + chr(13) + chr(10) + 'test2' );
</code></pre>
"
318,139670,0,8,sql,Data in a table with carriage return?,"<p>In SQL SERVER Is it possible to store data with carriage return in a table and then retrieve it back again with carriage return.</p>

<p>Eg:</p>

<pre><code>insert into table values ('test1 

test2

test3

test4');
</code></pre>

<p>When I retrieve it, I get the message in a line </p>

<p>test1  test2  test3  test4</p>

<p>The carriage return is treated as a single character.</p>

<p>Is there way to get the carriage returns or its just the way its going to be stored?</p>

<p>Thanks for the help guys!!!</p>

<p>Edit: I should have explained this before. I get the data from the web development (asp .net) and I just insert it into the table. I might not be doing any data manipulation.. just insert.</p>

<p>I return the data to the app development (C++) and may be some data or report viewer.</p>

<p>I don't want to manipulate on the data.</p>
","<p>The carriage return is stored as is. The problem here is that your sql client is not understanding it. If you did a raw dump of this data you'll see that the carriage returns are there in the data.</p>

<p>I use DBArtisan at work and it seems to work fine. However isql seems to have the same problem that you reported.</p>
"
317,139670,24,8,sql,Data in a table with carriage return?,"<p>In SQL SERVER Is it possible to store data with carriage return in a table and then retrieve it back again with carriage return.</p>

<p>Eg:</p>

<pre><code>insert into table values ('test1 

test2

test3

test4');
</code></pre>

<p>When I retrieve it, I get the message in a line </p>

<p>test1  test2  test3  test4</p>

<p>The carriage return is treated as a single character.</p>

<p>Is there way to get the carriage returns or its just the way its going to be stored?</p>

<p>Thanks for the help guys!!!</p>

<p>Edit: I should have explained this before. I get the data from the web development (asp .net) and I just insert it into the table. I might not be doing any data manipulation.. just insert.</p>

<p>I return the data to the app development (C++) and may be some data or report viewer.</p>

<p>I don't want to manipulate on the data.</p>
","<p>You can store Carriage return in the database.  The problem here is that you are using SQL Server Management Studio to display the results of your query.  You probably have it configured to show the results in a grid.  Change the configuration of SSMS to show results to text and you will see the carriage returns.</p>

<p>Right click in the query window -> Results To -> Results To Text</p>

<p>Run your query again.</p>
"
316,139670,0,8,sql,Data in a table with carriage return?,"<p>In SQL SERVER Is it possible to store data with carriage return in a table and then retrieve it back again with carriage return.</p>

<p>Eg:</p>

<pre><code>insert into table values ('test1 

test2

test3

test4');
</code></pre>

<p>When I retrieve it, I get the message in a line </p>

<p>test1  test2  test3  test4</p>

<p>The carriage return is treated as a single character.</p>

<p>Is there way to get the carriage returns or its just the way its going to be stored?</p>

<p>Thanks for the help guys!!!</p>

<p>Edit: I should have explained this before. I get the data from the web development (asp .net) and I just insert it into the table. I might not be doing any data manipulation.. just insert.</p>

<p>I return the data to the app development (C++) and may be some data or report viewer.</p>

<p>I don't want to manipulate on the data.</p>
","<p>You might need to put in a ""\n"" instead of a literal carriage return. </p>
"
92,32360,9,8,sql,1:1 Foreign Key Constraints,"<p>How do you specify that a foreign key constraint should be a 1:1 relationship in transact sql? Is declaring the column UNIQUE enough? Below is my existing code.!</p>

<pre><code>CREATE TABLE [dbo].MyTable(
    [MyTablekey] INT IDENTITY(1,1) NOT FOR REPLICATION NOT NULL,
    [OtherTableKey] INT NOT NULL UNIQUE
        CONSTRAINT [FK_MyTable_OtherTable] FOREIGN KEY REFERENCES [dbo].[OtherTable]([OtherTableKey]),
    ...
    CONSTRAINT [PK_MyTable] PRIMARY KEY CLUSTERED 
    (
        [MyTableKey] ASC
    ) WITH (PAD_INDEX  = OFF, STATISTICS_NORECOMPUTE  = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS  = ON, ALLOW_PAGE_LOCKS  = ON) ON [PRIMARY]
) ON [PRIMARY]
GO
</code></pre>
","<p>A foreign key column with the UNIQUE and NOT NULL constraints that references a UNIQUE, NOT NULL column in another table creates a 1:(0|1) relationship, which is probably what you want.</p>

<p>If there was a true 1:1 relationship, every record in the first table would have a corresponding record in the second table and vice-versa. In that case, you would probably just want to make one table (unless you needed some strange storage optimization).</p>
"
634,277900,5,8,sql,How can I run sql server stored procedures in parallel?,"<p>I want to do something like:</p>

<pre><code>exec sproc1 and sproc2 at the same time
when they are both finished exec sproc3
</code></pre>

<p>I can do this in dts.
Is there a way to do it in transact sql?
Or is there a way to do it with a batch script (eg vbs or powershell)?</p>
","<p>You could create a CLR Stored Procedure that (using C#) would call the first two on their own threads, and then block until both are complete... then run the third one.</p>

<p>Are you able to use CLR sprocs in your situation? If so, I'll edit this answer to have more detail.</p>
"
94,32360,1,8,sql,1:1 Foreign Key Constraints,"<p>How do you specify that a foreign key constraint should be a 1:1 relationship in transact sql? Is declaring the column UNIQUE enough? Below is my existing code.!</p>

<pre><code>CREATE TABLE [dbo].MyTable(
    [MyTablekey] INT IDENTITY(1,1) NOT FOR REPLICATION NOT NULL,
    [OtherTableKey] INT NOT NULL UNIQUE
        CONSTRAINT [FK_MyTable_OtherTable] FOREIGN KEY REFERENCES [dbo].[OtherTable]([OtherTableKey]),
    ...
    CONSTRAINT [PK_MyTable] PRIMARY KEY CLUSTERED 
    (
        [MyTableKey] ASC
    ) WITH (PAD_INDEX  = OFF, STATISTICS_NORECOMPUTE  = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS  = ON, ALLOW_PAGE_LOCKS  = ON) ON [PRIMARY]
) ON [PRIMARY]
GO
</code></pre>
","<p>@bosnic:</p>

<blockquote>
  <p>You have a table CLIENT that has a 1:1 relationship with table SALES_OFFICE because, for example, the logic of your system says so. </p>
</blockquote>

<p>What your app logic says, and what your data model say are 2 different things. There is nothing wrong with enforcing that relationship with your business logic code, but it has no place in the data model.</p>

<blockquote>
  <p>Would you really incorporate the data of SALES_OFFICE into CLIENT table? </p>
</blockquote>

<p>If every CLIENT has a unique SALES_OFFICE, and every SALES_OFFICE has a singular, unique CLIENT - then yes, they should be in the same table. We just need a better name. ;)</p>

<blockquote>
  <p>And if another tables need to relate them selfs with SALES_OFFICE? </p>
</blockquote>

<p>There's no reason to. Relate your other tables to CLIENT, since CLIENT has a unique SALES_OFFICE. </p>

<blockquote>
  <p>And what about database normalization best practices and patterns?</p>
</blockquote>

<p>This <em>is</em> normalization.</p>

<p>To be fair, SALES_OFFICE and CLIENT is obviously not a 1:1 relationship - it's 1:N. Hopefully, your SALES_OFFICE exists to serve more than 1 client, and will continue to exist (for a while, at least) without any clients.</p>

<p>A more realistic example is SALES_OFFICE and ZIP_CODE. A SALES_OFFICE must have exactly 1 ZIP_CODE, and 2 SALES_OFFICEs - even if they have an equivalent ZIP_CODE - do not share the <em>instance</em> of a ZIP_CODE (so, changing the ZIP_CODE of 1 does not impact the other). Wouldn't you agree that ZIP_CODE belongs as a column in SALES_OFFICE?</p>
"
1008,461580,4,8,sql,Persistence solutions for C++ (with a SQL database)?,"<p>I'm wondering what kind of persistence solutions are there for C++ with a SQL database? In addition to doing things with custom SQL (and encapsulating the data access to DAOs or something similar), are there some other (more general) solutions?</p>

<p>Like some general libraries or frameworks (something like Hibernate &amp; co for Java and .NET) or something else? (Something that I haven't even thought of can also be welcome to be suggested)</p>

<p>EDIT: Yep, I was searching more for an ORM solution or something similar to handle sql queries and the relationships between tables and objects than for the db engine itself. Thanks for all the answers anyway!</p>
","<p>It sounds like you are looking for some ORM so that you don't have to bother with hand written SQL code.</p>

<p>There is a post <a href=""http://stackoverflow.com/questions/74141/good-orm-for-c-solutions"">here</a> that goes over ORM solutions for C++.</p>

<p>You also did not mention the type of application you are writing, if it is a desktop application, mobile application, server application.</p>

<p>Mobile: You are best off using SQLite as your database engine because it can be embedded and has a small footprint.</p>

<p>Desktop App: You should still consider using SQLite here, but you also have the option with most desktop applications to have an always on connection to the internet in which case you may want to provide a network server for this task.  I suggest using Apache + MySQL + PHP and using a lightweight ORM such as <a href=""http://www.outlet-orm.org/site/"" rel=""nofollow"">Outlet ORM</a>, and then using standard HTTP post calls to access your resources.</p>

<p>Server App: You have many more options here but I still suggest using Apache + MySQL + PHP + ORM because I find it is much easier to maintain this layer in a script language than in C++.</p>
"
1007,461580,7,8,sql,Persistence solutions for C++ (with a SQL database)?,"<p>I'm wondering what kind of persistence solutions are there for C++ with a SQL database? In addition to doing things with custom SQL (and encapsulating the data access to DAOs or something similar), are there some other (more general) solutions?</p>

<p>Like some general libraries or frameworks (something like Hibernate &amp; co for Java and .NET) or something else? (Something that I haven't even thought of can also be welcome to be suggested)</p>

<p>EDIT: Yep, I was searching more for an ORM solution or something similar to handle sql queries and the relationships between tables and objects than for the db engine itself. Thanks for all the answers anyway!</p>
","<p><a href=""http://www.sqlite.org/"">SQLite</a> is great: it's fast, stable, proven, and easy to use and integrate. </p>

<p>There is also <a href=""http://www.equi4.com/metakit/"">Metakit</a> although the learning curve is a bit steep. But I've used it with success in a professional project.</p>
"
93,32360,0,8,sql,1:1 Foreign Key Constraints,"<p>How do you specify that a foreign key constraint should be a 1:1 relationship in transact sql? Is declaring the column UNIQUE enough? Below is my existing code.!</p>

<pre><code>CREATE TABLE [dbo].MyTable(
    [MyTablekey] INT IDENTITY(1,1) NOT FOR REPLICATION NOT NULL,
    [OtherTableKey] INT NOT NULL UNIQUE
        CONSTRAINT [FK_MyTable_OtherTable] FOREIGN KEY REFERENCES [dbo].[OtherTable]([OtherTableKey]),
    ...
    CONSTRAINT [PK_MyTable] PRIMARY KEY CLUSTERED 
    (
        [MyTableKey] ASC
    ) WITH (PAD_INDEX  = OFF, STATISTICS_NORECOMPUTE  = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS  = ON, ALLOW_PAGE_LOCKS  = ON) ON [PRIMARY]
) ON [PRIMARY]
GO
</code></pre>
","<blockquote>
  <p>If there was a true 1:1 relationship, every record in the first table would have a corresponding record in the second table and vice-versa. In that case, you would probably just want to make one table (unless you needed some strange storage optimization).</p>
</blockquote>

<p>This is very incorrect. Let me give you an example. You have a table CLIENT that has a 1:1 relationship with table SALES_OFFICE because, for example, the logic of your system says so. Would you really incorporate the data of SALES_OFFICE into CLIENT table? And if another tables need to relate them selfs with SALES_OFFICE? And what about database normalization best practices and patterns?</p>

<blockquote>
  <p>A foreign key column with the UNIQUE and NOT NULL constraints that references a UNIQUE, NOT NULL column in another table creates a 1:(0|1) relationship, which is probably what you want.</p>
</blockquote>

<p>The first part of your answer is the right answer, without the second part, unless the data in second table is really a kind of information that belongs to first table and never will be used by other tables.</p>
"
315,139670,1,8,sql,Data in a table with carriage return?,"<p>In SQL SERVER Is it possible to store data with carriage return in a table and then retrieve it back again with carriage return.</p>

<p>Eg:</p>

<pre><code>insert into table values ('test1 

test2

test3

test4');
</code></pre>

<p>When I retrieve it, I get the message in a line </p>

<p>test1  test2  test3  test4</p>

<p>The carriage return is treated as a single character.</p>

<p>Is there way to get the carriage returns or its just the way its going to be stored?</p>

<p>Thanks for the help guys!!!</p>

<p>Edit: I should have explained this before. I get the data from the web development (asp .net) and I just insert it into the table. I might not be doing any data manipulation.. just insert.</p>

<p>I return the data to the app development (C++) and may be some data or report viewer.</p>

<p>I don't want to manipulate on the data.</p>
","<p>Can you please clarify how you retrieve the data back from the database? What tool do you use? The data probably contains the carriage returns but it's not displayed if you get the results in grid (try the results in text option)</p>
"
90,32360,4,8,sql,1:1 Foreign Key Constraints,"<p>How do you specify that a foreign key constraint should be a 1:1 relationship in transact sql? Is declaring the column UNIQUE enough? Below is my existing code.!</p>

<pre><code>CREATE TABLE [dbo].MyTable(
    [MyTablekey] INT IDENTITY(1,1) NOT FOR REPLICATION NOT NULL,
    [OtherTableKey] INT NOT NULL UNIQUE
        CONSTRAINT [FK_MyTable_OtherTable] FOREIGN KEY REFERENCES [dbo].[OtherTable]([OtherTableKey]),
    ...
    CONSTRAINT [PK_MyTable] PRIMARY KEY CLUSTERED 
    (
        [MyTableKey] ASC
    ) WITH (PAD_INDEX  = OFF, STATISTICS_NORECOMPUTE  = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS  = ON, ALLOW_PAGE_LOCKS  = ON) ON [PRIMARY]
) ON [PRIMARY]
GO
</code></pre>
","<p>You could declare the column to be both the primary key and a foreign key.  This is a good strategy for ""extension"" tables that are used to avoid putting nullable columns into the main table.</p>
"
635,277900,1,8,sql,How can I run sql server stored procedures in parallel?,"<p>I want to do something like:</p>

<pre><code>exec sproc1 and sproc2 at the same time
when they are both finished exec sproc3
</code></pre>

<p>I can do this in dts.
Is there a way to do it in transact sql?
Or is there a way to do it with a batch script (eg vbs or powershell)?</p>
","<p>Do you absolutely need both SPs to be executed in parallel?</p>

<p>With simple CRUD statements within a single SP, I've found SQL S. does a very good job of determining which of them can be run in parallel and do so. I've never seen SQL S. run 2 SPs in parallel if both are called sequentially from a T-SQL statement, don't even know if it's even possible.</p>

<p>Now then, do the DTS really execute them in parallel? It could be it simply executes them sequentially, then calls the 3rd SP after the last finishes successfully.</p>

<p>If it really runs them in parallel, probably you should stick with DTS, but then I'd like to know what it does if I have a DTS package call, say, 10 heavy duty SPs in parallel... I may have to do some testings to learn that myself :D</p>
"
881,398100,4,7,sql,"SQL Selecting ""Window"" Around Particular Row","<p>It's quite possible a question like this has been asked before, but I can't think of the terms to search for.</p>

<p>I'm working on a photo gallery application, and want to display 9 thumbnails showing the context of the current photo being shown (in a 3x3 grid with the current photo in the centre, unless the current photo is in the first 4 photos being shown, in which case if e.g. if the current photo is the 2nd I want to select photos 1 through 9). For example, given an album containing the list of photos with ids:</p>

<p>1, 5, 9, 12, 13, 18, 19, 20, 21, 22, 23, 25, 26</p>

<p>If the current photo is 19, I want to also view:</p>

<p>9, 12, 13, 18, 19, 20, 21, 22, 23</p>

<p>If the current photo is 5, I want to also view:</p>

<p>1, 5, 9, 12, 13, 18, 19, 20, 21</p>

<p>I've been thinking of something along the lines of:</p>

<pre><code>SELECT *
FROM photos
WHERE ABS(id - currentphoto) &lt; 5
ORDER BY id ASC 
LIMIT 25
</code></pre>

<p>but this doesn't work in the case where the ids are non-sequential (as in the example above), or for the case where there are insufficient photos before the currentphoto.</p>

<p>Any thoughts?</p>

<p>Thanks,</p>

<p>Dom</p>

<p>p.s. Please leave a comment if anything is unclear, and I'll clarify the question. If anyone can think of a more useful title to help other people find this question in future, then please comment too.</p>
","<p>Probably could just use a UNION, and then trim off the extra results in the procedural code that displays the results (as this will return 20 rows in the non-edge cases):</p>

<pre><code>(SELECT 
     * 
FROM photos
   WHERE ID &lt; #current_id#
   ORDER BY ID DESC LIMIT 10)
UNION
  (SELECT *
   FROM photos
   WHERE ID &gt;= #current_id#
   ORDER BY ID ASC LIMIT 10)
ORDER BY ID ASC
</code></pre>

<p>EDIT: Increased limit to 10 on both sides of the UNION, as suggested by <strong>le dorfier</strong>.</p>

<p>EDIT 2: Modified to better reflect final implementation, as suggested by Dominic.</p>
"
1142,524150,0,7,sql,Best Practice for PK in SQL Server,"<p>I have been wondering what the best practices or ramifications are in setting up the PK in a M2M table in SQL Server. For instance:</p>

<p>I have 2 tables</p>

<ul>
<li>Users</li>
<li>Roles</li>
</ul>

<p>I am making a new table</p>

<ul>
<li>UserRole</li>
</ul>

<p>Which has 2 fields
 RoleId &amp; UserID</p>

<p>now should I </p>

<ol>
<li>create a UserRoleID as the PK and make UserID and RoleID the FKs</li>
<li>make the PK UserID AND RoleID and set them as FKs</li>
<li>something else</li>
</ol>

<p>I would like to know the performance issues with each of the options and what the recommended best practices are.</p>
","<p>Avoid the composite PK and put a unique index on the two FKs (Seems appropriate in this instance.). Not an issue in this case, but be consistent. Having to remember to address the multiple fields to join on when writing queries is a pain. If your composite key has to be made up of datetime, char or other types of fields, performance takes a hit. </p>
"
1140,524150,0,7,sql,Best Practice for PK in SQL Server,"<p>I have been wondering what the best practices or ramifications are in setting up the PK in a M2M table in SQL Server. For instance:</p>

<p>I have 2 tables</p>

<ul>
<li>Users</li>
<li>Roles</li>
</ul>

<p>I am making a new table</p>

<ul>
<li>UserRole</li>
</ul>

<p>Which has 2 fields
 RoleId &amp; UserID</p>

<p>now should I </p>

<ol>
<li>create a UserRoleID as the PK and make UserID and RoleID the FKs</li>
<li>make the PK UserID AND RoleID and set them as FKs</li>
<li>something else</li>
</ol>

<p>I would like to know the performance issues with each of the options and what the recommended best practices are.</p>
","<p>It depends on how you are using them.  Most of the time I make the primary key as a UserId and a RoleId to make sure they are unique.  Meaning the same user cannot have the same role.</p>

<p>Now this is where the ""depends"" comes into play.  If you are going to link the UserRole table to another table, that is where I create the UserRoleId primary key.  And make the UserId and RoleId into a unique constraint.  </p>

<p>The reason for this is not to have on the table that references the UserRole have both a UserId and a RoleId when it is not needed because you are linking to the UserRoleId and not the User table and the role table respectively.</p>
"
1145,525690,1,7,sql,Large Text and Images In SQL,"<p>Is it a good idea to store large amounts of text (eg html pages) inside your SQL database? Or is it a better idea to store it as html files in the filesystem?</p>

<p>The same goes for images - is it a good idea to store image data in the database or better to put them on disk?</p>

<p>Will storing large amounts of data cause me performance problems for example? What are the pros and cons of each method of storage?</p>

<p>In terms of the size of data, in this case I am looking in the region of ""a few pages"" of HTML and images less than about 500kb in size (probably a lot smaller though). Enough to produce your average article/blog entry/etc scale web page.</p>
","<p>It's a matter of size. It depends on how big your images/text really are.</p>

<p>Storing these values in a DB has many advantages over a file-system based approach, but at a certain point it becomes inefficient. For example, I wouldn't store extremely high-resolution imagery in a DB.</p>

<p>So it's a question of degree, and that, in turn, means the answer depends on your HW resources and your system's architecture. So I don't believe there's one right answer to your question. Maybe you could tell us more about the details of what you're trying to store and what your servers look like.</p>
"
1146,525690,1,7,sql,Large Text and Images In SQL,"<p>Is it a good idea to store large amounts of text (eg html pages) inside your SQL database? Or is it a better idea to store it as html files in the filesystem?</p>

<p>The same goes for images - is it a good idea to store image data in the database or better to put them on disk?</p>

<p>Will storing large amounts of data cause me performance problems for example? What are the pros and cons of each method of storage?</p>

<p>In terms of the size of data, in this case I am looking in the region of ""a few pages"" of HTML and images less than about 500kb in size (probably a lot smaller though). Enough to produce your average article/blog entry/etc scale web page.</p>
","<p>I think you could argue either side, but I come down on the side of large amount of text is OK (and thus becomes searchable), but images should be stored as separate files with links in the database. I have never come up with any compelling reason to store images in the database, even though its possible.</p>
"
1147,525690,0,7,sql,Large Text and Images In SQL,"<p>Is it a good idea to store large amounts of text (eg html pages) inside your SQL database? Or is it a better idea to store it as html files in the filesystem?</p>

<p>The same goes for images - is it a good idea to store image data in the database or better to put them on disk?</p>

<p>Will storing large amounts of data cause me performance problems for example? What are the pros and cons of each method of storage?</p>

<p>In terms of the size of data, in this case I am looking in the region of ""a few pages"" of HTML and images less than about 500kb in size (probably a lot smaller though). Enough to produce your average article/blog entry/etc scale web page.</p>
","<p>It was one of my dilemmas when I used to program PHP. Storing images like blobs in the database can make easier to manage security and permissions, but it's costly. 
I always used to store some metadata on the database and the binary contents on the filesystem. Access to images was not direct (<code>&lt;img src=""image/path"" /&gt;</code>) but was provided by PHP scripts that checked the user authentication and authorizations through sessions before showing the image (<code>&lt;img src=""showimage.php?id=$id"" /&gt;</code>). I suggest you to do so (whatever kind of application you're working at).</p>
"
1148,525690,6,7,sql,Large Text and Images In SQL,"<p>Is it a good idea to store large amounts of text (eg html pages) inside your SQL database? Or is it a better idea to store it as html files in the filesystem?</p>

<p>The same goes for images - is it a good idea to store image data in the database or better to put them on disk?</p>

<p>Will storing large amounts of data cause me performance problems for example? What are the pros and cons of each method of storage?</p>

<p>In terms of the size of data, in this case I am looking in the region of ""a few pages"" of HTML and images less than about 500kb in size (probably a lot smaller though). Enough to produce your average article/blog entry/etc scale web page.</p>
","<p>Storing binary data (documents, images etc) in the database has some advantages.</p>

<ul>
<li><p>You can commit the update of the document itself in the same transaction as the information (name, date etc) you want to store about the document.  This means you don't have to worry about writing your own two-phase commit (although ISTR that SQL Server 2008 has a solution for this).</p></li>
<li><p>You can back up the whole lot (documents and metadata) at once, without worrying about having to synchronise the database with the file system</p></li>
<li><p>You can deliver documents very simply over .NET web services, since they come straight out into DataTables, and are serialised effortlessly just by putting the DataTables into a DataSet and passing it.</p></li>
<li><p>You can apply database security to the objects, as to the rest of your data, and not have to worry about network file permissions.</p></li>
</ul>

<p>It does have some disadvantages too:</p>

<ul>
<li><p>Backups can get very large</p></li>
<li><p>The size of the binary object in the database can be quite a bit larger than the file it originally came from, and therefore in a client-server environment, it can increase the time taken to open them across the network.</p></li>
<li><p>Depending on the application, you might need to consider the load on the database server if it has to serve up a lot of large documents.</p></li>
</ul>

<p>All that said, it's a technique I use extensively, and it works very well.</p>
"
541,243510,2,7,sql,Oracle PL/SQL Query Order By issue with Distinct,"<p>Does anyone know what is wrong with this query?</p>

<pre><code> SELECT DISTINCT c.CN as ClaimNumber, 
         a.ItemDate as BillReceivedDate, c.DTN as
 DocTrackNumber
         FROM ItemData a,
         ItemDataPage b,
         KeyGroupData c
         WHERE a.ItemTypeNum in (112, 113, 116, 172, 189)
         AND a.ItemNum = b.ItemNum
         AND b.ItemNum = c.ItemNum
         ORDER BY a.DateStored DESC;
</code></pre>

<p>I have done T-Sql most of my career and this looks correct to me, however this query is for an Oracle database and Toad just places the cursor on the a.DateStored in the Order By section. I'm sure this is elementary for anyone doing PL/SQL.</p>

<p>Thanks!</p>

<p>[EDIT] For future reference, the error given by SQL*Plus was: ""ORA-01791: not a SELECTed expression""  </p>
","<p>I believe that the elements of the order by clause must also be in the select clause.</p>
"
540,243510,15,7,sql,Oracle PL/SQL Query Order By issue with Distinct,"<p>Does anyone know what is wrong with this query?</p>

<pre><code> SELECT DISTINCT c.CN as ClaimNumber, 
         a.ItemDate as BillReceivedDate, c.DTN as
 DocTrackNumber
         FROM ItemData a,
         ItemDataPage b,
         KeyGroupData c
         WHERE a.ItemTypeNum in (112, 113, 116, 172, 189)
         AND a.ItemNum = b.ItemNum
         AND b.ItemNum = c.ItemNum
         ORDER BY a.DateStored DESC;
</code></pre>

<p>I have done T-Sql most of my career and this looks correct to me, however this query is for an Oracle database and Toad just places the cursor on the a.DateStored in the Order By section. I'm sure this is elementary for anyone doing PL/SQL.</p>

<p>Thanks!</p>

<p>[EDIT] For future reference, the error given by SQL*Plus was: ""ORA-01791: not a SELECTed expression""  </p>
","<p>You will need to modify the query as such:</p>

<pre><code>SELECT DISTINCT c.CN as ClaimNumber, 
         a.ItemDate as BillReceivedDate, c.DTN as
 DocTrackNumber, a.DateStored
         FROM ItemData a,
         ItemDataPage b,
         KeyGroupData c
         WHERE a.ItemTypeNum in (112, 113, 116, 172, 189)
         AND a.ItemNum = b.ItemNum
         AND b.ItemNum = c.ItemNum
         ORDER BY a.DateStored DESC;
</code></pre>

<p>When doing a DISTINCT your order by needs to be one of the selected columns.</p>
"
1139,524150,10,7,sql,Best Practice for PK in SQL Server,"<p>I have been wondering what the best practices or ramifications are in setting up the PK in a M2M table in SQL Server. For instance:</p>

<p>I have 2 tables</p>

<ul>
<li>Users</li>
<li>Roles</li>
</ul>

<p>I am making a new table</p>

<ul>
<li>UserRole</li>
</ul>

<p>Which has 2 fields
 RoleId &amp; UserID</p>

<p>now should I </p>

<ol>
<li>create a UserRoleID as the PK and make UserID and RoleID the FKs</li>
<li>make the PK UserID AND RoleID and set them as FKs</li>
<li>something else</li>
</ol>

<p>I would like to know the performance issues with each of the options and what the recommended best practices are.</p>
","<p>Standard procedure for these cases is to have two indexes. The unique PK is the two fields composite, with the field with the greater cardinality first, i.e. UserID; and the second index with just the secondary field (i.e. RoleID).</p>

<p>Then cluster on whichever is likely to be involved in more multirecord result sets (i.e. if querying for multiple roles per user, or multiple users per role).</p>
"
855,378040,1,7,sql,Recursive sql problem,"<p>I have a problem that I would like have solved via a SQL query. This is going to
be used as a PoC (proof of concept).</p>

<p>The problem:</p>

<p>Product offerings are made up of one or many product instances, a product
instance can belong to many product offerings.
This can be realised like this in a table:</p>

<pre><code>PO | PI

-----

A | 10

A | 11

A | 12

B | 10

B | 11

C | 13
</code></pre>

<p>Now I would like to get back the product offer from a set of product instances.
E.g. if we send in 10,11,13 the expected result back is B &amp; C, and if we send in
only 10 then the result should be NULL since no product offering is made up of
only 10. Sending in 10,11,12 would result in A (not A &amp; B since 12 is not a valid product offer in it self).</p>

<p>Prerequisites:
The combination of product instances sent in can only result in one specific
combination of product offerings, so there is only one solution to each query.</p>
","<p>I don't have a db in front of me, but off the top of my head you want the list of POs that don't have any PIs not in your input list, ie  </p>

<pre><code>select distinct po 
from tbl 
where po not in ( select po from tbl where pi not in (10,11,13) )
</code></pre>

<p>Edit: Here are the example other cases:<br />
When input PI = 10,11,13 the inner select returns A so the outer select returns B, C<br />
When input PI = 10 the inner select returns A,B,C so the outer select returns no rows<br />
When input PI = 10,11,12 the inner select returns C so the outer select returns A,B</p>

<p>Edit: Adam has pointed out that this last case doesn't meet the requirement of only returning A (that'll teach me for rushing), so this isn't yet working code.</p>
"
16,4110,2,7,sql,What program can I use to generate diagrams of SQL view/table structure?,"<p>I've been tasked with redesigning part of a ms-sql database structure which currently involves a lot of views, some of which contain joins to other views. </p>

<p>Anyway, I wonder if anyone here could recommend a utility to automatically generate diagrams to help me visualise the whole structure.</p>

<p>What's the best program you've used for such problems?</p>
","<p>Toad Data Modeller from Quest does a nice job on this and is reasonably priced.  Embarcadero E/R studio is good too, as Bruce mentioned.</p>"
17,4110,1,7,sql,What program can I use to generate diagrams of SQL view/table structure?,"<p>I've been tasked with redesigning part of a ms-sql database structure which currently involves a lot of views, some of which contain joins to other views. </p>

<p>Anyway, I wonder if anyone here could recommend a utility to automatically generate diagrams to help me visualise the whole structure.</p>

<p>What's the best program you've used for such problems?</p>
","<P>OP asked about diagramming views and view dependencies, SQL Management Studio and Enterprise Manager doesn't allow you to diagram views. I can't vouch for the other tools.</P>
<P>The LINQ to SQL designer for Visual Studio does allow you to drop views on the design surface but there isn't a easy way to model the dependencies between the views. I'm not sure which tool has this type of diagramming functionality. You could take a look at Red Gate's SQLDoc tool but it just provides text based output.</P>"
18,4110,0,7,sql,What program can I use to generate diagrams of SQL view/table structure?,"<p>I've been tasked with redesigning part of a ms-sql database structure which currently involves a lot of views, some of which contain joins to other views. </p>

<p>Anyway, I wonder if anyone here could recommend a utility to automatically generate diagrams to help me visualise the whole structure.</p>

<p>What's the best program you've used for such problems?</p>
","<p>I upmodded Mark's post about Toad Data Modeler and wanted to point out that they have a beta version that is fully functional and free. The only downsides are the occasional bug and built in expiration (typically around the time a new beta is available), but for this poor bloke it does wonders until I can get my boss to chip in for a license.</p>
"
14,4110,0,7,sql,What program can I use to generate diagrams of SQL view/table structure?,"<p>I've been tasked with redesigning part of a ms-sql database structure which currently involves a lot of views, some of which contain joins to other views. </p>

<p>Anyway, I wonder if anyone here could recommend a utility to automatically generate diagrams to help me visualise the whole structure.</p>

<p>What's the best program you've used for such problems?</p>
","<P>If you are talking about MS SQL Server tables, I like the diagram support in SQL Server Management Studio. You just drag the tables from the explorer onto the canvas, and they are laid out for you along with lines for relationships. You'll have to do some adjusting by hand for the best looking diagrams, but it is a decent way to get diagrams.</P>"
539,243510,2,7,sql,Oracle PL/SQL Query Order By issue with Distinct,"<p>Does anyone know what is wrong with this query?</p>

<pre><code> SELECT DISTINCT c.CN as ClaimNumber, 
         a.ItemDate as BillReceivedDate, c.DTN as
 DocTrackNumber
         FROM ItemData a,
         ItemDataPage b,
         KeyGroupData c
         WHERE a.ItemTypeNum in (112, 113, 116, 172, 189)
         AND a.ItemNum = b.ItemNum
         AND b.ItemNum = c.ItemNum
         ORDER BY a.DateStored DESC;
</code></pre>

<p>I have done T-Sql most of my career and this looks correct to me, however this query is for an Oracle database and Toad just places the cursor on the a.DateStored in the Order By section. I'm sure this is elementary for anyone doing PL/SQL.</p>

<p>Thanks!</p>

<p>[EDIT] For future reference, the error given by SQL*Plus was: ""ORA-01791: not a SELECTed expression""  </p>
","<p>Nevermind, executing in SQL Plus gave me a more informative answer. The DateStored needs to be in the select statement so this works:</p>

<pre><code>    SELECT DISTINCT c.CN as ClaimNumber,          
a.ItemDate as BillReceivedDate, 
c.DTN as DocTrackNumber, 
a.DateStored         
FROM ItemData a,         
ItemDataPage b,         
KeyGroupData c         
WHERE a.ItemTypeNum in (112, 113, 116, 172, 189)         
AND a.ItemNum = b.ItemNum         
AND b.ItemNum = c.ItemNum         
ORDER BY a.DateStored DESC;
</code></pre>
"
1149,525690,1,7,sql,Large Text and Images In SQL,"<p>Is it a good idea to store large amounts of text (eg html pages) inside your SQL database? Or is it a better idea to store it as html files in the filesystem?</p>

<p>The same goes for images - is it a good idea to store image data in the database or better to put them on disk?</p>

<p>Will storing large amounts of data cause me performance problems for example? What are the pros and cons of each method of storage?</p>

<p>In terms of the size of data, in this case I am looking in the region of ""a few pages"" of HTML and images less than about 500kb in size (probably a lot smaller though). Enough to produce your average article/blog entry/etc scale web page.</p>
","<p>Something else to consider is how often these large chunks of text and images will be changing.  Changes to data are what cause fragmentation.  Fragmentation can occur both in your data files and your database structure.  A file system is much more suited to handle fragmentation than a database.  The more often a file changes, the quicker the system will fragment.</p>
"
1141,524150,2,7,sql,Best Practice for PK in SQL Server,"<p>I have been wondering what the best practices or ramifications are in setting up the PK in a M2M table in SQL Server. For instance:</p>

<p>I have 2 tables</p>

<ul>
<li>Users</li>
<li>Roles</li>
</ul>

<p>I am making a new table</p>

<ul>
<li>UserRole</li>
</ul>

<p>Which has 2 fields
 RoleId &amp; UserID</p>

<p>now should I </p>

<ol>
<li>create a UserRoleID as the PK and make UserID and RoleID the FKs</li>
<li>make the PK UserID AND RoleID and set them as FKs</li>
<li>something else</li>
</ol>

<p>I would like to know the performance issues with each of the options and what the recommended best practices are.</p>
","<p>Declare the PK as (UserID, RoleID).   (Note:  the order is important)</p>

<p>Declare UserID as an FK with the reference to the Users table.
Declare RoleID as an FK with the reference to the Roles table.</p>

<p>With any luck, your DBMS will give you a composite index on (UserID, RoleID)  in that order.</p>

<p>With any luck this will speed up joins between users and roles.  A good DBMS will give you a merge join for a join with no restrictions other than the join condition.  A three way join should run pretty fast as well,  assuming the number of roles is small.</p>

<p>When you join UserRoles and Roles,  without joining in Users,  you may find it's disappointingly slow.  How often do you do that,  and how important is speed in this case?  If it is important,  you can create an index on just RoleID.</p>
"
865,378040,1,7,sql,Recursive sql problem,"<p>I have a problem that I would like have solved via a SQL query. This is going to
be used as a PoC (proof of concept).</p>

<p>The problem:</p>

<p>Product offerings are made up of one or many product instances, a product
instance can belong to many product offerings.
This can be realised like this in a table:</p>

<pre><code>PO | PI

-----

A | 10

A | 11

A | 12

B | 10

B | 11

C | 13
</code></pre>

<p>Now I would like to get back the product offer from a set of product instances.
E.g. if we send in 10,11,13 the expected result back is B &amp; C, and if we send in
only 10 then the result should be NULL since no product offering is made up of
only 10. Sending in 10,11,12 would result in A (not A &amp; B since 12 is not a valid product offer in it self).</p>

<p>Prerequisites:
The combination of product instances sent in can only result in one specific
combination of product offerings, so there is only one solution to each query.</p>
","<p>Is it possible that a customers asks for a product more than once? </p>

<p>For example: he/she asks an offering for 10,10,11,11,12? </p>

<p>If this is possible than solutions like </p>

<p>select ...
from   ...
where  pi in (10,10,11,11,12) </p>

<p>will not work. </p>

<p>Because 'pi in (10,10,11,11,12)' is the same as 'pi in (10,11,12)'. </p>

<p>A solution for 10,10,11,11,12 is A&amp;B. </p>
"
880,398100,1,7,sql,"SQL Selecting ""Window"" Around Particular Row","<p>It's quite possible a question like this has been asked before, but I can't think of the terms to search for.</p>

<p>I'm working on a photo gallery application, and want to display 9 thumbnails showing the context of the current photo being shown (in a 3x3 grid with the current photo in the centre, unless the current photo is in the first 4 photos being shown, in which case if e.g. if the current photo is the 2nd I want to select photos 1 through 9). For example, given an album containing the list of photos with ids:</p>

<p>1, 5, 9, 12, 13, 18, 19, 20, 21, 22, 23, 25, 26</p>

<p>If the current photo is 19, I want to also view:</p>

<p>9, 12, 13, 18, 19, 20, 21, 22, 23</p>

<p>If the current photo is 5, I want to also view:</p>

<p>1, 5, 9, 12, 13, 18, 19, 20, 21</p>

<p>I've been thinking of something along the lines of:</p>

<pre><code>SELECT *
FROM photos
WHERE ABS(id - currentphoto) &lt; 5
ORDER BY id ASC 
LIMIT 25
</code></pre>

<p>but this doesn't work in the case where the ids are non-sequential (as in the example above), or for the case where there are insufficient photos before the currentphoto.</p>

<p>Any thoughts?</p>

<p>Thanks,</p>

<p>Dom</p>

<p>p.s. Please leave a comment if anything is unclear, and I'll clarify the question. If anyone can think of a more useful title to help other people find this question in future, then please comment too.</p>
","<p>If you are using SQL Server, you can use the row_number() function to give you the row order index and do something like this:</p>

<pre><code>declare @selected_photo integer;
set @selected_photo = 5;

declare @buffer_size integer;
set @buffer_size = 2;

select
   ph.rownum,
   ph.id
from
   (select row_number() over (order by Id) as rownum, * from Photos) as ph
where
   ph.rownum between case
                         when @selected_photo - @buffer_size &lt; 1 then 1
                         else @selected_photo - @buffer_size
                      end
                      and @selected_photo + @buffer_size
</code></pre>

<p>Edit:
Here is an article on simulating the row_number() function in MySQL, combining that with
this might get you what you need - I'd try it but don't have a MySQL db handy to play with at work. :-)</p>

<p><a href=""http://www.xaprb.com/blog/2006/12/02/how-to-number-rows-in-mysql/"" rel=""nofollow"">http://www.xaprb.com/blog/2006/12/02/how-to-number-rows-in-mysql/</a></p>
"
864,378040,0,7,sql,Recursive sql problem,"<p>I have a problem that I would like have solved via a SQL query. This is going to
be used as a PoC (proof of concept).</p>

<p>The problem:</p>

<p>Product offerings are made up of one or many product instances, a product
instance can belong to many product offerings.
This can be realised like this in a table:</p>

<pre><code>PO | PI

-----

A | 10

A | 11

A | 12

B | 10

B | 11

C | 13
</code></pre>

<p>Now I would like to get back the product offer from a set of product instances.
E.g. if we send in 10,11,13 the expected result back is B &amp; C, and if we send in
only 10 then the result should be NULL since no product offering is made up of
only 10. Sending in 10,11,12 would result in A (not A &amp; B since 12 is not a valid product offer in it self).</p>

<p>Prerequisites:
The combination of product instances sent in can only result in one specific
combination of product offerings, so there is only one solution to each query.</p>
","<p>SELECT DISTINCT COALESCE ( offer, NULL )
FROM products
WHERE instance IN ( @instancelist )</p>
"
879,398100,0,7,sql,"SQL Selecting ""Window"" Around Particular Row","<p>It's quite possible a question like this has been asked before, but I can't think of the terms to search for.</p>

<p>I'm working on a photo gallery application, and want to display 9 thumbnails showing the context of the current photo being shown (in a 3x3 grid with the current photo in the centre, unless the current photo is in the first 4 photos being shown, in which case if e.g. if the current photo is the 2nd I want to select photos 1 through 9). For example, given an album containing the list of photos with ids:</p>

<p>1, 5, 9, 12, 13, 18, 19, 20, 21, 22, 23, 25, 26</p>

<p>If the current photo is 19, I want to also view:</p>

<p>9, 12, 13, 18, 19, 20, 21, 22, 23</p>

<p>If the current photo is 5, I want to also view:</p>

<p>1, 5, 9, 12, 13, 18, 19, 20, 21</p>

<p>I've been thinking of something along the lines of:</p>

<pre><code>SELECT *
FROM photos
WHERE ABS(id - currentphoto) &lt; 5
ORDER BY id ASC 
LIMIT 25
</code></pre>

<p>but this doesn't work in the case where the ids are non-sequential (as in the example above), or for the case where there are insufficient photos before the currentphoto.</p>

<p>Any thoughts?</p>

<p>Thanks,</p>

<p>Dom</p>

<p>p.s. Please leave a comment if anything is unclear, and I'll clarify the question. If anyone can think of a more useful title to help other people find this question in future, then please comment too.</p>
","<p>This is standard ""Row ordering"" problem... If your database has rowId capability you can use that, otherwise you need a subquery that counts the numnber of rows with Ids less than the id of the current row... like this:</p>

<p>-- asssuming @Id is value of id in the ""middle""</p>

<pre><code> Select *  From Photos P
 Where (Select Count(*) From Photos
         Where id &lt;= P.Id)
     Between (Select Count(*) From Photos
              Where id &lt; @Id) - 4
        And  (Select Count(*) From Photos
              Where id &lt; @Id) + 4
</code></pre>

<p>As a comment raised the album issue you would want to add album predicate to each subquery</p>

<pre><code>   Select *  From Photos P
   Where (Select Count(*) From Photos
          Where album = @album
            And id &lt;= P.Id)
     Between (Select Case When Count(*) &lt; 4 
                      Then 4 Else Count(*) End
              From Photos
              Where album = @album
                 And id &lt; @Id) - 4
        And  (Select Case When Count(*) &lt; 4 
                      Then 4 Else Count(*) End
              From Photos
              Where album = @album
                  And id &lt; @Id) + 4
</code></pre>
"
15,4110,2,7,sql,What program can I use to generate diagrams of SQL view/table structure?,"<p>I've been tasked with redesigning part of a ms-sql database structure which currently involves a lot of views, some of which contain joins to other views. </p>

<p>Anyway, I wonder if anyone here could recommend a utility to automatically generate diagrams to help me visualise the whole structure.</p>

<p>What's the best program you've used for such problems?</p>
","<p>I am a big fan of Embarcadero's <a href=""http://www.embarcadero.com/products/er-studio"" rel=""nofollow"">ER/Studio</a>.  It is very powerful and produces excellent on-screen as well as printed results.  They have a free trial as well, so you should be able to get in and give it a shot without too much strife.</p>

<p>Good luck!</p>
"
1144,525690,2,7,sql,Large Text and Images In SQL,"<p>Is it a good idea to store large amounts of text (eg html pages) inside your SQL database? Or is it a better idea to store it as html files in the filesystem?</p>

<p>The same goes for images - is it a good idea to store image data in the database or better to put them on disk?</p>

<p>Will storing large amounts of data cause me performance problems for example? What are the pros and cons of each method of storage?</p>

<p>In terms of the size of data, in this case I am looking in the region of ""a few pages"" of HTML and images less than about 500kb in size (probably a lot smaller though). Enough to produce your average article/blog entry/etc scale web page.</p>
","<p>The more you put in, the more you will be moving around so the more overhead you will be creating.</p>

<p>If you have a great web server, no point in adding all of the extra stress to the database for no reason when you can delegate all of that stress to the web server.</p>

<p>Even from a maintenance point of view, it is a lot easier to move around and work with the files in a nice logical structure rather then constantly working with the database.</p>
"
856,378040,0,7,sql,Recursive sql problem,"<p>I have a problem that I would like have solved via a SQL query. This is going to
be used as a PoC (proof of concept).</p>

<p>The problem:</p>

<p>Product offerings are made up of one or many product instances, a product
instance can belong to many product offerings.
This can be realised like this in a table:</p>

<pre><code>PO | PI

-----

A | 10

A | 11

A | 12

B | 10

B | 11

C | 13
</code></pre>

<p>Now I would like to get back the product offer from a set of product instances.
E.g. if we send in 10,11,13 the expected result back is B &amp; C, and if we send in
only 10 then the result should be NULL since no product offering is made up of
only 10. Sending in 10,11,12 would result in A (not A &amp; B since 12 is not a valid product offer in it self).</p>

<p>Prerequisites:
The combination of product instances sent in can only result in one specific
combination of product offerings, so there is only one solution to each query.</p>
","<p>well some pseudo code from the top of my head here:</p>

<p>select from table where PI = 10 or pi =11, etc</p>

<p>store the result in a temp table</p>

<p>select distinct PO and count(PI) from temp table.</p>

<p>now for each PO you can get the total available PI offerings. if the number of PIs available  matches the count in the temp table, it means that you have all the PIs for that PO. add all the POs and you ave your result set.</p>
"
240,104620,4,7,sql,Any good SQL Anywhere database schema comparison tools?,"<p>Are there any good database schema comparison tools out there that support Sybase SQL Anywhere version 10?  I've seen a litany of them for SQL Server, a few for MySQL and Oracle, but nothing that supports SQL Anywhere correctly.  </p>

<p>I tried using DB Solo, but it turned all my non-unique indexes into unique ones, and I didn't see any options to change that.</p>
","<p>If you are willing to download SQL Anywhere Version 11, and Compare It!, check out the comparison technique shown here:</p>

<p><a href=""http://sqlanywhere.blogspot.com/2008/08/comparing-database-schemas.html"" rel=""nofollow"">http://sqlanywhere.blogspot.com/2008/08/comparing-database-schemas.html</a></p>

<p>You don't have to upgrade your SQL Anywhere Version 10 database.</p>
"
239,104620,0,7,sql,Any good SQL Anywhere database schema comparison tools?,"<p>Are there any good database schema comparison tools out there that support Sybase SQL Anywhere version 10?  I've seen a litany of them for SQL Server, a few for MySQL and Oracle, but nothing that supports SQL Anywhere correctly.  </p>

<p>I tried using DB Solo, but it turned all my non-unique indexes into unique ones, and I didn't see any options to change that.</p>
","<p>I use <a href=""http://www.red-gate.com/products/SQL_Data_Compare/index.htm"" rel=""nofollow"">SQL Data Compare</a> from Red Gate along with <a href=""http://www.red-gate.com/products/SQL_Compare/index.htm"" rel=""nofollow"">SQL Compare</a> the data compare allows you to Compare the contents of two databases and Automatically synchronize your data.
SQL compare allows you to do the same but with the database tables. Nice GUI on each and very easy setup. they also work on a remote database. </p>

<p>There not cheap but each has a 30 trail so you can get a feel if you like it or not. </p>
"
238,104620,0,7,sql,Any good SQL Anywhere database schema comparison tools?,"<p>Are there any good database schema comparison tools out there that support Sybase SQL Anywhere version 10?  I've seen a litany of them for SQL Server, a few for MySQL and Oracle, but nothing that supports SQL Anywhere correctly.  </p>

<p>I tried using DB Solo, but it turned all my non-unique indexes into unique ones, and I didn't see any options to change that.</p>
","<p>Try erwin (CA AllFusion ERwin Data Modeler). It supports quite a lot of different DBs, including SQL Anywhere, and is quite good in reverse/forward engineering and schema comparison. However, you may find it a bit too complex to use for the comparison...</p>
"
237,104620,0,7,sql,Any good SQL Anywhere database schema comparison tools?,"<p>Are there any good database schema comparison tools out there that support Sybase SQL Anywhere version 10?  I've seen a litany of them for SQL Server, a few for MySQL and Oracle, but nothing that supports SQL Anywhere correctly.  </p>

<p>I tried using DB Solo, but it turned all my non-unique indexes into unique ones, and I didn't see any options to change that.</p>
","<p><a href=""http://www.sqldelta.com/"" rel=""nofollow"">SQLDelta</a> is awesome. It is for SQL Server. I've used it with SQL 2000 and 2005. It will compare stored procedures, tables, views, permissions, indexes, etc. It can also compare data between tables I believe. You can sync the changes or generate SQL Scripts for later use. I use it often to script out db changes in development to production.</p>

<p>Ah...missed the Sybase remark. Not sure if SQLDelta can talk to it..but I'd probably give it a shot since Sybase is similar.</p>
"
857,378040,0,7,sql,Recursive sql problem,"<p>I have a problem that I would like have solved via a SQL query. This is going to
be used as a PoC (proof of concept).</p>

<p>The problem:</p>

<p>Product offerings are made up of one or many product instances, a product
instance can belong to many product offerings.
This can be realised like this in a table:</p>

<pre><code>PO | PI

-----

A | 10

A | 11

A | 12

B | 10

B | 11

C | 13
</code></pre>

<p>Now I would like to get back the product offer from a set of product instances.
E.g. if we send in 10,11,13 the expected result back is B &amp; C, and if we send in
only 10 then the result should be NULL since no product offering is made up of
only 10. Sending in 10,11,12 would result in A (not A &amp; B since 12 is not a valid product offer in it self).</p>

<p>Prerequisites:
The combination of product instances sent in can only result in one specific
combination of product offerings, so there is only one solution to each query.</p>
","<p>IMHO impossible via pure SQL without some stored-procedure code. But... i'm not sure.</p>

<p><b>Added:</b> On the other hand, I'm getting an idea about a recursive query (in MSSQL 2005 there is such a thing, which allows you to join a query with it's own results until there are no more rows returned) which might ""gather"" the correct answers by cross-joining the results of previous step with all products and then filtering out invalid combinations. You would however get all permutations of valid combinations and it would hardly be efficient. And the idea is pretty vague, so I can't guarantee that it can actually be implemented.</p>
"
858,378040,1,7,sql,Recursive sql problem,"<p>I have a problem that I would like have solved via a SQL query. This is going to
be used as a PoC (proof of concept).</p>

<p>The problem:</p>

<p>Product offerings are made up of one or many product instances, a product
instance can belong to many product offerings.
This can be realised like this in a table:</p>

<pre><code>PO | PI

-----

A | 10

A | 11

A | 12

B | 10

B | 11

C | 13
</code></pre>

<p>Now I would like to get back the product offer from a set of product instances.
E.g. if we send in 10,11,13 the expected result back is B &amp; C, and if we send in
only 10 then the result should be NULL since no product offering is made up of
only 10. Sending in 10,11,12 would result in A (not A &amp; B since 12 is not a valid product offer in it self).</p>

<p>Prerequisites:
The combination of product instances sent in can only result in one specific
combination of product offerings, so there is only one solution to each query.</p>
","<pre><code>  Select Distinct PO
   From Table T
   -- Next eliminates POs that contain other PIs
   Where Not Exists 
       (Select * From Table 
        Where PO = T.PO
            And PI Not In (10, 11, 12))
     -- And this eliminates POs that do not contain all the PIs
     And Not Exists 
        (Select Distinct PI From Table  
         Where PI In (10, 11, 12)
           Except 
         Select Distinct PI From Table  
         Where PO = T.PO
</code></pre>

<p>or, if your database does not implement EXCEPT... </p>

<pre><code>   Select Distinct PO
   From Table T
   -- Next predicate eliminates POs that contain other PIs
   Where Not Exists 
       (Select * From Table 
        Where PO = T.PO
            And PI Not In (10, 11, 12))
     -- And this eliminates POs that do not contain ALL the PIs
     And Not Exists 
         (Select Distinct PI From Table A
          Where PI In (10, 11, 12)
             And Not Exists
                 (Select Distinct PI From Table 
                  Where PO = T.PO 
                     And PdI = A.PI))
</code></pre>
"
859,378040,0,7,sql,Recursive sql problem,"<p>I have a problem that I would like have solved via a SQL query. This is going to
be used as a PoC (proof of concept).</p>

<p>The problem:</p>

<p>Product offerings are made up of one or many product instances, a product
instance can belong to many product offerings.
This can be realised like this in a table:</p>

<pre><code>PO | PI

-----

A | 10

A | 11

A | 12

B | 10

B | 11

C | 13
</code></pre>

<p>Now I would like to get back the product offer from a set of product instances.
E.g. if we send in 10,11,13 the expected result back is B &amp; C, and if we send in
only 10 then the result should be NULL since no product offering is made up of
only 10. Sending in 10,11,12 would result in A (not A &amp; B since 12 is not a valid product offer in it self).</p>

<p>Prerequisites:
The combination of product instances sent in can only result in one specific
combination of product offerings, so there is only one solution to each query.</p>
","<p>You will need a count of the items in your list, i.e. @list_count.  Figure out which Offerings have Instances that aren't in the list.  Select all Offerings that aren't in <em>that</em> list and <em>do</em> have Instances in the list:</p>

<pre><code>select P0,count(*) c from table where P0 not in (
select P0 from table where P1 not in (@list)
) and P1 in (@list) group by P0
</code></pre>

<p>I would store that in a temp table and select * records where c = @list_count</p>
"
860,378040,2,7,sql,Recursive sql problem,"<p>I have a problem that I would like have solved via a SQL query. This is going to
be used as a PoC (proof of concept).</p>

<p>The problem:</p>

<p>Product offerings are made up of one or many product instances, a product
instance can belong to many product offerings.
This can be realised like this in a table:</p>

<pre><code>PO | PI

-----

A | 10

A | 11

A | 12

B | 10

B | 11

C | 13
</code></pre>

<p>Now I would like to get back the product offer from a set of product instances.
E.g. if we send in 10,11,13 the expected result back is B &amp; C, and if we send in
only 10 then the result should be NULL since no product offering is made up of
only 10. Sending in 10,11,12 would result in A (not A &amp; B since 12 is not a valid product offer in it self).</p>

<p>Prerequisites:
The combination of product instances sent in can only result in one specific
combination of product offerings, so there is only one solution to each query.</p>
","<p><strong>Edit:</strong> Whilst I think mine works fine, Adam's answer is without a doubt more elegant and more efficient - I'll just leave mine here for posterity!</p>

<p>Apologies since I know this has been tagged as an Oracle issue since I started playing. This is some SQL2008 code which I think works for all the stated cases....</p>

<pre><code>declare @test table
(
    [PI] int
)
insert @test values (10), (11), (13)

declare @testCount int
select @testCount = COUNT(*) from @test

;with PO_WITH_COUNTS as 
(
    	select	PO_FULL.PO, COUNT(PO_FULL.[PI]) PI_Count
    	from	ProductOffering PO_FULL
    	left
    	join	(
    			select	PO_QUALIFYING.PO, PO_QUALIFYING.[PI]
    			from	ProductOffering PO_QUALIFYING
    			where	PO_QUALIFYING.[PI] in (select [PI] from @test)
    			) AS QUALIFYING
    			on		QUALIFYING.PO = PO_FULL.PO
    			and		QUALIFYING.[PI] = PO_FULL.[PI]
    	group by
    			PO_FULL.PO
    	having	COUNT(PO_FULL.[PI]) = COUNT(QUALIFYING.[PI])
)
select  PO_OUTER.PO
from    PO_WITH_COUNTS PO_OUTER 
cross 
join    PO_WITH_COUNTS PO_INNER
where   PO_OUTER.PI_Count = @testCount
or  	PO_OUTER.PO &lt;&gt; PO_INNER.PO
group by
    	PO_OUTER.PO, PO_OUTER.PI_Count
having  PO_OUTER.PI_Count = @testCount 
or  	PO_OUTER.PI_Count + SUM(PO_INNER.PI_Count) = @testCount
</code></pre>

<p>Not sure if Oracle has CTEs but could just state the inner query as two derived tables. The cross join in the outer query lets us find combinations of offerings that have all the valid items. I know that this will only work based on the statement in the question that the data is such that there is only 1 valid combination for each requested set, Without that it's even more complicated as counts are not enough to remove combinations that have duplicate products in them.</p>
"
861,378040,0,7,sql,Recursive sql problem,"<p>I have a problem that I would like have solved via a SQL query. This is going to
be used as a PoC (proof of concept).</p>

<p>The problem:</p>

<p>Product offerings are made up of one or many product instances, a product
instance can belong to many product offerings.
This can be realised like this in a table:</p>

<pre><code>PO | PI

-----

A | 10

A | 11

A | 12

B | 10

B | 11

C | 13
</code></pre>

<p>Now I would like to get back the product offer from a set of product instances.
E.g. if we send in 10,11,13 the expected result back is B &amp; C, and if we send in
only 10 then the result should be NULL since no product offering is made up of
only 10. Sending in 10,11,12 would result in A (not A &amp; B since 12 is not a valid product offer in it self).</p>

<p>Prerequisites:
The combination of product instances sent in can only result in one specific
combination of product offerings, so there is only one solution to each query.</p>
","<p>If we redefine a bit a problem:</p>

<p>Lets have a customer table with product instances:</p>

<pre><code>crete table cust_pi (
pi varchar(5),
customer varchar(5));
</code></pre>

<p>And a ""product_catalogue"" table:</p>

<pre><code>CREATE TABLE PI_PO_TEST
   (""PO"" VARCHAR2(5 CHAR),
   ""PI"" VARCHAR2(5 CHAR)
           );
</code></pre>

<p>Lets fill it with some sample data:</p>

<pre><code>insert into CUST_PI (PI, CUSTOMER)
values ('11', '1');
insert into CUST_PI (PI, CUSTOMER)
values ('10', '1');
insert into CUST_PI (PI, CUSTOMER)
values ('12', '1');
insert into CUST_PI (PI, CUSTOMER)
values ('13', '1');
insert into CUST_PI (PI, CUSTOMER)
values ('14', '1');
insert into PI_PO_TEST (PO, PI)
values ('A', '10');
insert into PI_PO_TEST (PO, PI)
values ('A', '11');
insert into PI_PO_TEST (PO, PI)
values ('A', '12');
insert into PI_PO_TEST (PO, PI)
values ('A', '13');
insert into PI_PO_TEST (PO, PI)
values ('B', '14');
insert into PI_PO_TEST (PO, PI)
values ('C', '11');
insert into PI_PO_TEST (PO, PI)
values ('C', '12');
insert into PI_PO_TEST (PO, PI)
values ('D', '15');
insert into PI_PO_TEST (PO, PI)
values ('D', '14');
</code></pre>

<p>Then my first shoot solution is like this:</p>

<pre><code>select po1 po /* select all product offerings that match the product definition 
                (i.e. have the same number of product instances per offering as 
                in product catalogue */
  from (select po po1, count(c.pi) k1
          from cust_pi c, pi_po_test t
         where c.pi = t.pi
           and customer = 1
         group by po) t1,
       (select po po2, count(*) k2 from pi_po_test group by po) t2
 where k1 = k2
   and po1 = po2
minus /* add those, that are contained within others */
select slave
  from (select po2 master, po1 slave
  /* this query returns, that if you have po ""master"" slave should be removed from result, 
     as it is contained within*/
          from (select t1.po po1, t2.po po2, count(t1.po) k1
                  from pi_po_test t1, pi_po_test t2
                 where t1.pi = t2.pi
                 group by t1.po, t2.po) t1,
               (select po, count(po) k2 from pi_po_test group by po) t2
         where t1.po2 = t2.po
           and k1 &lt; k2)
 where master in
 /* repeated query from begining. This could be done better :-) */
       (select po1 po
          from (select po po1, count(c.pi) k1
                  from cust_pi c, pi_po_test t
                 where c.pi = t.pi
                   and customer = 1
                 group by po) t1,
               (select po po2, count(*) k2 from pi_po_test group by po) t2
         where k1 = k2
           and po1 = po2)
</code></pre>

<p>All of that was done on Oracle, so your mileage may vary</p>
"
862,378040,7,7,sql,Recursive sql problem,"<p>I have a problem that I would like have solved via a SQL query. This is going to
be used as a PoC (proof of concept).</p>

<p>The problem:</p>

<p>Product offerings are made up of one or many product instances, a product
instance can belong to many product offerings.
This can be realised like this in a table:</p>

<pre><code>PO | PI

-----

A | 10

A | 11

A | 12

B | 10

B | 11

C | 13
</code></pre>

<p>Now I would like to get back the product offer from a set of product instances.
E.g. if we send in 10,11,13 the expected result back is B &amp; C, and if we send in
only 10 then the result should be NULL since no product offering is made up of
only 10. Sending in 10,11,12 would result in A (not A &amp; B since 12 is not a valid product offer in it self).</p>

<p>Prerequisites:
The combination of product instances sent in can only result in one specific
combination of product offerings, so there is only one solution to each query.</p>
","<p>Okay, I think I have it.  This meets the constraints you provided.  There might be a way to simplify this further, but it ate my brain a little:</p>

<pre><code>select distinct PO 
from POPI x 
where 
  PO not in (
    select PO 
    from POPI 
    where PI not in (10,11,12)
  ) 
  and PI not in (
    select PI 
    from POPI 
    where PO != x.PO 
      and PO not in (
        select PO 
        from POPI 
        where PI not in (10,11,12)
      )
  );
</code></pre>

<p>This yields only results who fill the given set which are disjoint with all other results, which I <strong>think</strong> is what you were asking for.  For the test examples given:</p>

<ul>
<li>Providing 10,11,12 yields A</li>
<li>Providing 10,11,13 yields B,C</li>
</ul>
"
863,378040,0,7,sql,Recursive sql problem,"<p>I have a problem that I would like have solved via a SQL query. This is going to
be used as a PoC (proof of concept).</p>

<p>The problem:</p>

<p>Product offerings are made up of one or many product instances, a product
instance can belong to many product offerings.
This can be realised like this in a table:</p>

<pre><code>PO | PI

-----

A | 10

A | 11

A | 12

B | 10

B | 11

C | 13
</code></pre>

<p>Now I would like to get back the product offer from a set of product instances.
E.g. if we send in 10,11,13 the expected result back is B &amp; C, and if we send in
only 10 then the result should be NULL since no product offering is made up of
only 10. Sending in 10,11,12 would result in A (not A &amp; B since 12 is not a valid product offer in it self).</p>

<p>Prerequisites:
The combination of product instances sent in can only result in one specific
combination of product offerings, so there is only one solution to each query.</p>
","<p>I tested this under 4 sets of values and they all returned a correct result. This uses a function that I use in SQL to generate a table from a string of parameters separated by semicolons.</p>

<pre><code>DECLARE @tbl TABLE (
    po varchar(10),
    pii int)

INSERT INTO @tbl
SELECT 'A', 10
UNION ALL
SELECT 'A', 11
UNION ALL
SELECT 'A', 12
UNION ALL
SELECT 'B', 10
UNION ALL
SELECT 'B', 11
UNION ALL
SELECT 'C', 13

DECLARE @value varchar(100)
SET @value = '10;11;12;'
--SET @value = '11;10;'
--SET @value = '13;'
--SET @value = '10;'

SELECT DISTINCT po
FROM @tbl a
INNER JOIN fMultiValParam (@value) p ON
a.pii = p.paramid
WHERE a.po NOT IN (
    SELECT t.po
    FROM @tbl t
    LEFT OUTER JOIN (SELECT *
    		FROM @tbl tt
    		INNER JOIN fMultiValParam (@value) p ON
    		tt.pii = p.paramid) tt ON
    t.pii = tt.pii
    AND t.po = tt.po
    WHERE tt.po IS NULL)
</code></pre>

<p>here's the function</p>

<pre><code>CREATE    FUNCTION [dbo].[fMultiValParam]
(@Param varchar(5000))
RETURNS @tblParam TABLE (ParamID varchar(40))
AS
BEGIN

IF (@Param IS NULL OR LEN(@Param) &lt; 2)
BEGIN
    RETURN
END

DECLARE @len INT
DECLARE @index INT
DECLARE @nextindex INT

SET @len = DATALENGTH(@Param)
SET @index = 0
SET @nextindex = 0

WHILE (@index &lt; @len)
BEGIN
    SET @Nextindex = CHARINDEX(';', @Param, @index)

    INSERT INTO @tblParam
    SELECT SUBSTRING(@Param, @index, @nextindex - @index)

    SET @index = @nextindex + 1

END
RETURN
END
</code></pre>
"
1116,512350,0,7,sql,What coding tricks have you used to avoid writing more sql?,"<p>This question was suggested by <a href=""http://stackoverflow.com/users/5486/kyralessa"">Kyralessa</a> in the <a href=""http://stackoverflow.com/questions/488020/what-is-your-most-useful-sql-trick-to-avoid-writing-more-code"">What is your most useful sql trick to avoid writing more sql?.</a>   I got so many good ideas to try from the last question, that I am interested to see what comes up with this question.</p>

<p>Once again, I am not keeping the reputation from this question.  I am waiting 7 days, for answers, then marking it wiki.  The reputation that the question has earned, goes into a bounty for the question.  </p>

<p>Ground Rules:</p>

<ul>
<li><p>While it is certainly reasonable to write code, to move processing from SQL into the code to address performance issues, that is really not the point of the question.  The question is not limited to performance issues.   The goal is less simply less sql to get the job done.</p></li>
<li><p>Communicate the concept, so that other users say ""Oh Wow, I didn't know you could do that.""</p></li>
<li><p>Example code is very useful, to help people that are primarily visual learners.</p></li>
<li><p>Explicitly state what Language you are using, and which dialect of SQL you are using.</p></li>
<li><p>Put yourself in your readers shoes.  What would they need to see right there on the screen in front of them, that will cause an epiphany.  Your answer is there to benefit the reader.  Write it for them.</p></li>
<li><p>Offsite links are ok, if they appear after the example.  Offsite links as a substitute for a real answer are not.</p></li>
</ul>

<p>There are probably other things to make it nicer for the reader that I haven't thought of.  Get Creative. Share knowledge.  Have fun showing off.</p>

<p>[EDIT] - It looks like there hasen't been any activity in a while.   5 votes = 50, so there is the bounty, and it has been wikified.</p>
","<p>I would highly recommend SQLAlchemy if it's possible for you to use a python environment.</p>

<p>The other thing I tried is writing my own schema generator for testing our systems at work. This was more to generate different combinations of queries to attempt to crash the system.  Basically, I defined a pseudo deparse tree, with dictionaries and lists</p>

<p><a href=""http://www.sqlalchemy.org/"" rel=""nofollow"">SQLAlchemy</a></p>

<p>Here's a code snippet</p>

<pre><code>&gt;&gt;&gt;for row in session.query(User, User.name).all():
...    print row.User, row.name
SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password FROM users []
&lt;User('ed','Ed Jones', 'f8s7ccs')&gt; ed
&lt;User('wendy','Wendy Williams', 'foobar')&gt; wendy
&lt;User('mary','Mary Contrary', 'xxg527')&gt; mary
&lt;User('fred','Fred Flinstone', 'blah')&gt; fred
</code></pre>
"
207,91360,1,7,sql,How to calculate the sum of values in a tree using SQL,"<p>I need to sum points on each level earned by a tree of users. Level 1 is the sum of users' points of the users 1 level below the user. Level 2 is the Level 1 points of the users 2 levels below the user, etc...</p>

<p>The calculation happens once a month on a non production server, no worries about performance.</p>

<p>What would the SQL look like to do it?</p>

<p>If you're confused, don't worry, I am as well!</p>

<p>User table:</p>

<pre><code>ID    ParentID    Points
1     0           230
2     1           150
3     0           80
4     1           110
5     4           54
6     4           342

Tree:
0
|---\
1    3
| \
2  4---
    \  \
     5  6
</code></pre>

<p>Output should be:</p>

<pre><code>ID    Points    Level1     Level2
1     230       150+110    150+110+54+342
2     150
3     80
4     110       54+342
5     54
6     342
</code></pre>

<p>SQL Server Syntax and functions preferably...</p>
","<p>Ok, this gives you the results you are looking for, but there are no guarantees that I didn't miss something. Consider it a starting point.  I used SQL 2005 to do this, SQL 2000 does not support CTE's</p>

<pre><code>WITH Parent (id, GrandParentId, parentId, Points, Level1Points, Level2Points)
AS
(
    -- Find root
    SELECT id,  
    		0 AS GrandParentId,
    		ParentId,
    		Points,
    		0 AS Level1Points,
    		0 AS Level2Points
    FROM tblPoints ptr
    WHERE ptr.ParentId = 0

    UNION ALL (
    -- Level2 Points
    SELECT pa.GrandParentId AS Id,
    		NULL AS GrandParentId,
    		NULL AS ParentId,
    		0 AS Points, 
    		0 AS Level1Points,
    		pa.Points  AS Level2Points
    FROM tblPoints pt
    		JOIN Parent pa ON pa.GrandParentId = pt.Id 
    UNION  ALL
    -- Level1 Points
    SELECT pt.ParentId AS Id,
    		NULL AS GrandParentId,
    		NULL AS ParentId,
    		0 AS Points, 
    		pt.Points AS Level1Points,
    		0 AS Level2Points
    FROM tblPoints pt
    		JOIN Parent pa ON pa.Id = pt.ParentId AND pa.ParentId IS NOT NULL 
    UNION  ALL
    -- Points
    SELECT pt.id,
    		pa.ParentId AS GrandParentId,
    		pt.ParentId,
    		pt.Points, 
    		0 AS Level1Points,
    		0 AS Level2Points
    FROM tblPoints pt
    		JOIN Parent pa ON pa.Id = pt.ParentId AND pa.ParentId IS NOT NULL )
)
SELECT id, 
    SUM(Points) AS Points,  
    SUM(Level1Points) AS Level1Points,
    CASE WHEN SUM(Level2Points) &gt; 0 THEN  SUM(Level1Points) + SUM(Level2Points) ELSE 0 END AS Level2Points
FROM Parent
GROUP BY id 
ORDER by id
</code></pre>
"
848,373490,3,7,sql,Insert Dates in the return from a query where there is none,"<p>We are building a query to count the number of events per hour, per day. Most days there are hours that do not have any activity and therefore where the query is run the count of activities per hour show up but there are gaps and the query excludes these. We still want to show the hours that do not have activity and display a zero so that zero value can then be charted. The query we using looks like this </p>

<pre><code>select datepart(Year, dev_time) as Year,
    datepart(Month, dev_time) as Month,
    datepart(Day, dev_time) as Day,
    datepart(Hour, dev_time) as Hour,
    count(tdm_msg) as Total_ACTIVITES
from TCKT_ACT
where tdm_msg = 4162 and dev_time &gt;= DATEADD(day, - 1, GETDATE())
group by datepart(Year, dev_time) ,
    datepart(Month, dev_time) ,
    datepart(Day, dev_time),
    datepart(Hour, dev_time)
order by datepart(Year, dev_time) asc,
    datepart(Month, dev_time) asc,
    datepart(Day, dev_time) asc,
    datepart(Hour, dev_time) asc
</code></pre>
","<p>First I created a table function based on the recursive common table query described by
Dave Markle (thanks for showing me this Dave!). This is extremely sweet because I only have to make the function once and I can use it for analysing any intervals.</p>

<pre><code>if exists (select * from dbo.sysobjects where name = 'fn_daterange') drop function fn_daterange;
go

create function fn_daterange
   (
   @MinDate as datetime,
   @MaxDate as datetime,
   @intval  as datetime
   )
returns table
--**************************************************************************
-- Procedure: fn_daterange()
--    Author: Ron Savage
--      Date: 12/16/2008
--
-- Description:
-- This function takes a starting and ending date and an interval, then
-- returns a table of all the dates in that range at the specified interval.
--
-- Change History:
-- Date        Init. Description
-- 12/16/2008  RS    Created.
-- **************************************************************************
as
return
   WITH times (startdate, enddate, intervl) AS
      (
      SELECT @MinDate as startdate, @MinDate + @intval - .0000001 as enddate, @intval as intervl
         UNION ALL
      SELECT startdate + intervl as startdate, enddate + intervl as enddate, intervl as intervl
      FROM times
      WHERE startdate + intervl &lt;= @MaxDate
      )
   select startdate, enddate from times;

go
</code></pre>

<p>So if you do a select from that function all by itself you get a table of time intervals like this:</p>

<p><strong>fn_daterange('12/14/2008 10:00:00', '12/14/2008 20:00:00', '01:00:00' )</strong></p>

<p>returns:</p>

<pre><code>startdate               enddate                 intervl                 
----------------------- ----------------------- ----------------------- 
2008-12-14 10:00:00.000 2008-12-14 10:59:59.997 1900-01-01 01:00:00.000 
2008-12-14 11:00:00.000 2008-12-14 11:59:59.997 1900-01-01 01:00:00.000 
2008-12-14 12:00:00.000 2008-12-14 12:59:59.997 1900-01-01 01:00:00.000 
2008-12-14 13:00:00.000 2008-12-14 13:59:59.997 1900-01-01 01:00:00.000 
2008-12-14 14:00:00.000 2008-12-14 14:59:59.997 1900-01-01 01:00:00.000 
2008-12-14 15:00:00.000 2008-12-14 15:59:59.997 1900-01-01 01:00:00.000 
2008-12-14 16:00:00.000 2008-12-14 16:59:59.997 1900-01-01 01:00:00.000 
2008-12-14 17:00:00.000 2008-12-14 17:59:59.997 1900-01-01 01:00:00.000 
2008-12-14 18:00:00.000 2008-12-14 18:59:59.997 1900-01-01 01:00:00.000 
2008-12-14 19:00:00.000 2008-12-14 19:59:59.997 1900-01-01 01:00:00.000 
2008-12-14 20:00:00.000 2008-12-14 20:59:59.997 1900-01-01 01:00:00.000
</code></pre>

<p>Then I made a sample table of event data:</p>

<pre><code>    eventdate               eventnote            
    ----------------------- -------------------- 
    2008-12-14 10:01:00.000 oo! an event!        
    2008-12-14 10:01:00.000 oo! an event!        
    2008-12-14 10:01:00.000 oo! an event!        
    2008-12-14 10:01:00.000 oo! an event!        
    2008-12-14 10:23:00.000 oo! an event!        
    2008-12-14 10:23:00.000 oo! an event!        
    2008-12-14 10:23:00.000 oo! an event!        
    2008-12-14 11:23:00.000 oo! an event!        
    2008-12-14 11:23:00.000 oo! an event!        
    2008-12-14 11:23:00.000 oo! an event!        
    2008-12-14 11:23:00.000 oo! an event!        
    2008-12-14 11:23:00.000 oo! an event!        
    2008-12-14 14:23:00.000 oo! an event!        
    2008-12-14 14:23:00.000 oo! an event!        
    2008-12-14 14:23:00.000 oo! an event!        
    2008-12-14 19:23:00.000 oo! an event!        
    2008-12-14 19:23:00.000 oo! an event!        
    2008-12-14 19:23:00.000 oo! an event!        
    2008-12-14 19:23:00.000 oo! an event!        
    2008-12-14 19:00:00.000 oo! an event!        
    2008-12-14 19:00:00.000 oo! an event!        
    2008-12-14 19:00:00.000 oo! an event!        

    22 Row(s) affected
</code></pre>

<p>Then I hooked them together with a LEFT OUTER JOIN like so:</p>

<pre><code>select
   dr.startdate,
   dr.enddate,
   count(me.eventdate) as eventcount
from
   fn_daterange('12/14/2008 10:00:00', '12/14/2008 20:00:00', '01:00:00' ) dr

   LEFT OUTER JOIN myevents me
      on ( me.eventdate between dr.startdate and dr.enddate)
group by
   dr.startdate,
   dr.enddate


startdate               enddate                 eventcount 
----------------------- ----------------------- ---------- 
2008-12-14 10:00:00.000 2008-12-14 10:59:59.993 7          
2008-12-14 11:00:00.000 2008-12-14 11:59:59.993 5          
2008-12-14 12:00:00.000 2008-12-14 12:59:59.993 0          
2008-12-14 13:00:00.000 2008-12-14 13:59:59.993 0          
2008-12-14 14:00:00.000 2008-12-14 14:59:59.993 3          
2008-12-14 15:00:00.000 2008-12-14 15:59:59.993 0          
2008-12-14 16:00:00.000 2008-12-14 16:59:59.993 0          
2008-12-14 17:00:00.000 2008-12-14 17:59:59.993 0          
2008-12-14 18:00:00.000 2008-12-14 18:59:59.993 0          
2008-12-14 19:00:00.000 2008-12-14 19:59:59.993 7          
2008-12-14 20:00:00.000 2008-12-14 20:59:59.993 0          

11 Row(s) affected
</code></pre>

<p>HOLY CRAP that is sweet - I can use this for all kinds of analysis at work! :-)</p>

<p>Thanks Fred for the question and Dave for the info on common table queries!</p>

<p>Ron</p>
"
1114,512350,0,7,sql,What coding tricks have you used to avoid writing more sql?,"<p>This question was suggested by <a href=""http://stackoverflow.com/users/5486/kyralessa"">Kyralessa</a> in the <a href=""http://stackoverflow.com/questions/488020/what-is-your-most-useful-sql-trick-to-avoid-writing-more-code"">What is your most useful sql trick to avoid writing more sql?.</a>   I got so many good ideas to try from the last question, that I am interested to see what comes up with this question.</p>

<p>Once again, I am not keeping the reputation from this question.  I am waiting 7 days, for answers, then marking it wiki.  The reputation that the question has earned, goes into a bounty for the question.  </p>

<p>Ground Rules:</p>

<ul>
<li><p>While it is certainly reasonable to write code, to move processing from SQL into the code to address performance issues, that is really not the point of the question.  The question is not limited to performance issues.   The goal is less simply less sql to get the job done.</p></li>
<li><p>Communicate the concept, so that other users say ""Oh Wow, I didn't know you could do that.""</p></li>
<li><p>Example code is very useful, to help people that are primarily visual learners.</p></li>
<li><p>Explicitly state what Language you are using, and which dialect of SQL you are using.</p></li>
<li><p>Put yourself in your readers shoes.  What would they need to see right there on the screen in front of them, that will cause an epiphany.  Your answer is there to benefit the reader.  Write it for them.</p></li>
<li><p>Offsite links are ok, if they appear after the example.  Offsite links as a substitute for a real answer are not.</p></li>
</ul>

<p>There are probably other things to make it nicer for the reader that I haven't thought of.  Get Creative. Share knowledge.  Have fun showing off.</p>

<p>[EDIT] - It looks like there hasen't been any activity in a while.   5 votes = 50, so there is the bounty, and it has been wikified.</p>
","<p>I recommend creating shared methods that focus on task, and use simple SQL elements, without having to write sql. I use Subsonic for my data access to MS SQL. However, you could make it non- database specific, such as a DAL. These examples could be customized to an ORM or however you access data. I'd recommend to create a static class that narrow's it down to a specific task. </p>

<p>For example, if you have a datagrid to populate and you know a view, table, stored proc to populate it from, create a function similar to the following c# code:</p>

<pre><code>public static void BindDataGridViewWhere(DataGridView dgv, string tablename, string selectList, string whereClause)
{
    Query qQuery = new Query(tablename);
    qQuery.SelectList = selectList;
    qQuery.WHERE(whereClause);
    DataSet dsDGV = qQuery.ExecuteDataSet();
    dgv.DataSource = dsDGV.Tables[0];
    dgv.RowHeadersVisible = false;
}
</code></pre>

<p>Then, in page init or something like that, simple 1 line call to this method passing the datagridview in with the where statement, what you want to appear and how in the select, and the whereclause and you're bound. </p>

<p>BindDataGridViewWhere(dgvCars, ""tbl_Cars"", ""CarName"", ""Color, mdl as Model"", ""Color = 'blue'"");</p>

<p>This works great for any object that you do a lot of binding with, such as dropdownboxes, listboxes, datagridviews, anything else. Then, for others that don't fit this model, have a method that just returns a dataset. That way if you need to interact with it before displaying it, you can do additional business logic,etc.</p>

<p>I like this approach because if you want to switch data frameworks, you have 1 place to make the change. You can build a screen very quickly this way.</p>
"
1095,497390,2,7,sql,Mathematical formula for calculating call duration,"<p>I was working for a telecom company some years ago and I had to generate a formula which calculates duration of a call according to the following algorithm:</p>

<ul>
<li>t1 is the first period  </li>
<li>t2 is the recurring period</li>
<li>RCT is the actual call time (in seconds)</li>
<li>CD is the effective call duration (for billing purposes)</li>
</ul>

<p>if RCT is less than t1, then the CD equals t1<br />
if RCT is greater than t1, then CD = t1 + x*t2, where x will ""round"" RCT to the next highest multiple of t2.</p>

<p>This algorithm translates to: ""Charge for the first t1 seconds, then charge every t2 seconds after that"".</p>

<p>Example:</p>

<pre><code>t1	t2	RCT	CD	
60	10	48	60
60	10	65	70
60	10	121	130
30	20	25	30
30	20	35	50
30	20	65	70
</code></pre>

<p>Can you create a function / SQL that will return the ""call duration"" CD?</p>

<p>Without using if then else ...?</p>
","<p>I would use:</p>

<pre><code>t1 + t2*ceiling( (rct - t1 + abs(rct - t1))*1.00/(2*t2) )
</code></pre>

<p>Or:</p>

<pre><code>t1 + t2*ceiling( Cast((rct - t1 + abs(rct - t1)) as float)/(2*t2) )
</code></pre>
"
1110,512350,2,7,sql,What coding tricks have you used to avoid writing more sql?,"<p>This question was suggested by <a href=""http://stackoverflow.com/users/5486/kyralessa"">Kyralessa</a> in the <a href=""http://stackoverflow.com/questions/488020/what-is-your-most-useful-sql-trick-to-avoid-writing-more-code"">What is your most useful sql trick to avoid writing more sql?.</a>   I got so many good ideas to try from the last question, that I am interested to see what comes up with this question.</p>

<p>Once again, I am not keeping the reputation from this question.  I am waiting 7 days, for answers, then marking it wiki.  The reputation that the question has earned, goes into a bounty for the question.  </p>

<p>Ground Rules:</p>

<ul>
<li><p>While it is certainly reasonable to write code, to move processing from SQL into the code to address performance issues, that is really not the point of the question.  The question is not limited to performance issues.   The goal is less simply less sql to get the job done.</p></li>
<li><p>Communicate the concept, so that other users say ""Oh Wow, I didn't know you could do that.""</p></li>
<li><p>Example code is very useful, to help people that are primarily visual learners.</p></li>
<li><p>Explicitly state what Language you are using, and which dialect of SQL you are using.</p></li>
<li><p>Put yourself in your readers shoes.  What would they need to see right there on the screen in front of them, that will cause an epiphany.  Your answer is there to benefit the reader.  Write it for them.</p></li>
<li><p>Offsite links are ok, if they appear after the example.  Offsite links as a substitute for a real answer are not.</p></li>
</ul>

<p>There are probably other things to make it nicer for the reader that I haven't thought of.  Get Creative. Share knowledge.  Have fun showing off.</p>

<p>[EDIT] - It looks like there hasen't been any activity in a while.   5 votes = 50, so there is the bounty, and it has been wikified.</p>
","<p>Generate SQL SPs, Views, etc. from the metadata in <code>INFORMATION_SCHEMA</code>.  That code generation can then be augmented with custom code.</p>

<p>If a number of SPs will do similar things, for ease of  a single point of maintenance, I will generate dynamic SQL instead.</p>

<p>All these things results in less SQL code, and more code that is re-used, and so better tested - like any library.</p>

<p><a href=""http://stackoverflow.com/questions/507869/trim-all-database-fields"">Here's an example of code generation to avoid writing SQL</a> </p>
"
1111,512350,10,7,sql,What coding tricks have you used to avoid writing more sql?,"<p>This question was suggested by <a href=""http://stackoverflow.com/users/5486/kyralessa"">Kyralessa</a> in the <a href=""http://stackoverflow.com/questions/488020/what-is-your-most-useful-sql-trick-to-avoid-writing-more-code"">What is your most useful sql trick to avoid writing more sql?.</a>   I got so many good ideas to try from the last question, that I am interested to see what comes up with this question.</p>

<p>Once again, I am not keeping the reputation from this question.  I am waiting 7 days, for answers, then marking it wiki.  The reputation that the question has earned, goes into a bounty for the question.  </p>

<p>Ground Rules:</p>

<ul>
<li><p>While it is certainly reasonable to write code, to move processing from SQL into the code to address performance issues, that is really not the point of the question.  The question is not limited to performance issues.   The goal is less simply less sql to get the job done.</p></li>
<li><p>Communicate the concept, so that other users say ""Oh Wow, I didn't know you could do that.""</p></li>
<li><p>Example code is very useful, to help people that are primarily visual learners.</p></li>
<li><p>Explicitly state what Language you are using, and which dialect of SQL you are using.</p></li>
<li><p>Put yourself in your readers shoes.  What would they need to see right there on the screen in front of them, that will cause an epiphany.  Your answer is there to benefit the reader.  Write it for them.</p></li>
<li><p>Offsite links are ok, if they appear after the example.  Offsite links as a substitute for a real answer are not.</p></li>
</ul>

<p>There are probably other things to make it nicer for the reader that I haven't thought of.  Get Creative. Share knowledge.  Have fun showing off.</p>

<p>[EDIT] - It looks like there hasen't been any activity in a while.   5 votes = 50, so there is the bounty, and it has been wikified.</p>
","<p>If you want to avoid writting SQL use an ORM such as nHibernate, or one of the Microsoft offerings Linq to SQL / Entity Framework</p>

<p>This is even better then using a generator since you won't need to rerun the generators, and if you use Fluent nHibernate you can enable Configuration via Convention and not even maintain a mapping file / class. </p>
"
836,370340,1,7,sql,"in SQL, or Django ORM, what's the conventional way to have an ordered one-to-many?","<p>Say I wanted to have a project, and one-to-many with to-do items, and wanted to re-order the to-do items arbitrarily? </p>

<p>In the past, I've added a numbered order field, and when someone wants to change the order, had to update all the items with their new order numbers.  This is probably the worst approach, since it's not atomic &amp; required several updates.</p>

<p>I notice Django has a multi-valued CommaSeparatedIntegerField which could contain the order by storing the ordered keys to the items in the to-do items table right in one field of the project table.</p>

<p>I've pondered a dewey decimal system where if I wanted to take item 3 and put it between 1 and 2 I would change it's order number to 1.5.</p>

<p>Something tells me there's an easier option that I'm missing though...</p>

<p>How would you give order to a one-to-many relationship?</p>
","<p>I've run into this so many times that I've settled on managing these dynamically in the BL or UI, and then just persisting the ordering to a purpose-built column once the user is happy. SQL is just intentially designed not to handle orderings, and it always fights back.</p>
"
837,370340,5,7,sql,"in SQL, or Django ORM, what's the conventional way to have an ordered one-to-many?","<p>Say I wanted to have a project, and one-to-many with to-do items, and wanted to re-order the to-do items arbitrarily? </p>

<p>In the past, I've added a numbered order field, and when someone wants to change the order, had to update all the items with their new order numbers.  This is probably the worst approach, since it's not atomic &amp; required several updates.</p>

<p>I notice Django has a multi-valued CommaSeparatedIntegerField which could contain the order by storing the ordered keys to the items in the to-do items table right in one field of the project table.</p>

<p>I've pondered a dewey decimal system where if I wanted to take item 3 and put it between 1 and 2 I would change it's order number to 1.5.</p>

<p>Something tells me there's an easier option that I'm missing though...</p>

<p>How would you give order to a one-to-many relationship?</p>
","<p>I hate this problem ... and I run into it all the time.</p>

<p>For my most recent Django site we had a Newsletter which contained N Articles and, of course, order was important. I assigned the default order as ascending Article.id, but this failed if Articles were entered in something other than ""correct"" order.</p>

<p>On the Newsletter change_form.html page I added a little bit of jQuery magic using the Interface plugin (<a href=""http://interface.eyecon.ro/"">http://interface.eyecon.ro/</a>). I show the titles of the associated Articles and the user can drag them around as they like. There is an onChange handler that recomputes the Article.id's in article_order field.</p>

<p>Enjoy,<br>
  Peter</p>

<p>For app=content, model=Newsletter, the following is in
templates/admin/content/newslettter/change_form.html</p>

<pre><code>{% extends 'admin/change_form.html' %}

{% block form_top %}{% endblock %}
{% block extrahead %}{{ block.super }}
&lt;script type=""text/javascript"" src=""/media/js/jquery.js""&gt;&lt;/script&gt;
&lt;script type=""text/javascript"" src=""/media/js/interface.js""&gt;&lt;/script&gt;
&lt;script&gt;
$(document).ready(
    function () {
        $('ol.articles').Sortable(
            {
                accept :        'sortableitem',
                helperclass :   'sorthelper',
                activeclass :   'sortableactive',
                hoverclass :    'sortablehover',
                opacity:        0.8,
                fx:             200,
                axis:           'vertically',
                opacity:        0.4,
                revert:         true,
                trim:           'art_',
                onchange:
                    function(list){
                        var arts = list[0].o[list[0].id];
                        var vals = new Array();
                        var a;
                        for (a in arts) {
                            vals[a] = arts[a].replace(/article./, '');
                        }
                        $('#id_article_order').attr('value', vals.join(','));
                    }
            });
    }
);
&lt;/script&gt;
{% endblock %}

{% block after_related_objects %}
{% if original.articles %}
&lt;style&gt;
.sortableitem {
    cursor:move;
    width: 300px;
    list-style-type: none;
    }
&lt;/style&gt;

&lt;h4&gt;Associated Articles&lt;/h4&gt;
&lt;ol class=""articles"" id=""article_list""&gt;
{% for art in original.articles %}
    &lt;li id=""article.{{art.id}}"" class=""sortableitem""&gt;{{art.title}}&lt;/li&gt;

{% endfor %}
&lt;/ol&gt;
{% endif %}
{% endblock %}
</code></pre>
"
838,370340,2,7,sql,"in SQL, or Django ORM, what's the conventional way to have an ordered one-to-many?","<p>Say I wanted to have a project, and one-to-many with to-do items, and wanted to re-order the to-do items arbitrarily? </p>

<p>In the past, I've added a numbered order field, and when someone wants to change the order, had to update all the items with their new order numbers.  This is probably the worst approach, since it's not atomic &amp; required several updates.</p>

<p>I notice Django has a multi-valued CommaSeparatedIntegerField which could contain the order by storing the ordered keys to the items in the to-do items table right in one field of the project table.</p>

<p>I've pondered a dewey decimal system where if I wanted to take item 3 and put it between 1 and 2 I would change it's order number to 1.5.</p>

<p>Something tells me there's an easier option that I'm missing though...</p>

<p>How would you give order to a one-to-many relationship?</p>
","<p>""added a numbered order field"" - good.</p>

<p>""update all the items with their new order numbers"" - avoidable.</p>

<p>Use numbers with gaps. </p>

<ul>
<li><p>Floating point.  That way, someone can insert ""1.1"" between 1 and 2.  I find that this works nicely, as most people can understand how the sequencing works.  And you don't have to worry too much about how much space to leave -- there's lots and lots of space between each number.</p></li>
<li><p>On the initial load, number the articles by the 100 or 1000 or something with space between each one.  In this case, you have to guess how many digits to leave for reordering.</p></li>
<li><p>A comma-separated position.  Initially, they're all (1,0), (2,0), (3,0), etc. But when you want to rearrange things, you might have to introduce (2,1) and (2,2) that go after (2,0) but before (3.0).</p>

<p>This looks kind of complicated, but some people like this kind of complexity.  It's essentially the same as floating-point, except the single number is replace by a (whole-number, implicit-fraction) tuple.  And this extends to handle hierarchies.</p></li>
</ul>
"
844,373490,3,7,sql,Insert Dates in the return from a query where there is none,"<p>We are building a query to count the number of events per hour, per day. Most days there are hours that do not have any activity and therefore where the query is run the count of activities per hour show up but there are gaps and the query excludes these. We still want to show the hours that do not have activity and display a zero so that zero value can then be charted. The query we using looks like this </p>

<pre><code>select datepart(Year, dev_time) as Year,
    datepart(Month, dev_time) as Month,
    datepart(Day, dev_time) as Day,
    datepart(Hour, dev_time) as Hour,
    count(tdm_msg) as Total_ACTIVITES
from TCKT_ACT
where tdm_msg = 4162 and dev_time &gt;= DATEADD(day, - 1, GETDATE())
group by datepart(Year, dev_time) ,
    datepart(Month, dev_time) ,
    datepart(Day, dev_time),
    datepart(Hour, dev_time)
order by datepart(Year, dev_time) asc,
    datepart(Month, dev_time) asc,
    datepart(Day, dev_time) asc,
    datepart(Hour, dev_time) asc
</code></pre>
","<p>You are going to somehow need a table of days and hours, and then you will have to do an outer join between that table and your query.  Here's how I would do it.  Note that this solution will only work in SQL Server 2005 and 2008.  If you don't have those platforms, you'll have to actually create a table of times in your database from which you can join off of:</p>

<pre><code>DECLARE @MinDate DATETIME;
SET @MinDate =  CONVERT(varchar, GETDATE(), 101);

WITH times AS (
    SELECT @MinDate as dt, 1 as depth
    UNION ALL
    SELECT DATEADD(hh, depth, @MinDate), 1 + depth as depth
    FROM times
    WHERE DATEADD(hh, depth, @MinDate) &lt;= GETDATE())
SELECT DATEPART(YEAR, t.dt) as [Year],
    DATEPART(MONTH, t.dt) as [Month],
    DATEPART(DAY, t.dt) as [Day],
    DATEPART(HOUR, t.dt) as [Hour],
    COUNT(tdm_msg) as Total_ACTIVITES
FROM times t
LEFT JOIN (SELECT * FROM TCKT_ACT WHERE tdm_msg = '4162' and dev_time &gt;= @MinDate) a
    ON  DATEPART(HOUR, t.dt)  = DATEPART(HOUR, a.dev_time)
    AND MONTH(t.dt) = MONTH(a.dev_time)
    AND DAY(t.dt)   = DAY(a.dev_time)
    AND YEAR(t.dt)  = YEAR(a.dev_time)
GROUP BY DATEPART(YEAR, t.dt) ,
    DATEPART(MONTH, t.dt) ,
    DATEPART(DAY, t.dt),
    DATEPART(HOUR, t.dt)
ORDER BY DATEPART(YEAR, t.dt) asc,
    DATEPART(MONTH, t.dt) asc,
    DATEPART(DAY, t.dt) asc,
    DATEPART(HOUR, t.dt) asc
OPTION (MAXRECURSION 0); /* Just in case you want a longer timespan later on... */
</code></pre>

<p>Note that the WITH statement at the top is called a recursive common table expression, and is a good way of generating sequential tables with relatively small numbers of elements, like you have here.   </p>
"
1112,512350,2,7,sql,What coding tricks have you used to avoid writing more sql?,"<p>This question was suggested by <a href=""http://stackoverflow.com/users/5486/kyralessa"">Kyralessa</a> in the <a href=""http://stackoverflow.com/questions/488020/what-is-your-most-useful-sql-trick-to-avoid-writing-more-code"">What is your most useful sql trick to avoid writing more sql?.</a>   I got so many good ideas to try from the last question, that I am interested to see what comes up with this question.</p>

<p>Once again, I am not keeping the reputation from this question.  I am waiting 7 days, for answers, then marking it wiki.  The reputation that the question has earned, goes into a bounty for the question.  </p>

<p>Ground Rules:</p>

<ul>
<li><p>While it is certainly reasonable to write code, to move processing from SQL into the code to address performance issues, that is really not the point of the question.  The question is not limited to performance issues.   The goal is less simply less sql to get the job done.</p></li>
<li><p>Communicate the concept, so that other users say ""Oh Wow, I didn't know you could do that.""</p></li>
<li><p>Example code is very useful, to help people that are primarily visual learners.</p></li>
<li><p>Explicitly state what Language you are using, and which dialect of SQL you are using.</p></li>
<li><p>Put yourself in your readers shoes.  What would they need to see right there on the screen in front of them, that will cause an epiphany.  Your answer is there to benefit the reader.  Write it for them.</p></li>
<li><p>Offsite links are ok, if they appear after the example.  Offsite links as a substitute for a real answer are not.</p></li>
</ul>

<p>There are probably other things to make it nicer for the reader that I haven't thought of.  Get Creative. Share knowledge.  Have fun showing off.</p>

<p>[EDIT] - It looks like there hasen't been any activity in a while.   5 votes = 50, so there is the bounty, and it has been wikified.</p>
","<p>Language: C#/ VB.NET. </p>

<p>I currently can write a DB backed system without writing any SQL at all. My DAL uses the POJO's class definitions to generate SQL on the fly. Example:</p>

<pre><code>SearchCriteria sc = new SearchCriteria();
sc.AddBinding(""Customer_id"", ""ALFKI"");
List&lt;Entity&gt; customers = SQL.Read(sc, new Customers());
</code></pre>

<p>The code above will return a list of Customer instances matching Customer_id to ""ALFKI"". The DAL connects to the db, builds the SQL, executes it, instantiates new objects, populate them and send them back. When you are done changing the objects, simply call</p>

<pre><code>SQL.Write(customer);
</code></pre>

<p>to have all changed items updated back to the db - mind you, only the ones that changed and only the columns that changed.</p>

<p>Added bonus: it supports SQL Server, Oracle, Informix. Client code never has to change.</p>
"
1113,512350,1,7,sql,What coding tricks have you used to avoid writing more sql?,"<p>This question was suggested by <a href=""http://stackoverflow.com/users/5486/kyralessa"">Kyralessa</a> in the <a href=""http://stackoverflow.com/questions/488020/what-is-your-most-useful-sql-trick-to-avoid-writing-more-code"">What is your most useful sql trick to avoid writing more sql?.</a>   I got so many good ideas to try from the last question, that I am interested to see what comes up with this question.</p>

<p>Once again, I am not keeping the reputation from this question.  I am waiting 7 days, for answers, then marking it wiki.  The reputation that the question has earned, goes into a bounty for the question.  </p>

<p>Ground Rules:</p>

<ul>
<li><p>While it is certainly reasonable to write code, to move processing from SQL into the code to address performance issues, that is really not the point of the question.  The question is not limited to performance issues.   The goal is less simply less sql to get the job done.</p></li>
<li><p>Communicate the concept, so that other users say ""Oh Wow, I didn't know you could do that.""</p></li>
<li><p>Example code is very useful, to help people that are primarily visual learners.</p></li>
<li><p>Explicitly state what Language you are using, and which dialect of SQL you are using.</p></li>
<li><p>Put yourself in your readers shoes.  What would they need to see right there on the screen in front of them, that will cause an epiphany.  Your answer is there to benefit the reader.  Write it for them.</p></li>
<li><p>Offsite links are ok, if they appear after the example.  Offsite links as a substitute for a real answer are not.</p></li>
</ul>

<p>There are probably other things to make it nicer for the reader that I haven't thought of.  Get Creative. Share knowledge.  Have fun showing off.</p>

<p>[EDIT] - It looks like there hasen't been any activity in a while.   5 votes = 50, so there is the bounty, and it has been wikified.</p>
","<p>Where I work we've done several things to reduce SQL and to reduce the associated overhead of using SQL in Java. (We run Java with MSSQL, MySQL, and Oracle).</p>

<p>The most useful trick is to use Java's setObject method for binding parameters.  This, combined with Varargs, lets you write a utility method for executing SQL:</p>

<pre><code>DBUtil.execSQL(Connection con, String sql, Object... params)
</code></pre>

<p>Simply iterate over the parameters and use statement.setObject(index, param[index-1]).  For nulls you use setNull().  We've extended this concept for queries, with a getResultSet method; the wrapped ResultSet object also closes its statement, making it easier to do resource management.</p>

<p>To reduce actual SQL code written, we have a query building framework that lets you specify a bunch of columns and their types, and then use this to automatically specify search criteria and output columns.  We can easily specify joins and join criteria and this handles most of the normal cases.  The advantage is that you can generate a report in about 10 lines of code, including different query parameters, sorting, grouping, etc.  The code is too complex to include here.</p>

<p>I've also used Oracle's ALL_TABLES and ALL_TAB_COLUMNS tables to generate SELECT statements; another trick I've used is using the ResultSetMetadata to analyze the table:</p>

<pre><code>ResultSet rs = DBUtil.getResultSet(con, ""SELECT * FROM "" + someTable);
ResultSetMetaData rsm = rs.getMetaData();

boolean first = true;
for (int i = 1; i &lt;= rsm.getColumnCount(); i++) {
  String col = rsm.getColumnName(i).toUpperCase();
  // do something with the column name
}
</code></pre>

<p>This makes it easy to generate certain kinds of statements; in this case we have an active table and an archive table and we are moving records from one to the other.  Without getting into a debate about using an archive table, the Java code I've written lets me modify the two tables without having to modify the archiving script.</p>

<p>Another trick we use is to use constants for all our table and column names.  This makes typing out SQL a little tedious but it allows us to (among other things) generate SQL easily for tables with similar or identical construction.  Since we use constants to define the column names the code actually enforces that the the identical columns have the same name.  Using constants also lets you find references to a particular column, thus allowing you to examine other SQL statements that may be related to the work you are doing.  This lets us re-use SQL from other modules, instead of blindly re-writing the same statement again.</p>
"
1119,512350,0,7,sql,What coding tricks have you used to avoid writing more sql?,"<p>This question was suggested by <a href=""http://stackoverflow.com/users/5486/kyralessa"">Kyralessa</a> in the <a href=""http://stackoverflow.com/questions/488020/what-is-your-most-useful-sql-trick-to-avoid-writing-more-code"">What is your most useful sql trick to avoid writing more sql?.</a>   I got so many good ideas to try from the last question, that I am interested to see what comes up with this question.</p>

<p>Once again, I am not keeping the reputation from this question.  I am waiting 7 days, for answers, then marking it wiki.  The reputation that the question has earned, goes into a bounty for the question.  </p>

<p>Ground Rules:</p>

<ul>
<li><p>While it is certainly reasonable to write code, to move processing from SQL into the code to address performance issues, that is really not the point of the question.  The question is not limited to performance issues.   The goal is less simply less sql to get the job done.</p></li>
<li><p>Communicate the concept, so that other users say ""Oh Wow, I didn't know you could do that.""</p></li>
<li><p>Example code is very useful, to help people that are primarily visual learners.</p></li>
<li><p>Explicitly state what Language you are using, and which dialect of SQL you are using.</p></li>
<li><p>Put yourself in your readers shoes.  What would they need to see right there on the screen in front of them, that will cause an epiphany.  Your answer is there to benefit the reader.  Write it for them.</p></li>
<li><p>Offsite links are ok, if they appear after the example.  Offsite links as a substitute for a real answer are not.</p></li>
</ul>

<p>There are probably other things to make it nicer for the reader that I haven't thought of.  Get Creative. Share knowledge.  Have fun showing off.</p>

<p>[EDIT] - It looks like there hasen't been any activity in a while.   5 votes = 50, so there is the bounty, and it has been wikified.</p>
","<p>Using built-in .NET features, such as Expression Columns (VB example shown) 
to data bind multiple columns to be displayed at once:</p>

<pre><code>ds.Tables(0).Columns.Add(
    New DataColumn(""CustomDescription"", GetType(String), 
                   ""LastName + ', ' + FirstName + ' - ' + 
                   WorkEmail""))
ResultsListBox.DataSource = ds
ResultsListBox.DataTextField = ""CustomDescription""
ResultsListBox.DataValueField = ""EmployeeID""
ResultsListBox.DataBind()
</code></pre>
"
1093,497390,2,7,sql,Mathematical formula for calculating call duration,"<p>I was working for a telecom company some years ago and I had to generate a formula which calculates duration of a call according to the following algorithm:</p>

<ul>
<li>t1 is the first period  </li>
<li>t2 is the recurring period</li>
<li>RCT is the actual call time (in seconds)</li>
<li>CD is the effective call duration (for billing purposes)</li>
</ul>

<p>if RCT is less than t1, then the CD equals t1<br />
if RCT is greater than t1, then CD = t1 + x*t2, where x will ""round"" RCT to the next highest multiple of t2.</p>

<p>This algorithm translates to: ""Charge for the first t1 seconds, then charge every t2 seconds after that"".</p>

<p>Example:</p>

<pre><code>t1	t2	RCT	CD	
60	10	48	60
60	10	65	70
60	10	121	130
30	20	25	30
30	20	35	50
30	20	65	70
</code></pre>

<p>Can you create a function / SQL that will return the ""call duration"" CD?</p>

<p>Without using if then else ...?</p>
","<p>EDIT: simplified further, and fixed &lt; vs &lt;= error. </p>

<p>No floating point and worked on every database I have access to:</p>

<pre><code>create table calls (t1 int, t2 int, rct int, cd int)

insert into calls (t1, t2, rct, cd) 
values (60, 10, 48, 60)

insert into calls (t1, t2, rct, cd) 
values (60, 10, 65, 70)

insert into calls  (t1, t2, rct, cd)
values (60, 10, 121, 130)

insert into calls  (t1, t2, rct, cd)
values (30, 20, 25, 30)

insert into calls  (t1, t2, rct, cd)
values (30, 20, 35, 50)

insert into calls  (t1, t2, rct, cd)
values (30, 20, 65, 70)

--Additional test to show that it works
insert into calls  (t1, t2, rct, cd)
values (60, 10, 70, 70)

select t1, t2, rct, cd, 
t1 + case when rct &lt;= t1 
  then 0 
  else ( (rct-1-t1) / t2 + 1) * t2 end as CalceCD
from calls
</code></pre>

<p>Result: </p>

<pre>
t1          t2          rct         cd          CalceCD
----------- ----------- ----------- ----------- -----------
60          10          48          60          60
60          10          65          70          70
60          10          121         130         130
30          20          25          30          30
30          20          35          50          50
30          20          65          70          70
60          10          70          70          70

(6 row(s) affected)

</pre>

<p>You would be free to create the function as a UDF or whatever your SQL environment allows to clean up the select.</p>

<p>Edit: yes, floor and an offset of one avoids floating math.</p>
"
200,91360,1,7,sql,How to calculate the sum of values in a tree using SQL,"<p>I need to sum points on each level earned by a tree of users. Level 1 is the sum of users' points of the users 1 level below the user. Level 2 is the Level 1 points of the users 2 levels below the user, etc...</p>

<p>The calculation happens once a month on a non production server, no worries about performance.</p>

<p>What would the SQL look like to do it?</p>

<p>If you're confused, don't worry, I am as well!</p>

<p>User table:</p>

<pre><code>ID    ParentID    Points
1     0           230
2     1           150
3     0           80
4     1           110
5     4           54
6     4           342

Tree:
0
|---\
1    3
| \
2  4---
    \  \
     5  6
</code></pre>

<p>Output should be:</p>

<pre><code>ID    Points    Level1     Level2
1     230       150+110    150+110+54+342
2     150
3     80
4     110       54+342
5     54
6     342
</code></pre>

<p>SQL Server Syntax and functions preferably...</p>
","<p>I would say: create a stored procedure, probably has the best performance.
Or if you have a maximum number of levels, you could create subqueries, but they will have a very poort performance.</p>

<p>(Or you could get MS SQL Server 2008 and get the new hierarchy functions... ;) )</p>
"
847,373490,0,7,sql,Insert Dates in the return from a query where there is none,"<p>We are building a query to count the number of events per hour, per day. Most days there are hours that do not have any activity and therefore where the query is run the count of activities per hour show up but there are gaps and the query excludes these. We still want to show the hours that do not have activity and display a zero so that zero value can then be charted. The query we using looks like this </p>

<pre><code>select datepart(Year, dev_time) as Year,
    datepart(Month, dev_time) as Month,
    datepart(Day, dev_time) as Day,
    datepart(Hour, dev_time) as Hour,
    count(tdm_msg) as Total_ACTIVITES
from TCKT_ACT
where tdm_msg = 4162 and dev_time &gt;= DATEADD(day, - 1, GETDATE())
group by datepart(Year, dev_time) ,
    datepart(Month, dev_time) ,
    datepart(Day, dev_time),
    datepart(Hour, dev_time)
order by datepart(Year, dev_time) asc,
    datepart(Month, dev_time) asc,
    datepart(Day, dev_time) asc,
    datepart(Hour, dev_time) asc
</code></pre>
","<p>The basic answer here involves a left outer join (LOJ), and an explicit <code>COUNT(column)</code> since that does not count nulls but COUNT(*) counts all rows.  The hard part is generating a table against which to do the LOJ.  The WITH clause and recursive solution will work in a number of DBMS (MS SQL Server, apparently, and almost certainly DB2 -- probably others too).</p>

<p>Many DBMS support temporary tables and stored procedures; the combination could be used to populate a table with an appropriate set of values for the date/time field, and then do the LOJ against that table (or, more precisely, FROM temp_table LEFT OUTER JOIN main_table ...).  Not as neat and tidy, but works most places.</p>
"
201,91360,2,7,sql,How to calculate the sum of values in a tree using SQL,"<p>I need to sum points on each level earned by a tree of users. Level 1 is the sum of users' points of the users 1 level below the user. Level 2 is the Level 1 points of the users 2 levels below the user, etc...</p>

<p>The calculation happens once a month on a non production server, no worries about performance.</p>

<p>What would the SQL look like to do it?</p>

<p>If you're confused, don't worry, I am as well!</p>

<p>User table:</p>

<pre><code>ID    ParentID    Points
1     0           230
2     1           150
3     0           80
4     1           110
5     4           54
6     4           342

Tree:
0
|---\
1    3
| \
2  4---
    \  \
     5  6
</code></pre>

<p>Output should be:</p>

<pre><code>ID    Points    Level1     Level2
1     230       150+110    150+110+54+342
2     150
3     80
4     110       54+342
5     54
6     342
</code></pre>

<p>SQL Server Syntax and functions preferably...</p>
","<p>If you were using Oracle DBMS that would be pretty straightforward since Oracle supports tree queries with the <strong>CONNECT BY/STARTS WITH</strong> syntax. For SQL Server I think you might find <a href=""http://searchwindevelopment.techtarget.com/tip/0,289483,sid8_gci1277481,00.html"" rel=""nofollow"">Common Table Expressions</a> useful</p>
"
202,91360,2,7,sql,How to calculate the sum of values in a tree using SQL,"<p>I need to sum points on each level earned by a tree of users. Level 1 is the sum of users' points of the users 1 level below the user. Level 2 is the Level 1 points of the users 2 levels below the user, etc...</p>

<p>The calculation happens once a month on a non production server, no worries about performance.</p>

<p>What would the SQL look like to do it?</p>

<p>If you're confused, don't worry, I am as well!</p>

<p>User table:</p>

<pre><code>ID    ParentID    Points
1     0           230
2     1           150
3     0           80
4     1           110
5     4           54
6     4           342

Tree:
0
|---\
1    3
| \
2  4---
    \  \
     5  6
</code></pre>

<p>Output should be:</p>

<pre><code>ID    Points    Level1     Level2
1     230       150+110    150+110+54+342
2     150
3     80
4     110       54+342
5     54
6     342
</code></pre>

<p>SQL Server Syntax and functions preferably...</p>
","<p>Trees don't work well with SQL. If you have very (very very) few write accesses, you could change the tree implementation to use nested sets, that would make this query incredibly easy (SELECT SUM(points) FROM users where left > x and right &lt; y, if I'm not mistaken). However, any changes on the tree require touching a massive amount of rows. It's probably better to just do the recursion in you client. </p>
"
203,91360,0,7,sql,How to calculate the sum of values in a tree using SQL,"<p>I need to sum points on each level earned by a tree of users. Level 1 is the sum of users' points of the users 1 level below the user. Level 2 is the Level 1 points of the users 2 levels below the user, etc...</p>

<p>The calculation happens once a month on a non production server, no worries about performance.</p>

<p>What would the SQL look like to do it?</p>

<p>If you're confused, don't worry, I am as well!</p>

<p>User table:</p>

<pre><code>ID    ParentID    Points
1     0           230
2     1           150
3     0           80
4     1           110
5     4           54
6     4           342

Tree:
0
|---\
1    3
| \
2  4---
    \  \
     5  6
</code></pre>

<p>Output should be:</p>

<pre><code>ID    Points    Level1     Level2
1     230       150+110    150+110+54+342
2     150
3     80
4     110       54+342
5     54
6     342
</code></pre>

<p>SQL Server Syntax and functions preferably...</p>
","<p>You have a couple of options:</p>

<ol>
<li>Use a cursor and a recursive user-defined function call (it's quite slow)</li>
<li>Create a cache table, update it on INSERT using a trigger (it's the fastest solution but could be problematic if you have lots of updates to the main table)</li>
<li>Do a client-side recursive calculation (preferable if you don't have too many records)</li>
</ol>
"
846,373490,0,7,sql,Insert Dates in the return from a query where there is none,"<p>We are building a query to count the number of events per hour, per day. Most days there are hours that do not have any activity and therefore where the query is run the count of activities per hour show up but there are gaps and the query excludes these. We still want to show the hours that do not have activity and display a zero so that zero value can then be charted. The query we using looks like this </p>

<pre><code>select datepart(Year, dev_time) as Year,
    datepart(Month, dev_time) as Month,
    datepart(Day, dev_time) as Day,
    datepart(Hour, dev_time) as Hour,
    count(tdm_msg) as Total_ACTIVITES
from TCKT_ACT
where tdm_msg = 4162 and dev_time &gt;= DATEADD(day, - 1, GETDATE())
group by datepart(Year, dev_time) ,
    datepart(Month, dev_time) ,
    datepart(Day, dev_time),
    datepart(Hour, dev_time)
order by datepart(Year, dev_time) asc,
    datepart(Month, dev_time) asc,
    datepart(Day, dev_time) asc,
    datepart(Hour, dev_time) asc
</code></pre>
","<p>It sounds like you could use a ""left outer join"" using another table that has the numbers 1 through 24 in it...</p>
"
845,373490,2,7,sql,Insert Dates in the return from a query where there is none,"<p>We are building a query to count the number of events per hour, per day. Most days there are hours that do not have any activity and therefore where the query is run the count of activities per hour show up but there are gaps and the query excludes these. We still want to show the hours that do not have activity and display a zero so that zero value can then be charted. The query we using looks like this </p>

<pre><code>select datepart(Year, dev_time) as Year,
    datepart(Month, dev_time) as Month,
    datepart(Day, dev_time) as Day,
    datepart(Hour, dev_time) as Hour,
    count(tdm_msg) as Total_ACTIVITES
from TCKT_ACT
where tdm_msg = 4162 and dev_time &gt;= DATEADD(day, - 1, GETDATE())
group by datepart(Year, dev_time) ,
    datepart(Month, dev_time) ,
    datepart(Day, dev_time),
    datepart(Hour, dev_time)
order by datepart(Year, dev_time) asc,
    datepart(Month, dev_time) asc,
    datepart(Day, dev_time) asc,
    datepart(Hour, dev_time) asc
</code></pre>
","<p>We had a similar problem with some performance monitoring software but, being in a DB2/z mainframe shop, we're dead set against having to do SQL gymnastics to get those sort of results.  SQL queries that perform 'functions' on every row they retrieve are notoriously unscalable and the DBAs would have a field day laughing at us if we tried to use them.</p>

<p>Instead, we found it easier to refactor the database schema to include a count of events in each row (apparently our DBAs don't mind using more disk space, just more CPU grunt).  In your case, that would be adding a column called <code>tdm_quant</code> which you would set to 1 for every row that you insert (i.e., each event).</p>

<p>Then the fifth field of your query changes from <code>count(tdm_msg)</code> to <code>sum(tdm_quant)</code> which will achieve the same result.</p>

<p>In addition to that you can insert a special record (once an hour, or 24 of them at the start of each day, or populate the entire years worth on January 1 if you wish) where the <code>tdm_quant</code> field is set to zero.  Being zero, these records will have no effect on the <code>sum(tdm_quant)</code> but you will get your desired behaviour, a row returned for <strong>every</strong> hour of the day which will have zero as <code>Total_ACTIVITIES</code> where no events occurred in that hour.</p>

<p>The rest of your query will not need to change.</p>
"
1118,512350,1,7,sql,What coding tricks have you used to avoid writing more sql?,"<p>This question was suggested by <a href=""http://stackoverflow.com/users/5486/kyralessa"">Kyralessa</a> in the <a href=""http://stackoverflow.com/questions/488020/what-is-your-most-useful-sql-trick-to-avoid-writing-more-code"">What is your most useful sql trick to avoid writing more sql?.</a>   I got so many good ideas to try from the last question, that I am interested to see what comes up with this question.</p>

<p>Once again, I am not keeping the reputation from this question.  I am waiting 7 days, for answers, then marking it wiki.  The reputation that the question has earned, goes into a bounty for the question.  </p>

<p>Ground Rules:</p>

<ul>
<li><p>While it is certainly reasonable to write code, to move processing from SQL into the code to address performance issues, that is really not the point of the question.  The question is not limited to performance issues.   The goal is less simply less sql to get the job done.</p></li>
<li><p>Communicate the concept, so that other users say ""Oh Wow, I didn't know you could do that.""</p></li>
<li><p>Example code is very useful, to help people that are primarily visual learners.</p></li>
<li><p>Explicitly state what Language you are using, and which dialect of SQL you are using.</p></li>
<li><p>Put yourself in your readers shoes.  What would they need to see right there on the screen in front of them, that will cause an epiphany.  Your answer is there to benefit the reader.  Write it for them.</p></li>
<li><p>Offsite links are ok, if they appear after the example.  Offsite links as a substitute for a real answer are not.</p></li>
</ul>

<p>There are probably other things to make it nicer for the reader that I haven't thought of.  Get Creative. Share knowledge.  Have fun showing off.</p>

<p>[EDIT] - It looks like there hasen't been any activity in a while.   5 votes = 50, so there is the bounty, and it has been wikified.</p>
","<p>In one of my projects, I use a meta-model (tables, columns, relations) which adds information to the built-in sys* views.</p>

<p>Part of the data in my meta-model is used to generate logging triggers for insert/update/delete, and to implement cascading deletes in the instead-of delete triggers. With approx. 100 tables the generated code for these triggers is about 12.000 lines of TSQL code.</p>

<p>An SP generates a C# data structure which compares the live database schema with my development database schema to make sure upgrades went ok.</p>

<p>Recently the meta-model even allowed me to generate C# code for delete validation (i.e. can't delete record if depending records exist) in FormView-based Asp.Net forms.</p>
"
1117,512350,2,7,sql,What coding tricks have you used to avoid writing more sql?,"<p>This question was suggested by <a href=""http://stackoverflow.com/users/5486/kyralessa"">Kyralessa</a> in the <a href=""http://stackoverflow.com/questions/488020/what-is-your-most-useful-sql-trick-to-avoid-writing-more-code"">What is your most useful sql trick to avoid writing more sql?.</a>   I got so many good ideas to try from the last question, that I am interested to see what comes up with this question.</p>

<p>Once again, I am not keeping the reputation from this question.  I am waiting 7 days, for answers, then marking it wiki.  The reputation that the question has earned, goes into a bounty for the question.  </p>

<p>Ground Rules:</p>

<ul>
<li><p>While it is certainly reasonable to write code, to move processing from SQL into the code to address performance issues, that is really not the point of the question.  The question is not limited to performance issues.   The goal is less simply less sql to get the job done.</p></li>
<li><p>Communicate the concept, so that other users say ""Oh Wow, I didn't know you could do that.""</p></li>
<li><p>Example code is very useful, to help people that are primarily visual learners.</p></li>
<li><p>Explicitly state what Language you are using, and which dialect of SQL you are using.</p></li>
<li><p>Put yourself in your readers shoes.  What would they need to see right there on the screen in front of them, that will cause an epiphany.  Your answer is there to benefit the reader.  Write it for them.</p></li>
<li><p>Offsite links are ok, if they appear after the example.  Offsite links as a substitute for a real answer are not.</p></li>
</ul>

<p>There are probably other things to make it nicer for the reader that I haven't thought of.  Get Creative. Share knowledge.  Have fun showing off.</p>

<p>[EDIT] - It looks like there hasen't been any activity in a while.   5 votes = 50, so there is the bounty, and it has been wikified.</p>
","<p>I rolled my own ORL (Object-Relational Mapper) in PHP for MySQL. It really simplifies everything that has to do with changing the database, and it works very well for simple situations.</p>

<p>It consists of a base class that you can inherit from. You subclass it easily:</p>

<pre><code>&lt;?php
class CSomething extends CDatabaseObject
{

}

// create a new Something
$oSomething = new CSomething();
$oSomething-&gt;somevariable = 'blah';
$oSomething-&gt;Save();

// fetch an old Something by primary key
$oSomething = new CSomething(1);
// .. and delete it
$oSomething-&gt;Delete();
?&gt;
</code></pre>

<p>It automatically figures out the indexes in the table, and the primary key. If it is required, you can of course tell the class these things if it does something bad.</p>

<p>You can do basic searches by specifying the WHERE clause of the SQL (so it isn't entirely SQL free). Since it nows about the data types of the fields, parameterized queries are simple.</p>

<p>Of course, it can't do everything I need, but it saves a lot of development time and code. </p>
"
1094,497390,4,7,sql,Mathematical formula for calculating call duration,"<p>I was working for a telecom company some years ago and I had to generate a formula which calculates duration of a call according to the following algorithm:</p>

<ul>
<li>t1 is the first period  </li>
<li>t2 is the recurring period</li>
<li>RCT is the actual call time (in seconds)</li>
<li>CD is the effective call duration (for billing purposes)</li>
</ul>

<p>if RCT is less than t1, then the CD equals t1<br />
if RCT is greater than t1, then CD = t1 + x*t2, where x will ""round"" RCT to the next highest multiple of t2.</p>

<p>This algorithm translates to: ""Charge for the first t1 seconds, then charge every t2 seconds after that"".</p>

<p>Example:</p>

<pre><code>t1	t2	RCT	CD	
60	10	48	60
60	10	65	70
60	10	121	130
30	20	25	30
30	20	35	50
30	20	65	70
</code></pre>

<p>Can you create a function / SQL that will return the ""call duration"" CD?</p>

<p>Without using if then else ...?</p>
","<p>Assuming int columns:</p>

<pre><code>SELECT t1
    ,t2
    ,RCT
    CASE
    WHEN RCT &lt; t1
        THEN t1 
    ELSE
        t1 + t2 * ((RCT - t1) / t2 + SIGN((RCT - t1) % t2))
    END AS CD
</code></pre>

<p>But I guess there is still one CASE, let me see if I can get rid of it.</p>

<p>With only integer arithmetic (still not ANSI):</p>

<pre><code>SELECT  t1
       ,t2
       ,RCT
       ,CD
       ,t1 + SIGN(RCT / t1) * t2 * ((RCT - t1) / t2 + SIGN((RCT - t1) % t2)) AS CalcCD
FROM    Calls
</code></pre>
"
1115,512350,0,7,sql,What coding tricks have you used to avoid writing more sql?,"<p>This question was suggested by <a href=""http://stackoverflow.com/users/5486/kyralessa"">Kyralessa</a> in the <a href=""http://stackoverflow.com/questions/488020/what-is-your-most-useful-sql-trick-to-avoid-writing-more-code"">What is your most useful sql trick to avoid writing more sql?.</a>   I got so many good ideas to try from the last question, that I am interested to see what comes up with this question.</p>

<p>Once again, I am not keeping the reputation from this question.  I am waiting 7 days, for answers, then marking it wiki.  The reputation that the question has earned, goes into a bounty for the question.  </p>

<p>Ground Rules:</p>

<ul>
<li><p>While it is certainly reasonable to write code, to move processing from SQL into the code to address performance issues, that is really not the point of the question.  The question is not limited to performance issues.   The goal is less simply less sql to get the job done.</p></li>
<li><p>Communicate the concept, so that other users say ""Oh Wow, I didn't know you could do that.""</p></li>
<li><p>Example code is very useful, to help people that are primarily visual learners.</p></li>
<li><p>Explicitly state what Language you are using, and which dialect of SQL you are using.</p></li>
<li><p>Put yourself in your readers shoes.  What would they need to see right there on the screen in front of them, that will cause an epiphany.  Your answer is there to benefit the reader.  Write it for them.</p></li>
<li><p>Offsite links are ok, if they appear after the example.  Offsite links as a substitute for a real answer are not.</p></li>
</ul>

<p>There are probably other things to make it nicer for the reader that I haven't thought of.  Get Creative. Share knowledge.  Have fun showing off.</p>

<p>[EDIT] - It looks like there hasen't been any activity in a while.   5 votes = 50, so there is the bounty, and it has been wikified.</p>
","<p>I have used <a href=""http://www.outlet-orm.org/site/"" rel=""nofollow"">outlet-orm</a> which is an awesome ORM solution that doesn't generate.  I think out of all the tricks I have done in the past this one has been by far the most convenient and time saving.</p>
"
339,150250,1,7,sql,While-clause in T-SQL that loops forever,"<p>I was recently tasked with debugging a strange problem within an e-commerce application. After an application upgrade the site started to hang from time to time and I was sent in to debug. After checking the event log I found that the SQL-server wrote ~200 000 events in a couple of minutes with the message saying that a constraint had failed. After much debugging and some tracing I found the culprit. I've removed some unnecessary code and cleaned it up a bit but essentially this is it</p>

<pre><code>WHILE EXISTS (SELECT * FROM ShoppingCartItem WHERE ShoppingCartItem.PurchID = @PurchID)
BEGIN
	SELECT TOP 1 
		@TmpGFSID = ShoppingCartItem.GFSID, 
		@TmpQuantity = ShoppingCartItem.Quantity,
		@TmpShoppingCartItemID = ShoppingCartItem.ShoppingCartItemID,
	FROM
		ShoppingCartItem INNER JOIN GoodsForSale on ShoppingCartItem.GFSID = GoodsForSale.GFSID
	WHERE ShoppingCartItem.PurchID = @PurchID

	EXEC @ErrorCode = spGoodsForSale_ReverseReservations @TmpGFSID, @TmpQuantity
	IF @ErrorCode &lt;&gt; 0
	BEGIN
		Goto Cleanup	
	END

	DELETE FROM ShoppingCartItem WHERE ShoppingCartItem.ShoppingCartItemID = @TmpShoppingCartItemID
	-- @@ROWCOUNT is 1 after this
END
</code></pre>

<p>Facts:</p>

<ol>
<li>There's only one or two records matching the first select-clause</li>
<li>RowCount from the DELETE statement indicates that it has been removed</li>
<li>The WHILE-clause will loop forever</li>
</ol>

<p>The procedure has been rewritten to select the rows that should be deleted into a temporary in-memory table instead so the immediate problem is solved but this really sparked my curiosity.</p>

<p>Why does it loop forever?</p>

<p><strong>Clarification</strong>: The delete doesn't fail (@@rowcount is 1 after the delete stmt when debugged)
<strong>Clarification 2</strong>: It shouldn't matter whether or not the SELECT TOP ... clause is ordered by any specific field since the record with the returned id will be deleted so in the next loop it should get another record.</p>

<p><strong>Update</strong>: After checking the subversion logs I found the culprit commit that made this stored procedure to go haywire. The only real difference that I can find is that there previously was no join in the SELECT TOP 1 statement i.e. without that join it worked without any transaction statements surrounding the delete. It appears to be the introduction of the join that made SQL server more picky.</p>

<p><strong>Update clarification</strong>:  <a href=""http://stackoverflow.com/questions/150250/while-clause-in-t-sql-that-loops-forever#150400"">brien</a> pointed out that there's no need for the join but we actually do use some fields from the GoodsForSale table but I've removed them to keep the code simply so that we can concentrate on the problem at hand</p>
","<p>Is there a record in ShoppingCartItem with that @PurchID where the GFSID is not in the GoodsForSale table?  That would explain why the EXISTS returns true, but there are no more  records to delete.</p>
"
80,32000,1,7,sql,C# - SQLClient - Simplest INSERT,"<p>I'm basically trying to figure out the simplest way to perform your basic insert operation in C#.NET using the SqlClient namespace. </p>

<p>I'm using <code>SqlConnection</code> for my db link, I've already had success executing some reads, and I want to know the simplest way to insert data. I'm finding what seem to be pretty verbose methods when I google.</p>
","<p>Since you seem to be just getting started with this now is the best time to familiarize yourself with the concept of a Data Access Layer (<a href=""http://en.wikipedia.org/wiki/Data_access_layer"" rel=""nofollow"">obligatory wikipedia link</a>).  It will be very helpful for you down the road when you're apps have more interaction with the database throughout and you want to minimize code duplication.  Also makes for more consistent behavior, making testing and tons of other things easier.</p>
"
336,150250,0,7,sql,While-clause in T-SQL that loops forever,"<p>I was recently tasked with debugging a strange problem within an e-commerce application. After an application upgrade the site started to hang from time to time and I was sent in to debug. After checking the event log I found that the SQL-server wrote ~200 000 events in a couple of minutes with the message saying that a constraint had failed. After much debugging and some tracing I found the culprit. I've removed some unnecessary code and cleaned it up a bit but essentially this is it</p>

<pre><code>WHILE EXISTS (SELECT * FROM ShoppingCartItem WHERE ShoppingCartItem.PurchID = @PurchID)
BEGIN
	SELECT TOP 1 
		@TmpGFSID = ShoppingCartItem.GFSID, 
		@TmpQuantity = ShoppingCartItem.Quantity,
		@TmpShoppingCartItemID = ShoppingCartItem.ShoppingCartItemID,
	FROM
		ShoppingCartItem INNER JOIN GoodsForSale on ShoppingCartItem.GFSID = GoodsForSale.GFSID
	WHERE ShoppingCartItem.PurchID = @PurchID

	EXEC @ErrorCode = spGoodsForSale_ReverseReservations @TmpGFSID, @TmpQuantity
	IF @ErrorCode &lt;&gt; 0
	BEGIN
		Goto Cleanup	
	END

	DELETE FROM ShoppingCartItem WHERE ShoppingCartItem.ShoppingCartItemID = @TmpShoppingCartItemID
	-- @@ROWCOUNT is 1 after this
END
</code></pre>

<p>Facts:</p>

<ol>
<li>There's only one or two records matching the first select-clause</li>
<li>RowCount from the DELETE statement indicates that it has been removed</li>
<li>The WHILE-clause will loop forever</li>
</ol>

<p>The procedure has been rewritten to select the rows that should be deleted into a temporary in-memory table instead so the immediate problem is solved but this really sparked my curiosity.</p>

<p>Why does it loop forever?</p>

<p><strong>Clarification</strong>: The delete doesn't fail (@@rowcount is 1 after the delete stmt when debugged)
<strong>Clarification 2</strong>: It shouldn't matter whether or not the SELECT TOP ... clause is ordered by any specific field since the record with the returned id will be deleted so in the next loop it should get another record.</p>

<p><strong>Update</strong>: After checking the subversion logs I found the culprit commit that made this stored procedure to go haywire. The only real difference that I can find is that there previously was no join in the SELECT TOP 1 statement i.e. without that join it worked without any transaction statements surrounding the delete. It appears to be the introduction of the join that made SQL server more picky.</p>

<p><strong>Update clarification</strong>:  <a href=""http://stackoverflow.com/questions/150250/while-clause-in-t-sql-that-loops-forever#150400"">brien</a> pointed out that there's no need for the join but we actually do use some fields from the GoodsForSale table but I've removed them to keep the code simply so that we can concentrate on the problem at hand</p>
","<p>Obviously, something is not being deleted or modified where it should. If the condition is still the same on the next iteration, it's going to keep going.</p>

<p>Also, you're comparing @TmpShoppingCartItemID, and not @PurchID. I can see how these could be different, and you could delete a different row than the one that's being checked for in the while statement.</p>
"
204,91360,1,7,sql,How to calculate the sum of values in a tree using SQL,"<p>I need to sum points on each level earned by a tree of users. Level 1 is the sum of users' points of the users 1 level below the user. Level 2 is the Level 1 points of the users 2 levels below the user, etc...</p>

<p>The calculation happens once a month on a non production server, no worries about performance.</p>

<p>What would the SQL look like to do it?</p>

<p>If you're confused, don't worry, I am as well!</p>

<p>User table:</p>

<pre><code>ID    ParentID    Points
1     0           230
2     1           150
3     0           80
4     1           110
5     4           54
6     4           342

Tree:
0
|---\
1    3
| \
2  4---
    \  \
     5  6
</code></pre>

<p>Output should be:</p>

<pre><code>ID    Points    Level1     Level2
1     230       150+110    150+110+54+342
2     150
3     80
4     110       54+342
5     54
6     342
</code></pre>

<p>SQL Server Syntax and functions preferably...</p>
","<p>If you are working with trees stored in a relational database, I'd suggest looking at ""nested set"" or ""modified preorder tree traversal"". The SQL will be as simple as that:</p>

<p>SELECT id, SUM(value) AS value FROM table WHERE left>left_value_of_your_node AND right

<p>... and do this for every node you are interested in.</p>

<p>Maybe this will help you:
<a href=""http://www.dbazine.com/oracle/or-articles/tropashko4"" rel=""nofollow"">http://www.dbazine.com/oracle/or-articles/tropashko4</a> or use google.</p>
"
338,150250,0,7,sql,While-clause in T-SQL that loops forever,"<p>I was recently tasked with debugging a strange problem within an e-commerce application. After an application upgrade the site started to hang from time to time and I was sent in to debug. After checking the event log I found that the SQL-server wrote ~200 000 events in a couple of minutes with the message saying that a constraint had failed. After much debugging and some tracing I found the culprit. I've removed some unnecessary code and cleaned it up a bit but essentially this is it</p>

<pre><code>WHILE EXISTS (SELECT * FROM ShoppingCartItem WHERE ShoppingCartItem.PurchID = @PurchID)
BEGIN
	SELECT TOP 1 
		@TmpGFSID = ShoppingCartItem.GFSID, 
		@TmpQuantity = ShoppingCartItem.Quantity,
		@TmpShoppingCartItemID = ShoppingCartItem.ShoppingCartItemID,
	FROM
		ShoppingCartItem INNER JOIN GoodsForSale on ShoppingCartItem.GFSID = GoodsForSale.GFSID
	WHERE ShoppingCartItem.PurchID = @PurchID

	EXEC @ErrorCode = spGoodsForSale_ReverseReservations @TmpGFSID, @TmpQuantity
	IF @ErrorCode &lt;&gt; 0
	BEGIN
		Goto Cleanup	
	END

	DELETE FROM ShoppingCartItem WHERE ShoppingCartItem.ShoppingCartItemID = @TmpShoppingCartItemID
	-- @@ROWCOUNT is 1 after this
END
</code></pre>

<p>Facts:</p>

<ol>
<li>There's only one or two records matching the first select-clause</li>
<li>RowCount from the DELETE statement indicates that it has been removed</li>
<li>The WHILE-clause will loop forever</li>
</ol>

<p>The procedure has been rewritten to select the rows that should be deleted into a temporary in-memory table instead so the immediate problem is solved but this really sparked my curiosity.</p>

<p>Why does it loop forever?</p>

<p><strong>Clarification</strong>: The delete doesn't fail (@@rowcount is 1 after the delete stmt when debugged)
<strong>Clarification 2</strong>: It shouldn't matter whether or not the SELECT TOP ... clause is ordered by any specific field since the record with the returned id will be deleted so in the next loop it should get another record.</p>

<p><strong>Update</strong>: After checking the subversion logs I found the culprit commit that made this stored procedure to go haywire. The only real difference that I can find is that there previously was no join in the SELECT TOP 1 statement i.e. without that join it worked without any transaction statements surrounding the delete. It appears to be the introduction of the join that made SQL server more picky.</p>

<p><strong>Update clarification</strong>:  <a href=""http://stackoverflow.com/questions/150250/while-clause-in-t-sql-that-loops-forever#150400"">brien</a> pointed out that there's no need for the join but we actually do use some fields from the GoodsForSale table but I've removed them to keep the code simply so that we can concentrate on the problem at hand</p>
","<p>I not sure if I understand the problem, but in the select clause it's making an inner join with another table. That join can cause to get no records and then the delete fails. Try using a left join.</p>
"
609,271120,7,7,sql,Ruby on Rails plugin for showing line numbers in log for SQL queries,"<p>Does anybody know any plugin, that can show line numbers for SQL queries in Rails logs? Something like this:</p>

<pre><code>User Load (0.003154)   SELECT * FROM `users` WHERE (`users`.`id` = 1) - (user.rb, line 24)
</code></pre>

<p>Thanks!</p>
","<p>This plugin puts the stack trace in your logs.  As Daniel mentions it would be tricky to determine the line you wanted but I suspect you could work something out, and the trace itself may be good enough.</p>

<p><a href=""https://github.com/ruckus/active-record-query-trace"" rel=""nofollow"">https://github.com/ruckus/active-record-query-trace</a></p>

<p>Be careful to set it up so you can turn it on and off.  I used this for awhile, and while useful for tracking down specific bugs, it drove me nuts if it was on all the time.</p>
"
340,150250,3,7,sql,While-clause in T-SQL that loops forever,"<p>I was recently tasked with debugging a strange problem within an e-commerce application. After an application upgrade the site started to hang from time to time and I was sent in to debug. After checking the event log I found that the SQL-server wrote ~200 000 events in a couple of minutes with the message saying that a constraint had failed. After much debugging and some tracing I found the culprit. I've removed some unnecessary code and cleaned it up a bit but essentially this is it</p>

<pre><code>WHILE EXISTS (SELECT * FROM ShoppingCartItem WHERE ShoppingCartItem.PurchID = @PurchID)
BEGIN
	SELECT TOP 1 
		@TmpGFSID = ShoppingCartItem.GFSID, 
		@TmpQuantity = ShoppingCartItem.Quantity,
		@TmpShoppingCartItemID = ShoppingCartItem.ShoppingCartItemID,
	FROM
		ShoppingCartItem INNER JOIN GoodsForSale on ShoppingCartItem.GFSID = GoodsForSale.GFSID
	WHERE ShoppingCartItem.PurchID = @PurchID

	EXEC @ErrorCode = spGoodsForSale_ReverseReservations @TmpGFSID, @TmpQuantity
	IF @ErrorCode &lt;&gt; 0
	BEGIN
		Goto Cleanup	
	END

	DELETE FROM ShoppingCartItem WHERE ShoppingCartItem.ShoppingCartItemID = @TmpShoppingCartItemID
	-- @@ROWCOUNT is 1 after this
END
</code></pre>

<p>Facts:</p>

<ol>
<li>There's only one or two records matching the first select-clause</li>
<li>RowCount from the DELETE statement indicates that it has been removed</li>
<li>The WHILE-clause will loop forever</li>
</ol>

<p>The procedure has been rewritten to select the rows that should be deleted into a temporary in-memory table instead so the immediate problem is solved but this really sparked my curiosity.</p>

<p>Why does it loop forever?</p>

<p><strong>Clarification</strong>: The delete doesn't fail (@@rowcount is 1 after the delete stmt when debugged)
<strong>Clarification 2</strong>: It shouldn't matter whether or not the SELECT TOP ... clause is ordered by any specific field since the record with the returned id will be deleted so in the next loop it should get another record.</p>

<p><strong>Update</strong>: After checking the subversion logs I found the culprit commit that made this stored procedure to go haywire. The only real difference that I can find is that there previously was no join in the SELECT TOP 1 statement i.e. without that join it worked without any transaction statements surrounding the delete. It appears to be the introduction of the join that made SQL server more picky.</p>

<p><strong>Update clarification</strong>:  <a href=""http://stackoverflow.com/questions/150250/while-clause-in-t-sql-that-loops-forever#150400"">brien</a> pointed out that there's no need for the join but we actually do use some fields from the GoodsForSale table but I've removed them to keep the code simply so that we can concentrate on the problem at hand</p>
","<p>Are you operating in explicit or implicit <a href=""http://doc.ddart.net/mssql/sql70/ta-tz_8.htm"" rel=""nofollow"">transaction mode</a>?</p>

<p>Since you're in explicit mode, I think you need to surround the DELETE operation with BEGIN TRANSACTION and COMMIT TRANSACTION statements.</p>

<pre><code>WHILE EXISTS (SELECT * FROM ShoppingCartItem WHERE ShoppingCartItem.PurchID = @PurchID)
BEGIN
    SELECT TOP 1 
            @TmpGFSID = ShoppingCartItem.GFSID, 
            @TmpQuantity = ShoppingCartItem.Quantity,
            @TmpShoppingCartItemID = ShoppingCartItem.ShoppingCartItemID,
    FROM
            ShoppingCartItem INNER JOIN GoodsForSale on ShoppingCartItem.GFSID = GoodsForSale.GFSID
    WHERE ShoppingCartItem.PurchID = @PurchID

    EXEC @ErrorCode = spGoodsForSale_ReverseReservations @TmpGFSID, @TmpQuantity
    IF @ErrorCode &lt;&gt; 0
    BEGIN
            Goto Cleanup    
    END

    BEGIN TRANSACTION delete

        DELETE FROM ShoppingCartItem WHERE ShoppingCartItem.ShoppingCartItemID = @TmpShoppingCartItemID
        -- @@ROWCOUNT is 1 after this

    COMMIT TRANSACTION delete
END
</code></pre>

<p><strong>Clarification:</strong> The reason you'd need to use transactions is that the delete doesn't actually happen in the database until you do a COMMIT operation.  This is generally used when you have multiple write operations in an atomic transaction.  Basically, you only want the changes to happen to the DB if all of the operations are successful.</p>

<p>In your case, there's only 1 operation, but since you're in explicit transaction mode, you need to tell SQL Server to <strong>really</strong> make the changes.</p>
"
341,150250,0,7,sql,While-clause in T-SQL that loops forever,"<p>I was recently tasked with debugging a strange problem within an e-commerce application. After an application upgrade the site started to hang from time to time and I was sent in to debug. After checking the event log I found that the SQL-server wrote ~200 000 events in a couple of minutes with the message saying that a constraint had failed. After much debugging and some tracing I found the culprit. I've removed some unnecessary code and cleaned it up a bit but essentially this is it</p>

<pre><code>WHILE EXISTS (SELECT * FROM ShoppingCartItem WHERE ShoppingCartItem.PurchID = @PurchID)
BEGIN
	SELECT TOP 1 
		@TmpGFSID = ShoppingCartItem.GFSID, 
		@TmpQuantity = ShoppingCartItem.Quantity,
		@TmpShoppingCartItemID = ShoppingCartItem.ShoppingCartItemID,
	FROM
		ShoppingCartItem INNER JOIN GoodsForSale on ShoppingCartItem.GFSID = GoodsForSale.GFSID
	WHERE ShoppingCartItem.PurchID = @PurchID

	EXEC @ErrorCode = spGoodsForSale_ReverseReservations @TmpGFSID, @TmpQuantity
	IF @ErrorCode &lt;&gt; 0
	BEGIN
		Goto Cleanup	
	END

	DELETE FROM ShoppingCartItem WHERE ShoppingCartItem.ShoppingCartItemID = @TmpShoppingCartItemID
	-- @@ROWCOUNT is 1 after this
END
</code></pre>

<p>Facts:</p>

<ol>
<li>There's only one or two records matching the first select-clause</li>
<li>RowCount from the DELETE statement indicates that it has been removed</li>
<li>The WHILE-clause will loop forever</li>
</ol>

<p>The procedure has been rewritten to select the rows that should be deleted into a temporary in-memory table instead so the immediate problem is solved but this really sparked my curiosity.</p>

<p>Why does it loop forever?</p>

<p><strong>Clarification</strong>: The delete doesn't fail (@@rowcount is 1 after the delete stmt when debugged)
<strong>Clarification 2</strong>: It shouldn't matter whether or not the SELECT TOP ... clause is ordered by any specific field since the record with the returned id will be deleted so in the next loop it should get another record.</p>

<p><strong>Update</strong>: After checking the subversion logs I found the culprit commit that made this stored procedure to go haywire. The only real difference that I can find is that there previously was no join in the SELECT TOP 1 statement i.e. without that join it worked without any transaction statements surrounding the delete. It appears to be the introduction of the join that made SQL server more picky.</p>

<p><strong>Update clarification</strong>:  <a href=""http://stackoverflow.com/questions/150250/while-clause-in-t-sql-that-loops-forever#150400"">brien</a> pointed out that there's no need for the join but we actually do use some fields from the GoodsForSale table but I've removed them to keep the code simply so that we can concentrate on the problem at hand</p>
","<p>What is the point of the join?  You aren't getting anything from the GoodsForSale table, so why bother with the join?</p>
"
342,150250,0,7,sql,While-clause in T-SQL that loops forever,"<p>I was recently tasked with debugging a strange problem within an e-commerce application. After an application upgrade the site started to hang from time to time and I was sent in to debug. After checking the event log I found that the SQL-server wrote ~200 000 events in a couple of minutes with the message saying that a constraint had failed. After much debugging and some tracing I found the culprit. I've removed some unnecessary code and cleaned it up a bit but essentially this is it</p>

<pre><code>WHILE EXISTS (SELECT * FROM ShoppingCartItem WHERE ShoppingCartItem.PurchID = @PurchID)
BEGIN
	SELECT TOP 1 
		@TmpGFSID = ShoppingCartItem.GFSID, 
		@TmpQuantity = ShoppingCartItem.Quantity,
		@TmpShoppingCartItemID = ShoppingCartItem.ShoppingCartItemID,
	FROM
		ShoppingCartItem INNER JOIN GoodsForSale on ShoppingCartItem.GFSID = GoodsForSale.GFSID
	WHERE ShoppingCartItem.PurchID = @PurchID

	EXEC @ErrorCode = spGoodsForSale_ReverseReservations @TmpGFSID, @TmpQuantity
	IF @ErrorCode &lt;&gt; 0
	BEGIN
		Goto Cleanup	
	END

	DELETE FROM ShoppingCartItem WHERE ShoppingCartItem.ShoppingCartItemID = @TmpShoppingCartItemID
	-- @@ROWCOUNT is 1 after this
END
</code></pre>

<p>Facts:</p>

<ol>
<li>There's only one or two records matching the first select-clause</li>
<li>RowCount from the DELETE statement indicates that it has been removed</li>
<li>The WHILE-clause will loop forever</li>
</ol>

<p>The procedure has been rewritten to select the rows that should be deleted into a temporary in-memory table instead so the immediate problem is solved but this really sparked my curiosity.</p>

<p>Why does it loop forever?</p>

<p><strong>Clarification</strong>: The delete doesn't fail (@@rowcount is 1 after the delete stmt when debugged)
<strong>Clarification 2</strong>: It shouldn't matter whether or not the SELECT TOP ... clause is ordered by any specific field since the record with the returned id will be deleted so in the next loop it should get another record.</p>

<p><strong>Update</strong>: After checking the subversion logs I found the culprit commit that made this stored procedure to go haywire. The only real difference that I can find is that there previously was no join in the SELECT TOP 1 statement i.e. without that join it worked without any transaction statements surrounding the delete. It appears to be the introduction of the join that made SQL server more picky.</p>

<p><strong>Update clarification</strong>:  <a href=""http://stackoverflow.com/questions/150250/while-clause-in-t-sql-that-loops-forever#150400"">brien</a> pointed out that there's no need for the join but we actually do use some fields from the GoodsForSale table but I've removed them to keep the code simply so that we can concentrate on the problem at hand</p>
","<p>I think we need some more information on the constraint failure error you're getting in the logs.  </p>
"
343,150250,0,7,sql,While-clause in T-SQL that loops forever,"<p>I was recently tasked with debugging a strange problem within an e-commerce application. After an application upgrade the site started to hang from time to time and I was sent in to debug. After checking the event log I found that the SQL-server wrote ~200 000 events in a couple of minutes with the message saying that a constraint had failed. After much debugging and some tracing I found the culprit. I've removed some unnecessary code and cleaned it up a bit but essentially this is it</p>

<pre><code>WHILE EXISTS (SELECT * FROM ShoppingCartItem WHERE ShoppingCartItem.PurchID = @PurchID)
BEGIN
	SELECT TOP 1 
		@TmpGFSID = ShoppingCartItem.GFSID, 
		@TmpQuantity = ShoppingCartItem.Quantity,
		@TmpShoppingCartItemID = ShoppingCartItem.ShoppingCartItemID,
	FROM
		ShoppingCartItem INNER JOIN GoodsForSale on ShoppingCartItem.GFSID = GoodsForSale.GFSID
	WHERE ShoppingCartItem.PurchID = @PurchID

	EXEC @ErrorCode = spGoodsForSale_ReverseReservations @TmpGFSID, @TmpQuantity
	IF @ErrorCode &lt;&gt; 0
	BEGIN
		Goto Cleanup	
	END

	DELETE FROM ShoppingCartItem WHERE ShoppingCartItem.ShoppingCartItemID = @TmpShoppingCartItemID
	-- @@ROWCOUNT is 1 after this
END
</code></pre>

<p>Facts:</p>

<ol>
<li>There's only one or two records matching the first select-clause</li>
<li>RowCount from the DELETE statement indicates that it has been removed</li>
<li>The WHILE-clause will loop forever</li>
</ol>

<p>The procedure has been rewritten to select the rows that should be deleted into a temporary in-memory table instead so the immediate problem is solved but this really sparked my curiosity.</p>

<p>Why does it loop forever?</p>

<p><strong>Clarification</strong>: The delete doesn't fail (@@rowcount is 1 after the delete stmt when debugged)
<strong>Clarification 2</strong>: It shouldn't matter whether or not the SELECT TOP ... clause is ordered by any specific field since the record with the returned id will be deleted so in the next loop it should get another record.</p>

<p><strong>Update</strong>: After checking the subversion logs I found the culprit commit that made this stored procedure to go haywire. The only real difference that I can find is that there previously was no join in the SELECT TOP 1 statement i.e. without that join it worked without any transaction statements surrounding the delete. It appears to be the introduction of the join that made SQL server more picky.</p>

<p><strong>Update clarification</strong>:  <a href=""http://stackoverflow.com/questions/150250/while-clause-in-t-sql-that-loops-forever#150400"">brien</a> pointed out that there's no need for the join but we actually do use some fields from the GoodsForSale table but I've removed them to keep the code simply so that we can concentrate on the problem at hand</p>
","<p>If the above comments did not help you so far, I propose adding / replacing:</p>

<pre><code>DECLARE Old@ShoppingCartItemID INT

SET @OldShoppingCartItemID = 0

WHILE EXISTS (SELECT ... WHERE ShoppingCartItemID &gt; @ShoppingCartItemID)

SELECT TOP 1 WHERE ShoppingCartItemID &gt; @OldShoppingCartItemID ORDER BY ShoppingCartItemID 

SET @OldShoppingCartItemID = @TmpShoppingCartItemID
</code></pre>
"
344,150250,3,7,sql,While-clause in T-SQL that loops forever,"<p>I was recently tasked with debugging a strange problem within an e-commerce application. After an application upgrade the site started to hang from time to time and I was sent in to debug. After checking the event log I found that the SQL-server wrote ~200 000 events in a couple of minutes with the message saying that a constraint had failed. After much debugging and some tracing I found the culprit. I've removed some unnecessary code and cleaned it up a bit but essentially this is it</p>

<pre><code>WHILE EXISTS (SELECT * FROM ShoppingCartItem WHERE ShoppingCartItem.PurchID = @PurchID)
BEGIN
	SELECT TOP 1 
		@TmpGFSID = ShoppingCartItem.GFSID, 
		@TmpQuantity = ShoppingCartItem.Quantity,
		@TmpShoppingCartItemID = ShoppingCartItem.ShoppingCartItemID,
	FROM
		ShoppingCartItem INNER JOIN GoodsForSale on ShoppingCartItem.GFSID = GoodsForSale.GFSID
	WHERE ShoppingCartItem.PurchID = @PurchID

	EXEC @ErrorCode = spGoodsForSale_ReverseReservations @TmpGFSID, @TmpQuantity
	IF @ErrorCode &lt;&gt; 0
	BEGIN
		Goto Cleanup	
	END

	DELETE FROM ShoppingCartItem WHERE ShoppingCartItem.ShoppingCartItemID = @TmpShoppingCartItemID
	-- @@ROWCOUNT is 1 after this
END
</code></pre>

<p>Facts:</p>

<ol>
<li>There's only one or two records matching the first select-clause</li>
<li>RowCount from the DELETE statement indicates that it has been removed</li>
<li>The WHILE-clause will loop forever</li>
</ol>

<p>The procedure has been rewritten to select the rows that should be deleted into a temporary in-memory table instead so the immediate problem is solved but this really sparked my curiosity.</p>

<p>Why does it loop forever?</p>

<p><strong>Clarification</strong>: The delete doesn't fail (@@rowcount is 1 after the delete stmt when debugged)
<strong>Clarification 2</strong>: It shouldn't matter whether or not the SELECT TOP ... clause is ordered by any specific field since the record with the returned id will be deleted so in the next loop it should get another record.</p>

<p><strong>Update</strong>: After checking the subversion logs I found the culprit commit that made this stored procedure to go haywire. The only real difference that I can find is that there previously was no join in the SELECT TOP 1 statement i.e. without that join it worked without any transaction statements surrounding the delete. It appears to be the introduction of the join that made SQL server more picky.</p>

<p><strong>Update clarification</strong>:  <a href=""http://stackoverflow.com/questions/150250/while-clause-in-t-sql-that-loops-forever#150400"">brien</a> pointed out that there's no need for the join but we actually do use some fields from the GoodsForSale table but I've removed them to keep the code simply so that we can concentrate on the problem at hand</p>
","<pre><code>FROM
  ShoppingCartItem
    INNER JOIN
  GoodsForSale
    on ShoppingCartItem.GFSID = GoodsForSale.GFSID
</code></pre>

<p>Oops, your join brings the result set down to zero rows.</p>

<pre><code> SELECT TOP 1
    @TmpGFSID = ShoppingCartItem.GFSID,
    @TmpQuantity = ShoppingCartItem.Quantity,
    @TmpShoppingCartItemID =
      ShoppingCartItem.ShoppingCartItemID
</code></pre>

<p>Oops, you used multi-assignment against a set with no rows.  This causes the variables to remain unchanged (they will have the same value that they had last time through the loop).  The variables do NOT get assigned to null in this case.</p>

<p>If you put this code at the start of the loop, it will (correctly) fail faster:</p>

<pre><code> SELECT
    @TmpGFSID = null,
    @TmpQuantity = null,
    @TmpShoppingCartItemID = null
</code></pre>

<p>If you change your code to fetch a key (without joining) and then fetching the related data by key in a second query, you'll win.</p>
"
345,150250,0,7,sql,While-clause in T-SQL that loops forever,"<p>I was recently tasked with debugging a strange problem within an e-commerce application. After an application upgrade the site started to hang from time to time and I was sent in to debug. After checking the event log I found that the SQL-server wrote ~200 000 events in a couple of minutes with the message saying that a constraint had failed. After much debugging and some tracing I found the culprit. I've removed some unnecessary code and cleaned it up a bit but essentially this is it</p>

<pre><code>WHILE EXISTS (SELECT * FROM ShoppingCartItem WHERE ShoppingCartItem.PurchID = @PurchID)
BEGIN
	SELECT TOP 1 
		@TmpGFSID = ShoppingCartItem.GFSID, 
		@TmpQuantity = ShoppingCartItem.Quantity,
		@TmpShoppingCartItemID = ShoppingCartItem.ShoppingCartItemID,
	FROM
		ShoppingCartItem INNER JOIN GoodsForSale on ShoppingCartItem.GFSID = GoodsForSale.GFSID
	WHERE ShoppingCartItem.PurchID = @PurchID

	EXEC @ErrorCode = spGoodsForSale_ReverseReservations @TmpGFSID, @TmpQuantity
	IF @ErrorCode &lt;&gt; 0
	BEGIN
		Goto Cleanup	
	END

	DELETE FROM ShoppingCartItem WHERE ShoppingCartItem.ShoppingCartItemID = @TmpShoppingCartItemID
	-- @@ROWCOUNT is 1 after this
END
</code></pre>

<p>Facts:</p>

<ol>
<li>There's only one or two records matching the first select-clause</li>
<li>RowCount from the DELETE statement indicates that it has been removed</li>
<li>The WHILE-clause will loop forever</li>
</ol>

<p>The procedure has been rewritten to select the rows that should be deleted into a temporary in-memory table instead so the immediate problem is solved but this really sparked my curiosity.</p>

<p>Why does it loop forever?</p>

<p><strong>Clarification</strong>: The delete doesn't fail (@@rowcount is 1 after the delete stmt when debugged)
<strong>Clarification 2</strong>: It shouldn't matter whether or not the SELECT TOP ... clause is ordered by any specific field since the record with the returned id will be deleted so in the next loop it should get another record.</p>

<p><strong>Update</strong>: After checking the subversion logs I found the culprit commit that made this stored procedure to go haywire. The only real difference that I can find is that there previously was no join in the SELECT TOP 1 statement i.e. without that join it worked without any transaction statements surrounding the delete. It appears to be the introduction of the join that made SQL server more picky.</p>

<p><strong>Update clarification</strong>:  <a href=""http://stackoverflow.com/questions/150250/while-clause-in-t-sql-that-loops-forever#150400"">brien</a> pointed out that there's no need for the join but we actually do use some fields from the GoodsForSale table but I've removed them to keep the code simply so that we can concentrate on the problem at hand</p>
","<p>If there are any shopping cart items that do not exist in the GoodsForSale table then this will spin into an infinite loop. </p>

<p>Try changing your exists statement to take account of that </p>

<pre><code>(SELECT * FROM ShoppingCartItem WHERE  JOIN GoodsForSale on ShoppingCartItem.GFSID = GoodsForSale.GFSID where ShoppingCartItem.PurchID = @PurchID)
</code></pre>

<p>Or better still, rewriting this so it does not require a loop. Looping like this is an infinite loop waiting to happen. You should replace with set based operations and a transaction. </p>
"
1138,524150,1,7,sql,Best Practice for PK in SQL Server,"<p>I have been wondering what the best practices or ramifications are in setting up the PK in a M2M table in SQL Server. For instance:</p>

<p>I have 2 tables</p>

<ul>
<li>Users</li>
<li>Roles</li>
</ul>

<p>I am making a new table</p>

<ul>
<li>UserRole</li>
</ul>

<p>Which has 2 fields
 RoleId &amp; UserID</p>

<p>now should I </p>

<ol>
<li>create a UserRoleID as the PK and make UserID and RoleID the FKs</li>
<li>make the PK UserID AND RoleID and set them as FKs</li>
<li>something else</li>
</ol>

<p>I would like to know the performance issues with each of the options and what the recommended best practices are.</p>
","<p>It depends whether you expect to hang any other meaning to the fact that a specific user has a specific role.  If not then just create a clustered PK to span across the two fields.</p>

<p>Add FKs for both and add an index to the second field.  Give some consideration to which order the fields should appear in.  Are you more likely to be retrieving a set of roles a user belongs to or the set of users in a specific role?  </p>
"
205,91360,0,7,sql,How to calculate the sum of values in a tree using SQL,"<p>I need to sum points on each level earned by a tree of users. Level 1 is the sum of users' points of the users 1 level below the user. Level 2 is the Level 1 points of the users 2 levels below the user, etc...</p>

<p>The calculation happens once a month on a non production server, no worries about performance.</p>

<p>What would the SQL look like to do it?</p>

<p>If you're confused, don't worry, I am as well!</p>

<p>User table:</p>

<pre><code>ID    ParentID    Points
1     0           230
2     1           150
3     0           80
4     1           110
5     4           54
6     4           342

Tree:
0
|---\
1    3
| \
2  4---
    \  \
     5  6
</code></pre>

<p>Output should be:</p>

<pre><code>ID    Points    Level1     Level2
1     230       150+110    150+110+54+342
2     150
3     80
4     110       54+342
5     54
6     342
</code></pre>

<p>SQL Server Syntax and functions preferably...</p>
","<p>You can write a simple recursive function to do the job. My MSSQL is a little bit rusty, but it would look like this:</p>

<pre><code>CREATE FUNCTION CALC
(
@node integer,
)
returns 
(
@total integer
)
as
begin
    select @total = (select node_value from yourtable where node_id = @node);

    declare @children table (value integer);
    insert into @children   
    select calc(node_id) from yourtable where parent_id = @node;

    @current = @current + select sum(value) from @children;
    return
end
</code></pre>
"
206,91360,1,7,sql,How to calculate the sum of values in a tree using SQL,"<p>I need to sum points on each level earned by a tree of users. Level 1 is the sum of users' points of the users 1 level below the user. Level 2 is the Level 1 points of the users 2 levels below the user, etc...</p>

<p>The calculation happens once a month on a non production server, no worries about performance.</p>

<p>What would the SQL look like to do it?</p>

<p>If you're confused, don't worry, I am as well!</p>

<p>User table:</p>

<pre><code>ID    ParentID    Points
1     0           230
2     1           150
3     0           80
4     1           110
5     4           54
6     4           342

Tree:
0
|---\
1    3
| \
2  4---
    \  \
     5  6
</code></pre>

<p>Output should be:</p>

<pre><code>ID    Points    Level1     Level2
1     230       150+110    150+110+54+342
2     150
3     80
4     110       54+342
5     54
6     342
</code></pre>

<p>SQL Server Syntax and functions preferably...</p>
","<p>SQL in general, like others said, does not handle well such relations. Typically, a surrogate 'relations' table is needed (id, parent_id, unique key on (id, parent_id)), where:</p>

<ul>
<li><p>every time you add a record in 'table', you:</p>

<p><code>INSERT INTO relations (id, parent_id) VALUES ([current_id], [current_id]);</code></p>

<p><code>INSERT INTO relations (id, parent_id) VALUES ([current_id], [current_parent_id]);</code></p>

<p><code>INSERT INTO relations (id, parent_id)</code>
<code>SELECT [current_id], parent_id</code>
<code>FROM relations</code>
<code>WHERE id = [current_parent_id];</code></p></li>
<li><p>have logic to avoid cycles</p></li>
<li><p>make sure that updates, deletions on 'relations' are handled with stored procedures</p></li>
</ul>

<p>Given that table, you want:</p>

<pre><code>SELECT rel.parent_id, SUM(tbl.points)
FROM table tbl INNER JOIN relations rel ON tbl.id=rel.id
WHERE rel.parent_id &lt;&gt; 0
GROUP BY rel.parent_id;
</code></pre>
"
79,32000,0,7,sql,C# - SQLClient - Simplest INSERT,"<p>I'm basically trying to figure out the simplest way to perform your basic insert operation in C#.NET using the SqlClient namespace. </p>

<p>I'm using <code>SqlConnection</code> for my db link, I've already had success executing some reads, and I want to know the simplest way to insert data. I'm finding what seem to be pretty verbose methods when I google.</p>
","<pre><code>using (SqlConnection myConnection new SqlConnection(""Your connection string"")) 
{ 
    SqlCommand myCommand = new SqlCommand(""INSERT INTO ... VALUES ..."", myConnection); 
    myConnection.Open(); 
    myCommand.ExecuteNonQuery(); 
}
</code></pre>
"
78,32000,15,7,sql,C# - SQLClient - Simplest INSERT,"<p>I'm basically trying to figure out the simplest way to perform your basic insert operation in C#.NET using the SqlClient namespace. </p>

<p>I'm using <code>SqlConnection</code> for my db link, I've already had success executing some reads, and I want to know the simplest way to insert data. I'm finding what seem to be pretty verbose methods when I google.</p>
","<pre><code>using (var conn = new SqlConnection(yourConnectionString))
{
    var cmd = new SqlCommand(""insert into Foo values (@bar)"", conn);
    cmd.Parameters.AddWithValue(""@bar"", 17);
    conn.Open();
    cmd.ExecuteNonQuery();
}
</code></pre>
"
337,150250,0,7,sql,While-clause in T-SQL that loops forever,"<p>I was recently tasked with debugging a strange problem within an e-commerce application. After an application upgrade the site started to hang from time to time and I was sent in to debug. After checking the event log I found that the SQL-server wrote ~200 000 events in a couple of minutes with the message saying that a constraint had failed. After much debugging and some tracing I found the culprit. I've removed some unnecessary code and cleaned it up a bit but essentially this is it</p>

<pre><code>WHILE EXISTS (SELECT * FROM ShoppingCartItem WHERE ShoppingCartItem.PurchID = @PurchID)
BEGIN
	SELECT TOP 1 
		@TmpGFSID = ShoppingCartItem.GFSID, 
		@TmpQuantity = ShoppingCartItem.Quantity,
		@TmpShoppingCartItemID = ShoppingCartItem.ShoppingCartItemID,
	FROM
		ShoppingCartItem INNER JOIN GoodsForSale on ShoppingCartItem.GFSID = GoodsForSale.GFSID
	WHERE ShoppingCartItem.PurchID = @PurchID

	EXEC @ErrorCode = spGoodsForSale_ReverseReservations @TmpGFSID, @TmpQuantity
	IF @ErrorCode &lt;&gt; 0
	BEGIN
		Goto Cleanup	
	END

	DELETE FROM ShoppingCartItem WHERE ShoppingCartItem.ShoppingCartItemID = @TmpShoppingCartItemID
	-- @@ROWCOUNT is 1 after this
END
</code></pre>

<p>Facts:</p>

<ol>
<li>There's only one or two records matching the first select-clause</li>
<li>RowCount from the DELETE statement indicates that it has been removed</li>
<li>The WHILE-clause will loop forever</li>
</ol>

<p>The procedure has been rewritten to select the rows that should be deleted into a temporary in-memory table instead so the immediate problem is solved but this really sparked my curiosity.</p>

<p>Why does it loop forever?</p>

<p><strong>Clarification</strong>: The delete doesn't fail (@@rowcount is 1 after the delete stmt when debugged)
<strong>Clarification 2</strong>: It shouldn't matter whether or not the SELECT TOP ... clause is ordered by any specific field since the record with the returned id will be deleted so in the next loop it should get another record.</p>

<p><strong>Update</strong>: After checking the subversion logs I found the culprit commit that made this stored procedure to go haywire. The only real difference that I can find is that there previously was no join in the SELECT TOP 1 statement i.e. without that join it worked without any transaction statements surrounding the delete. It appears to be the introduction of the join that made SQL server more picky.</p>

<p><strong>Update clarification</strong>:  <a href=""http://stackoverflow.com/questions/150250/while-clause-in-t-sql-that-loops-forever#150400"">brien</a> pointed out that there's no need for the join but we actually do use some fields from the GoodsForSale table but I've removed them to keep the code simply so that we can concentrate on the problem at hand</p>
","<p>Is SQL Server caching the result of the while clause query?  </p>

<p>Is the delete being committed to the database, or does it end up in some transaction that never closes?</p>
"
679,299770,0,6,sql,Simple Oracle SQL date syntax question,"<p>I am trying to convert a working MS Access query to run on an Oracle database being accessed via VB Script (.asp). This is the last section of the WHERE clause:</p>

<pre><code>sql = sql &amp; ""WHERE (UAT.HB.MB_MODE = 'A' AND   UAT.HB.PRINT_DATE &gt;= '"" 
&amp; SD &amp; ""' AND UAT.HB.PRINT_DATE &lt;= '"" &amp; ED  &amp;""'  )""
</code></pre>

<p>The variable ""SD"" (i.e. ""start date"") is a text string that can contain a value such as ""11/11/2008"". The same goes for the variable ""ED"" (i.e. ""end date"").</p>

<p>However, the dates do not work. Does Oracle require a special way to use dates?</p>

<p>Do the dates have to be converted? Do I surround them with the '#' keyword like you would in MS Access?</p>
","<p>Here's a couple examples for converting to and from dates:</p>

<ul>
<li><code>select to_date('2008/11/18:12:00:00AM', 'yyyy/mm/dd:hh:mi:ssam') from dual</code></li>
<li><code>select to_char(sysdate, 'mm/dd/yyyy') from dual</code></li>
</ul>
"
675,299770,-1,6,sql,Simple Oracle SQL date syntax question,"<p>I am trying to convert a working MS Access query to run on an Oracle database being accessed via VB Script (.asp). This is the last section of the WHERE clause:</p>

<pre><code>sql = sql &amp; ""WHERE (UAT.HB.MB_MODE = 'A' AND   UAT.HB.PRINT_DATE &gt;= '"" 
&amp; SD &amp; ""' AND UAT.HB.PRINT_DATE &lt;= '"" &amp; ED  &amp;""'  )""
</code></pre>

<p>The variable ""SD"" (i.e. ""start date"") is a text string that can contain a value such as ""11/11/2008"". The same goes for the variable ""ED"" (i.e. ""end date"").</p>

<p>However, the dates do not work. Does Oracle require a special way to use dates?</p>

<p>Do the dates have to be converted? Do I surround them with the '#' keyword like you would in MS Access?</p>
","<p>The default date format for Oracle is ""dd-mon-yy"".  You can do a TO_CHAR function on the date field to convert it to a format you prefer to match on.</p>
"
678,299770,8,6,sql,Simple Oracle SQL date syntax question,"<p>I am trying to convert a working MS Access query to run on an Oracle database being accessed via VB Script (.asp). This is the last section of the WHERE clause:</p>

<pre><code>sql = sql &amp; ""WHERE (UAT.HB.MB_MODE = 'A' AND   UAT.HB.PRINT_DATE &gt;= '"" 
&amp; SD &amp; ""' AND UAT.HB.PRINT_DATE &lt;= '"" &amp; ED  &amp;""'  )""
</code></pre>

<p>The variable ""SD"" (i.e. ""start date"") is a text string that can contain a value such as ""11/11/2008"". The same goes for the variable ""ED"" (i.e. ""end date"").</p>

<p>However, the dates do not work. Does Oracle require a special way to use dates?</p>

<p>Do the dates have to be converted? Do I surround them with the '#' keyword like you would in MS Access?</p>
","<p>Don't assume the default Oracle date format is anything.  Check the <a href=""http://download-uk.oracle.com/docs/cd/B19306_01/server.102/b14237/initparams122.htm"">NLS_DATE_FORMAT</a> or use <a href=""http://download.oracle.com/docs/cd/B19306_01/server.102/b14200/functions183.htm"">TO_DATE</a> to convert it.  Like this:  </p>

<pre><code>TO_DATE('2008-11-18 14:13:59', 'YYYY-MM-DD HH24:Mi:SS')
</code></pre>

<p>Note the 'Mi' for the minutes and not 'MM'.  That catches a lot of people.  </p>
"
677,299770,1,6,sql,Simple Oracle SQL date syntax question,"<p>I am trying to convert a working MS Access query to run on an Oracle database being accessed via VB Script (.asp). This is the last section of the WHERE clause:</p>

<pre><code>sql = sql &amp; ""WHERE (UAT.HB.MB_MODE = 'A' AND   UAT.HB.PRINT_DATE &gt;= '"" 
&amp; SD &amp; ""' AND UAT.HB.PRINT_DATE &lt;= '"" &amp; ED  &amp;""'  )""
</code></pre>

<p>The variable ""SD"" (i.e. ""start date"") is a text string that can contain a value such as ""11/11/2008"". The same goes for the variable ""ED"" (i.e. ""end date"").</p>

<p>However, the dates do not work. Does Oracle require a special way to use dates?</p>

<p>Do the dates have to be converted? Do I surround them with the '#' keyword like you would in MS Access?</p>
","<p>according to <a href=""http://www.java2s.com/Code/Oracle/Date-Timezone/SimpleExamplesofStoringandRetrievingDates.htm"" rel=""nofollow"">this</a> you can use the following:</p>

<pre><code>to_date('19960725','YYYYMMDD')
</code></pre>
"
676,299770,14,6,sql,Simple Oracle SQL date syntax question,"<p>I am trying to convert a working MS Access query to run on an Oracle database being accessed via VB Script (.asp). This is the last section of the WHERE clause:</p>

<pre><code>sql = sql &amp; ""WHERE (UAT.HB.MB_MODE = 'A' AND   UAT.HB.PRINT_DATE &gt;= '"" 
&amp; SD &amp; ""' AND UAT.HB.PRINT_DATE &lt;= '"" &amp; ED  &amp;""'  )""
</code></pre>

<p>The variable ""SD"" (i.e. ""start date"") is a text string that can contain a value such as ""11/11/2008"". The same goes for the variable ""ED"" (i.e. ""end date"").</p>

<p>However, the dates do not work. Does Oracle require a special way to use dates?</p>

<p>Do the dates have to be converted? Do I surround them with the '#' keyword like you would in MS Access?</p>
","<p>In Oracle, your date should be written as an ANSI date literal like this:</p>

<pre><code>DATE '2008-11-11'
</code></pre>

<p>Or converted to a date from a string like this:</p>

<pre><code>TO_DATE('11/11/2008', 'MM/DD/YYYY')
</code></pre>

<p>See <a href=""http://download-west.oracle.com/docs/cd/B19306_01/server.102/b14200/sql_elements003.htm#BABGIGCJ"">http://download-west.oracle.com/docs/cd/B19306_01/server.102/b14200/sql_elements003.htm#BABGIGCJ</a></p>
"
791,351840,6,6,sql,How do you do an IN or CONTAINS in LINQ using LAMBDA expressions?,"<p>I have the following Transact-Sql that I am trying to convert to LINQ ... and struggling.  </p>

<pre><code>SELECT * FROM Project
WHERE Project.ProjectId IN (SELECT ProjectId FROM ProjectMember Where MemberId = 'a45bd16d-9be0-421b-b5bf-143d334c8155')
</code></pre>

<p>Any help would be greatly appreciated ... I would like to do it with Lambda expressions, if possible.  </p>

<p>Thanks in advance!</p>
","<p>GFrizzle beat me to it. But here is a C# version</p>

<pre><code>var projectsMemberWorkedOn = from p in Projects
                    join projectMember in ProjectMembers on
                        p.ProjectId equals projectMember.ProjectId
                    where projectMember.MemberId == ""a45bd16d-9be0-421b-b5bf-143d334c8155""
                    select p;
</code></pre>

<p>And as a bonus a purely LINQ method chain version as well:</p>

<pre><code>var projectsMemberWorkedOn =
            Projects.Join( ProjectMembers, p =&gt; p.ProjectId, projectMember =&gt; projectMember.ProjectId,
                ( p, projectMember ) =&gt; new { p, projectMember } )
                .Where( @t =&gt; @t.projectMember.MemberId == ""a45bd16d-9be0-421b-b5bf-143d334c8155"" )
                .Select(@t =&gt; @t.p );
</code></pre>
"
792,351840,3,6,sql,How do you do an IN or CONTAINS in LINQ using LAMBDA expressions?,"<p>I have the following Transact-Sql that I am trying to convert to LINQ ... and struggling.  </p>

<pre><code>SELECT * FROM Project
WHERE Project.ProjectId IN (SELECT ProjectId FROM ProjectMember Where MemberId = 'a45bd16d-9be0-421b-b5bf-143d334c8155')
</code></pre>

<p>Any help would be greatly appreciated ... I would like to do it with Lambda expressions, if possible.  </p>

<p>Thanks in advance!</p>
","<p>You probably want the <strong>Any()</strong> operator:</p>

<pre><code>var q = db.Projects
          .Where(p =&gt; db.ProjectMembers
                        .Where(pm =&gt; pm.MemberId == memberId)
                        .Any  (pm =&gt; p.ProjectId == pm.ProjectId));
</code></pre>

<p>Since the result set of <code>db.ProjectMembers.Where(...)</code> will always be the same, you can split it up so that it's executed only once:</p>

<pre><code>var projectMembers = db.ProjectMembers.Where(pm =&gt; pm.MemberId == memberId);
var q              = db.Projects
                       .Where(p  =&gt; projectMembers
                                    .Any(pm =&gt; p.ProjectId == pm.ProjectId));
</code></pre>
"
771,350400,0,6,sql,Testing for whitespace in SQL Server,"<p>I've got some blank values in my table, and I can't seem to catch them in an IF statement. </p>

<p>I've tried</p>

<p><code>IF @value = ''</code> and <code>if @value = NULL</code> and neither one catches the blank values. Is there any way to test whether or not a varchar is entirely whitespace?</p>

<p>AHA! Turns out I was testing for null wrong. Thanks. </p>
","<p>You may have fields with multiple spaces ('   ') so you'll get better results if you trim that:</p>

<pre><code>where ltrim(yourcolumnname) = ''
</code></pre>
"
680,299770,0,6,sql,Simple Oracle SQL date syntax question,"<p>I am trying to convert a working MS Access query to run on an Oracle database being accessed via VB Script (.asp). This is the last section of the WHERE clause:</p>

<pre><code>sql = sql &amp; ""WHERE (UAT.HB.MB_MODE = 'A' AND   UAT.HB.PRINT_DATE &gt;= '"" 
&amp; SD &amp; ""' AND UAT.HB.PRINT_DATE &lt;= '"" &amp; ED  &amp;""'  )""
</code></pre>

<p>The variable ""SD"" (i.e. ""start date"") is a text string that can contain a value such as ""11/11/2008"". The same goes for the variable ""ED"" (i.e. ""end date"").</p>

<p>However, the dates do not work. Does Oracle require a special way to use dates?</p>

<p>Do the dates have to be converted? Do I surround them with the '#' keyword like you would in MS Access?</p>
","<p>The default Oracle date format can change from one database to the next.  So if you don't know the date format your database is using then you should use the TO_DATE function with an explicit date format string.  Given the fact that the default date format could change at any time, using an explicit date format string is the best thing to do anyway.</p>

<p>ex:
TO_DATE('11/11/2008 17:30','MM/DD/YYYY HH24:MI')</p>
"
681,299770,0,6,sql,Simple Oracle SQL date syntax question,"<p>I am trying to convert a working MS Access query to run on an Oracle database being accessed via VB Script (.asp). This is the last section of the WHERE clause:</p>

<pre><code>sql = sql &amp; ""WHERE (UAT.HB.MB_MODE = 'A' AND   UAT.HB.PRINT_DATE &gt;= '"" 
&amp; SD &amp; ""' AND UAT.HB.PRINT_DATE &lt;= '"" &amp; ED  &amp;""'  )""
</code></pre>

<p>The variable ""SD"" (i.e. ""start date"") is a text string that can contain a value such as ""11/11/2008"". The same goes for the variable ""ED"" (i.e. ""end date"").</p>

<p>However, the dates do not work. Does Oracle require a special way to use dates?</p>

<p>Do the dates have to be converted? Do I surround them with the '#' keyword like you would in MS Access?</p>
","<p>Don't forget that the date includes a time (defaults to 00:00:00), so<br />
don't get caught out by something like this:<br />
given three dates, <code>start_date, print_date, end_date</code>, all on the <strong><em>same</em></strong> day<br />
<code>print_date &gt;= start_date AND print_date &lt;= end_date</code> fails because <code>print_date</code> was greater than <code>end_date</code> <strong>:</strong><br />
 <code>start_date</code> was 2008-11-19 (00:00:00)<br />
  and <code>end_date</code> was 2008-11-19 (00:00:00)<br />
  and <code>print_date</code> was 2008-11-19 (<strong>16:00:00</strong>)   </p>
"
575,256380,3,6,sql,"Is there an easy way to plot Polyline Area, i.e. service coverage area, and also check to see if visitor's address lies within that area using Google Maps API and PHP?","<p>I am the owner of a business that is building a new website application. My partner is the programmer who is doing the development and neither one of us has any real in-depth experience with Google Map API or it's polyline/polygon area capabilities.</p>

<p>We need an easy way to capture inputs within our user admin area where our locations can enter their service coverage area info i.e. 1st street north of Jones blvd, or a 5 mile radius from the location address, etc. and have the Google Map API plot the polyline borders.</p>

<p>Then, visitors to our site need to be able to see this info when they view the google map for one of our locations and also see if their service address falls within that service area or not. We then need to set a flag somehow to trigger a notification to the visitor that their address is not eligible for service or delivery.</p>

<p>If anyone can assist us with this (example php code to interface with the suggested APIs would be preferred and ideal as we simply don't understand the complexities of the Google API, the polyline coordinate capture tool, etc), it would be greatly appreciated, as we have struggled to figure out how to create this in php and more importantly how to integrate it into our existing site.</p>

<p>Thank you in advance for your replies and assistance.</p>

<p>Sincerely, </p>

<p>Larry D
Managing Director
SunMark Ventures</p>

<p>Update: Thank you for your answer CodeMeIT...how do recommend we capture these longlats in our sql database...i.e. what is the field format or type and do we need to have separate fields for long and lat, and how can we standardize for all locations, i.e. how many long and lats are needed to create a polygon area, as we want to be able to have our location managers input this info for their own locations from their user login areas...</p>

<p>Thank you in advance for your assistance...greatly appreciated!</p>
","<p><strong>Draw polygon on map</strong></p>

<p>You can draw polygons that covering your service area on google map.  Those polygons are defined by a set of latlongs that you can collect from a google earth and sasve them somewhere. Once you had all the coordinates that can cover your each service area, you can see the link to find out how to draw them on google map</p>

<p><a href=""http://code.google.com/apis/maps/documentation/examples/polygon-simple.html"" rel=""nofollow"">Google Map polygons Sample</a></p>

<p><strong>Check if user is within service area</strong></p>

<p>If the user had address information entered or stored somewhere, you can take the address to google map geocoding service to find out the address's latitude and longitude. </p>

<p><a href=""http://code.google.com/apis/maps/documentation/services.html#Geocoding"" rel=""nofollow"">Google MAP Geocoding Service API</a></p>

<p>After getting the address' coordinate, the code can check if the coordinateis within any bound of the polygons of your service area. If false, that is out of service area.</p>

<p><a href=""http://www.assemblysys.com/dataServices/php_pointinpolygon.php"" rel=""nofollow"">PHP for checking point in polygon</a></p>
"
772,350400,10,6,sql,Testing for whitespace in SQL Server,"<p>I've got some blank values in my table, and I can't seem to catch them in an IF statement. </p>

<p>I've tried</p>

<p><code>IF @value = ''</code> and <code>if @value = NULL</code> and neither one catches the blank values. Is there any way to test whether or not a varchar is entirely whitespace?</p>

<p>AHA! Turns out I was testing for null wrong. Thanks. </p>
","<pre><code>ltrim(rtrim(isNull(@value,''))) = ''
</code></pre>
"
790,351840,4,6,sql,How do you do an IN or CONTAINS in LINQ using LAMBDA expressions?,"<p>I have the following Transact-Sql that I am trying to convert to LINQ ... and struggling.  </p>

<pre><code>SELECT * FROM Project
WHERE Project.ProjectId IN (SELECT ProjectId FROM ProjectMember Where MemberId = 'a45bd16d-9be0-421b-b5bf-143d334c8155')
</code></pre>

<p>Any help would be greatly appreciated ... I would like to do it with Lambda expressions, if possible.  </p>

<p>Thanks in advance!</p>
","<p>No need for a lambda, you've just got a simple LINQ join here:</p>

<pre><code>From p in db.Projects _
Join m in db.ProjectMember On p.ProjectId Equals m.ProjectId _
Where m.MemberId = ""a45bd16d-9be0-421b-b5bf-143d334c8155"" _
Select p
</code></pre>
"
789,351840,5,6,sql,How do you do an IN or CONTAINS in LINQ using LAMBDA expressions?,"<p>I have the following Transact-Sql that I am trying to convert to LINQ ... and struggling.  </p>

<pre><code>SELECT * FROM Project
WHERE Project.ProjectId IN (SELECT ProjectId FROM ProjectMember Where MemberId = 'a45bd16d-9be0-421b-b5bf-143d334c8155')
</code></pre>

<p>Any help would be greatly appreciated ... I would like to do it with Lambda expressions, if possible.  </p>

<p>Thanks in advance!</p>
","<p>In this context, you can just use .Contains(), something like this:</p>

<pre><code>var projects = 
from p in db.Projects
where db.ProjectMembers.Where(m =&gt; m.MemberId == ""a45bd16d-9be0-421b-b5bf-143d334c8155"").Select(pp =&gt; pp.ProjectID).Contains(p.ProjectID)
select p;
</code></pre>
"
768,350400,2,6,sql,Testing for whitespace in SQL Server,"<p>I've got some blank values in my table, and I can't seem to catch them in an IF statement. </p>

<p>I've tried</p>

<p><code>IF @value = ''</code> and <code>if @value = NULL</code> and neither one catches the blank values. Is there any way to test whether or not a varchar is entirely whitespace?</p>

<p>AHA! Turns out I was testing for null wrong. Thanks. </p>
","<p>if length(@value) = 0  or  @value is null </p>
"
769,350400,3,6,sql,Testing for whitespace in SQL Server,"<p>I've got some blank values in my table, and I can't seem to catch them in an IF statement. </p>

<p>I've tried</p>

<p><code>IF @value = ''</code> and <code>if @value = NULL</code> and neither one catches the blank values. Is there any way to test whether or not a varchar is entirely whitespace?</p>

<p>AHA! Turns out I was testing for null wrong. Thanks. </p>
","<p>(LTRIM(RTRIM(@Value))=''   should do the trick.</p>
"
1076,494720,0,6,sql,Top 1 on Left Join SubQuery,"<p>I am trying to take a person and display their current insurance along with their former insurance.  I guess one could say that I'm trying to flaten my view of customers or people.  I'm running into an issue where I'm getting multiple records back due to multiple records existing within my left join subqueries.  I had hoped I could solve this by adding ""TOP 1"" to the subquery, but that actually returns nothing...</p>

<p>Any ideas?</p>

<pre><code>    SELECT 
	p.person_id AS 'MIRID'
	, p.firstname AS 'FIRST'
	, p.lastname AS 'LAST'
	, pg.name AS 'GROUP'
	, e.name AS 'AOR'
	, p.leaddate AS 'CONTACT DATE'
	, [dbo].[GetPICampaignDisp](p.person_id, '2009') AS 'PI - 2009'
	, [dbo].[GetPICampaignDisp](p.person_id, '2008') AS 'PI - 2008'
	, [dbo].[GetPICampaignDisp](p.person_id, '2007') AS 'PI - 2007'
	, a_disp.name AS 'CURR DISP'
	, a_ins.name AS 'CURR INS'
	, a_prodtype.name AS 'CURR INS TYPE'
	, a_t.date AS 'CURR INS APP DATE'
	, a_t.effdate AS 'CURR INS EFF DATE' 
	, b_disp.name AS 'PREV DISP'
	, b_ins.name AS 'PREV INS'
	, b_prodtype.name AS 'PREV INS TYPE'
	, b_t.date AS 'PREV INS APP DATE'
	, b_t.effdate AS 'PREV INS EFF DATE'
	, b_t.termdate AS 'PREV INS TERM DATE'
FROM 
	[person] p
LEFT OUTER JOIN 
	[employee] e
ON 
	e.employee_id = p.agentofrecord_id
INNER JOIN 
	[dbo].[person_physician] pp
ON 
	p.person_id = pp.person_id
INNER JOIN 
	[dbo].[physician] ph
ON
	ph.physician_id = pp.physician_id
INNER JOIN
	[dbo].[clinic] c
ON 
	c.clinic_id = ph.clinic_id
INNER JOIN
	[dbo].[d_Physgroup] pg
ON
	pg.d_physgroup_id = c.physgroup_id
LEFT OUTER JOIN 
	(
		SELECT
			tr1.*
		FROM 
			[transaction] tr1
		LEFT OUTER JOIN 
			[d_vendor] ins1
		ON 
			ins1.d_vendor_id = tr1.d_vendor_id
		LEFT OUTER JOIN 
			[d_product_type] prodtype1
		ON 
			prodtype1.d_product_type_id = tr1.d_product_type_id
		LEFT OUTER JOIN 
			[d_commission_type] ctype1
		ON 
			ctype1.d_commission_type_id = tr1.d_commission_type_id
		WHERE
			prodtype1.name &lt;&gt; 'Medicare Part D'
			AND tr1.termdate IS NULL
	) AS a_t
ON
	a_t.person_id = p.person_id
LEFT OUTER JOIN 
	[d_vendor] a_ins
ON 
	a_ins.d_vendor_id = a_t.d_vendor_id
LEFT OUTER JOIN 
	[d_product_type] a_prodtype
ON 
	a_prodtype.d_product_type_id = a_t.d_product_type_id
LEFT OUTER JOIN 
	[d_commission_type] a_ctype
ON 
	a_ctype.d_commission_type_id = a_t.d_commission_type_id
LEFT OUTER JOIN
	[d_disposition] a_disp
ON
	a_disp.d_disposition_id = a_t.d_disposition_id
LEFT OUTER JOIN 
	(
		SELECT
			tr2.*
		FROM 
			[transaction] tr2
		LEFT OUTER JOIN 
			[d_vendor] ins2
		ON 
			ins2.d_vendor_id = tr2.d_vendor_id
		LEFT OUTER JOIN 
			[d_product_type] prodtype2
		ON 
			prodtype2.d_product_type_id = tr2.d_product_type_id
		LEFT OUTER JOIN 
			[d_commission_type] ctype2
		ON 
			ctype2.d_commission_type_id = tr2.d_commission_type_id
		WHERE
			prodtype2.name &lt;&gt; 'Medicare Part D'
			AND tr2.termdate IS NOT NULL
	) AS b_t
ON
	b_t.person_id = p.person_id
LEFT OUTER JOIN 
	[d_vendor] b_ins
ON 
	b_ins.d_vendor_id = b_t.d_vendor_id
LEFT OUTER JOIN 
	[d_product_type] b_prodtype
ON 
	b_prodtype.d_product_type_id = b_t.d_product_type_id
LEFT OUTER JOIN 
	[d_commission_type] b_ctype
ON 
	b_ctype.d_commission_type_id = b_t.d_commission_type_id
LEFT OUTER JOIN
	[d_disposition] b_disp
ON
	b_disp.d_disposition_id = b_t.d_disposition_id
WHERE
	pg.d_physgroup_id = @PhysGroupID
</code></pre>
","<p>Couldn't take the time to dig through all your SQL (what a beast!), here's an idea that might make things easier to handle:</p>

<pre><code>select 
 p.person_id, p.name &lt;and other person columns&gt;,
 (select &lt;current policy columns&gt;
  from pol &lt;and other tables for policy&gt;
  where pol.&lt;columns for join&gt; = p.person_id
  and &lt;restrictions for current policy&gt;),
 (select &lt;previous policy columns&gt;
  from pol &lt;and other tables for policy&gt;
  where pol.&lt;columns for join&gt; = p.person_id
  and &lt;restrictions for previouspolicy&gt;),
 &lt;other columns&gt;
from person p &lt;and ""directly related"" tables&gt;
</code></pre>

<p>This makes the statement easier to read by separating the different parts into their own subselects, and it also makes it easier to add a ""Top 1"" in without affecting the rest of the statement. Hope that helps.</p>
"
770,350400,8,6,sql,Testing for whitespace in SQL Server,"<p>I've got some blank values in my table, and I can't seem to catch them in an IF statement. </p>

<p>I've tried</p>

<p><code>IF @value = ''</code> and <code>if @value = NULL</code> and neither one catches the blank values. Is there any way to test whether or not a varchar is entirely whitespace?</p>

<p>AHA! Turns out I was testing for null wrong. Thanks. </p>
","<p>To compare with NULL, use the IS NULL keyword.</p>

<pre><code>--Generic example:
SELECT *
FROM MY_TABLE
WHERE SOME_FIELD IS NULL;

--Instead of    

SELECT *
FROM MY_TABLE
WHERE SOME_FIELD = NULL;
</code></pre>
"
1078,494720,1,6,sql,Top 1 on Left Join SubQuery,"<p>I am trying to take a person and display their current insurance along with their former insurance.  I guess one could say that I'm trying to flaten my view of customers or people.  I'm running into an issue where I'm getting multiple records back due to multiple records existing within my left join subqueries.  I had hoped I could solve this by adding ""TOP 1"" to the subquery, but that actually returns nothing...</p>

<p>Any ideas?</p>

<pre><code>    SELECT 
	p.person_id AS 'MIRID'
	, p.firstname AS 'FIRST'
	, p.lastname AS 'LAST'
	, pg.name AS 'GROUP'
	, e.name AS 'AOR'
	, p.leaddate AS 'CONTACT DATE'
	, [dbo].[GetPICampaignDisp](p.person_id, '2009') AS 'PI - 2009'
	, [dbo].[GetPICampaignDisp](p.person_id, '2008') AS 'PI - 2008'
	, [dbo].[GetPICampaignDisp](p.person_id, '2007') AS 'PI - 2007'
	, a_disp.name AS 'CURR DISP'
	, a_ins.name AS 'CURR INS'
	, a_prodtype.name AS 'CURR INS TYPE'
	, a_t.date AS 'CURR INS APP DATE'
	, a_t.effdate AS 'CURR INS EFF DATE' 
	, b_disp.name AS 'PREV DISP'
	, b_ins.name AS 'PREV INS'
	, b_prodtype.name AS 'PREV INS TYPE'
	, b_t.date AS 'PREV INS APP DATE'
	, b_t.effdate AS 'PREV INS EFF DATE'
	, b_t.termdate AS 'PREV INS TERM DATE'
FROM 
	[person] p
LEFT OUTER JOIN 
	[employee] e
ON 
	e.employee_id = p.agentofrecord_id
INNER JOIN 
	[dbo].[person_physician] pp
ON 
	p.person_id = pp.person_id
INNER JOIN 
	[dbo].[physician] ph
ON
	ph.physician_id = pp.physician_id
INNER JOIN
	[dbo].[clinic] c
ON 
	c.clinic_id = ph.clinic_id
INNER JOIN
	[dbo].[d_Physgroup] pg
ON
	pg.d_physgroup_id = c.physgroup_id
LEFT OUTER JOIN 
	(
		SELECT
			tr1.*
		FROM 
			[transaction] tr1
		LEFT OUTER JOIN 
			[d_vendor] ins1
		ON 
			ins1.d_vendor_id = tr1.d_vendor_id
		LEFT OUTER JOIN 
			[d_product_type] prodtype1
		ON 
			prodtype1.d_product_type_id = tr1.d_product_type_id
		LEFT OUTER JOIN 
			[d_commission_type] ctype1
		ON 
			ctype1.d_commission_type_id = tr1.d_commission_type_id
		WHERE
			prodtype1.name &lt;&gt; 'Medicare Part D'
			AND tr1.termdate IS NULL
	) AS a_t
ON
	a_t.person_id = p.person_id
LEFT OUTER JOIN 
	[d_vendor] a_ins
ON 
	a_ins.d_vendor_id = a_t.d_vendor_id
LEFT OUTER JOIN 
	[d_product_type] a_prodtype
ON 
	a_prodtype.d_product_type_id = a_t.d_product_type_id
LEFT OUTER JOIN 
	[d_commission_type] a_ctype
ON 
	a_ctype.d_commission_type_id = a_t.d_commission_type_id
LEFT OUTER JOIN
	[d_disposition] a_disp
ON
	a_disp.d_disposition_id = a_t.d_disposition_id
LEFT OUTER JOIN 
	(
		SELECT
			tr2.*
		FROM 
			[transaction] tr2
		LEFT OUTER JOIN 
			[d_vendor] ins2
		ON 
			ins2.d_vendor_id = tr2.d_vendor_id
		LEFT OUTER JOIN 
			[d_product_type] prodtype2
		ON 
			prodtype2.d_product_type_id = tr2.d_product_type_id
		LEFT OUTER JOIN 
			[d_commission_type] ctype2
		ON 
			ctype2.d_commission_type_id = tr2.d_commission_type_id
		WHERE
			prodtype2.name &lt;&gt; 'Medicare Part D'
			AND tr2.termdate IS NOT NULL
	) AS b_t
ON
	b_t.person_id = p.person_id
LEFT OUTER JOIN 
	[d_vendor] b_ins
ON 
	b_ins.d_vendor_id = b_t.d_vendor_id
LEFT OUTER JOIN 
	[d_product_type] b_prodtype
ON 
	b_prodtype.d_product_type_id = b_t.d_product_type_id
LEFT OUTER JOIN 
	[d_commission_type] b_ctype
ON 
	b_ctype.d_commission_type_id = b_t.d_commission_type_id
LEFT OUTER JOIN
	[d_disposition] b_disp
ON
	b_disp.d_disposition_id = b_t.d_disposition_id
WHERE
	pg.d_physgroup_id = @PhysGroupID
</code></pre>
","<p>Thanks for all of the feedback and ideas...  </p>

<p>In the simplest of terms, I have a person table that stores contact information like name, email, etc.  I have another table that stores transactions.  Each transaction is really an insurance policy that would contain information on the provider, product type, product name, etc.</p>

<p>I want to avoid giving the user duplicate person records since this causes them to look for the duplicates prior to running mail merges, etc.  I'm getting duplicates when there is more than 1 transaction that has not been terminated, and when there is more than 1 transaction that has been terminated.  </p>

<p>Someone else suggested that I consider a cursor to grab my distinct contact records and then perform the sub selects to get the current and previous insurance information.  I don't know if I want to head down that path though.</p>
"
1077,494720,7,6,sql,Top 1 on Left Join SubQuery,"<p>I am trying to take a person and display their current insurance along with their former insurance.  I guess one could say that I'm trying to flaten my view of customers or people.  I'm running into an issue where I'm getting multiple records back due to multiple records existing within my left join subqueries.  I had hoped I could solve this by adding ""TOP 1"" to the subquery, but that actually returns nothing...</p>

<p>Any ideas?</p>

<pre><code>    SELECT 
	p.person_id AS 'MIRID'
	, p.firstname AS 'FIRST'
	, p.lastname AS 'LAST'
	, pg.name AS 'GROUP'
	, e.name AS 'AOR'
	, p.leaddate AS 'CONTACT DATE'
	, [dbo].[GetPICampaignDisp](p.person_id, '2009') AS 'PI - 2009'
	, [dbo].[GetPICampaignDisp](p.person_id, '2008') AS 'PI - 2008'
	, [dbo].[GetPICampaignDisp](p.person_id, '2007') AS 'PI - 2007'
	, a_disp.name AS 'CURR DISP'
	, a_ins.name AS 'CURR INS'
	, a_prodtype.name AS 'CURR INS TYPE'
	, a_t.date AS 'CURR INS APP DATE'
	, a_t.effdate AS 'CURR INS EFF DATE' 
	, b_disp.name AS 'PREV DISP'
	, b_ins.name AS 'PREV INS'
	, b_prodtype.name AS 'PREV INS TYPE'
	, b_t.date AS 'PREV INS APP DATE'
	, b_t.effdate AS 'PREV INS EFF DATE'
	, b_t.termdate AS 'PREV INS TERM DATE'
FROM 
	[person] p
LEFT OUTER JOIN 
	[employee] e
ON 
	e.employee_id = p.agentofrecord_id
INNER JOIN 
	[dbo].[person_physician] pp
ON 
	p.person_id = pp.person_id
INNER JOIN 
	[dbo].[physician] ph
ON
	ph.physician_id = pp.physician_id
INNER JOIN
	[dbo].[clinic] c
ON 
	c.clinic_id = ph.clinic_id
INNER JOIN
	[dbo].[d_Physgroup] pg
ON
	pg.d_physgroup_id = c.physgroup_id
LEFT OUTER JOIN 
	(
		SELECT
			tr1.*
		FROM 
			[transaction] tr1
		LEFT OUTER JOIN 
			[d_vendor] ins1
		ON 
			ins1.d_vendor_id = tr1.d_vendor_id
		LEFT OUTER JOIN 
			[d_product_type] prodtype1
		ON 
			prodtype1.d_product_type_id = tr1.d_product_type_id
		LEFT OUTER JOIN 
			[d_commission_type] ctype1
		ON 
			ctype1.d_commission_type_id = tr1.d_commission_type_id
		WHERE
			prodtype1.name &lt;&gt; 'Medicare Part D'
			AND tr1.termdate IS NULL
	) AS a_t
ON
	a_t.person_id = p.person_id
LEFT OUTER JOIN 
	[d_vendor] a_ins
ON 
	a_ins.d_vendor_id = a_t.d_vendor_id
LEFT OUTER JOIN 
	[d_product_type] a_prodtype
ON 
	a_prodtype.d_product_type_id = a_t.d_product_type_id
LEFT OUTER JOIN 
	[d_commission_type] a_ctype
ON 
	a_ctype.d_commission_type_id = a_t.d_commission_type_id
LEFT OUTER JOIN
	[d_disposition] a_disp
ON
	a_disp.d_disposition_id = a_t.d_disposition_id
LEFT OUTER JOIN 
	(
		SELECT
			tr2.*
		FROM 
			[transaction] tr2
		LEFT OUTER JOIN 
			[d_vendor] ins2
		ON 
			ins2.d_vendor_id = tr2.d_vendor_id
		LEFT OUTER JOIN 
			[d_product_type] prodtype2
		ON 
			prodtype2.d_product_type_id = tr2.d_product_type_id
		LEFT OUTER JOIN 
			[d_commission_type] ctype2
		ON 
			ctype2.d_commission_type_id = tr2.d_commission_type_id
		WHERE
			prodtype2.name &lt;&gt; 'Medicare Part D'
			AND tr2.termdate IS NOT NULL
	) AS b_t
ON
	b_t.person_id = p.person_id
LEFT OUTER JOIN 
	[d_vendor] b_ins
ON 
	b_ins.d_vendor_id = b_t.d_vendor_id
LEFT OUTER JOIN 
	[d_product_type] b_prodtype
ON 
	b_prodtype.d_product_type_id = b_t.d_product_type_id
LEFT OUTER JOIN 
	[d_commission_type] b_ctype
ON 
	b_ctype.d_commission_type_id = b_t.d_commission_type_id
LEFT OUTER JOIN
	[d_disposition] b_disp
ON
	b_disp.d_disposition_id = b_t.d_disposition_id
WHERE
	pg.d_physgroup_id = @PhysGroupID
</code></pre>
","<p>The pattern I normally use for this is:</p>

<blockquote>
  <p>SELECT whatever<br />
  FROM person<br />
  LEFT JOIN subtable  AS s1<br />
     ON s1.personid = person.personid</p>
  
  <p>...  </p>
  
  <p>WHERE NOT EXISTS<br />
  (    SELECT 1 FROM subtable<br />
       WHERE personid = person.personid<br />
           AND orderbydate > s1.orderbydate
  )</p>
</blockquote>

<p>Which avoids the TOP 1 clause and maybe makes it a little clearer.</p>

<p>BTW, I like the way you've put this query together in general, except I'd leave out the brackets, assuming you have rationally named tables and columns; and you might even gain some performance (but at least elegance) by listing columns for tr1 and tr2, rather than ""tr1.*"" and ""tr2.*"".</p>
"
773,350400,2,6,sql,Testing for whitespace in SQL Server,"<p>I've got some blank values in my table, and I can't seem to catch them in an IF statement. </p>

<p>I've tried</p>

<p><code>IF @value = ''</code> and <code>if @value = NULL</code> and neither one catches the blank values. Is there any way to test whether or not a varchar is entirely whitespace?</p>

<p>AHA! Turns out I was testing for null wrong. Thanks. </p>
","<p>where length(rtrim(ltrim(yourcolumnname))) = 0 OR yourcolumnname is null</p>
"
1075,494720,0,6,sql,Top 1 on Left Join SubQuery,"<p>I am trying to take a person and display their current insurance along with their former insurance.  I guess one could say that I'm trying to flaten my view of customers or people.  I'm running into an issue where I'm getting multiple records back due to multiple records existing within my left join subqueries.  I had hoped I could solve this by adding ""TOP 1"" to the subquery, but that actually returns nothing...</p>

<p>Any ideas?</p>

<pre><code>    SELECT 
	p.person_id AS 'MIRID'
	, p.firstname AS 'FIRST'
	, p.lastname AS 'LAST'
	, pg.name AS 'GROUP'
	, e.name AS 'AOR'
	, p.leaddate AS 'CONTACT DATE'
	, [dbo].[GetPICampaignDisp](p.person_id, '2009') AS 'PI - 2009'
	, [dbo].[GetPICampaignDisp](p.person_id, '2008') AS 'PI - 2008'
	, [dbo].[GetPICampaignDisp](p.person_id, '2007') AS 'PI - 2007'
	, a_disp.name AS 'CURR DISP'
	, a_ins.name AS 'CURR INS'
	, a_prodtype.name AS 'CURR INS TYPE'
	, a_t.date AS 'CURR INS APP DATE'
	, a_t.effdate AS 'CURR INS EFF DATE' 
	, b_disp.name AS 'PREV DISP'
	, b_ins.name AS 'PREV INS'
	, b_prodtype.name AS 'PREV INS TYPE'
	, b_t.date AS 'PREV INS APP DATE'
	, b_t.effdate AS 'PREV INS EFF DATE'
	, b_t.termdate AS 'PREV INS TERM DATE'
FROM 
	[person] p
LEFT OUTER JOIN 
	[employee] e
ON 
	e.employee_id = p.agentofrecord_id
INNER JOIN 
	[dbo].[person_physician] pp
ON 
	p.person_id = pp.person_id
INNER JOIN 
	[dbo].[physician] ph
ON
	ph.physician_id = pp.physician_id
INNER JOIN
	[dbo].[clinic] c
ON 
	c.clinic_id = ph.clinic_id
INNER JOIN
	[dbo].[d_Physgroup] pg
ON
	pg.d_physgroup_id = c.physgroup_id
LEFT OUTER JOIN 
	(
		SELECT
			tr1.*
		FROM 
			[transaction] tr1
		LEFT OUTER JOIN 
			[d_vendor] ins1
		ON 
			ins1.d_vendor_id = tr1.d_vendor_id
		LEFT OUTER JOIN 
			[d_product_type] prodtype1
		ON 
			prodtype1.d_product_type_id = tr1.d_product_type_id
		LEFT OUTER JOIN 
			[d_commission_type] ctype1
		ON 
			ctype1.d_commission_type_id = tr1.d_commission_type_id
		WHERE
			prodtype1.name &lt;&gt; 'Medicare Part D'
			AND tr1.termdate IS NULL
	) AS a_t
ON
	a_t.person_id = p.person_id
LEFT OUTER JOIN 
	[d_vendor] a_ins
ON 
	a_ins.d_vendor_id = a_t.d_vendor_id
LEFT OUTER JOIN 
	[d_product_type] a_prodtype
ON 
	a_prodtype.d_product_type_id = a_t.d_product_type_id
LEFT OUTER JOIN 
	[d_commission_type] a_ctype
ON 
	a_ctype.d_commission_type_id = a_t.d_commission_type_id
LEFT OUTER JOIN
	[d_disposition] a_disp
ON
	a_disp.d_disposition_id = a_t.d_disposition_id
LEFT OUTER JOIN 
	(
		SELECT
			tr2.*
		FROM 
			[transaction] tr2
		LEFT OUTER JOIN 
			[d_vendor] ins2
		ON 
			ins2.d_vendor_id = tr2.d_vendor_id
		LEFT OUTER JOIN 
			[d_product_type] prodtype2
		ON 
			prodtype2.d_product_type_id = tr2.d_product_type_id
		LEFT OUTER JOIN 
			[d_commission_type] ctype2
		ON 
			ctype2.d_commission_type_id = tr2.d_commission_type_id
		WHERE
			prodtype2.name &lt;&gt; 'Medicare Part D'
			AND tr2.termdate IS NOT NULL
	) AS b_t
ON
	b_t.person_id = p.person_id
LEFT OUTER JOIN 
	[d_vendor] b_ins
ON 
	b_ins.d_vendor_id = b_t.d_vendor_id
LEFT OUTER JOIN 
	[d_product_type] b_prodtype
ON 
	b_prodtype.d_product_type_id = b_t.d_product_type_id
LEFT OUTER JOIN 
	[d_commission_type] b_ctype
ON 
	b_ctype.d_commission_type_id = b_t.d_commission_type_id
LEFT OUTER JOIN
	[d_disposition] b_disp
ON
	b_disp.d_disposition_id = b_t.d_disposition_id
WHERE
	pg.d_physgroup_id = @PhysGroupID
</code></pre>
","<p>It's difficult to understand your question so first I'll throw this out there: does changing your SELECT to SELECT DISTINCT do what you want?</p>

<p>Otherwise, let me get this straight, you're trying to get your customers' current insurance and previous insurance, but they may actually have many insurances before that, recorded in the [transactions] table? I looked at your SQL for quite a few minutes but can't figure out what it all means, so could you please reduce it down to only the parts that are necessary? Then I'll think about it some more. It sounds to me like you need a GROUP BY somehow, but I can't work it out exactly yet.</p>
"
476,205190,8,6,sql,Select from same table as an Insert or Update,"<p>Clearly the following is incorrect.</p>

<pre><code>INSERT INTO `aTable` (`A`,`B`) VALUES((SELECT MAX(`A`) FROM `aTable`)*2),'name');
</code></pre>

<p>I get the value:</p>

<p>SQL query: </p>

<pre><code>INSERT INTO `aTable` (`A`, `B` )
VALUES 
(
  (
   SELECT MAX(`A`)
   FROM `aTable`
  ) *2
 , 'name'
)
</code></pre>

<p>MySQL said:</p>

<p>1093 - You can't specify target table 'aTable' for update in FROM clause </p>

<p>So, I'm trying to make a bitmap table, each row corresponds to one Bit, and has a 'map' value.</p>

<p>To insert in the table, I don't want to do two queries, I want to do one.
How should I do this?</p>

<p>No one commented on this, but since I am trying to make a bitmap, it should be * 2 not ^ 2, my mistake, please note that is why the comments often say ^ 2, it was an error in the version that the commenters read.</p>
","<p>try:</p>

<pre><code>insert into aTable select max(a)^2, 'name' from aTable;
</code></pre>

<p>or</p>

<pre><code>insert into aTable select max(a)^2, 'name' from aTable group by B;
</code></pre>

<p>If you need a join, you can do this:</p>

<pre><code>insert into aTable select max(a)^2, 'name' from aTable, bTable;
</code></pre>

<p>My ""Server version"" is ""5.0.51b-community-nt MySQL Community Edition (GPL)""</p>
"
1017,472550,1,6,sql,How to change the Auto Growth size? MS SQL Server 2005,"<p>In MS Sql server 2005, by default 1MB Auto Growth is there, How can i change it to whatever i need.?</p>

<p>Thanx,
Ambanna</p>
","<p>You want to set the size to handle your data needs for the next few months. You do not want to depend on auto grow as a habit. You'll fill up your disk, and you delay performance of the server while files grow.</p>
"
485,206490,10,6,sql,Index varchar on MS SQL Server 2005,"<p>I need to index a varchar field on my table in MS SQL Server 2005, but it's not clear to me how to do so.  If I try to add a non-clustered index on the field, it says ""Column 'xxxx' in table 'mytable' is of a type that is invalid for use as a key column in an index""</p>

<p>My table has an auto-increment int ID that is set as the primary key on the table.  If I set this property as the index, and then add my varchar column as an ""included column"", the index goes through.  But I'm not sure that's what I want - I want to be able to search the table based on the varchar field alone, and my understanding of indexes was that all indexed elements had to be provided to actually see a speedup in the query, but I don't want to have to included the int ID (because I don't know what it is, at the time of this given query).</p>

<p>Am I trying to do this incorrectly? Would the ID + my varchar as an included column accomplish what I am looking for?</p>
","<p>Is your <code>varchar(max)</code>?  I think those aren't allowed to be used in an index.</p>

<p>Otherwise, post your <code>CREATE TABLE</code> statement, normally there is no problem adding a <code>varchar</code> to an index.</p>
"
996,456940,5,6,sql,SQL Queries - How Slow is Too Slow?,"<p>Do you have any formal or informal standards for reasonably achievable SQL query speed? How do you enforce them? Assume a production OLTP database under full realistic production load of a couple dozen queries per second, properly equipped and configured.</p>

<p>Personal example for illustrative purposes (not a recommendation, highly contingent on many factors, some outside your control):</p>

<p>Expectation:</p>

<p>Each transactional unit (single statement, multiple SQL statements from beginning to end transaction boundaries, or a single stored procedure, whichever is largest) must execute in 1 second or less on average, without anomalous outliers.</p>

<p>Resolution:</p>

<p>Slower queries must be optimized to standard. Slow queries for reports and other analysis are moved to an OLAP cube (best case) or a static snapshot database.</p>

<p>(Obviously some execution queries (Insert/Update/Delete) can't be moved, so must be optimized, but so far in my experience it's been achievable.)</p>
","<p>Given that you can't expect deterministic performance on a system that could (at least in theory) be subject to transient load spikes, you want your performance SLA to be probabilistic.  An example of this might be:</p>

<p>95% of transactions to complete within 2 seconds.<br>
95% of search queries (more appropriate for a search screen) to complete within 10 seconds.<br>
95% of operational reports to complete within 10 seconds.</p>

<p>Transactional and search queries can't be moved off transactional system, so the only actions you can take are database or application tuning, or buying faster hardware.  </p>

<p>For operational reports, you need to be ruthless about what qualifies as an operational report.  Only reports that <em>absolutely</em> need to have access to up-to-date data should be run off the live system.  Reports that do a lot of I/O are very anti-social on a production system, and normalised schemas tend to be quite inefficient for reporting.  Move any reports that do not require real-time data off onto a data warehouse or some other separate reporting facility.</p>
"
997,456940,1,6,sql,SQL Queries - How Slow is Too Slow?,"<p>Do you have any formal or informal standards for reasonably achievable SQL query speed? How do you enforce them? Assume a production OLTP database under full realistic production load of a couple dozen queries per second, properly equipped and configured.</p>

<p>Personal example for illustrative purposes (not a recommendation, highly contingent on many factors, some outside your control):</p>

<p>Expectation:</p>

<p>Each transactional unit (single statement, multiple SQL statements from beginning to end transaction boundaries, or a single stored procedure, whichever is largest) must execute in 1 second or less on average, without anomalous outliers.</p>

<p>Resolution:</p>

<p>Slower queries must be optimized to standard. Slow queries for reports and other analysis are moved to an OLAP cube (best case) or a static snapshot database.</p>

<p>(Obviously some execution queries (Insert/Update/Delete) can't be moved, so must be optimized, but so far in my experience it's been achievable.)</p>
","<p>I usually go by the one second rule when writing/refactoring stored procedures, although my workplace doesn't have any specific rules about this. It's just my common sense. Experience tells me that if it takes up to ten seconds or more for a procedure to execute, which doesn't perform any large bulk inserts, there are usually serious problems in the code that can easily be corrected.</p>

<p>They way most common problem I encounter in SP:s with poor performance is incorrect use of indexes, causing costly index seek operations.</p>
"
998,456940,1,6,sql,SQL Queries - How Slow is Too Slow?,"<p>Do you have any formal or informal standards for reasonably achievable SQL query speed? How do you enforce them? Assume a production OLTP database under full realistic production load of a couple dozen queries per second, properly equipped and configured.</p>

<p>Personal example for illustrative purposes (not a recommendation, highly contingent on many factors, some outside your control):</p>

<p>Expectation:</p>

<p>Each transactional unit (single statement, multiple SQL statements from beginning to end transaction boundaries, or a single stored procedure, whichever is largest) must execute in 1 second or less on average, without anomalous outliers.</p>

<p>Resolution:</p>

<p>Slower queries must be optimized to standard. Slow queries for reports and other analysis are moved to an OLAP cube (best case) or a static snapshot database.</p>

<p>(Obviously some execution queries (Insert/Update/Delete) can't be moved, so must be optimized, but so far in my experience it's been achievable.)</p>
","<p>O of N is good and anything worse like N^2 will eventually be too slow. </p>
"
473,205190,1,6,sql,Select from same table as an Insert or Update,"<p>Clearly the following is incorrect.</p>

<pre><code>INSERT INTO `aTable` (`A`,`B`) VALUES((SELECT MAX(`A`) FROM `aTable`)*2),'name');
</code></pre>

<p>I get the value:</p>

<p>SQL query: </p>

<pre><code>INSERT INTO `aTable` (`A`, `B` )
VALUES 
(
  (
   SELECT MAX(`A`)
   FROM `aTable`
  ) *2
 , 'name'
)
</code></pre>

<p>MySQL said:</p>

<p>1093 - You can't specify target table 'aTable' for update in FROM clause </p>

<p>So, I'm trying to make a bitmap table, each row corresponds to one Bit, and has a 'map' value.</p>

<p>To insert in the table, I don't want to do two queries, I want to do one.
How should I do this?</p>

<p>No one commented on this, but since I am trying to make a bitmap, it should be * 2 not ^ 2, my mistake, please note that is why the comments often say ^ 2, it was an error in the version that the commenters read.</p>
","<p>I think you need to drop the ""VALUES"", and have a valid select statement.</p>

<p><a href=""http://dev.mysql.com/doc/refman/5.0/en/ansi-diff-select-into-table.html"" rel=""nofollow"">see this link</a></p>

<p>I'm not particularly a mySQL guy, I use MSSQL mostly.  But If you format the select statement correctly, It should work.  </p>
"
474,205190,0,6,sql,Select from same table as an Insert or Update,"<p>Clearly the following is incorrect.</p>

<pre><code>INSERT INTO `aTable` (`A`,`B`) VALUES((SELECT MAX(`A`) FROM `aTable`)*2),'name');
</code></pre>

<p>I get the value:</p>

<p>SQL query: </p>

<pre><code>INSERT INTO `aTable` (`A`, `B` )
VALUES 
(
  (
   SELECT MAX(`A`)
   FROM `aTable`
  ) *2
 , 'name'
)
</code></pre>

<p>MySQL said:</p>

<p>1093 - You can't specify target table 'aTable' for update in FROM clause </p>

<p>So, I'm trying to make a bitmap table, each row corresponds to one Bit, and has a 'map' value.</p>

<p>To insert in the table, I don't want to do two queries, I want to do one.
How should I do this?</p>

<p>No one commented on this, but since I am trying to make a bitmap, it should be * 2 not ^ 2, my mistake, please note that is why the comments often say ^ 2, it was an error in the version that the commenters read.</p>
","<p>as soon as the Select is correct you can do this.</p>
"
475,205190,2,6,sql,Select from same table as an Insert or Update,"<p>Clearly the following is incorrect.</p>

<pre><code>INSERT INTO `aTable` (`A`,`B`) VALUES((SELECT MAX(`A`) FROM `aTable`)*2),'name');
</code></pre>

<p>I get the value:</p>

<p>SQL query: </p>

<pre><code>INSERT INTO `aTable` (`A`, `B` )
VALUES 
(
  (
   SELECT MAX(`A`)
   FROM `aTable`
  ) *2
 , 'name'
)
</code></pre>

<p>MySQL said:</p>

<p>1093 - You can't specify target table 'aTable' for update in FROM clause </p>

<p>So, I'm trying to make a bitmap table, each row corresponds to one Bit, and has a 'map' value.</p>

<p>To insert in the table, I don't want to do two queries, I want to do one.
How should I do this?</p>

<p>No one commented on this, but since I am trying to make a bitmap, it should be * 2 not ^ 2, my mistake, please note that is why the comments often say ^ 2, it was an error in the version that the commenters read.</p>
","<p>I take it that <a href=""http://dev.mysql.com/doc/refman/5.0/en/insert-select.html"" rel=""nofollow"">INSERT ... SELECT</a> isn't working?  I see this in the documentation for it:</p>

<blockquote>
  <p>The target table of the INSERT
  statement may appear in the FROM
  clause of the SELECT part of the
  query. (This was not possible in some
  older versions of MySQL.) In this
  case, MySQL creates a temporary table
  to hold the rows from the SELECT and
  then inserts those rows into the
  target table.</p>
</blockquote>

<p>Out of curiosity, which version of MySQL are you using?</p>
"
208,94930,2,6,sql,Fetch one row per account id from list,"<p>I have a table with game scores, allowing multiple rows per account id: <code>scores (id, score, accountid)</code>. I want a list of the top 10 scorer ids and their scores.</p>

<p>Can you provide an sql statement to select the top 10 scores, but only one score per account id? </p>

<p>Thanks!</p>
","<p>select top 10 username, max(score) from usertable group by username order by max(score) desc</p>
"
209,94930,1,6,sql,Fetch one row per account id from list,"<p>I have a table with game scores, allowing multiple rows per account id: <code>scores (id, score, accountid)</code>. I want a list of the top 10 scorer ids and their scores.</p>

<p>Can you provide an sql statement to select the top 10 scores, but only one score per account id? </p>

<p>Thanks!</p>
","<p>PostgreSQL has the DISTINCT ON clause, that works this way:</p>

<pre><code>SELECT DISTINCT ON (accountid) id, score, accountid
FROM scoretable
ORDER BY score DESC
LIMIT 10;
</code></pre>

<p>I don't think it's standard SQL though, so expect other databases to do it differently.</p>
"
486,206490,2,6,sql,Index varchar on MS SQL Server 2005,"<p>I need to index a varchar field on my table in MS SQL Server 2005, but it's not clear to me how to do so.  If I try to add a non-clustered index on the field, it says ""Column 'xxxx' in table 'mytable' is of a type that is invalid for use as a key column in an index""</p>

<p>My table has an auto-increment int ID that is set as the primary key on the table.  If I set this property as the index, and then add my varchar column as an ""included column"", the index goes through.  But I'm not sure that's what I want - I want to be able to search the table based on the varchar field alone, and my understanding of indexes was that all indexed elements had to be provided to actually see a speedup in the query, but I don't want to have to included the int ID (because I don't know what it is, at the time of this given query).</p>

<p>Am I trying to do this incorrectly? Would the ID + my varchar as an included column accomplish what I am looking for?</p>
","<p>No, the ID + varchar column would not work. That would work great for queries where you do a lookup on the ID and only select the ID or/and the varchar column - then you'd have a covering index and everything could be retrieved only by looking at the index.</p>

<p>I'm guessing you have a clustered index on your ID column as that's the primary key. Then you'd need to create a nonclustered index on the varchar column - which should be possible. The nonclustered index will automatically include the ID as well.</p>

<p>Also remember that the index will only be good for queryes like WHERE VarcharColumn = 'xyz' and WHERE VarcharColumn LIKE 'xyz%'.</p>

<p>It won't help for LIKE '%xyz%' and '%xyz' queries.</p>
"
210,94930,4,6,sql,Fetch one row per account id from list,"<p>I have a table with game scores, allowing multiple rows per account id: <code>scores (id, score, accountid)</code>. I want a list of the top 10 scorer ids and their scores.</p>

<p>Can you provide an sql statement to select the top 10 scores, but only one score per account id? </p>

<p>Thanks!</p>
","<pre><code>select username, max(score) from usertable group by username order by max(score) desc limit 10;
</code></pre>
"
211,94930,2,6,sql,Fetch one row per account id from list,"<p>I have a table with game scores, allowing multiple rows per account id: <code>scores (id, score, accountid)</code>. I want a list of the top 10 scorer ids and their scores.</p>

<p>Can you provide an sql statement to select the top 10 scores, but only one score per account id? </p>

<p>Thanks!</p>
","<p>First limit the selection to the highest score for each account id.
Then take the top ten scores.</p>

<pre><code>SELECT TOP 10 AccountId, Score
FROM Scores s1
WHERE AccountId NOT IN 
    (SELECT AccountId s2 FROM Scores 
     WHERE s1.AccountId = s2.AccountId and s1.Score &gt; s2.Score)
ORDER BY Score DESC
</code></pre>
"
212,94930,1,6,sql,Fetch one row per account id from list,"<p>I have a table with game scores, allowing multiple rows per account id: <code>scores (id, score, accountid)</code>. I want a list of the top 10 scorer ids and their scores.</p>

<p>Can you provide an sql statement to select the top 10 scores, but only one score per account id? </p>

<p>Thanks!</p>
","<pre><code>SELECT accountid, MAX(score) as top_score
FROM Scores
GROUP BY accountid,
ORDER BY top_score DESC
LIMIT 0, 10</code></pre>

<p>That should work fine in mysql.  It's possible you may need to use 'ORDER BY MAX(score) DESC' instead of that order by - I don't have my SQL reference on hand.</p>
"
487,206490,0,6,sql,Index varchar on MS SQL Server 2005,"<p>I need to index a varchar field on my table in MS SQL Server 2005, but it's not clear to me how to do so.  If I try to add a non-clustered index on the field, it says ""Column 'xxxx' in table 'mytable' is of a type that is invalid for use as a key column in an index""</p>

<p>My table has an auto-increment int ID that is set as the primary key on the table.  If I set this property as the index, and then add my varchar column as an ""included column"", the index goes through.  But I'm not sure that's what I want - I want to be able to search the table based on the varchar field alone, and my understanding of indexes was that all indexed elements had to be provided to actually see a speedup in the query, but I don't want to have to included the int ID (because I don't know what it is, at the time of this given query).</p>

<p>Am I trying to do this incorrectly? Would the ID + my varchar as an included column accomplish what I am looking for?</p>
","<p>You don't need to include the varchar field in the primary key for it to be indexed. To create an index just modify the table in Management Studio click on the Manage Indexes and Keys button and click Add to add a new index. Then select the VARCHAR field. There should be no problem.</p>
"
488,206490,1,6,sql,Index varchar on MS SQL Server 2005,"<p>I need to index a varchar field on my table in MS SQL Server 2005, but it's not clear to me how to do so.  If I try to add a non-clustered index on the field, it says ""Column 'xxxx' in table 'mytable' is of a type that is invalid for use as a key column in an index""</p>

<p>My table has an auto-increment int ID that is set as the primary key on the table.  If I set this property as the index, and then add my varchar column as an ""included column"", the index goes through.  But I'm not sure that's what I want - I want to be able to search the table based on the varchar field alone, and my understanding of indexes was that all indexed elements had to be provided to actually see a speedup in the query, but I don't want to have to included the int ID (because I don't know what it is, at the time of this given query).</p>

<p>Am I trying to do this incorrectly? Would the ID + my varchar as an included column accomplish what I am looking for?</p>
","<p>Setting a column as primary key per default creates a clustered index, so you don't have to create another INT+VARCHAR index. </p>

<p>What you're looking for is an index on your VARCHAR alone - without +INT, since your primary key is implicitly included - after all SQL Server should be able to locate the actual row when performing index lookups. There is a restriction though, I believe the overall size of index columns should be &lt; 900 byte (at least it was with SQL Server 2000). How long is your VARCHAR?</p>
"
489,206490,4,6,sql,Index varchar on MS SQL Server 2005,"<p>I need to index a varchar field on my table in MS SQL Server 2005, but it's not clear to me how to do so.  If I try to add a non-clustered index on the field, it says ""Column 'xxxx' in table 'mytable' is of a type that is invalid for use as a key column in an index""</p>

<p>My table has an auto-increment int ID that is set as the primary key on the table.  If I set this property as the index, and then add my varchar column as an ""included column"", the index goes through.  But I'm not sure that's what I want - I want to be able to search the table based on the varchar field alone, and my understanding of indexes was that all indexed elements had to be provided to actually see a speedup in the query, but I don't want to have to included the int ID (because I don't know what it is, at the time of this given query).</p>

<p>Am I trying to do this incorrectly? Would the ID + my varchar as an included column accomplish what I am looking for?</p>
","<p>I assume yours is a VARCHAR(MAX) column which, as the error says, is an invalida data type for an index. Suggestion: create a calculated column that is the hash value of the VARCHAR(MAX) column (e.g. using the HashBytes function) then create an index on the calculated column only. Then, in the search condition (e.g. WHERE clause) of your SQL DML you would use both the VARCHAR(MAX) search value itself <em>plus</em> a hash of your VARCHAR(MAX) search value on the respective columns in your table. It may be a good idea to encapsulate the hashing of search values in a 'helper' stored procedure.</p>
"
1016,472550,13,6,sql,How to change the Auto Growth size? MS SQL Server 2005,"<p>In MS Sql server 2005, by default 1MB Auto Growth is there, How can i change it to whatever i need.?</p>

<p>Thanx,
Ambanna</p>
","<p>In SQL Server Management Studio, right click on the database.<br />
Go to Properties.<br />
Then go to the Files section.<br />
Click on either the data or log autogrowth column (Click the ...)<br />
Then change it to whatever you want it to be.  </p>
"
643,279540,1,5,sql,Email Notification Service,"<p>What are some ideas (using .NET and SQL 2005) for implementing a service that sends emails?  The emails are to be data-driven.  The date and time an email is to be sent is a field in a table.</p>
","<p>Thanks everyone for the feedback. For simplicity's sake I've started out with a SP that looks up the reminders to be sent and uses sp_ send_ dbmail (SQL Database Mail) to send the emails.  This runs on a job every minute.  I update the record to indicate the reminder was sent with the MailItemId sent back from sp_ send_ dbmail.  The volume of reminders expected is worst case in the 10^2 range per day.</p>

<p>I'd love to hear feedback about any shortcomings people think this solution may have.</p>

<p>By the way, I can't believe Vista doesn't come with a local SMTP server! Luckily Google is more generous, I used Gmail's server for testing.</p>
"
638,279540,0,5,sql,Email Notification Service,"<p>What are some ideas (using .NET and SQL 2005) for implementing a service that sends emails?  The emails are to be data-driven.  The date and time an email is to be sent is a field in a table.</p>
","<p>Usually, I just spin up a process such as <a href=""http://caspian.dotconf.net/menu/Software/SendEmail/"" rel=""nofollow"">http://caspian.dotconf.net/menu/Software/SendEmail/</a></p>
"
642,279540,0,5,sql,Email Notification Service,"<p>What are some ideas (using .NET and SQL 2005) for implementing a service that sends emails?  The emails are to be data-driven.  The date and time an email is to be sent is a field in a table.</p>
","<p><a href=""http://technet.microsoft.com/en-us/library/ms169673(SQL.90).aspx"" rel=""nofollow"">Data Driven SSRS Subscriptions</a>? Just a thought.</p>
"
641,279540,2,5,sql,Email Notification Service,"<p>What are some ideas (using .NET and SQL 2005) for implementing a service that sends emails?  The emails are to be data-driven.  The date and time an email is to be sent is a field in a table.</p>
","<p>I have built several high volume email notification services used to send data driven emails in the past. A few recommendations:</p>

<ul>
<li>Look into using a high quality email service provider that specializes in managing bounces, unsubscribes, isp and black list management, etc. If sending email is critical to your business, but not your main business it will be worth it. Most will have an api for sending templated messages, click tracking, open rates and will have provide triggers etc. </li>
<li>Look into the SQL Server Service Broker to queue the actual messages, otherwise you can consider Microsoft Message Queuing Services. There is no need to build your own queuing service. We spent too much time dealing with queing infrastructure code when this was already solved.</li>
<li>Develop a flexible set of events on your business tier to allow for the triggering of such messages and put them in your queue asynchronously, this will save you alot of grief in the long run as opposed to polling on the DB or hacking it in with Database triggers.</li>
</ul>
"
640,279540,1,5,sql,Email Notification Service,"<p>What are some ideas (using .NET and SQL 2005) for implementing a service that sends emails?  The emails are to be data-driven.  The date and time an email is to be sent is a field in a table.</p>
","<p>You can use triggers to send emails on UPDATE/DELETE/INSERT. The triggers can be implemented with .Net, just send mails from there using the classes in <a href=""http://msdn.microsoft.com/en-us/library/system.net.mail.aspx"" rel=""nofollow"">System.Net.Mail</a> namespace.</p>

<p>Here is a good <a href=""http://aspalliance.com/1273_CLR_Triggers_for_SQL_Server_2005.all"" rel=""nofollow"">article</a> how to implement CLR (.Net) triggers in .Net.</p>

<p>For a light-weight SMPT server, and to minimize the delays, you can use the one, recommended in <a href=""http://stackoverflow.com/questions/279540/email-notification-service#279545"">Kenny's answer</a>.</p>
"
639,279540,0,5,sql,Email Notification Service,"<p>What are some ideas (using .NET and SQL 2005) for implementing a service that sends emails?  The emails are to be data-driven.  The date and time an email is to be sent is a field in a table.</p>
","<p>I was going to suggest SQL Server Notification Services, which will handle the job nicely. But I see that's been dropped from SQL Server 2008, so you probably don't want to go there.</p>
"
597,264090,0,5,sql,"In SQL, how to delete a row from one table if it doesn't have a corresponding row in another table?","<p>How can I make:</p>

<p>DELETE FROM foo WHERE id=1 AND <strong>bar not contains id==1</strong></p>

<p>To elaborate, how can I remove a row with <code>id = 1</code>, from table <code>foo</code>, only if there is not a row in table <code>bar</code> with <code>id = 1</code>.</p>
","<p>Use the SQL ""Exists"" command.</p>

<p><a href=""http://www.techonthenet.com/sql/exists.php"" rel=""nofollow"">http://www.techonthenet.com/sql/exists.php</a></p>
"
65,25460,1,5,sql,Asynchronous Stored Procedure Calls,"<p>Is it possible to call a stored prodcedure from another stored procedure asynchronously?</p>

<p><strong>Edit:</strong> Specifically I'm working with a DB2 database.</p>
","<p>With MS Sql Server 2005, try the Service Broker and/or CLR stored procedures.  I don't think there's anything built directly into TSQL.</p>
"
66,25460,0,5,sql,Asynchronous Stored Procedure Calls,"<p>Is it possible to call a stored prodcedure from another stored procedure asynchronously?</p>

<p><strong>Edit:</strong> Specifically I'm working with a DB2 database.</p>
","<p>It sounds like you need to put some scheduled jobs in place with Cron (or windows equiv). You could use the initial stored proc call to set some kind of flag in the DB, which is then checked periodically by a cron job. If you need to have a specific delay before the 2nd job executes, you should be able to do that by having the task scheduled by the cron job.</p>
"
649,281210,8,5,sql,Is it possible to use/access scalar functions with LINQ to SQL?,"<p>We have scalar functions in our database for returning things like ""number of tasks for a customer"" or ""total invoice amount for a customer"".  </p>

<p>We are experimenting and looking to try to do this w/o stored procedures ... normally we would just call this function in our stored procedure and return it as a single value. </p>

<p>Is there a way to use or access scalar functions with LINQ to SQL?  If so, I would be interested in see an example of how to ... if not, how would it be best to handle this type of situation ... if it is even doable.</p>
","<p>LINQ-to-SQL supports use with UDFs, if that is what you mean. Just drag the UDF onto the designer surface and you're done. This creates a matching method on the data-context, marked <a href=""http://msdn.microsoft.com/en-us/library/system.data.linq.mapping.functionattribute.aspx""><code>[Function(..., IsComposable=true)]</code></a> or similar, telling LINQ-to-SQL that it can use this in queries (note that EF doesn't support this usage).</p>

<p>You would then use it in your query like:</p>

<pre><code>var qry = from cust in ctx.Custs
           select new {Id = cust.Id, Value = ctx.GetTotalValue(cust.Id)};
</code></pre>

<p>which will become TSQL something like:</p>

<pre><code>SELECT t1.Id, dbo.MyUdf(t1.Id)
FROM CUSTOMER t1
</code></pre>

<p>(or there-abouts).</p>

<p>The fact that it is composable means that you can use the value in queries - for example in a <code>Where()</code>/<code>WHERE</code> - and so reduce the data brought back from the server (although obviously the UDF will still need to be executed in some way).</p>

<p><a href=""http://groups.google.co.uk/group/microsoft.public.dotnet.languages.csharp/browse_thread/thread/608b6b08532ed7eb/4cf42640934bf45e#bfc790be1a24e37a"">Here's a similar example</a>, showing a pseudo-UDF at use on a data-context, illustrating that the C# version of the method is not used.</p>

<p>Actually, I'm currently looking at such UDFs to provide ""out of model"" data in a composable way - i.e. a particular part of the system needs access to some data (that happens to be in the same database) that isn't really part of the same model, but which I want to <code>JOIN</code> in interesting ways. I also have existing SPs for this purpose... so I'm looking at porting those SPs to tabular UDFs, which provides a level of contract/abstraction surrounding the out-of-model data. So because it isn't part of my model, I can only get it via the UDF - yet I retain the ability to compose this with my regular model.</p>
"
596,264090,11,5,sql,"In SQL, how to delete a row from one table if it doesn't have a corresponding row in another table?","<p>How can I make:</p>

<p>DELETE FROM foo WHERE id=1 AND <strong>bar not contains id==1</strong></p>

<p>To elaborate, how can I remove a row with <code>id = 1</code>, from table <code>foo</code>, only if there is not a row in table <code>bar</code> with <code>id = 1</code>.</p>
","<p>using a join:   </p>

<pre><code>delete f
from   foo f
left
join   bar b on
       f.id = b.id 
where  f.id = 1 and
       b.id is null
</code></pre>
"
595,264090,19,5,sql,"In SQL, how to delete a row from one table if it doesn't have a corresponding row in another table?","<p>How can I make:</p>

<p>DELETE FROM foo WHERE id=1 AND <strong>bar not contains id==1</strong></p>

<p>To elaborate, how can I remove a row with <code>id = 1</code>, from table <code>foo</code>, only if there is not a row in table <code>bar</code> with <code>id = 1</code>.</p>
","<pre><code>DELETE FROM foo WHERE id=1 AND NOT EXISTS (SELECT * FROM bar WHERE id=1)
</code></pre>

<p>I'm assuming you mean that foo and bar are tables, and you want to remove a record from foo if it doesn't exist in bar.</p>
"
648,281210,1,5,sql,Is it possible to use/access scalar functions with LINQ to SQL?,"<p>We have scalar functions in our database for returning things like ""number of tasks for a customer"" or ""total invoice amount for a customer"".  </p>

<p>We are experimenting and looking to try to do this w/o stored procedures ... normally we would just call this function in our stored procedure and return it as a single value. </p>

<p>Is there a way to use or access scalar functions with LINQ to SQL?  If so, I would be interested in see an example of how to ... if not, how would it be best to handle this type of situation ... if it is even doable.</p>
","<p>I believe <a href=""http://msdn.microsoft.com/en-us/library/bb386973.aspx"" rel=""nofollow"">this MSDN documentation</a> is what you're after (as part of <a href=""http://msdn.microsoft.com/en-us/library/bb546175.aspx"" rel=""nofollow"">this wider topic of calling user-defined functions in LINQ to SQL</a>). Can't say I've done it myself, but it sounds right...</p>
"
667,292660,2,5,sql,SQL - How to make a conditional INSERT,"<p>Using <strong>only MySQL</strong>, I'm seeing if it's possible run an insert statement ONLY if the table is new. I successfully created a user variable to see if the table exists. The problem is that you can't use ""WHERE"" along with an insert statement. Any ideas on how to get this working?</p>

<pre><code>// See if the ""country"" table exists -- saving the result to a variable
SELECT
    @table_exists := COUNT(*)
FROM
    information_schema.TABLES
WHERE
    TABLE_SCHEMA = DATABASE() AND TABLE_NAME = 'country';

// Create the table if it doesn't exist
CREATE TABLE IF NOT EXISTS country (
    id INT unsigned auto_increment primary key,
    name VARCHAR(64)
);

// Insert data into the table if @table_exists &gt; 0
INSERT INTO country (name) VALUES ('Afghanistan'),('Aland Islands') WHERE 0 &lt; @table_exists;
</code></pre>
","<p>Use an if statement instead of the where clause:</p>

<p><a href=""http://dev.mysql.com/doc/refman/5.0/en/if-statement.html"" rel=""nofollow"">http://dev.mysql.com/doc/refman/5.0/en/if-statement.html</a></p>
"
64,25460,5,5,sql,Asynchronous Stored Procedure Calls,"<p>Is it possible to call a stored prodcedure from another stored procedure asynchronously?</p>

<p><strong>Edit:</strong> Specifically I'm working with a DB2 database.</p>
","<p>Executive summary:  Yes, if your database has a message queue service.</p>

<p>You can push a message onto a queue and the queue processor will consume it asynchronously.</p>

<ul>
<li>Oracle: queues</li>
<li>Sql Server: service broker</li>
<li>DB2: event broker</li>
</ul>

<p>For ""pure"" stored procedure languages (PL/Sql or T-Sql) the answer is no, since it works against the fundamental transaction model most databases have.</p>

<p>However, if your database has a queuing mechanism, you can use that to get the same result.</p>
"
666,292660,6,5,sql,SQL - How to make a conditional INSERT,"<p>Using <strong>only MySQL</strong>, I'm seeing if it's possible run an insert statement ONLY if the table is new. I successfully created a user variable to see if the table exists. The problem is that you can't use ""WHERE"" along with an insert statement. Any ideas on how to get this working?</p>

<pre><code>// See if the ""country"" table exists -- saving the result to a variable
SELECT
    @table_exists := COUNT(*)
FROM
    information_schema.TABLES
WHERE
    TABLE_SCHEMA = DATABASE() AND TABLE_NAME = 'country';

// Create the table if it doesn't exist
CREATE TABLE IF NOT EXISTS country (
    id INT unsigned auto_increment primary key,
    name VARCHAR(64)
);

// Insert data into the table if @table_exists &gt; 0
INSERT INTO country (name) VALUES ('Afghanistan'),('Aland Islands') WHERE 0 &lt; @table_exists;
</code></pre>
","<pre><code>IF @TableExists &gt; 0 THEN
   BEGIN
       INSERT INTO country (name) VALUES ('Afghanistan'),('Aland Islands');
   END
</code></pre>
"
37,20840,6,5,sql,SQL Server - Dirty Reads Pros & Cons,"<p>Why should I or shouldn't I use dirty reads:</p>

<pre><code>set transaction isolation level read uncommitted
</code></pre>

<p>in SQL Server?</p>
","<p>Generally when you need to do a sizeable (or frequent) queries to busy tables, where read committed would possibly be blocked by locks from uncommited transactions, but ONLY when you can live with inaccurate data. </p>

<p>As an example, on a gaming web site I worked on recently there was a summary display of some stats about recent games, this was all based on dirty reads, it was more important for us to include then exclude the transactional data not yet committed (we knew anyway that few, if any, transactions would be backed out), we felt that on average the data would be more accurate that way.</p>
"
38,20840,0,5,sql,SQL Server - Dirty Reads Pros & Cons,"<p>Why should I or shouldn't I use dirty reads:</p>

<pre><code>set transaction isolation level read uncommitted
</code></pre>

<p>in SQL Server?</p>
","<p>use it if you want the data back right away and it is not that important if it is right<br>
do not use if if the data is important to be correct or if you are doing updates with it</p>

<p>Also take a look at snapshot isolation which has been introduced in sql server 2005</p>
"
39,20840,14,5,sql,SQL Server - Dirty Reads Pros & Cons,"<p>Why should I or shouldn't I use dirty reads:</p>

<pre><code>set transaction isolation level read uncommitted
</code></pre>

<p>in SQL Server?</p>
","<p>From <a href=""http://msdn.microsoft.com/en-us/library/aa259216(SQL.80).aspx"">MSDN</a>:</p>

<blockquote>
  <p>When this option is set, it is possible to read uncommitted or dirty data; values in the data can be changed and rows can appear or disappear in the data set before the end of the transaction. </p>
</blockquote>

<p>Simply put, when you are using this isolation level, and you are performing multiple queries on an active table as part of one transaction, there is no guarantee that the information returned to you within different parts of the transaction will remain the same. You could query the same data twice within one transaction and get different results (this might happen in the case where a different user was updating the same data in the midst of your transaction). This can obviously have severe ramifications for parts of your application that rely on data integrity.</p>
"
740,343230,3,5,sql,Where to look for database samples/schema?,"<p>I found <a href=""http://www.databaseanswers.org/data_models/"" rel=""nofollow"">http://www.databaseanswers.org/data_models/</a> very useful. Any other suggestions?</p>
","<p>If you're just looking for data models, I recommend the following books:</p>

<ul>
<li><a href=""http://rads.stackoverflow.com/amzn/click/0471380237"" rel=""nofollow"">The Data Model Resource Book, Vol.
1: A Library of Universal Data
Models for All Enterprises</a></li>
<li><a href=""http://rads.stackoverflow.com/amzn/click/0471353485"" rel=""nofollow"">The Data Model Resource Book, Vol. 2: A Library of Data Models for Specific Industries</a> </li>
<li><a href=""http://rads.stackoverflow.com/amzn/click/0470178450"" rel=""nofollow"">The Data Model Resource Book: Universal Patterns for Data Modeling</a> </li>
</ul>

<p>I have Vol 1 and Vol 2 and these have been pretty helpful in the past.</p>
"
739,343230,0,5,sql,Where to look for database samples/schema?,"<p>I found <a href=""http://www.databaseanswers.org/data_models/"" rel=""nofollow"">http://www.databaseanswers.org/data_models/</a> very useful. Any other suggestions?</p>
","<p><a href=""http://stackoverflow.com/questions/295838/where-can-i-get-a-large-sql-server-sample-database"">Here</a> and <a href=""http://stackoverflow.com/questions/57068/good-databases-with-sample-data"">here</a> are two similar questions with lots of answers on stackoverflow.</p>
"
738,343230,0,5,sql,Where to look for database samples/schema?,"<p>I found <a href=""http://www.databaseanswers.org/data_models/"" rel=""nofollow"">http://www.databaseanswers.org/data_models/</a> very useful. Any other suggestions?</p>
","<p>Microsoft have db samples in <strong>VS2005</strong> and <strong>VS2008</strong>, but you can also download it from here:
<a href=""http://msdn.microsoft.com/en-us/library/ms227484.aspx"" rel=""nofollow"">Northwind Database</a></p>
"
1079,495390,4,5,sql,ORM or something to handle SQL tables with an order column efficiently,"<p>I got an Java application using SQL tables that contains an ordered list of entities, ordered by
an order column. I would like to add/remove things in/from the middle
of the list. Now, I'm wondering if some persistence framework / orm / you-name-it 
could provide this kind of functionality with batch update of order
column. </p>

<p>At the basic case Hibernate (and probably others also) provide this
functionality. 
The problem is that the objects are handled one at time, which becomes
problem when the list is large enough. Alternate solution would be to
do the thing with a batch SQL update, like the following for example:</p>

<pre><code>UPDATE table SET order_col = order_col + 1 WHERE order_col &gt; 47
INSERT TO table VALUES ('new_id', 'new_description, ..., 47)
</code></pre>

<p>which is done quite fast by the database engine but isn't supported. </p>

<p>Now, I understand that this
kind of batch updates don't fit so well when thinking the objects and their
versioning, dirty checking etc.
I'd still ask if somebody has some nice ideas or if some persistence
framework / ORM / you-name-it would provide some help. 
Of course I can do the thing with custom SQL/HQL/... but was wondering
if there would be some solution already (I'd think somebody else could
have done something like this before and even put it under open source). Also other good ideas related to the problem are welcome =)</p>
","<p>My advice is to do two things:</p>

<ol>
<li>Choose very large increments between your items, say one million.  This way you can move an item at 8,000,000 to before 7,000,000 by changing just it to 6,500,000; and</li>
<li>Every now and again reorder the items as a batch job.</li>
</ol>

<p>The large increments don't eliminate the problem of doing a large reorder but the need to do a big reorder highly unlikely and the batch job is there to reorder them say once every day/week/month as required.</p>

<p>Changing a whole bunch of items at once is just messy and asking for trouble.</p>
"
1080,495390,2,5,sql,ORM or something to handle SQL tables with an order column efficiently,"<p>I got an Java application using SQL tables that contains an ordered list of entities, ordered by
an order column. I would like to add/remove things in/from the middle
of the list. Now, I'm wondering if some persistence framework / orm / you-name-it 
could provide this kind of functionality with batch update of order
column. </p>

<p>At the basic case Hibernate (and probably others also) provide this
functionality. 
The problem is that the objects are handled one at time, which becomes
problem when the list is large enough. Alternate solution would be to
do the thing with a batch SQL update, like the following for example:</p>

<pre><code>UPDATE table SET order_col = order_col + 1 WHERE order_col &gt; 47
INSERT TO table VALUES ('new_id', 'new_description, ..., 47)
</code></pre>

<p>which is done quite fast by the database engine but isn't supported. </p>

<p>Now, I understand that this
kind of batch updates don't fit so well when thinking the objects and their
versioning, dirty checking etc.
I'd still ask if somebody has some nice ideas or if some persistence
framework / ORM / you-name-it would provide some help. 
Of course I can do the thing with custom SQL/HQL/... but was wondering
if there would be some solution already (I'd think somebody else could
have done something like this before and even put it under open source). Also other good ideas related to the problem are welcome =)</p>
","<p>If you really want to end up with a continuous sequential order, you can do it like this:</p>

<p>First of all, multiply the <code>sortorder</code> by say 1000</p>

<pre><code>UPDATE testtable SET sortorder = sortorder * 1000
</code></pre>

<p>Now do your inserts and insert suitable <code>sortorder</code> values to have the new entries in the right place.</p>

<p>Now do a table update and update the values using the <a href=""http://en.wikipedia.org/wiki/Select_(SQL)#ROW_NUMBER.28.29_window_function"" rel=""nofollow"">ROW_NUMBER</a> function</p>

<pre><code>UPDATE testtable
SET sortorder = subq.newsortorder
FROM
  (
  SELECT
    ID as innerID,
    ROW_NUMBER() OVER(ORDER BY sortorder ASC) as newsortorder
  FROM testtable
  ) subq
WHERE subq.innerID = ID
</code></pre>

<p>The ID is selected as <code>innerID</code> as the updated table can't be aliased and the ID column would otherwise end up ambiguous.</p>

<p>This is updating the <code>sortorder</code> with the row's number when sorted by <code>sortorder</code>.</p>
"
705,319280,16,5,sql,Postgresql Concurrency,"<p>In a project that I'm working, there's a table with a ""on update"" trigger, that monitors if a boolean column has changed (ex.: false -> true = do some action). But this action can only be done once for a row.</p>

<p>There will be multiple clients accessing the database, so I can suppose that eventually, multiple clients will try to update the same row column in parallel.</p>

<p>Does the ""update"" trigger itself handle the concurrency itself, or I need to do it in a transaction and manually lock the table?</p>
","<p>Triggers don't handle concurrency, and PostgreSQL should do the right thing whether or not you use explicit transactions.</p>

<p>PostgreSQL uses <em>optimistic locking</em> which means the first person to actually update the row gets a lock on that row.  If a second person tries to update the row, their update statement waits to see if the first commits their change or rolls back.  </p>

<p>If the first person commits, the second person gets an error, rather than their change going through and obliterating a change that might have been interesting to them.</p>

<p>If the first person rolls back, the second person's update un-blocks, and goes through normally, because now it's not going to overwrite anything.</p>

<p>The second person can also use the <code>NOWAIT</code> option, which makes the error happen immediately instead of blocking, if their update conflicts with an unresolved change.</p>
"
363,155540,5,5,sql,How can I tell when .Net System.Diagnostics.Process ran sucessfully or failed?,"<p>I'm writing a scheduler or sorts.  It's basically a table with a list of exes (like ""C:\a.exe"") and a console app that looks at the records in the table every minute or so and runs the tasks that haven't been run yet.</p>

<p>I run the tasks like this:</p>

<pre><code>System.Diagnostics.Process p = new System.Diagnostics.Process();
p.StartInfo.UseShellExecute = false;
p.StartInfo.FileName = someExe; // like ""a.exe""
p.Start();
</code></pre>

<p>How can I tell if a particular task failed?  For example what if a.exe throws an unhandled exception?  I'd like the above code to know when this happens and update the tasks table with something like ""the particular task failed"" etc.</p>

<p>How can I do this?</p>

<p>p.s.  I'm not using the Sql Agent or the Windows Scheduler because someone else told me not to.  He has more ""experience"" so I'm basically just following orders.  Feel free to suggest alternatives.</p>

<p>Thanks!</p>
","<p>I think you're looking for Process.ExitCode, assuming the process returns one.
You may need to use WaitForExit() though. There is also an ErrorDataReceived event which is triggered when an app sends to stderr.</p>
"
364,155540,2,5,sql,How can I tell when .Net System.Diagnostics.Process ran sucessfully or failed?,"<p>I'm writing a scheduler or sorts.  It's basically a table with a list of exes (like ""C:\a.exe"") and a console app that looks at the records in the table every minute or so and runs the tasks that haven't been run yet.</p>

<p>I run the tasks like this:</p>

<pre><code>System.Diagnostics.Process p = new System.Diagnostics.Process();
p.StartInfo.UseShellExecute = false;
p.StartInfo.FileName = someExe; // like ""a.exe""
p.Start();
</code></pre>

<p>How can I tell if a particular task failed?  For example what if a.exe throws an unhandled exception?  I'd like the above code to know when this happens and update the tasks table with something like ""the particular task failed"" etc.</p>

<p>How can I do this?</p>

<p>p.s.  I'm not using the Sql Agent or the Windows Scheduler because someone else told me not to.  He has more ""experience"" so I'm basically just following orders.  Feel free to suggest alternatives.</p>

<p>Thanks!</p>
","<p>In addition to the ExitCode, you can also do something like this:</p>

<pre><code>string output = p.StandardOutput.ReadToEnd();
</code></pre>

<p>That will capture everything that would have been written to a command window.  Then you can parse that string for known patterns for displaying errors, depending on the app.</p>
"
365,155540,8,5,sql,How can I tell when .Net System.Diagnostics.Process ran sucessfully or failed?,"<p>I'm writing a scheduler or sorts.  It's basically a table with a list of exes (like ""C:\a.exe"") and a console app that looks at the records in the table every minute or so and runs the tasks that haven't been run yet.</p>

<p>I run the tasks like this:</p>

<pre><code>System.Diagnostics.Process p = new System.Diagnostics.Process();
p.StartInfo.UseShellExecute = false;
p.StartInfo.FileName = someExe; // like ""a.exe""
p.Start();
</code></pre>

<p>How can I tell if a particular task failed?  For example what if a.exe throws an unhandled exception?  I'd like the above code to know when this happens and update the tasks table with something like ""the particular task failed"" etc.</p>

<p>How can I do this?</p>

<p>p.s.  I'm not using the Sql Agent or the Windows Scheduler because someone else told me not to.  He has more ""experience"" so I'm basically just following orders.  Feel free to suggest alternatives.</p>

<p>Thanks!</p>
","<p>You can catch the <a href=""http://msdn.microsoft.com/en-us/library/system.componentmodel.win32exception.aspx"">Win32Exception</a> to check if <a href=""http://msdn.microsoft.com/en-us/library/e8zac0ca.aspx"">Process.Start()</a> failed due to the file not existing or execute access is denied.</p>

<p>But you can not catch exceptions thrown by the processes that you create  using this class. In the first place, the application might not be written in .NET so there might not be a concept of exception at all.</p>

<p>What you can do is check on the <a href=""http://msdn.microsoft.com/en-us/library/system.diagnostics.process.exitcode.aspx"">ExitCode</a> of the application or read the <a href=""http://msdn.microsoft.com/en-us/library/system.diagnostics.process.standardoutput.aspx"">StandardOutput</a> and <a href=""http://msdn.microsoft.com/en-us/library/system.diagnostics.process.standarderror.aspx"">StandardError</a> streams to check whether error messages are being posted.</p>
"
366,155540,0,5,sql,How can I tell when .Net System.Diagnostics.Process ran sucessfully or failed?,"<p>I'm writing a scheduler or sorts.  It's basically a table with a list of exes (like ""C:\a.exe"") and a console app that looks at the records in the table every minute or so and runs the tasks that haven't been run yet.</p>

<p>I run the tasks like this:</p>

<pre><code>System.Diagnostics.Process p = new System.Diagnostics.Process();
p.StartInfo.UseShellExecute = false;
p.StartInfo.FileName = someExe; // like ""a.exe""
p.Start();
</code></pre>

<p>How can I tell if a particular task failed?  For example what if a.exe throws an unhandled exception?  I'd like the above code to know when this happens and update the tasks table with something like ""the particular task failed"" etc.</p>

<p>How can I do this?</p>

<p>p.s.  I'm not using the Sql Agent or the Windows Scheduler because someone else told me not to.  He has more ""experience"" so I'm basically just following orders.  Feel free to suggest alternatives.</p>

<p>Thanks!</p>
","<p>To expand on what @jop said. You will also need to wait for the process to close. Thus:</p>

<pre><code>        p.Start();
        p.WaitForExit();
        int returnCode = p.ExitCode;
</code></pre>

<p>Non-zero codes are typically errors. Some application use negative ones are errors, and positive ones as status codes/warnings.</p>
"
383,177240,2,5,sql,How to use a function-based index on a column that contains NULLs in Oracle 10+?,"<p>Lets just say you have a table in Oracle:</p>

<pre><code>CREATE TABLE person (
  id NUMBER PRIMARY KEY,
  given_names VARCHAR2(50),
  surname VARCHAR2(50)
);
</code></pre>

<p>with these function-based indices:</p>

<pre><code>CREATE INDEX idx_person_upper_given_names ON person (UPPER(given_names));
CREATE INDEX idx_person_upper_last_name ON person (UPPER(last_name));
</code></pre>

<p>Now, given_names has no NULL values but for argument's sake last_name does.  If I do this:</p>

<pre><code>SELECT * FROM person WHERE UPPER(given_names) LIKE 'P%'
</code></pre>

<p>the explain plan tells me its using the index but change it to:</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%'
</code></pre>

<p>it doesn't.  The Oracle docs say that to use the function-based index will only be used when several conditions are met, one of which is ensuring there are no NULL values since they aren't indexed.</p>

<p>I've tried these queries:</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%' AND UPPER(last_name) IS NOT NULL
</code></pre>

<p>and</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%' AND last_name IS NOT NULL
</code></pre>

<p>In the latter case I even added an index on last_name but no matter what I try it uses a full table scan.  Assuming I can't get rid of the NULL values, how do I get this query to use the index on UPPER(last_name)?</p>
","<p>In your example you've created the same index twice - this would give an error so I'm assuming that was a mistake in pasting, not the actual code you tried.</p>

<p>I tried it with</p>

<pre><code>CREATE INDEX idx_person_upper_surname ON person (UPPER(surname));

SELECT * FROM person WHERE UPPER(surname) LIKE 'P%';
</code></pre>

<p>and it produced the expected query plan:</p>

<pre><code>Execution Plan
----------------------------------------------------------
   0      SELECT STATEMENT Optimizer=ALL_ROWS (Cost=1 Card=1 Bytes=67)
   1    0   TABLE ACCESS (BY INDEX ROWID) OF 'PERSON' (TABLE) (Cost=1
          Card=1 Bytes=67)

   2    1     INDEX (RANGE SCAN) OF 'IDX_PERSON_UPPER_SURNAME' (INDEX)
           (Cost=1 Card=1)
</code></pre>

<p>To answer your question, yes it should work. Try double checking that you do have the second index created correctly.</p>

<p>Also try an explicit hint:</p>

<pre><code>SELECT /*+INDEX(PERSON IDX_PERSON_UPPER_SURNAME)*/ * 
FROM person 
WHERE UPPER(surname) LIKE 'P%';
</code></pre>

<p>If that works, but only with the hint, then it is likely related to CBO statistics gone wrong, or CBO related init parameters.</p>
"
384,177240,0,5,sql,How to use a function-based index on a column that contains NULLs in Oracle 10+?,"<p>Lets just say you have a table in Oracle:</p>

<pre><code>CREATE TABLE person (
  id NUMBER PRIMARY KEY,
  given_names VARCHAR2(50),
  surname VARCHAR2(50)
);
</code></pre>

<p>with these function-based indices:</p>

<pre><code>CREATE INDEX idx_person_upper_given_names ON person (UPPER(given_names));
CREATE INDEX idx_person_upper_last_name ON person (UPPER(last_name));
</code></pre>

<p>Now, given_names has no NULL values but for argument's sake last_name does.  If I do this:</p>

<pre><code>SELECT * FROM person WHERE UPPER(given_names) LIKE 'P%'
</code></pre>

<p>the explain plan tells me its using the index but change it to:</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%'
</code></pre>

<p>it doesn't.  The Oracle docs say that to use the function-based index will only be used when several conditions are met, one of which is ensuring there are no NULL values since they aren't indexed.</p>

<p>I've tried these queries:</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%' AND UPPER(last_name) IS NOT NULL
</code></pre>

<p>and</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%' AND last_name IS NOT NULL
</code></pre>

<p>In the latter case I even added an index on last_name but no matter what I try it uses a full table scan.  Assuming I can't get rid of the NULL values, how do I get this query to use the index on UPPER(last_name)?</p>
","<p>Are you sure you want the index to be used?  Full table scans are not bad.  Depending on the size of the table, it might be more efficient to do a table scan than use an index.  It also depends on the density and distribution of the data, which is why statistics are gathered.  The cost based optimizer can usually be trusted to make the right choice.  Unless you have a specific performance problem, I wouldn't worry too much about it.</p>
"
385,177240,6,5,sql,How to use a function-based index on a column that contains NULLs in Oracle 10+?,"<p>Lets just say you have a table in Oracle:</p>

<pre><code>CREATE TABLE person (
  id NUMBER PRIMARY KEY,
  given_names VARCHAR2(50),
  surname VARCHAR2(50)
);
</code></pre>

<p>with these function-based indices:</p>

<pre><code>CREATE INDEX idx_person_upper_given_names ON person (UPPER(given_names));
CREATE INDEX idx_person_upper_last_name ON person (UPPER(last_name));
</code></pre>

<p>Now, given_names has no NULL values but for argument's sake last_name does.  If I do this:</p>

<pre><code>SELECT * FROM person WHERE UPPER(given_names) LIKE 'P%'
</code></pre>

<p>the explain plan tells me its using the index but change it to:</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%'
</code></pre>

<p>it doesn't.  The Oracle docs say that to use the function-based index will only be used when several conditions are met, one of which is ensuring there are no NULL values since they aren't indexed.</p>

<p>I've tried these queries:</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%' AND UPPER(last_name) IS NOT NULL
</code></pre>

<p>and</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%' AND last_name IS NOT NULL
</code></pre>

<p>In the latter case I even added an index on last_name but no matter what I try it uses a full table scan.  Assuming I can't get rid of the NULL values, how do I get this query to use the index on UPPER(last_name)?</p>
","<p>The index can be used, though the optimiser may have chosen not to use it for your particular example:</p>

<pre><code>SQL&gt; create table my_objects
  2  as select object_id, object_name
  3  from all_objects;

Table created.

SQL&gt; select count(*) from my_objects;
  2  /

  COUNT(*)
----------
     83783


SQL&gt; alter table my_objects modify object_name null;

Table altered.

SQL&gt; update my_objects
  2  set object_name=null
  3  where object_name like 'T%';

1305 rows updated.

SQL&gt; create index my_objects_name on my_objects (lower(object_name));

Index created.

SQL&gt; set autotrace traceonly

SQL&gt; select * from my_objects
  2  where lower(object_name) like 'emp%';

29 rows selected.


Execution Plan
----------------------------------------------------------

------------------------------------------------------------------------------------
| Id  | Operation                   | Name            | Rows  | Bytes | Cost (%CPU)|
------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT            |                 |    17 |   510 |   355   (1)|
|   1 |  TABLE ACCESS BY INDEX ROWID| MY_OBJECTS      |    17 |   510 |   355   (1)|
|*  2 |   INDEX RANGE SCAN          | MY_OBJECTS_NAME |   671 |       |     6   (0)|
------------------------------------------------------------------------------------
</code></pre>

<p>The documentation you read was presumably pointing out that, just like any other index, all-null keys are not stored in the index.</p>
"
386,177240,0,5,sql,How to use a function-based index on a column that contains NULLs in Oracle 10+?,"<p>Lets just say you have a table in Oracle:</p>

<pre><code>CREATE TABLE person (
  id NUMBER PRIMARY KEY,
  given_names VARCHAR2(50),
  surname VARCHAR2(50)
);
</code></pre>

<p>with these function-based indices:</p>

<pre><code>CREATE INDEX idx_person_upper_given_names ON person (UPPER(given_names));
CREATE INDEX idx_person_upper_last_name ON person (UPPER(last_name));
</code></pre>

<p>Now, given_names has no NULL values but for argument's sake last_name does.  If I do this:</p>

<pre><code>SELECT * FROM person WHERE UPPER(given_names) LIKE 'P%'
</code></pre>

<p>the explain plan tells me its using the index but change it to:</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%'
</code></pre>

<p>it doesn't.  The Oracle docs say that to use the function-based index will only be used when several conditions are met, one of which is ensuring there are no NULL values since they aren't indexed.</p>

<p>I've tried these queries:</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%' AND UPPER(last_name) IS NOT NULL
</code></pre>

<p>and</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%' AND last_name IS NOT NULL
</code></pre>

<p>In the latter case I even added an index on last_name but no matter what I try it uses a full table scan.  Assuming I can't get rid of the NULL values, how do I get this query to use the index on UPPER(last_name)?</p>
","<p>You can circumvent the problem of null values being unindexed in this or other situations by also indexing based on a literal value:</p>

<pre><code>CREATE INDEX idx_person_upper_surname ON person (UPPER(surname),0);
</code></pre>

<p>This allows you to use the index for such queries as:</p>

<pre><code>Select *
From   person
Where  UPPER(surname) is null;
</code></pre>

<p>This query would normally not usa an index, except for bitmap indexes or indexes including a nonnullable real column other than surname.</p>
"
387,177240,0,5,sql,How to use a function-based index on a column that contains NULLs in Oracle 10+?,"<p>Lets just say you have a table in Oracle:</p>

<pre><code>CREATE TABLE person (
  id NUMBER PRIMARY KEY,
  given_names VARCHAR2(50),
  surname VARCHAR2(50)
);
</code></pre>

<p>with these function-based indices:</p>

<pre><code>CREATE INDEX idx_person_upper_given_names ON person (UPPER(given_names));
CREATE INDEX idx_person_upper_last_name ON person (UPPER(last_name));
</code></pre>

<p>Now, given_names has no NULL values but for argument's sake last_name does.  If I do this:</p>

<pre><code>SELECT * FROM person WHERE UPPER(given_names) LIKE 'P%'
</code></pre>

<p>the explain plan tells me its using the index but change it to:</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%'
</code></pre>

<p>it doesn't.  The Oracle docs say that to use the function-based index will only be used when several conditions are met, one of which is ensuring there are no NULL values since they aren't indexed.</p>

<p>I've tried these queries:</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%' AND UPPER(last_name) IS NOT NULL
</code></pre>

<p>and</p>

<pre><code>SELECT * FROM person WHERE UPPER(last_name) LIKE 'P%' AND last_name IS NOT NULL
</code></pre>

<p>In the latter case I even added an index on last_name but no matter what I try it uses a full table scan.  Assuming I can't get rid of the NULL values, how do I get this query to use the index on UPPER(last_name)?</p>
","<p>Oracle will still use a function-based indexes with columns that contain null - I think you misinterpreted the documentation.</p>

<p>You need to put a nvl in the function index if you want to check for this though.</p>

<p>Something like...</p>

<pre><code>create index idx_person_upper_surname on person (nvl(upper(surname),'N/A'));
</code></pre>

<p>You can then query using the index with</p>

<pre><code>select * from person where nvl(upper(surname),'N/A') = 'PIERPOINT'
</code></pre>

<p>Although, all a bit ugly. Since most people have surnames, perhaps a ""not null"" is appropriate :-).</p>
"
923,430000,2,5,sql,SQL Exclude LIKE items from table,"<p>I'm trying to figure out how to exclude items from a select statement from table A using an exclusion list from table B. The catch is that I'm excluding based on the prefix of a field.</p>

<p>So a field value maybe ""FORD Muffler"" and to exclude it from a basic query I would do:</p>

<pre><code>SELECT FieldName 
FROM TableName 
WHERE UPPER(ColumnName) NOT LIKE 'FORD%'
</code></pre>

<p>But to use a list of values to exclude from a different tabel I would use a Subquery like:</p>

<pre><code>SELECT FieldName 
FROM TableName 
WHERE UPPER(ColumnName) NOT IN (Select FieldName2 FROM TableName2)
</code></pre>

<p>The problem is that it only excludes exact matches and not LIKE or Wildcards (%).</p>

<p>How can I accomplish this task? Redesigning the table isn't an option as it is an existing table in use.</p>

<p>EDIT: Sorry I am using SQL Server (2005).</p>
","<pre><code>SELECT * FROM table_A 
LEFT OUTER JOIN table_B 
    ON (locate(table_b.column, UPPER(table_a.column)) == 1)
WHERE table_b.column IS NULL
</code></pre>
"
922,430000,5,5,sql,SQL Exclude LIKE items from table,"<p>I'm trying to figure out how to exclude items from a select statement from table A using an exclusion list from table B. The catch is that I'm excluding based on the prefix of a field.</p>

<p>So a field value maybe ""FORD Muffler"" and to exclude it from a basic query I would do:</p>

<pre><code>SELECT FieldName 
FROM TableName 
WHERE UPPER(ColumnName) NOT LIKE 'FORD%'
</code></pre>

<p>But to use a list of values to exclude from a different tabel I would use a Subquery like:</p>

<pre><code>SELECT FieldName 
FROM TableName 
WHERE UPPER(ColumnName) NOT IN (Select FieldName2 FROM TableName2)
</code></pre>

<p>The problem is that it only excludes exact matches and not LIKE or Wildcards (%).</p>

<p>How can I accomplish this task? Redesigning the table isn't an option as it is an existing table in use.</p>

<p>EDIT: Sorry I am using SQL Server (2005).</p>
","<p>Dunno how efficient this would be, but it should work:</p>

<pre><code>SELECT FieldName 
FROM TableName t1
WHERE NOT EXISTS (
    SELECT *
    FROM TableName2 t2
    WHERE t1.FieldName LIKE t2.FieldName2 + '%'
)
</code></pre>
"
144,56070,3,5,sql,DELETE Statement hangs on SQL Server for no apparent reason,"<p><strong>Edit</strong>: Solved, there was a trigger with a loop on the table (read my own answer further below).</p>

<p><hr /></p>

<p>We have a simple delete statement that looks like this:</p>

<pre><code>DELETE FROM tablename WHERE pk = 12345
</code></pre>

<p>This just hangs, no timeout, no nothing.</p>

<p>We've looked at the execution plan, and it consists of many lookups on related tables to ensure no foreign keys would trip up the delete, but we've verified that none of those other tables have any rows referring to that particular row.</p>

<p>There is no other user connected to the database at this time.</p>

<p>We've run DBCC CHECKDB against it, and it reports 0 errors.</p>

<p>Looking at the results of <em><code>sp_who</code></em> and <em><code>sp_lock</code></em> while the query is hanging, I notice that my spid has plenty of PAG and KEY locks, as well as the occasional TAB lock.</p>

<p>The table has 1.777.621 rows, and yes, pk is the primary key, so it's a single row delete based on index. There is no table scan in the execution plan, though I notice that it contains something that says <em>Table Spool (Eager Spool)</em>, but says Estimated number of rows 1. Can this actually be a table-scan in disguise? It only says it looks at the primary key column.</p>

<p>Tried DBCC DBREINDEX and UPDATE STATISTICS on the table. Both completed within reasonable time.</p>

<p>There is unfortunately a high number of indexes on this particular table. It is the core table in our system, with plenty of columns, and references, both outgoing and incoming. The exact number is 48 indexes + the primary key clustered index.</p>

<p>What else should we look at?</p>

<p>Note also that this table did not have this problem before, this problem occured suddently today. We also have many databases with the same table setup (copies of customer databases), and they behave as expected, it's just this one that is problematic.</p>
","<p>One piece of information missing is the number of indices on the table you are deleting the data from. As SQL Server uses the Primary Key as a pointer in every index, any change to the primary index requires updating every index. Though, unless we are talking a high number, this shouldn't be an issue.</p>

<p>I am guessing, from your description, that this is a primary table in the database, referenced by many other tables in FK relationships.  This would account for the large number of locks as it checks the rest of the tables for references. And, if you have cascading deletes turned on, this could lead to a delete in table a requiring checks several tables deep.</p>
"
145,56070,1,5,sql,DELETE Statement hangs on SQL Server for no apparent reason,"<p><strong>Edit</strong>: Solved, there was a trigger with a loop on the table (read my own answer further below).</p>

<p><hr /></p>

<p>We have a simple delete statement that looks like this:</p>

<pre><code>DELETE FROM tablename WHERE pk = 12345
</code></pre>

<p>This just hangs, no timeout, no nothing.</p>

<p>We've looked at the execution plan, and it consists of many lookups on related tables to ensure no foreign keys would trip up the delete, but we've verified that none of those other tables have any rows referring to that particular row.</p>

<p>There is no other user connected to the database at this time.</p>

<p>We've run DBCC CHECKDB against it, and it reports 0 errors.</p>

<p>Looking at the results of <em><code>sp_who</code></em> and <em><code>sp_lock</code></em> while the query is hanging, I notice that my spid has plenty of PAG and KEY locks, as well as the occasional TAB lock.</p>

<p>The table has 1.777.621 rows, and yes, pk is the primary key, so it's a single row delete based on index. There is no table scan in the execution plan, though I notice that it contains something that says <em>Table Spool (Eager Spool)</em>, but says Estimated number of rows 1. Can this actually be a table-scan in disguise? It only says it looks at the primary key column.</p>

<p>Tried DBCC DBREINDEX and UPDATE STATISTICS on the table. Both completed within reasonable time.</p>

<p>There is unfortunately a high number of indexes on this particular table. It is the core table in our system, with plenty of columns, and references, both outgoing and incoming. The exact number is 48 indexes + the primary key clustered index.</p>

<p>What else should we look at?</p>

<p>Note also that this table did not have this problem before, this problem occured suddently today. We also have many databases with the same table setup (copies of customer databases), and they behave as expected, it's just this one that is problematic.</p>
","<p>Ok, this is embarrasing.</p>

<p>A collegue had added a trigger to that table a while ago, and the trigger had a bug. Although he had fixed the bug, the trigger had never been recreated for that table.</p>

<p>So the server was actually doing nothing, it just did it a huge number of times.</p>

<p>Oh well...</p>

<p>Thanks for the eyeballs to everyone who read this and pondered the problem.</p>

<p>I'm going to accept Josef's answer, as his was the closest, and indirectly thouched upon the issue with the cascading deletes.</p>
"
921,430000,8,5,sql,SQL Exclude LIKE items from table,"<p>I'm trying to figure out how to exclude items from a select statement from table A using an exclusion list from table B. The catch is that I'm excluding based on the prefix of a field.</p>

<p>So a field value maybe ""FORD Muffler"" and to exclude it from a basic query I would do:</p>

<pre><code>SELECT FieldName 
FROM TableName 
WHERE UPPER(ColumnName) NOT LIKE 'FORD%'
</code></pre>

<p>But to use a list of values to exclude from a different tabel I would use a Subquery like:</p>

<pre><code>SELECT FieldName 
FROM TableName 
WHERE UPPER(ColumnName) NOT IN (Select FieldName2 FROM TableName2)
</code></pre>

<p>The problem is that it only excludes exact matches and not LIKE or Wildcards (%).</p>

<p>How can I accomplish this task? Redesigning the table isn't an option as it is an existing table in use.</p>

<p>EDIT: Sorry I am using SQL Server (2005).</p>
","<p>I think this will do it:</p>

<pre><code>SELECT FieldName
FROM TableName
LEFT JOIN TableName2 ON UPPER(ColumnName) LIKE TableName2.FieldName2 + '%'
WHERE TableName2.FieldName2 IS NULL
</code></pre>
"
143,56070,2,5,sql,DELETE Statement hangs on SQL Server for no apparent reason,"<p><strong>Edit</strong>: Solved, there was a trigger with a loop on the table (read my own answer further below).</p>

<p><hr /></p>

<p>We have a simple delete statement that looks like this:</p>

<pre><code>DELETE FROM tablename WHERE pk = 12345
</code></pre>

<p>This just hangs, no timeout, no nothing.</p>

<p>We've looked at the execution plan, and it consists of many lookups on related tables to ensure no foreign keys would trip up the delete, but we've verified that none of those other tables have any rows referring to that particular row.</p>

<p>There is no other user connected to the database at this time.</p>

<p>We've run DBCC CHECKDB against it, and it reports 0 errors.</p>

<p>Looking at the results of <em><code>sp_who</code></em> and <em><code>sp_lock</code></em> while the query is hanging, I notice that my spid has plenty of PAG and KEY locks, as well as the occasional TAB lock.</p>

<p>The table has 1.777.621 rows, and yes, pk is the primary key, so it's a single row delete based on index. There is no table scan in the execution plan, though I notice that it contains something that says <em>Table Spool (Eager Spool)</em>, but says Estimated number of rows 1. Can this actually be a table-scan in disguise? It only says it looks at the primary key column.</p>

<p>Tried DBCC DBREINDEX and UPDATE STATISTICS on the table. Both completed within reasonable time.</p>

<p>There is unfortunately a high number of indexes on this particular table. It is the core table in our system, with plenty of columns, and references, both outgoing and incoming. The exact number is 48 indexes + the primary key clustered index.</p>

<p>What else should we look at?</p>

<p>Note also that this table did not have this problem before, this problem occured suddently today. We also have many databases with the same table setup (copies of customer databases), and they behave as expected, it's just this one that is problematic.</p>
","<p>Try recreating the index on that table, and try regenerating the statistics.</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/aa258828(SQL.80).aspx"" rel=""nofollow"">DBCC REINDEX</a><br/></p>

<p><a href=""http://msdn.microsoft.com/en-us/library/aa260645(SQL.80).aspx"" rel=""nofollow"">UPDATE STATISTICS</a></p>
"
519,226460,1,5,sql,Semi-Tricky SQL Query,"<p>I am trying to write a query for SQL Server 2005 but I can't figure out how to do it.  I have a table with the following fields:</p>

<p><strong>MessageID int<br/>
CategoryID int<br/>
Priority tinyint<br/>
MessageText NVARCHAR(MAX)<br/></strong></p>

<p>I need a query that will return * for each row that has the highest priority within a Category.  For example, if I had the following data:</p>

<p><strong>MessageID, CategoryID, Priority, MessageText</strong><br/>
1, 100, 1, Error #1234 occurred<br/>
2, 100, 2, Error #243 occurred<br/>
3, 100, 3, Error #976 occurred<br/>
4, 200, 4, Error #194 occurred<br/>
5, 200, 1, Error #736 occurred<br/>
6, 300, 3, Error #54 occurred<br/>
7, 300, 2, Error #888 occurred<br/></p>

<p>then the result would be:</p>

<p><strong>MessageID, CategoryID, Priority, MessageText</strong><br/>
3, 100, 3, Error #976 occurred<br/>
4, 200, 4, Error #194 occurred<br/>
6, 300, 3, Error #54 occurred<br/></p>

<p>Notice that it returns one row per category, and that it is the row which had the highest priority for that Category.</p>

<p>Can anyone tell me how I can write this query?</p>
","<p>I believe that this should work, table name assumed as Messages</p>

<pre><code>SELECT
    M.MessageId,
    M.CategoryId,
    M.Priority,
    M.MessageText
FROM 
(
    SELECT 
    	CategoryId,
    	MAX(Priority) AS Priority
    FROM Messages
    GROUP BY CategoryId
) AS MaxValues
    INNER JOIN Messages M
    	ON (MaxValues.CategoryId = M.CategoryId
    			AND MaxValues.Priority = M.Priority)
</code></pre>

<p><strong>NOTE</strong></p>

<p>The only ""gotcha"" in this method is that if you have more than one max priority...</p>
"
560,251110,10,5,sql,How to remove a field from SQLServer2005 table,"<p>I tried this:</p>

<pre><code>ALTER TABLE My.Table DROP MyField
</code></pre>

<p>and got this error:</p>

<p>-MyField is not a constraint.</p>

<p>-Could not drop constraint. See previous errors.</p>

<p>There is just one row of data in the table and the field was just added.</p>

<p><strong>EDIT:</strong>
Just to follow up, the sql was missing COLUMN indeed.
Now I get even more seriously looking errors though:</p>

<ul>
<li>The object 'some_object__somenumbers' is dependent on column 'MyField'</li>
<li>ALTER TABLE DROP COLUMN MyField failed because one or more objects access this column.</li>
</ul>

<p><strong>EDIT:</strong></p>

<pre><code>ALTER TABLE TableName DROP Constraint ConstraintName
</code></pre>

<p>worked, after that I was able to use the previous code to remove the column. Credit goes to both of you, thanks.</p>
","<p>I think you are just missing the COLUMN keyword:</p>

<pre><code>ALTER TABLE TableName DROP COLUMN ColumnName
</code></pre>

<p>You will also need to make sure that any constraint that is depending on ColumnName is dropped first. </p>

<p>You can do this by:</p>

<pre><code>ALTER TABLE TableName DROP ConstraintName
</code></pre>

<p>For each constraint that you have. </p>

<p>If you have indexes based on the column, you will also need to drop those indexes first.</p>

<pre><code>DROP INDEX TableName.IndexName
</code></pre>
"
561,251110,4,5,sql,How to remove a field from SQLServer2005 table,"<p>I tried this:</p>

<pre><code>ALTER TABLE My.Table DROP MyField
</code></pre>

<p>and got this error:</p>

<p>-MyField is not a constraint.</p>

<p>-Could not drop constraint. See previous errors.</p>

<p>There is just one row of data in the table and the field was just added.</p>

<p><strong>EDIT:</strong>
Just to follow up, the sql was missing COLUMN indeed.
Now I get even more seriously looking errors though:</p>

<ul>
<li>The object 'some_object__somenumbers' is dependent on column 'MyField'</li>
<li>ALTER TABLE DROP COLUMN MyField failed because one or more objects access this column.</li>
</ul>

<p><strong>EDIT:</strong></p>

<pre><code>ALTER TABLE TableName DROP Constraint ConstraintName
</code></pre>

<p>worked, after that I was able to use the previous code to remove the column. Credit goes to both of you, thanks.</p>
","<p>Brian solved your original problem - for your new problem (The object 'some_object__somenumbers' is dependent on column 'MyField') it means you have a dependancy issue. Something like an index, foreign key reference, default value, etc. To drop the constraint use:</p>

<pre><code>ALTER TABLE TableName DROP ConstraintName
</code></pre>

<p>Also - you'll need to drop all the constraints dependant on that column before it'll let you drop the column itself.</p>
"
523,226460,1,5,sql,Semi-Tricky SQL Query,"<p>I am trying to write a query for SQL Server 2005 but I can't figure out how to do it.  I have a table with the following fields:</p>

<p><strong>MessageID int<br/>
CategoryID int<br/>
Priority tinyint<br/>
MessageText NVARCHAR(MAX)<br/></strong></p>

<p>I need a query that will return * for each row that has the highest priority within a Category.  For example, if I had the following data:</p>

<p><strong>MessageID, CategoryID, Priority, MessageText</strong><br/>
1, 100, 1, Error #1234 occurred<br/>
2, 100, 2, Error #243 occurred<br/>
3, 100, 3, Error #976 occurred<br/>
4, 200, 4, Error #194 occurred<br/>
5, 200, 1, Error #736 occurred<br/>
6, 300, 3, Error #54 occurred<br/>
7, 300, 2, Error #888 occurred<br/></p>

<p>then the result would be:</p>

<p><strong>MessageID, CategoryID, Priority, MessageText</strong><br/>
3, 100, 3, Error #976 occurred<br/>
4, 200, 4, Error #194 occurred<br/>
6, 300, 3, Error #54 occurred<br/></p>

<p>Notice that it returns one row per category, and that it is the row which had the highest priority for that Category.</p>

<p>Can anyone tell me how I can write this query?</p>
","<p>If you'd like to do it without all of the subqueries:</p>

<pre><code>SELECT
     MessageID,
     CategoryID,
     Priority,
     MessageText
FROM
     dbo.Messages M1
LEFT OUTER JOIN dbo.Messages M2 ON
     M2.CategoryID = M1.CategoryID AND
     M2.Priority &gt; M1.Priority
WHERE
     M2.MessageID IS NULL
</code></pre>

<p>You might have to adjust the query depending on how you want to handle ties. You didn't have any such examples, so I wasn't sure.</p>
"
522,226460,0,5,sql,Semi-Tricky SQL Query,"<p>I am trying to write a query for SQL Server 2005 but I can't figure out how to do it.  I have a table with the following fields:</p>

<p><strong>MessageID int<br/>
CategoryID int<br/>
Priority tinyint<br/>
MessageText NVARCHAR(MAX)<br/></strong></p>

<p>I need a query that will return * for each row that has the highest priority within a Category.  For example, if I had the following data:</p>

<p><strong>MessageID, CategoryID, Priority, MessageText</strong><br/>
1, 100, 1, Error #1234 occurred<br/>
2, 100, 2, Error #243 occurred<br/>
3, 100, 3, Error #976 occurred<br/>
4, 200, 4, Error #194 occurred<br/>
5, 200, 1, Error #736 occurred<br/>
6, 300, 3, Error #54 occurred<br/>
7, 300, 2, Error #888 occurred<br/></p>

<p>then the result would be:</p>

<p><strong>MessageID, CategoryID, Priority, MessageText</strong><br/>
3, 100, 3, Error #976 occurred<br/>
4, 200, 4, Error #194 occurred<br/>
6, 300, 3, Error #54 occurred<br/></p>

<p>Notice that it returns one row per category, and that it is the row which had the highest priority for that Category.</p>

<p>Can anyone tell me how I can write this query?</p>
","<p>This is shorter and easier to read (imo).</p>

<pre><code>select ms.*
from 
  messages ms
 ,(
  select ms1.categoryid, max(ms1.priority) as max_priority
  from messages ms1
  group by ms1.categoryid
  ) tmp
where ms.categoryid = tmp.categoryid
  and ms.priority = tmp.max_priority;
</code></pre>
"
521,226460,6,5,sql,Semi-Tricky SQL Query,"<p>I am trying to write a query for SQL Server 2005 but I can't figure out how to do it.  I have a table with the following fields:</p>

<p><strong>MessageID int<br/>
CategoryID int<br/>
Priority tinyint<br/>
MessageText NVARCHAR(MAX)<br/></strong></p>

<p>I need a query that will return * for each row that has the highest priority within a Category.  For example, if I had the following data:</p>

<p><strong>MessageID, CategoryID, Priority, MessageText</strong><br/>
1, 100, 1, Error #1234 occurred<br/>
2, 100, 2, Error #243 occurred<br/>
3, 100, 3, Error #976 occurred<br/>
4, 200, 4, Error #194 occurred<br/>
5, 200, 1, Error #736 occurred<br/>
6, 300, 3, Error #54 occurred<br/>
7, 300, 2, Error #888 occurred<br/></p>

<p>then the result would be:</p>

<p><strong>MessageID, CategoryID, Priority, MessageText</strong><br/>
3, 100, 3, Error #976 occurred<br/>
4, 200, 4, Error #194 occurred<br/>
6, 300, 3, Error #54 occurred<br/></p>

<p>Notice that it returns one row per category, and that it is the row which had the highest priority for that Category.</p>

<p>Can anyone tell me how I can write this query?</p>
","<p>Verified:</p>

<pre><code>SELECT
    highest_priority_messages.*
FROM
(
    SELECT
    m.MessageID
    , m.CategoryID
    , m.Priority
    , m.MessageText
    , Rank() OVER 
        (PARTITION BY m.CategoryID ORDER BY m.Priority DESC) AS p_rank
    FROM [Message] m
    GROUP BY 
        m.CategoryID 
        , m.Priority
        , m.MessageID
        , m.MessageText
) highest_priority_messages
WHERE 
    p_rank = 1
</code></pre>
"
520,226460,0,5,sql,Semi-Tricky SQL Query,"<p>I am trying to write a query for SQL Server 2005 but I can't figure out how to do it.  I have a table with the following fields:</p>

<p><strong>MessageID int<br/>
CategoryID int<br/>
Priority tinyint<br/>
MessageText NVARCHAR(MAX)<br/></strong></p>

<p>I need a query that will return * for each row that has the highest priority within a Category.  For example, if I had the following data:</p>

<p><strong>MessageID, CategoryID, Priority, MessageText</strong><br/>
1, 100, 1, Error #1234 occurred<br/>
2, 100, 2, Error #243 occurred<br/>
3, 100, 3, Error #976 occurred<br/>
4, 200, 4, Error #194 occurred<br/>
5, 200, 1, Error #736 occurred<br/>
6, 300, 3, Error #54 occurred<br/>
7, 300, 2, Error #888 occurred<br/></p>

<p>then the result would be:</p>

<p><strong>MessageID, CategoryID, Priority, MessageText</strong><br/>
3, 100, 3, Error #976 occurred<br/>
4, 200, 4, Error #194 occurred<br/>
6, 300, 3, Error #54 occurred<br/></p>

<p>Notice that it returns one row per category, and that it is the row which had the highest priority for that Category.</p>

<p>Can anyone tell me how I can write this query?</p>
","<pre><code>SELECT
    Messages.MessageID
    , Messages.CategoryID
    , Messages.Priority
    , Messages. MessageText
FROM
    Messages
    INNER JOIN
    (
    	SELECT 
    		CategoryID
    		, MAX(Priority) AS Priority
    	FROM 
    		Messages
    	GROUP BY
    		CategoryID
    ) AS MaxResults
    ON
    	(
    		Messages.CategoryID = MaxResults.CategoryID
    		AND
    		Messages.Priority = MaxResults.Priority
    	)
</code></pre>

<p>It looks like this is basically the same answer given above... with the same Caveat.</p>

<p>Although this one will work right off the bat.</p>
"
524,226460,0,5,sql,Semi-Tricky SQL Query,"<p>I am trying to write a query for SQL Server 2005 but I can't figure out how to do it.  I have a table with the following fields:</p>

<p><strong>MessageID int<br/>
CategoryID int<br/>
Priority tinyint<br/>
MessageText NVARCHAR(MAX)<br/></strong></p>

<p>I need a query that will return * for each row that has the highest priority within a Category.  For example, if I had the following data:</p>

<p><strong>MessageID, CategoryID, Priority, MessageText</strong><br/>
1, 100, 1, Error #1234 occurred<br/>
2, 100, 2, Error #243 occurred<br/>
3, 100, 3, Error #976 occurred<br/>
4, 200, 4, Error #194 occurred<br/>
5, 200, 1, Error #736 occurred<br/>
6, 300, 3, Error #54 occurred<br/>
7, 300, 2, Error #888 occurred<br/></p>

<p>then the result would be:</p>

<p><strong>MessageID, CategoryID, Priority, MessageText</strong><br/>
3, 100, 3, Error #976 occurred<br/>
4, 200, 4, Error #194 occurred<br/>
6, 300, 3, Error #54 occurred<br/></p>

<p>Notice that it returns one row per category, and that it is the row which had the highest priority for that Category.</p>

<p>Can anyone tell me how I can write this query?</p>
","<p>I'm not quite high enough rank (yet) to post a comment, so I'd like to add to cfeduke's solution:</p>

<pre><code>SELECT
    highest_priority_messages.*
FROM
(
    SELECT
    m.MessageID
    , m.CategoryID
    , m.Priority
    , m.MessageText
    , Rank() OVER 
        (PARTITION BY m.CategoryID ORDER BY m.Priority DESC, m.MessageID DESC) AS p_rank
    FROM [Message] m
    GROUP BY 
        m.CategoryID 
        , m.Priority
        , m.MessageID
        , m.MessageText
) highest_priority_messages
WHERE 
    p_rank = 1
</code></pre>

<p>If you add another CategoryID 100 Message with Priority 3, the original solution would bring back 2 rows, by adding another order condition we eliminate the chance of two items ranking the same.</p>

<p>Here's a copy of the row I inserted to test this.</p>

<pre><code>insert into [Message] (MessageID, CategoryID, Priority, MessageText)
select 8, 100, 3, 'Error #976-2 occurred'
</code></pre>
"
562,252230,2,4,sql,Stored procedures or inline queries?,"<p>First of all there is a <a href=""http://stackoverflow.com/questions/59880/are-stored-procedures-more-efficient-in-general-than-inline-statements-on-moder"">partial question</a> regarding this, but it is not exactly what I'm asking, so, bear with me and go for it.</p>

<p>My question is, after looking at what <a href=""http://subsonicproject.com/"" rel=""nofollow"">SubSonic</a> does and the excellent videos from Rob Connery I need to ask: <strong>Shall we use a tool like this and do Inline queries or</strong> shall we do the queries <strong>using</strong> a call to the <strong>stored procedure?</strong></p>

<p>I don't want to minimize any work from Rob (which I think it's amazing) but I just want your opinion on this cause I need to start a new project and I'm in the middle of the line; shall I use SubSonic (or other like tool, like NHibernate) or I just continue my method that is always call a stored procedure even if it's a simple as</p>

<pre><code>Select this, that from myTable where myStuff = StackOverflow;
</code></pre>
","<p>It doesn't need to be one or the other. If it's a simple query, use the SubSonic query tool. If it's more complex, use a stored procedure and load up a collection or create a dataset from the results.</p>

<p>See here: <a href=""http://stackoverflow.com/questions/15142/what-are-the-pros-and-cons-to-keeping-sql-in-stored-procs-versus-code"">http://stackoverflow.com/questions/15142/what-are-the-pros-and-cons-to-keeping-sql-in-stored-procs-versus-code</a> and here <a href=""http://stackoverflow.com/questions/228175/subsonic-and-stored-procedures"">http://stackoverflow.com/questions/228175/subsonic-and-stored-procedures</a></p>
"
563,252230,2,4,sql,Stored procedures or inline queries?,"<p>First of all there is a <a href=""http://stackoverflow.com/questions/59880/are-stored-procedures-more-efficient-in-general-than-inline-statements-on-moder"">partial question</a> regarding this, but it is not exactly what I'm asking, so, bear with me and go for it.</p>

<p>My question is, after looking at what <a href=""http://subsonicproject.com/"" rel=""nofollow"">SubSonic</a> does and the excellent videos from Rob Connery I need to ask: <strong>Shall we use a tool like this and do Inline queries or</strong> shall we do the queries <strong>using</strong> a call to the <strong>stored procedure?</strong></p>

<p>I don't want to minimize any work from Rob (which I think it's amazing) but I just want your opinion on this cause I need to start a new project and I'm in the middle of the line; shall I use SubSonic (or other like tool, like NHibernate) or I just continue my method that is always call a stored procedure even if it's a simple as</p>

<pre><code>Select this, that from myTable where myStuff = StackOverflow;
</code></pre>
","<p>See answers <a href=""http://stackoverflow.com/questions/15142/what-are-the-pros-and-cons-to-keeping-sql-in-stored-procs-versus-code"">here</a> and <a href=""http://stackoverflow.com/questions/59880/are-stored-procedures-more-efficient-in-general-than-inline-statements-on-moder"">here</a>.  I use sprocs whenever I can, except when red tape means it takes a week to make it into the database.</p>
"
564,252230,1,4,sql,Stored procedures or inline queries?,"<p>First of all there is a <a href=""http://stackoverflow.com/questions/59880/are-stored-procedures-more-efficient-in-general-than-inline-statements-on-moder"">partial question</a> regarding this, but it is not exactly what I'm asking, so, bear with me and go for it.</p>

<p>My question is, after looking at what <a href=""http://subsonicproject.com/"" rel=""nofollow"">SubSonic</a> does and the excellent videos from Rob Connery I need to ask: <strong>Shall we use a tool like this and do Inline queries or</strong> shall we do the queries <strong>using</strong> a call to the <strong>stored procedure?</strong></p>

<p>I don't want to minimize any work from Rob (which I think it's amazing) but I just want your opinion on this cause I need to start a new project and I'm in the middle of the line; shall I use SubSonic (or other like tool, like NHibernate) or I just continue my method that is always call a stored procedure even if it's a simple as</p>

<pre><code>Select this, that from myTable where myStuff = StackOverflow;
</code></pre>
","<p>I wouldn't personally follow rigid rules.  Certainly during the development stages, you want to be able to quickly change your queries so I would inline them.</p>

<p>Later on, I would move to stored procedures because they offer the following two advantages.  I'm sure there are more but these two win me over.</p>

<p>1/ Stored procedures group the data and the code for manipulating/extracting that data at one point.  This makes the life of your DBA a lot easier (assuming your app is sizable enough to warrant a DBA) since they can optimize based on known factors.</p>

<p>One of the big bugbears of a DBA is ad-hoc queries (especially by clowns who don't know what a full table scan is).  DBAs prefer to have nice consistent queries that they can tune the database to.</p>

<p>2/ Stored procedures can contain logic which is best left in the database.  I've seen stored procs in DB2/z with many dozens of lines but all the client has to code is a single line like ""give me that list"".</p>

<p>Because the logic for ""that list"" is stored in the database, the DBAs can modify how it's stored and extracted at will <strong>without</strong> compromising or changing the client code.  This is similar to encapsulation that made object-orientd languages 'cleaner' than what came before.</p>
"
403,185110,4,4,sql,SQL Date Range Split,"<p>Can you please let me know the SQL to split date ranges when they overlap?</p>

<p>Data (sample data with a date range and possibly other columns):</p>

<pre><code>    Col1 FromDate ToDate
 1. 1    1/1/2008 31/12/2010
 2. 1    1/1/2009 31/12/2012
 3. 1    1/1/2009 31/12/2014
</code></pre>

<p>Output:</p>

<pre><code>   Col1  From Date ToDate
1. 1     1/1/2008 31/12/2008 (from row 1 above)
2. 1     1/1/2009 31/12/2010 (from rows 1,2 and 3 above)
3. 1     1/1/2011 31/12/2012 (from rows 2 and 3 above)
4. 1     1/1/2013 31/12/2014 (from row 3 above)
</code></pre>
","<p>This should do the trick (MySQL dialect, but easily adaptable)</p>

<p>Initial setup</p>

<pre><code>SQL query: SELECT * FROM `test` LIMIT 0, 30 ;
Rows: 3
start       end
2008-01-01  2010-12-31
2009-01-01  2012-12-31
2009-01-01  2014-12-31
</code></pre>

<p>Query</p>

<pre><code>SELECT 
  `start` , min( `end` )
FROM (
  SELECT t1.start, t2.end
  FROM test t1, test t2
  WHERE t1.start &lt; t2.end
  UNION
  SELECT t1.end + INTERVAL 1 DAY , t2.end
  FROM test t1, test t2
  WHERE t1.end + INTERVAL 1 DAY &lt; t2.end
  UNION
  SELECT t1.start, t2.start - INTERVAL 1 DAY
  FROM test t1, test t2
  WHERE t1.start &lt; t2.start - INTERVAL 1 DAY
) allRanges
GROUP BY `start`
</code></pre>

<p>Result</p>

<pre><code>start       min( `end` )
2008-01-01  2008-12-31
2009-01-01  2010-12-31
2011-01-01  2012-12-31
2013-01-01  2014-12-31
</code></pre>
"
404,185110,2,4,sql,SQL Date Range Split,"<p>Can you please let me know the SQL to split date ranges when they overlap?</p>

<p>Data (sample data with a date range and possibly other columns):</p>

<pre><code>    Col1 FromDate ToDate
 1. 1    1/1/2008 31/12/2010
 2. 1    1/1/2009 31/12/2012
 3. 1    1/1/2009 31/12/2014
</code></pre>

<p>Output:</p>

<pre><code>   Col1  From Date ToDate
1. 1     1/1/2008 31/12/2008 (from row 1 above)
2. 1     1/1/2009 31/12/2010 (from rows 1,2 and 3 above)
3. 1     1/1/2011 31/12/2012 (from rows 2 and 3 above)
4. 1     1/1/2013 31/12/2014 (from row 3 above)
</code></pre>
","<p>Skliwz's answer adapted for SQL Server:</p>

<pre><code>DECLARE @DateTest TABLE 
(
    FromDate datetime,
    ToDate datetime 
)

insert into @DateTest (FromDate, ToDate)
(
select cast('1/1/2008' as datetime), cast('12/31/2010' as datetime)
union
select cast('1/1/2009' as datetime), cast('12/31/2012' as datetime)
union
select cast('1/1/2009' as datetime), cast('12/31/2014' as datetime)
)

SELECT 
  FromDate , min(ToDate)
FROM (
  SELECT t1.FromDate, t2.ToDate
  FROM 
    @DateTest t1, 
    @DateTest t2
  WHERE t1.FromDate &lt; t2.ToDate

  UNION

  SELECT dateadd(DAY, 1, t1.ToDate), t2.ToDate
  FROM 
    @DateTest t1, 
    @DateTest t2
  WHERE dateadd(DAY, 1, t1.ToDate) &lt; t2.ToDate
) allRanges
group by FromDate
</code></pre>
"
199,89820,2,4,sql,How to reference a custom field in SQL,"<p>I am using mssql and am having trouble using a subquery. The real query is quite complicated, but it has the same structure as this:</p>

<pre><code>select 
  customerName, 
  customerId,
  (
    select count(*) 
    from Purchases 
    where Purchases.customerId=customerData.customerId
  ) as numberTransactions
from customerData
</code></pre>

<p>And what I want to do is order the table by the number of transactions, but when I use</p>

<pre><code>order by numberTransactions
</code></pre>

<p>It tells me there is no such field. Is it possible to do this? Should I be using some sort of special keyword, such as <code>this</code>, or <code>self</code>?</p>
","<p><strong><em>There are better ways to get your result but just from your example query this will work on SQL2000 or better.</em></strong></p>

<p>If you wrap your alias in single ticks <strong>'numberTransactions'</strong> and then call <strong>ORDER BY 'numberTransactions'</strong></p>

<pre><code>select
  customerName, 
  customerId,
  (
    select count(*) 
    from Purchases 
    where Purchases.customerId=customerData.customerId
  ) as 'numberTransactions'
from customerData
ORDER BY 'numberTransactions'
</code></pre>
"
1122,515690,4,4,sql,SQL query to select unreferenced rows,"<p>I'm having a brain-dead moment... I have two tables described by:</p>

<pre><code>CREATE TABLE table_a (
    id             INTEGER          PRIMARY KEY AUTO_INCREMENT,
    name           VARCHAR(255)     NOT NULL
    UNIQUE (name))

CREATE TABLE table_b (
    id             INTEGER          PRIMARY KEY AUTO_INCREMENT,
    a_key          INTEGER          NOT NULL,
    other_stuff    VARCHAR(255)     NOT NULL,
    FOREIGN KEY(a_key)  REFERENCES table_a(id)
         ON DELETE CASCADE)
</code></pre>

<p>How can I select all rows from table_a that do not have an entry in table_b.a_key?</p>
","<p>Naively, you can use a NOT EXISTS subquery:</p>

<pre><code>SELECT A.*
FROM table_a A
WHERE NOT EXISTS (
  SELECT 1
  FROM table_b B
  WHERE B.a_key = A.id
)
</code></pre>

<p>You can also try an outer join. But they'll usually optimize to the same query internally.</p>
"
1123,515690,4,4,sql,SQL query to select unreferenced rows,"<p>I'm having a brain-dead moment... I have two tables described by:</p>

<pre><code>CREATE TABLE table_a (
    id             INTEGER          PRIMARY KEY AUTO_INCREMENT,
    name           VARCHAR(255)     NOT NULL
    UNIQUE (name))

CREATE TABLE table_b (
    id             INTEGER          PRIMARY KEY AUTO_INCREMENT,
    a_key          INTEGER          NOT NULL,
    other_stuff    VARCHAR(255)     NOT NULL,
    FOREIGN KEY(a_key)  REFERENCES table_a(id)
         ON DELETE CASCADE)
</code></pre>

<p>How can I select all rows from table_a that do not have an entry in table_b.a_key?</p>
","<pre><code>SELECT 
table_a.* 
FROM table_a 
LEFT JOIN table_b 
ON table_a.id = table_b.a_key 
WHERE b.id IS NULL;
</code></pre>

<p>This does a JOIN on table_a and table_b and where the JOIN finds no join result for table_b, it prints the corresponding row entry for table_a.</p>
"
198,89820,6,4,sql,How to reference a custom field in SQL,"<p>I am using mssql and am having trouble using a subquery. The real query is quite complicated, but it has the same structure as this:</p>

<pre><code>select 
  customerName, 
  customerId,
  (
    select count(*) 
    from Purchases 
    where Purchases.customerId=customerData.customerId
  ) as numberTransactions
from customerData
</code></pre>

<p>And what I want to do is order the table by the number of transactions, but when I use</p>

<pre><code>order by numberTransactions
</code></pre>

<p>It tells me there is no such field. Is it possible to do this? Should I be using some sort of special keyword, such as <code>this</code>, or <code>self</code>?</p>
","<p>Sometimes you have to wrestle with SQL's syntax (expected scope of clauses)</p>

<pre><code>SELECT *
FROM
(
select
  customerName,
  customerId,
  (
    select count(*)
    from Purchases
    where Purchases.customerId=customerData.customerId
  ) as numberTransactions
from customerData
) as sub
order by sub.numberTransactions
</code></pre>

<p>Also, a solution using JOIN is correct.  Look at the query plan, SQL Server should give identical plans for both solutions.</p>
"
197,89820,0,4,sql,How to reference a custom field in SQL,"<p>I am using mssql and am having trouble using a subquery. The real query is quite complicated, but it has the same structure as this:</p>

<pre><code>select 
  customerName, 
  customerId,
  (
    select count(*) 
    from Purchases 
    where Purchases.customerId=customerData.customerId
  ) as numberTransactions
from customerData
</code></pre>

<p>And what I want to do is order the table by the number of transactions, but when I use</p>

<pre><code>order by numberTransactions
</code></pre>

<p>It tells me there is no such field. Is it possible to do this? Should I be using some sort of special keyword, such as <code>this</code>, or <code>self</code>?</p>
","<p>I think you can do this in SQL2005, but not SQL2000. </p>
"
644,279610,1,4,sql,Create DB2 History Table Trigger,"<p>I want to create a history table to track field changes across a number of tables in DB2. </p>

<p>I know history is usually done with copying an entire table's structure and giving it a suffixed name (e.g. user --> user_history). Then you can use a pretty simple trigger to copy the old record into the history table on an UPDATE.</p>

<p>However, for my application this would use too much space. It doesn't seem like a good idea (to me at least) to copy an entire record to another table every time a field changes. So I thought I could have a generic 'history' table which would track individual field changes:</p>

<pre><code>CREATE TABLE history
(
    history_id LONG GENERATED ALWAYS AS IDENTITY,
    record_id INTEGER NOT NULL,
    table_name VARCHAR(32) NOT NULL,
    field_name VARCHAR(64) NOT NULL,
    field_value VARCHAR(1024),
    change_time TIMESTAMP,
    PRIMARY KEY (history_id)
);
</code></pre>

<p>OK, so every table that I want to track has a single, auto-generated id field as the primary key, which would be put into the 'record_id' field. And the maximum VARCHAR size in the tables is 1024. Obviously if a non-VARCHAR field changes, it would have to be converted into a VARCHAR before inserting the record into the history table.</p>

<p>Now, this could be a completely retarded way to do things (hey, let me know why if it is), but I think it it's a good way of tracking changes that need to be pulled up rarely and need to be stored for a significant amount of time.  </p>

<p>Anyway, I need help with writing the trigger to add records to the history table on an update. Let's for example take a hypothetical user table:</p>

<pre><code>CREATE TABLE user
(
   user_id INTEGER GENERATED ALWAYS AS IDENTITY,
   username VARCHAR(32) NOT NULL,
   first_name VARCHAR(64) NOT NULL,
   last_name VARCHAR(64) NOT NULL,
   email_address VARCHAR(256) NOT NULL
   PRIMARY KEY(user_id)
);
</code></pre>

<p>So, can anyone help me with a trigger on an update of the user table to insert the changes into the history table? My guess is that some procedural SQL will need to be used to loop through the fields in the old record, compare them with the fields in the new record and if they don't match, then add a new entry into the history table. </p>

<p>It'd be preferable to use the same trigger action SQL for every table, regardless of its fields, if it's possible.</p>

<p>Thanks!</p>
","<p>I don't think this is a good idea, as you generate even more overhead per value  with a big table where more than one value changes. But that depends on your application.</p>

<p>Furthermore you should consider the practical value of such a history table. You have to get a lot of rows together to even get a glimpse of context to the value changed and it requeries you to code another application that does just this complex history logic for an enduser. And for an DB-admin it would be cumbersome to restore values out of the history.</p>

<p>it may sound a bit harsh, but that is not the intend. An experienced programmer in our shop had a simmilar idea through table journaling. He got it up and running, but it ate diskspace like there's no tomorrow. </p>

<p>Just think about what your history table should really accomplish.</p>
"
1124,515690,1,4,sql,SQL query to select unreferenced rows,"<p>I'm having a brain-dead moment... I have two tables described by:</p>

<pre><code>CREATE TABLE table_a (
    id             INTEGER          PRIMARY KEY AUTO_INCREMENT,
    name           VARCHAR(255)     NOT NULL
    UNIQUE (name))

CREATE TABLE table_b (
    id             INTEGER          PRIMARY KEY AUTO_INCREMENT,
    a_key          INTEGER          NOT NULL,
    other_stuff    VARCHAR(255)     NOT NULL,
    FOREIGN KEY(a_key)  REFERENCES table_a(id)
         ON DELETE CASCADE)
</code></pre>

<p>How can I select all rows from table_a that do not have an entry in table_b.a_key?</p>
","<p>If it is SQL server 2005+ you could try EXCEPT</p>

<pre><code>SELECT id
FROM table_a
EXCEPT
SELECT a_key
FROM table_b;
</code></pre>
"
1126,515690,0,4,sql,SQL query to select unreferenced rows,"<p>I'm having a brain-dead moment... I have two tables described by:</p>

<pre><code>CREATE TABLE table_a (
    id             INTEGER          PRIMARY KEY AUTO_INCREMENT,
    name           VARCHAR(255)     NOT NULL
    UNIQUE (name))

CREATE TABLE table_b (
    id             INTEGER          PRIMARY KEY AUTO_INCREMENT,
    a_key          INTEGER          NOT NULL,
    other_stuff    VARCHAR(255)     NOT NULL,
    FOREIGN KEY(a_key)  REFERENCES table_a(id)
         ON DELETE CASCADE)
</code></pre>

<p>How can I select all rows from table_a that do not have an entry in table_b.a_key?</p>
","<pre><code>select a.*
from table_a a
where a.id not in (select b.a_key from table_b b where b.a_key = a.id)
</code></pre>
"
196,89820,0,4,sql,How to reference a custom field in SQL,"<p>I am using mssql and am having trouble using a subquery. The real query is quite complicated, but it has the same structure as this:</p>

<pre><code>select 
  customerName, 
  customerId,
  (
    select count(*) 
    from Purchases 
    where Purchases.customerId=customerData.customerId
  ) as numberTransactions
from customerData
</code></pre>

<p>And what I want to do is order the table by the number of transactions, but when I use</p>

<pre><code>order by numberTransactions
</code></pre>

<p>It tells me there is no such field. Is it possible to do this? Should I be using some sort of special keyword, such as <code>this</code>, or <code>self</code>?</p>
","<p>The same thing could be achieved by using <code>GROUP BY</code> and a <code>JOIN</code>, and you'll be rid of the subquery. This might be faster too.</p>
"
1132,522710,2,4,sql,How to fix: Dynamic SQL generation for the DeleteCommand is not supported against a SelectCommand that does not return any key column information,"<p>My code works. After I copy about 10 tables I get an error. <code>Dynamic SQL generation for the DeleteCommand is not supported against a SelectCommand that does not return any key column information.</code> Okay, I know I need to generate a primary key. But why can I copy 10 or so tables over, and THEN I get the error. Does each row have to return a primary key? If a row doesn't have a primary key, how do I generate one?</p>

<p>Here is my code:</p>

<pre><code>using System;
using System.Collections.Generic;
using System.Data;
using System.Data.OleDb;
using System.IO;
using System.Linq;
using System.Text;

namespace LCR_ShepherdStaffupdater_1._0
{
    public class DatabaseHandling
    {
        static DataTable datatableB = new DataTable();
        static DataTable datatableA = new DataTable();
        public static DataSet datasetA = new DataSet();
        public static DataSet datasetB = new DataSet();
        static OleDbDataAdapter adapterA = new OleDbDataAdapter();
        static OleDbDataAdapter adapterB = new OleDbDataAdapter();
        static string connectionstringA = ""Provider=Microsoft.Jet.OLEDB.4.0;"" + ""Data Source="" + Settings.getfilelocationA();
        static string connectionstringB = ""Provider=Microsoft.Jet.OLEDB.4.0;"" + ""Data Source="" + Settings.getfilelocationB();
        static OleDbConnection dataconnectionB = new OleDbConnection(connectionstringB);
        static OleDbConnection dataconnectionA = new OleDbConnection(connectionstringA);
        static DataTable tableListA;
        static DataTable tableListB;

        static public void addTableA(string table, bool addtoDataSet)
        {
            dataconnectionA.Open();
            datatableA = new DataTable(table);
            try
            {
                OleDbCommand commandselectA = new OleDbCommand(""SELECT * FROM ["" + table + ""]"", dataconnectionA);
                adapterA.SelectCommand = commandselectA;
                adapterA.Fill(datatableA);
            }
            catch
            {
                Logging.updateLog(""Error: Tried to get "" + table + "" from DataSetA. Table doesn't exist!"", true, false, false);
            }

            if (addtoDataSet == true)
            {
                datasetA.Tables.Add(datatableA);
                Logging.updateLog(""Added DataTableA: "" + datatableA.TableName.ToString() + "" Successfully!"", false, false, false);
            }

            dataconnectionA.Close();
        }

        static public void addTableB(string table, bool addtoDataSet)
        {
            dataconnectionB.Open();
            datatableB = new DataTable(table);

            try
            {
                OleDbCommand commandselectB = new OleDbCommand(""SELECT * FROM ["" + table + ""]"", dataconnectionB);
                adapterB.SelectCommand = commandselectB;
                adapterB.Fill(datatableB);
            }
            catch
            {
                Logging.updateLog(""Error: Tried to get "" + table + "" from DataSetB. Table doesn't exist!"", true, false, false);
            }



            if (addtoDataSet == true)
            {
                datasetB.Tables.Add(datatableB);
                Logging.updateLog(""Added DataTableB: "" + datatableB.TableName.ToString() + "" Successfully!"", false, false, false);
            }

            dataconnectionB.Close();
        }

        static public string[] getTablesA(string connectionString)
        {
            dataconnectionA.Open();
            tableListA = dataconnectionA.GetOleDbSchemaTable(OleDbSchemaGuid.Tables, new Object[] { null, null, null, ""TABLE"" });
            string[] stringTableListA = new string[tableListA.Rows.Count];

            for (int i = 0; i &lt; tableListA.Rows.Count; i++)
            {
                stringTableListA[i] = tableListA.Rows[i].ItemArray[2].ToString();
            }
            dataconnectionA.Close();
            return stringTableListA;
        }

        static public string[] getTablesB(string connectionString)
        {
            dataconnectionB.Open();
            tableListB = dataconnectionB.GetOleDbSchemaTable(OleDbSchemaGuid.Tables, new Object[] { null, null, null, ""TABLE"" });
            string[] stringTableListB = new string[tableListB.Rows.Count];

            for (int i = 0; i &lt; tableListB.Rows.Count; i++)
            {
                stringTableListB[i] = tableListB.Rows[i].ItemArray[2].ToString();
            }
            dataconnectionB.Close();
            return stringTableListB;
        }

        static public void createDataSet()
        {

            string[] tempA = getTablesA(connectionstringA);
            string[] tempB = getTablesB(connectionstringB);
            int percentage = 0;
            int maximum = (tempA.Length + tempB.Length);

            Logging.updateNotice(""Loading Tables..."");
            Logging.updateLog(""Started Loading File A"", false, false, true);
            for (int i = 0; i &lt; tempA.Length ; i++)
            {
                if (!datasetA.Tables.Contains(tempA[i]))
                {
                    addTableA(tempA[i], true);
                    percentage++;
                    Logging.loadStatus(percentage, maximum);
                }
                else
                {
                    datasetA.Tables.Remove(tempA[i]);
                    addTableA(tempA[i], true);
                    percentage++;
                    Logging.loadStatus(percentage, maximum);
                }
            }
            Logging.updateLog(""Finished loading File A"", false, false, true);
            Logging.updateLog(""Started loading File B"", false, false, true);
            for (int i = 0; i &lt; tempB.Length ; i++)
            {
                if (!datasetB.Tables.Contains(tempB[i]))
                {
                    addTableB(tempB[i], true);
                    percentage++;
                    Logging.loadStatus(percentage, maximum);
                }
                else
                {
                    datasetB.Tables.Remove(tempB[i]);
                    addTableB(tempB[i], true);
                    percentage++;
                    Logging.loadStatus(percentage, maximum);
                }
            }
            Logging.updateLog(""Finished loading File B"", false, false, true);
            Logging.updateLog(""Both files loaded into memory successfully"", false, true, false);


        }

        static public DataTable getDataTableA()
        {
            datatableA = datasetA.Tables[Settings.textA];

            return datatableA;
        }
        static public DataTable getDataTableB()
        {
            datatableB = datasetB.Tables[Settings.textB];
            return datatableB;
        }

        static public DataSet getDataSetA()
        {
            return datasetA;
        }

        static public DataSet getDataSetB()
        {
            return datasetB;
        }

        static public void InitiateCopyProcessA()
        {
            DataSet tablesA;
            tablesA = DatabaseHandling.getDataSetA();
            int percentage = 0;
            int maximum = (tablesA.Tables.Count);

                foreach (DataTable table in tablesA.Tables)
                {
                    Logging.loadStatus(percentage, maximum);
                    OverwriteTable(table, table.TableName);
                    Logging.updateLog(""Copied "" + table.TableName + "" successfully."", false, true, false);
                    percentage++;
                }

        }

        static void OverwriteTable(DataTable sourceTable, string tableName)
        {
            using (var destConn = new OleDbConnection(connectionstringA))
            using (var destCmd = new OleDbCommand(tableName, destConn) { CommandType = CommandType.TableDirect })
            using (var destDA = new OleDbDataAdapter(destCmd))

            {
                // Since we're using a single table, we can have the CommandBuilder
                // generate the appropriate INSERT and DELETE SQL statements
                using (var destCmdB = new OleDbCommandBuilder(destDA))
                {
                    destCmdB.QuotePrefix = ""[""; // quote reserved column names
                    destCmdB.QuoteSuffix = ""]"";
                    destDA.DeleteCommand = destCmdB.GetDeleteCommand();
                    destDA.InsertCommand = destCmdB.GetInsertCommand();

                    // Get rows from destination, and delete them
                    var destTable = new DataTable();
                    destDA.Fill(destTable);
                    foreach (DataRow dr in destTable.Rows)
                    {
                        dr.Delete();
                    }

                     destDA.Update(destTable);

                    // Set rows from source as Added, so the DataAdapter will insert them
                    foreach (DataRow dr in sourceTable.Rows)
                    {
                        dr.SetAdded();
                    }
                    destDA.Update(sourceTable);
                }
            }
        }



        }          
    }
</code></pre>

<p>Google was not very helpful to me on this. Please provide a coding example.</p>
","<p>No coding example is really going to work.  You have to make a determination from the table as to what is the unique identifier for the table.  If there is no primary key (or at the least, a unique index), then you are out of luck.</p>

<p>The only way around this is to create a dynamic command yourself, which compares every value in the table to the record you want to delete.  If they are the same, then delete them.</p>

<p>However, you run the risk of deleting multiple rows from the table, since there might be multiple rows in the table with the same values.</p>
"
766,349540,3,4,sql,Sniffing queries to SQL Server,"<p>Is there a way to sniff SQL queries sent to a SQL Server db on any level (above transport level)?   Perhaps there's some kind of a tracer in ASP.NET or built-in log in SQL Server ? </p>
","<p>The tool your looking for is <a href=""http://msdn.microsoft.com/en-us/library/ms181091.aspx"" rel=""nofollow"">SQL Server Profiler</a>, learn to use it and to love it.</p>

<p>Try starting with a filter on ApplicationName and/or HostName for your IIS server running your ASP.NET application. Profiler can get quite chatty.</p>
"
645,279610,1,4,sql,Create DB2 History Table Trigger,"<p>I want to create a history table to track field changes across a number of tables in DB2. </p>

<p>I know history is usually done with copying an entire table's structure and giving it a suffixed name (e.g. user --> user_history). Then you can use a pretty simple trigger to copy the old record into the history table on an UPDATE.</p>

<p>However, for my application this would use too much space. It doesn't seem like a good idea (to me at least) to copy an entire record to another table every time a field changes. So I thought I could have a generic 'history' table which would track individual field changes:</p>

<pre><code>CREATE TABLE history
(
    history_id LONG GENERATED ALWAYS AS IDENTITY,
    record_id INTEGER NOT NULL,
    table_name VARCHAR(32) NOT NULL,
    field_name VARCHAR(64) NOT NULL,
    field_value VARCHAR(1024),
    change_time TIMESTAMP,
    PRIMARY KEY (history_id)
);
</code></pre>

<p>OK, so every table that I want to track has a single, auto-generated id field as the primary key, which would be put into the 'record_id' field. And the maximum VARCHAR size in the tables is 1024. Obviously if a non-VARCHAR field changes, it would have to be converted into a VARCHAR before inserting the record into the history table.</p>

<p>Now, this could be a completely retarded way to do things (hey, let me know why if it is), but I think it it's a good way of tracking changes that need to be pulled up rarely and need to be stored for a significant amount of time.  </p>

<p>Anyway, I need help with writing the trigger to add records to the history table on an update. Let's for example take a hypothetical user table:</p>

<pre><code>CREATE TABLE user
(
   user_id INTEGER GENERATED ALWAYS AS IDENTITY,
   username VARCHAR(32) NOT NULL,
   first_name VARCHAR(64) NOT NULL,
   last_name VARCHAR(64) NOT NULL,
   email_address VARCHAR(256) NOT NULL
   PRIMARY KEY(user_id)
);
</code></pre>

<p>So, can anyone help me with a trigger on an update of the user table to insert the changes into the history table? My guess is that some procedural SQL will need to be used to loop through the fields in the old record, compare them with the fields in the new record and if they don't match, then add a new entry into the history table. </p>

<p>It'd be preferable to use the same trigger action SQL for every table, regardless of its fields, if it's possible.</p>

<p>Thanks!</p>
","<p>Have you considered doing this as a two step process?  Implement a simple trigger that records the original and changed version of the entire row.  Then write a separate program that runs once a day to extract the changed fields as you describe above.</p>

<p>This makes the trigger simpler, safer, faster and you have more choices for how to implement the post processing step.</p>
"
646,279610,1,4,sql,Create DB2 History Table Trigger,"<p>I want to create a history table to track field changes across a number of tables in DB2. </p>

<p>I know history is usually done with copying an entire table's structure and giving it a suffixed name (e.g. user --> user_history). Then you can use a pretty simple trigger to copy the old record into the history table on an UPDATE.</p>

<p>However, for my application this would use too much space. It doesn't seem like a good idea (to me at least) to copy an entire record to another table every time a field changes. So I thought I could have a generic 'history' table which would track individual field changes:</p>

<pre><code>CREATE TABLE history
(
    history_id LONG GENERATED ALWAYS AS IDENTITY,
    record_id INTEGER NOT NULL,
    table_name VARCHAR(32) NOT NULL,
    field_name VARCHAR(64) NOT NULL,
    field_value VARCHAR(1024),
    change_time TIMESTAMP,
    PRIMARY KEY (history_id)
);
</code></pre>

<p>OK, so every table that I want to track has a single, auto-generated id field as the primary key, which would be put into the 'record_id' field. And the maximum VARCHAR size in the tables is 1024. Obviously if a non-VARCHAR field changes, it would have to be converted into a VARCHAR before inserting the record into the history table.</p>

<p>Now, this could be a completely retarded way to do things (hey, let me know why if it is), but I think it it's a good way of tracking changes that need to be pulled up rarely and need to be stored for a significant amount of time.  </p>

<p>Anyway, I need help with writing the trigger to add records to the history table on an update. Let's for example take a hypothetical user table:</p>

<pre><code>CREATE TABLE user
(
   user_id INTEGER GENERATED ALWAYS AS IDENTITY,
   username VARCHAR(32) NOT NULL,
   first_name VARCHAR(64) NOT NULL,
   last_name VARCHAR(64) NOT NULL,
   email_address VARCHAR(256) NOT NULL
   PRIMARY KEY(user_id)
);
</code></pre>

<p>So, can anyone help me with a trigger on an update of the user table to insert the changes into the history table? My guess is that some procedural SQL will need to be used to loop through the fields in the old record, compare them with the fields in the new record and if they don't match, then add a new entry into the history table. </p>

<p>It'd be preferable to use the same trigger action SQL for every table, regardless of its fields, if it's possible.</p>

<p>Thanks!</p>
","<p>We do something similar on our SQL Server database, but the audit tables are for each indvidual table audited (one central table would be huge as our database is many many gigabytes in size)</p>

<p>One thing you need to do is make sure you also record who made the change. You should also record the old and new value together (makes it easier to put data back if you need to) and the change type (insert, update, delete). You don't mention recording deletes from the table, but we find those the some of the  things we most frequently use the table for.</p>

<p>We use dynamic SQl to generate the code to create the audit tables (by using the table that stores the system information) and all audit tables have the exact same structure (makes is easier to get data back out).</p>

<p>When you create the code to store the data in your history table, create the code as well to restore the data if need be. This will save tons of time down the road when something needs to be restored and you are under pressure from senior management to get it done now.</p>

<p>Now I don't know if you were planning to be able to restore data from your history table, but once you have once, I can guarantee that management will want it used that way.</p>
"
647,279610,1,4,sql,Create DB2 History Table Trigger,"<p>I want to create a history table to track field changes across a number of tables in DB2. </p>

<p>I know history is usually done with copying an entire table's structure and giving it a suffixed name (e.g. user --> user_history). Then you can use a pretty simple trigger to copy the old record into the history table on an UPDATE.</p>

<p>However, for my application this would use too much space. It doesn't seem like a good idea (to me at least) to copy an entire record to another table every time a field changes. So I thought I could have a generic 'history' table which would track individual field changes:</p>

<pre><code>CREATE TABLE history
(
    history_id LONG GENERATED ALWAYS AS IDENTITY,
    record_id INTEGER NOT NULL,
    table_name VARCHAR(32) NOT NULL,
    field_name VARCHAR(64) NOT NULL,
    field_value VARCHAR(1024),
    change_time TIMESTAMP,
    PRIMARY KEY (history_id)
);
</code></pre>

<p>OK, so every table that I want to track has a single, auto-generated id field as the primary key, which would be put into the 'record_id' field. And the maximum VARCHAR size in the tables is 1024. Obviously if a non-VARCHAR field changes, it would have to be converted into a VARCHAR before inserting the record into the history table.</p>

<p>Now, this could be a completely retarded way to do things (hey, let me know why if it is), but I think it it's a good way of tracking changes that need to be pulled up rarely and need to be stored for a significant amount of time.  </p>

<p>Anyway, I need help with writing the trigger to add records to the history table on an update. Let's for example take a hypothetical user table:</p>

<pre><code>CREATE TABLE user
(
   user_id INTEGER GENERATED ALWAYS AS IDENTITY,
   username VARCHAR(32) NOT NULL,
   first_name VARCHAR(64) NOT NULL,
   last_name VARCHAR(64) NOT NULL,
   email_address VARCHAR(256) NOT NULL
   PRIMARY KEY(user_id)
);
</code></pre>

<p>So, can anyone help me with a trigger on an update of the user table to insert the changes into the history table? My guess is that some procedural SQL will need to be used to loop through the fields in the old record, compare them with the fields in the new record and if they don't match, then add a new entry into the history table. </p>

<p>It'd be preferable to use the same trigger action SQL for every table, regardless of its fields, if it's possible.</p>

<p>Thanks!</p>
","<pre><code>CREATE TABLE HIST.TB_HISTORY ( 
    HIST_ID     BIGINT GENERATED ALWAYS AS IDENTITY (START WITH 0, INCREMENT BY 1, NO CACHE) NOT NULL,
    HIST_COLUMNNAME     VARCHAR(128) NOT NULL,
    HIST_OLDVALUE       VARCHAR(255),
    HIST_NEWVALUE       VARCHAR(255),
    HIST_CHANGEDDATE    TIMESTAMP NOT NULL
    PRIMARY KEY(HIST_SAFTYNO)
)
GO


CREATE TRIGGER COMMON.TG_BANKCODE AFTER
UPDATE OF FRD_BANKCODE ON COMMON.TB_MAINTENANCE
REFERENCING OLD AS oldcol NEW AS newcol FOR EACH ROW MODE DB2SQL
WHEN(COALESCE(newcol.FRD_BANKCODE,'#null#') &lt;&gt; COALESCE(oldcol.FRD_BANKCODE,'#null#'))
BEGIN ATOMIC

    CALL FB_CHECKING.SP_FRAUDHISTORY_ON_DATACHANGED(
                newcol.FRD_FRAUDID,
                'FRD_BANKCODE',
                oldcol.FRD_BANKCODE,
                newcol.FRD_BANKCODE,
                newcol.FRD_UPDATEDBY
    );--

    INSERT INTO FB_CHECKING.TB_FRAUDMAINHISTORY(        
        HIST_COLUMNNAME, 
        HIST_OLDVALUE, 
        HIST_NEWVALUE, 
        HIST_CHANGEDDATE
</code></pre>
"
767,349540,0,4,sql,Sniffing queries to SQL Server,"<p>Is there a way to sniff SQL queries sent to a SQL Server db on any level (above transport level)?   Perhaps there's some kind of a tracer in ASP.NET or built-in log in SQL Server ? </p>
","<p>When you are in SQL Management Studio, open the query editor and set it to the correct database you would like to profile.
Run the following query: select db_id()
That will tell you your database id .<br />
Go to Tools > SQL Profile Manager.
Click file > New trace ...
Connect to your database server.<br />
On the window that shows up, click on the Events Selection tab.<br />
Click the Show All Columns checkbox.<br />
Then click Column Filters and choose DatabaseID in the Edit Filter box.  On the right, choose ""Equals"" and put in the database id from the query above.  Click OK and then Run.</p>
"
765,349540,8,4,sql,Sniffing queries to SQL Server,"<p>Is there a way to sniff SQL queries sent to a SQL Server db on any level (above transport level)?   Perhaps there's some kind of a tracer in ASP.NET or built-in log in SQL Server ? </p>
","<p>SQL Server Profiler perhaps?  This will pick up what queries are executed.  You can also get statistics, query plans and many other items of interest from this.</p>
"
558,248990,3,4,sql,Summarize aggregated data,"<p>I have a table like as follows:</p>

<pre>
SoftwareName    Count    Country
Project         15       Canada
Visio           12       Canada
Project         10       USA
Visio           5        USA
</pre>

<p>How do I query it to give me a summary like...</p>

<pre>
SoftwareName    Canada    USA    Total
Project         15        10     25
Visio           12        5      17
</pre>

<p>How to do in T-SQL?</p>
","<p>OK...Here's how to do it using PIVOT:</p>

<pre><code>SELECT Softwarename, Canada, USA, Canada + USA As TOTAL from SoftwareDemo 
PIVOT 
    (
     SUM([Count])
     FOR Country
     IN (Canada, USA)
    ) AS x


Softwarename                                       Canada      USA         TOTAL
-------------------------------------------------- ----------- ----------- -----------
Project                                            15          10          25
Visio                                              12          5           17

(2 row(s) affected)
</code></pre>
"
557,248990,1,4,sql,Summarize aggregated data,"<p>I have a table like as follows:</p>

<pre>
SoftwareName    Count    Country
Project         15       Canada
Visio           12       Canada
Project         10       USA
Visio           5        USA
</pre>

<p>How do I query it to give me a summary like...</p>

<pre>
SoftwareName    Canada    USA    Total
Project         15        10     25
Visio           12        5      17
</pre>

<p>How to do in T-SQL?</p>
","<p>in SQL 2005 or later there-SQL keyword ""Pivot"" that does this for you,
Check out the following link:</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ms177410.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms177410.aspx</a> </p>
"
714,325370,0,4,sql,How can I filter out the rows which contain a particular column with null or empty data in SQL?,"<p>In SQL, How we make a check to filter all row which contain a column data is null or empty ?<br />
For examile  </p>

<pre><code>Select Name,Age from MEMBERS
</code></pre>

<p>We need a check Name should not equal to null or empty.</p>
","<p>T-SQL</p>

<pre><code>select name,age from members where COALESCE(name, '') &lt;&gt; ''
</code></pre>
"
713,325370,4,4,sql,How can I filter out the rows which contain a particular column with null or empty data in SQL?,"<p>In SQL, How we make a check to filter all row which contain a column data is null or empty ?<br />
For examile  </p>

<pre><code>Select Name,Age from MEMBERS
</code></pre>

<p>We need a check Name should not equal to null or empty.</p>
","<p>For DBMSs that treat '' as a value (not null), Vinko's query works:</p>

<pre><code>select name,age from members where name is not null and name &lt;&gt; ''
</code></pre>

<p>For Oracle, which treats '' as a null, tha above doesn't work but this does:</p>

<pre><code>select name,age from members where name is not null
</code></pre>

<p>I tried to think of a ""DBMS-agnostic"" solution, but failed - mainly due to the different concatenation operators/functions used by different DBMSs!</p>
"
712,325370,0,4,sql,How can I filter out the rows which contain a particular column with null or empty data in SQL?,"<p>In SQL, How we make a check to filter all row which contain a column data is null or empty ?<br />
For examile  </p>

<pre><code>Select Name,Age from MEMBERS
</code></pre>

<p>We need a check Name should not equal to null or empty.</p>
","<p>Depending on the Database being used; try
Select Name, Age from Members
where name IS NOT NULL</p>

<p>if you need to filter the otherway
Select Name, Age from Members
where name IS NULL</p>

<p>Certain RDBMS treat enpty string different from null, and you would need to add;
Select Name, Age from Members
where Name IS NOT NULL
OR Name &lt;> ''</p>
"
711,325370,1,4,sql,How can I filter out the rows which contain a particular column with null or empty data in SQL?,"<p>In SQL, How we make a check to filter all row which contain a column data is null or empty ?<br />
For examile  </p>

<pre><code>Select Name,Age from MEMBERS
</code></pre>

<p>We need a check Name should not equal to null or empty.</p>
","<p>Select Name,Age from MEMBERS where name is null or name = ''</p>

<p>you can find and learn anymore from <a href=""http://www.w3schools.com/sql/default.asp"" rel=""nofollow"">http://www.w3schools.com/sql/default.asp</a></p>
"
710,325370,8,4,sql,How can I filter out the rows which contain a particular column with null or empty data in SQL?,"<p>In SQL, How we make a check to filter all row which contain a column data is null or empty ?<br />
For examile  </p>

<pre><code>Select Name,Age from MEMBERS
</code></pre>

<p>We need a check Name should not equal to null or empty.</p>
","<p>This will work in all sane databases (<em>wink, wink</em>) and will return the rows for which name is not null nor empty</p>

<pre><code>select name,age from members where name is not null and name &lt;&gt; ''
</code></pre>
"
709,325370,0,4,sql,How can I filter out the rows which contain a particular column with null or empty data in SQL?,"<p>In SQL, How we make a check to filter all row which contain a column data is null or empty ?<br />
For examile  </p>

<pre><code>Select Name,Age from MEMBERS
</code></pre>

<p>We need a check Name should not equal to null or empty.</p>
","<p>nvl(Name, 'some dumb string') this will return Name if Name is not null and different of '' (oracle, don't know for others). It will be equal to 'some dumb string' if null or equal to ''.</p>
"
938,435980,1,4,sql,How to find WITH RECOMPILE metadata in SQL Server (2005)?,"<p>How do you find which SPs are declared WITH RECOMPILE, either in INFORMATION_SCHEMA, sys.objects or some other metadata?</p>

<p>(I'm adding some code to my system health monitoring and want to warn on ones which are declared that way where it is not justifiable.)</p>

<p><strong>Note: I'm not looking for general text search for 'WITH RECOMPILE' - I can already do that, but it will give false positive for any commented or literal versions of the text.</strong></p>
","<p>For a quick and dirty way I would use:</p>

<pre><code>SELECT
     o.name
FROM
     syscomments c
INNER JOIN sys.objects o ON
     o.object_id = c.id
WHERE
     c.text LIKE '%WITH RECOMPILE%'
</code></pre>

<p>That's probably not a good idea for use in an actual application though. If I have a few minutes I'll try to dig up a cleaner way. The above will also catch procs that have that string commented out, it uses the MS SQL Server specific table syscomments, etc.</p>
"
1045,486270,7,4,sql,What's the most efficient way to check the presence of a row in a table?,"<p>Say I want to check if a record in a MySQL table exists. I'd run a query, check the number of rows returned. If 0 rows do this, otherwise do that.</p>

<pre><code>SELECT * FROM table WHERE id=5
SELECT id FROM table WHERE id=5
</code></pre>

<p>Is there any difference at all between these two queries? Is effort spent in returning every column, or is effort spent in filtering out the columns we don't care about?</p>

<pre><code>SELECT COUNT(*) FROM table WHERE id=5
</code></pre>

<p>Is a whole new question. Would the server grab all the values and then count the values (harder than usual), or would it not bother grabbing anything and just increment a variable each time it finds a match (easier than usual)?</p>

<p>I think I'm making a lot of false assumptions about how MySQL works, but that's the meat of the question! Where am I wrong? Educate me, Stack Overflow!</p>
","<p>Optimizers are pretty smart (generally).  They typically only grab what they need so I'd go with:</p>

<pre><code>SELECT COUNT(1) FROM mytable WHERE id = 5
</code></pre>
"
538,240400,8,4,sql,MYSQL: Create Table If Not Exists,"<p>If I do a <strong>Create Table If Not Exists</strong>, and a table with the same name exists with fewer rows (or columns), what would happen?</p>
","<p>The table will not be created if a table with the same name already exists regardless of table layout.</p>
"
537,240400,4,4,sql,MYSQL: Create Table If Not Exists,"<p>If I do a <strong>Create Table If Not Exists</strong>, and a table with the same name exists with fewer rows (or columns), what would happen?</p>
","<p>Nothing.  If the ""IF Not Exists"" clause fails, the rest of the create is skipped.</p>
"
939,435980,1,4,sql,How to find WITH RECOMPILE metadata in SQL Server (2005)?,"<p>How do you find which SPs are declared WITH RECOMPILE, either in INFORMATION_SCHEMA, sys.objects or some other metadata?</p>

<p>(I'm adding some code to my system health monitoring and want to warn on ones which are declared that way where it is not justifiable.)</p>

<p><strong>Note: I'm not looking for general text search for 'WITH RECOMPILE' - I can already do that, but it will give false positive for any commented or literal versions of the text.</strong></p>
","<p>Here's a query I use which will search user defined views, stored procedures and functions for any given search string:</p>

<pre><code>DECLARE @strSearch varchar(50)
SELECT @strSearch = 'my search string'

SELECT
    so.[Name],
    OBJECT_ID(so.[Name])	
FROM
    [sysobjects] so
JOIN
    syscomments sc
ON
    sc.[ID] = OBJECT_ID(so.[Name])
WHERE 
    (so.[xtype] = 'FN' OR so.[xtype] = 'P' OR so.[xtype] = 'V') AND
    so.[category] = 0 AND
    sc.encrypted = 0 AND
    sc.[text] like '%' + @strSearch + '%'
</code></pre>
"
940,435980,0,4,sql,How to find WITH RECOMPILE metadata in SQL Server (2005)?,"<p>How do you find which SPs are declared WITH RECOMPILE, either in INFORMATION_SCHEMA, sys.objects or some other metadata?</p>

<p>(I'm adding some code to my system health monitoring and want to warn on ones which are declared that way where it is not justifiable.)</p>

<p><strong>Note: I'm not looking for general text search for 'WITH RECOMPILE' - I can already do that, but it will give false positive for any commented or literal versions of the text.</strong></p>
","<p>Thanks to <a href=""http://www.sqlservercentral.com/Forums/UserInfo480409.aspx"" rel=""nofollow"">GSquared</a> on <a href=""http://www.sqlservercentral.com/Forums/Topic634987-338-1.aspx"" rel=""nofollow"">SQL Server Central Forums</a>, I found it, there is a flag called <code>is_recompiled</code> in <code>sys.sql_modules</code>.</p>
"
142,54980,2,4,sql,How do prepared statements work?,"<p>I'm writing some DB routines and I'm using prepared statements.  My environment is PDO with PHP5.</p>

<p>I understand prepared statements primarily provide a performance benefit, as well as some auxiliary bonuses such as not having to manually SQL-escape input data.</p>

<p>My question is about the performance part.</p>

<p>I have two implementations of a getPrice function below that takes a product id and returns its price.</p>

<p>getPrice_A reuses the same PDOStatement object across subsequent calls within the same script execution.  Is this necessary or recommended?  If so, is there any way to avoid duplicating this extra code across every single get*() in every single model?</p>

<p>getPrice_B creates a new PDOStatement object on every call.  Will the DBMS recognize this statement has already been prepared and still be able to skip some work?  In other words, does this implementation properly take advantage of the performance benefits of prepared statements?</p>

<p>Having written all this out and read it over, I imagine getPrice_B is fine and getPrice_A is providing a negligible benefit on top of that, which may or may not be worth the extra complication.</p>

<p>I'd still like to hear for sure from someone more knowledgable though.</p>

<p>Assume that <code>$pdo</code> is a valid, connected PDO object in the examples below.</p>

<pre><code>&lt;?php
class Product {
    static function &amp;getPrice_A($id) {
        static $stmt;
        if (!$stmt) {
            $stmt = $pdo-&gt;prepare('SELECT price FROM products WHERE id = ?');
        }
        $stmt-&gt;execute(array($id));
        return $stmt-&gt;fetchColumn(0);
    }

    static function &amp;getPrice_B($id) {
        $stmt = $pdo-&gt;prepare('SELECT price FROM products WHERE id = ?');
        $stmt-&gt;execute(array($id));
        return $stmt-&gt;fetchColumn(0);
    }
}

// example usage:
$price = Product::getPrice(4982);
echo ""Product 4982 costs $price\n"";
</code></pre>
","<p>From what I understand, prepared statements will reuse the generated SQL plan if it is the same statement, so the database will see the same prepared statement and not have to do the work to figure out how to query the database. I would say the extra work of saving the prepared statement in <code>Product::getPrice_A</code> is not typically very helpful, more because it can obscure the code rather than an issue of performance.  When dealing with performance, I feel it's always best to focus on code clarity and then performance when you have real statistics that indicate a problem.</p>

<p>I would say ""yes, the extra work is unnecessary"" (regardless of if it really boosts performance).  Also, I am not a very big DB expert, but the performance gain of prepared statements is something I heard from others, and it is at the database level, not the code level (so if the code is actually invoking a parameterized statement on the actual DB, then the DB can do these execution plan caching... though depending on the database, you may get the benefit even without the parameterized statement).</p>

<p>Anyways, if you are really worried about (and seeing) database performance issues, you should look into a caching solution... of which I would highly recommend <a href=""http://www.danga.com/memcached/"" rel=""nofollow"">memcached</a>.  With such a solution, you can cache your query results and not even hit the database for things you access frequently.</p>
"
1050,486270,0,4,sql,What's the most efficient way to check the presence of a row in a table?,"<p>Say I want to check if a record in a MySQL table exists. I'd run a query, check the number of rows returned. If 0 rows do this, otherwise do that.</p>

<pre><code>SELECT * FROM table WHERE id=5
SELECT id FROM table WHERE id=5
</code></pre>

<p>Is there any difference at all between these two queries? Is effort spent in returning every column, or is effort spent in filtering out the columns we don't care about?</p>

<pre><code>SELECT COUNT(*) FROM table WHERE id=5
</code></pre>

<p>Is a whole new question. Would the server grab all the values and then count the values (harder than usual), or would it not bother grabbing anything and just increment a variable each time it finds a match (easier than usual)?</p>

<p>I think I'm making a lot of false assumptions about how MySQL works, but that's the meat of the question! Where am I wrong? Educate me, Stack Overflow!</p>
","<p>The difference between your 3 queries depends on how you've built your index.   Only returning the primary key is likely to be faster as MySQL will have your index in memory, and not have to hit disk.  Adding the <code>LIMIT 1</code> is also a good trick that will speed up the optimizer significantly in early 5.0.x branches and earlier. </p>

<p>try <code>EXPLAIN SELECT id FROM table WHERE id=5</code> and check the Extras column for the presence of <code>USING INDEX</code>.  If its there, then you're query is coming straight from the index, and is going to be much faster.</p>
"
555,248990,6,4,sql,Summarize aggregated data,"<p>I have a table like as follows:</p>

<pre>
SoftwareName    Count    Country
Project         15       Canada
Visio           12       Canada
Project         10       USA
Visio           5        USA
</pre>

<p>How do I query it to give me a summary like...</p>

<pre>
SoftwareName    Canada    USA    Total
Project         15        10     25
Visio           12        5      17
</pre>

<p>How to do in T-SQL?</p>
","<pre><code>SELECT SoftwareName, 
  SUM( CASE Country WHEN 'Canada' THEN [Count] ELSE 0 END ) AS Canada,
  SUM( CASE Country WHEN 'USA'    THEN [Count] ELSE 0 END ) AS USA,
  SUM( [Count] ) AS Total
FROM [Table] 
GROUP BY SoftwareName;
</code></pre>
"
556,248990,1,4,sql,Summarize aggregated data,"<p>I have a table like as follows:</p>

<pre>
SoftwareName    Count    Country
Project         15       Canada
Visio           12       Canada
Project         10       USA
Visio           5        USA
</pre>

<p>How do I query it to give me a summary like...</p>

<pre>
SoftwareName    Canada    USA    Total
Project         15        10     25
Visio           12        5      17
</pre>

<p>How to do in T-SQL?</p>
","<p>This is called table pivoting.  In your simple case, there are just two columns; in general, there could be 200 countries or so, in which case, the pivoting becomes rather hard.</p>

<p>There are many resources online describing how to do it: Google for 'pivot table sql'.</p>
"
1046,486270,3,4,sql,What's the most efficient way to check the presence of a row in a table?,"<p>Say I want to check if a record in a MySQL table exists. I'd run a query, check the number of rows returned. If 0 rows do this, otherwise do that.</p>

<pre><code>SELECT * FROM table WHERE id=5
SELECT id FROM table WHERE id=5
</code></pre>

<p>Is there any difference at all between these two queries? Is effort spent in returning every column, or is effort spent in filtering out the columns we don't care about?</p>

<pre><code>SELECT COUNT(*) FROM table WHERE id=5
</code></pre>

<p>Is a whole new question. Would the server grab all the values and then count the values (harder than usual), or would it not bother grabbing anything and just increment a variable each time it finds a match (easier than usual)?</p>

<p>I think I'm making a lot of false assumptions about how MySQL works, but that's the meat of the question! Where am I wrong? Educate me, Stack Overflow!</p>
","<p>Limit your results to at most one row by appending LIMIT 1, if all you want to do is check the presence of a record.</p>

<pre><code>SELECT id FROM table WHERE id=5 LIMIT 1
</code></pre>

<p>This will definitely ensure that no more than one row is returned or processed. In my experience, LIMIT 1 (or TOP 1 depending in the DB) to check for existence of a row makes a big difference in terms of performance for large tables.</p>

<p>EDIT: I think I misread your question, but I'll leave my answer here anyway if it's of any help.</p>
"
1047,486270,0,4,sql,What's the most efficient way to check the presence of a row in a table?,"<p>Say I want to check if a record in a MySQL table exists. I'd run a query, check the number of rows returned. If 0 rows do this, otherwise do that.</p>

<pre><code>SELECT * FROM table WHERE id=5
SELECT id FROM table WHERE id=5
</code></pre>

<p>Is there any difference at all between these two queries? Is effort spent in returning every column, or is effort spent in filtering out the columns we don't care about?</p>

<pre><code>SELECT COUNT(*) FROM table WHERE id=5
</code></pre>

<p>Is a whole new question. Would the server grab all the values and then count the values (harder than usual), or would it not bother grabbing anything and just increment a variable each time it finds a match (easier than usual)?</p>

<p>I think I'm making a lot of false assumptions about how MySQL works, but that's the meat of the question! Where am I wrong? Educate me, Stack Overflow!</p>
","<p>For the first two queries, most people will generally say, always specify exactly what you need and leave the rest. Effort isn't all specific as bandwidth could be spent in returning data that you aren't even going to do anything with.</p>

<p>As for the previous answer will do for your result set, unless you're dealing with a language that supports affected rows. This can sometimes work when getting data to collect information on how many rows were returned in the last query. You'll need to look at your interface documentation as to how to get that information.</p>
"
566,252230,1,4,sql,Stored procedures or inline queries?,"<p>First of all there is a <a href=""http://stackoverflow.com/questions/59880/are-stored-procedures-more-efficient-in-general-than-inline-statements-on-moder"">partial question</a> regarding this, but it is not exactly what I'm asking, so, bear with me and go for it.</p>

<p>My question is, after looking at what <a href=""http://subsonicproject.com/"" rel=""nofollow"">SubSonic</a> does and the excellent videos from Rob Connery I need to ask: <strong>Shall we use a tool like this and do Inline queries or</strong> shall we do the queries <strong>using</strong> a call to the <strong>stored procedure?</strong></p>

<p>I don't want to minimize any work from Rob (which I think it's amazing) but I just want your opinion on this cause I need to start a new project and I'm in the middle of the line; shall I use SubSonic (or other like tool, like NHibernate) or I just continue my method that is always call a stored procedure even if it's a simple as</p>

<pre><code>Select this, that from myTable where myStuff = StackOverflow;
</code></pre>
","<p>I've done a mix of inline queries and stored procedures. I prefer more of the stored procedure/view approach as it gains a nice spot for you to make a change if needed. When you have inline queries you always have to go and change the code to change an inline query and then re-roll the application. You also might have the inline query in multiple places so you would have to change a lot more code than with one stored procedure.</p>

<p>Then again if you have to add a parameter to a stored procedure, your still changing a lot of code anyways. </p>

<p>Another note is how often the data changes behind the stored procedure, where I work we have third party tables that may break up into normalized tables, or a table becomes obsolete. In that case a stored procedure/view may minimize the exposure you have to that change.</p>

<p>I've also written a entire application without stored procedures. It had three classes and 10 pages, was not worth it at all. I think there comes a point when its overkill, or can be justified, but it also comes down to your personal opinion and preference. </p>
"
565,252230,2,4,sql,Stored procedures or inline queries?,"<p>First of all there is a <a href=""http://stackoverflow.com/questions/59880/are-stored-procedures-more-efficient-in-general-than-inline-statements-on-moder"">partial question</a> regarding this, but it is not exactly what I'm asking, so, bear with me and go for it.</p>

<p>My question is, after looking at what <a href=""http://subsonicproject.com/"" rel=""nofollow"">SubSonic</a> does and the excellent videos from Rob Connery I need to ask: <strong>Shall we use a tool like this and do Inline queries or</strong> shall we do the queries <strong>using</strong> a call to the <strong>stored procedure?</strong></p>

<p>I don't want to minimize any work from Rob (which I think it's amazing) but I just want your opinion on this cause I need to start a new project and I'm in the middle of the line; shall I use SubSonic (or other like tool, like NHibernate) or I just continue my method that is always call a stored procedure even if it's a simple as</p>

<pre><code>Select this, that from myTable where myStuff = StackOverflow;
</code></pre>
","<p>Stored procedures are gold when you have several applications that depend on the same database. It let's you define and maintain query logic once, rather than several places.</p>

<p>On the other hand, it's pretty easy for stored procedures themselves to become a big jumbled mess in the database, since most systems don't have a good method for organizing them logically.  And they can be more difficult to version and track changes.</p>
"
1125,515690,11,4,sql,SQL query to select unreferenced rows,"<p>I'm having a brain-dead moment... I have two tables described by:</p>

<pre><code>CREATE TABLE table_a (
    id             INTEGER          PRIMARY KEY AUTO_INCREMENT,
    name           VARCHAR(255)     NOT NULL
    UNIQUE (name))

CREATE TABLE table_b (
    id             INTEGER          PRIMARY KEY AUTO_INCREMENT,
    a_key          INTEGER          NOT NULL,
    other_stuff    VARCHAR(255)     NOT NULL,
    FOREIGN KEY(a_key)  REFERENCES table_a(id)
         ON DELETE CASCADE)
</code></pre>

<p>How can I select all rows from table_a that do not have an entry in table_b.a_key?</p>
","<pre><code>SELECT table_a.*
FROM table_a
    LEFT JOIN table_b
        ON table_a.id = table_b.a_key
WHERE table_b.id IS NULL
</code></pre>
"
567,252230,0,4,sql,Stored procedures or inline queries?,"<p>First of all there is a <a href=""http://stackoverflow.com/questions/59880/are-stored-procedures-more-efficient-in-general-than-inline-statements-on-moder"">partial question</a> regarding this, but it is not exactly what I'm asking, so, bear with me and go for it.</p>

<p>My question is, after looking at what <a href=""http://subsonicproject.com/"" rel=""nofollow"">SubSonic</a> does and the excellent videos from Rob Connery I need to ask: <strong>Shall we use a tool like this and do Inline queries or</strong> shall we do the queries <strong>using</strong> a call to the <strong>stored procedure?</strong></p>

<p>I don't want to minimize any work from Rob (which I think it's amazing) but I just want your opinion on this cause I need to start a new project and I'm in the middle of the line; shall I use SubSonic (or other like tool, like NHibernate) or I just continue my method that is always call a stored procedure even if it's a simple as</p>

<pre><code>Select this, that from myTable where myStuff = StackOverflow;
</code></pre>
","<p>Are you going to only ever access your database from that one application?</p>

<p>If not, then you are probably better off using stored procedures so that you can have a consistent interface to your database.</p>

<p>Is there any significant cost to distributing your application if you need to make a change?</p>

<p>If so, then you are probably better off using stored procedures which can be changed at the server and those changes won't need to be distributed.</p>

<p>Are you at all concerned about the security of your database?</p>

<p>If so, then you probably want to use stored procedures so that you don't have to grant direct access to tables to a user.</p>

<p>If you're writing a small application, without a wide audience, for a system that won't be used or accessed outside of your application, then inline SQL might be ok.</p>
"
450,197220,1,4,sql,SqlDataReader.HasRows returns false since SQL 2008 upgrade,"<p>I've got an ASP.NET 2.0 website that connects to a SQL database. I've upgraded the SQL server from 2000 to 2008 and since then, one page refuses to work. </p>

<p>I've worked out the problem is that the call to SqlDataReader.HasRows is returning false even though the dataset is not empty and removing the check allows the loop through reader.Read() to access the expected data. </p>

<pre><code>    _connectionString = WebConfigurationManager.ConnectionStrings[""SQLServer""].ConnectionString;
    SqlConnection connection = new SqlConnection(_connectionString);
    SqlCommand command = new SqlCommand(searchtype, connection);
    SqlParameter _parSeachTerm = new SqlParameter(""@searchterm"", SqlDbType.VarChar, 255);
    _parSeachTerm.Value = searchterm;
    command.Parameters.Add(_parSeachTerm);
    command.CommandType = CommandType.StoredProcedure;
    try
    {
        connection.Open();
        SqlDataReader reader = command.ExecuteReader();
        if (reader.HasRows) //this always returns false!?
        {
            while (reader.Read())
            {...
</code></pre>

<p>Does anybody have any idea what's going on? There are similar code blocks on other pages where HasRows returns the correct value.</p>

<p>EDIT- Just to clarify, the stored procedure DOES return results which I have confirmed because the loop runs through fine if I remove the HasRows check. Changing just the name of the SQL server in the connection string to an identical database running on SQL 2000 makes the problem go away. I've checked that NOCOUNT is off, so what else could make HasRows return false when that's not the case??</p>

<p>EDIT2- Here's the SP</p>

<pre><code>CREATE PROCEDURE StaffEnquirySurnameSearch

@searchterm varchar(255)

AS

SELECT  AD.Name, AD.Company, AD.telephoneNumber, AD.manager, CVS.Position, CVS.CompanyArea, CVS.Location, CVS.Title, AD.guid AS guid,
AD.firstname, AD.surname
FROM ADCVS AD
LEFT OUTER JOIN CVS ON
AD.Guid=CVS.Guid 
WHERE AD.SurName LIKE @searchterm
ORDER BY AD.Surname, AD.Firstname
GO
</code></pre>

<p>Many thanks in advance.</p>
","<p>Does the stored procedure work if you invoke it in directly, say in SSMS?  I'd start by making sure that it does.</p>
"
788,351340,2,4,sql,What's the shortest TSQL to concatenate a person's name which may contain nulls,"<p>3 fields: FirstName, MiddleName, LastName</p>

<p>Any field can be null, but I don't want extra spaces. Format should be ""First Middle Last"", ""First Last"", ""Last"", etc.</p>
","<p>Why not use a computed column on the table that performs the concat for you using your preferred syntax from the many posted here? Then you will just query the computed column - very elegant and if you persist the computed column then you may even get slight performance increase.
<a href=""http://msdn.microsoft.com/en-us/library/ms186241.aspx"" rel=""nofollow"">Example here</a></p>
"
451,197220,0,4,sql,SqlDataReader.HasRows returns false since SQL 2008 upgrade,"<p>I've got an ASP.NET 2.0 website that connects to a SQL database. I've upgraded the SQL server from 2000 to 2008 and since then, one page refuses to work. </p>

<p>I've worked out the problem is that the call to SqlDataReader.HasRows is returning false even though the dataset is not empty and removing the check allows the loop through reader.Read() to access the expected data. </p>

<pre><code>    _connectionString = WebConfigurationManager.ConnectionStrings[""SQLServer""].ConnectionString;
    SqlConnection connection = new SqlConnection(_connectionString);
    SqlCommand command = new SqlCommand(searchtype, connection);
    SqlParameter _parSeachTerm = new SqlParameter(""@searchterm"", SqlDbType.VarChar, 255);
    _parSeachTerm.Value = searchterm;
    command.Parameters.Add(_parSeachTerm);
    command.CommandType = CommandType.StoredProcedure;
    try
    {
        connection.Open();
        SqlDataReader reader = command.ExecuteReader();
        if (reader.HasRows) //this always returns false!?
        {
            while (reader.Read())
            {...
</code></pre>

<p>Does anybody have any idea what's going on? There are similar code blocks on other pages where HasRows returns the correct value.</p>

<p>EDIT- Just to clarify, the stored procedure DOES return results which I have confirmed because the loop runs through fine if I remove the HasRows check. Changing just the name of the SQL server in the connection string to an identical database running on SQL 2000 makes the problem go away. I've checked that NOCOUNT is off, so what else could make HasRows return false when that's not the case??</p>

<p>EDIT2- Here's the SP</p>

<pre><code>CREATE PROCEDURE StaffEnquirySurnameSearch

@searchterm varchar(255)

AS

SELECT  AD.Name, AD.Company, AD.telephoneNumber, AD.manager, CVS.Position, CVS.CompanyArea, CVS.Location, CVS.Title, AD.guid AS guid,
AD.firstname, AD.surname
FROM ADCVS AD
LEFT OUTER JOIN CVS ON
AD.Guid=CVS.Guid 
WHERE AD.SurName LIKE @searchterm
ORDER BY AD.Surname, AD.Firstname
GO
</code></pre>

<p>Many thanks in advance.</p>
","<p>First, check the procedure as @tvanfosson says. 
Second, the check for HasRows() is actually unnecessary in the code snippet. </p>
"
452,197220,0,4,sql,SqlDataReader.HasRows returns false since SQL 2008 upgrade,"<p>I've got an ASP.NET 2.0 website that connects to a SQL database. I've upgraded the SQL server from 2000 to 2008 and since then, one page refuses to work. </p>

<p>I've worked out the problem is that the call to SqlDataReader.HasRows is returning false even though the dataset is not empty and removing the check allows the loop through reader.Read() to access the expected data. </p>

<pre><code>    _connectionString = WebConfigurationManager.ConnectionStrings[""SQLServer""].ConnectionString;
    SqlConnection connection = new SqlConnection(_connectionString);
    SqlCommand command = new SqlCommand(searchtype, connection);
    SqlParameter _parSeachTerm = new SqlParameter(""@searchterm"", SqlDbType.VarChar, 255);
    _parSeachTerm.Value = searchterm;
    command.Parameters.Add(_parSeachTerm);
    command.CommandType = CommandType.StoredProcedure;
    try
    {
        connection.Open();
        SqlDataReader reader = command.ExecuteReader();
        if (reader.HasRows) //this always returns false!?
        {
            while (reader.Read())
            {...
</code></pre>

<p>Does anybody have any idea what's going on? There are similar code blocks on other pages where HasRows returns the correct value.</p>

<p>EDIT- Just to clarify, the stored procedure DOES return results which I have confirmed because the loop runs through fine if I remove the HasRows check. Changing just the name of the SQL server in the connection string to an identical database running on SQL 2000 makes the problem go away. I've checked that NOCOUNT is off, so what else could make HasRows return false when that's not the case??</p>

<p>EDIT2- Here's the SP</p>

<pre><code>CREATE PROCEDURE StaffEnquirySurnameSearch

@searchterm varchar(255)

AS

SELECT  AD.Name, AD.Company, AD.telephoneNumber, AD.manager, CVS.Position, CVS.CompanyArea, CVS.Location, CVS.Title, AD.guid AS guid,
AD.firstname, AD.surname
FROM ADCVS AD
LEFT OUTER JOIN CVS ON
AD.Guid=CVS.Guid 
WHERE AD.SurName LIKE @searchterm
ORDER BY AD.Surname, AD.Firstname
GO
</code></pre>

<p>Many thanks in advance.</p>
","<p>You're not using RAISEERROR by chance?  We found some problems using the same pattern as above (check HasRows, then reader.Read()) and found that if RAISEERROR was used with a certain error code (above 16, I believe) then the HasRows would return false <strong>and</strong> we would have problems catching an exception.</p>
"
453,197220,0,4,sql,SqlDataReader.HasRows returns false since SQL 2008 upgrade,"<p>I've got an ASP.NET 2.0 website that connects to a SQL database. I've upgraded the SQL server from 2000 to 2008 and since then, one page refuses to work. </p>

<p>I've worked out the problem is that the call to SqlDataReader.HasRows is returning false even though the dataset is not empty and removing the check allows the loop through reader.Read() to access the expected data. </p>

<pre><code>    _connectionString = WebConfigurationManager.ConnectionStrings[""SQLServer""].ConnectionString;
    SqlConnection connection = new SqlConnection(_connectionString);
    SqlCommand command = new SqlCommand(searchtype, connection);
    SqlParameter _parSeachTerm = new SqlParameter(""@searchterm"", SqlDbType.VarChar, 255);
    _parSeachTerm.Value = searchterm;
    command.Parameters.Add(_parSeachTerm);
    command.CommandType = CommandType.StoredProcedure;
    try
    {
        connection.Open();
        SqlDataReader reader = command.ExecuteReader();
        if (reader.HasRows) //this always returns false!?
        {
            while (reader.Read())
            {...
</code></pre>

<p>Does anybody have any idea what's going on? There are similar code blocks on other pages where HasRows returns the correct value.</p>

<p>EDIT- Just to clarify, the stored procedure DOES return results which I have confirmed because the loop runs through fine if I remove the HasRows check. Changing just the name of the SQL server in the connection string to an identical database running on SQL 2000 makes the problem go away. I've checked that NOCOUNT is off, so what else could make HasRows return false when that's not the case??</p>

<p>EDIT2- Here's the SP</p>

<pre><code>CREATE PROCEDURE StaffEnquirySurnameSearch

@searchterm varchar(255)

AS

SELECT  AD.Name, AD.Company, AD.telephoneNumber, AD.manager, CVS.Position, CVS.CompanyArea, CVS.Location, CVS.Title, AD.guid AS guid,
AD.firstname, AD.surname
FROM ADCVS AD
LEFT OUTER JOIN CVS ON
AD.Guid=CVS.Guid 
WHERE AD.SurName LIKE @searchterm
ORDER BY AD.Surname, AD.Firstname
GO
</code></pre>

<p>Many thanks in advance.</p>
","<p>It is either your connection string, the stored procedure, or a bug in the sql driver.
Most people are guessing the stored procedure.
So show us the code.
While you are at it, show us the connection string and searchtype variable contents.</p>
"
454,197220,1,4,sql,SqlDataReader.HasRows returns false since SQL 2008 upgrade,"<p>I've got an ASP.NET 2.0 website that connects to a SQL database. I've upgraded the SQL server from 2000 to 2008 and since then, one page refuses to work. </p>

<p>I've worked out the problem is that the call to SqlDataReader.HasRows is returning false even though the dataset is not empty and removing the check allows the loop through reader.Read() to access the expected data. </p>

<pre><code>    _connectionString = WebConfigurationManager.ConnectionStrings[""SQLServer""].ConnectionString;
    SqlConnection connection = new SqlConnection(_connectionString);
    SqlCommand command = new SqlCommand(searchtype, connection);
    SqlParameter _parSeachTerm = new SqlParameter(""@searchterm"", SqlDbType.VarChar, 255);
    _parSeachTerm.Value = searchterm;
    command.Parameters.Add(_parSeachTerm);
    command.CommandType = CommandType.StoredProcedure;
    try
    {
        connection.Open();
        SqlDataReader reader = command.ExecuteReader();
        if (reader.HasRows) //this always returns false!?
        {
            while (reader.Read())
            {...
</code></pre>

<p>Does anybody have any idea what's going on? There are similar code blocks on other pages where HasRows returns the correct value.</p>

<p>EDIT- Just to clarify, the stored procedure DOES return results which I have confirmed because the loop runs through fine if I remove the HasRows check. Changing just the name of the SQL server in the connection string to an identical database running on SQL 2000 makes the problem go away. I've checked that NOCOUNT is off, so what else could make HasRows return false when that's not the case??</p>

<p>EDIT2- Here's the SP</p>

<pre><code>CREATE PROCEDURE StaffEnquirySurnameSearch

@searchterm varchar(255)

AS

SELECT  AD.Name, AD.Company, AD.telephoneNumber, AD.manager, CVS.Position, CVS.CompanyArea, CVS.Location, CVS.Title, AD.guid AS guid,
AD.firstname, AD.surname
FROM ADCVS AD
LEFT OUTER JOIN CVS ON
AD.Guid=CVS.Guid 
WHERE AD.SurName LIKE @searchterm
ORDER BY AD.Surname, AD.Firstname
GO
</code></pre>

<p>Many thanks in advance.</p>
","<p><code>HasRows</code> requires a scrollable cursor. </p>

<p>Do the rows you are bringing back contain any large <code>image/BLOB</code> data?</p>

<p>As someone else suggested, I think posting the <code>Stored Procedure</code> might throw some light on the matter...</p>
"
455,197220,0,4,sql,SqlDataReader.HasRows returns false since SQL 2008 upgrade,"<p>I've got an ASP.NET 2.0 website that connects to a SQL database. I've upgraded the SQL server from 2000 to 2008 and since then, one page refuses to work. </p>

<p>I've worked out the problem is that the call to SqlDataReader.HasRows is returning false even though the dataset is not empty and removing the check allows the loop through reader.Read() to access the expected data. </p>

<pre><code>    _connectionString = WebConfigurationManager.ConnectionStrings[""SQLServer""].ConnectionString;
    SqlConnection connection = new SqlConnection(_connectionString);
    SqlCommand command = new SqlCommand(searchtype, connection);
    SqlParameter _parSeachTerm = new SqlParameter(""@searchterm"", SqlDbType.VarChar, 255);
    _parSeachTerm.Value = searchterm;
    command.Parameters.Add(_parSeachTerm);
    command.CommandType = CommandType.StoredProcedure;
    try
    {
        connection.Open();
        SqlDataReader reader = command.ExecuteReader();
        if (reader.HasRows) //this always returns false!?
        {
            while (reader.Read())
            {...
</code></pre>

<p>Does anybody have any idea what's going on? There are similar code blocks on other pages where HasRows returns the correct value.</p>

<p>EDIT- Just to clarify, the stored procedure DOES return results which I have confirmed because the loop runs through fine if I remove the HasRows check. Changing just the name of the SQL server in the connection string to an identical database running on SQL 2000 makes the problem go away. I've checked that NOCOUNT is off, so what else could make HasRows return false when that's not the case??</p>

<p>EDIT2- Here's the SP</p>

<pre><code>CREATE PROCEDURE StaffEnquirySurnameSearch

@searchterm varchar(255)

AS

SELECT  AD.Name, AD.Company, AD.telephoneNumber, AD.manager, CVS.Position, CVS.CompanyArea, CVS.Location, CVS.Title, AD.guid AS guid,
AD.firstname, AD.surname
FROM ADCVS AD
LEFT OUTER JOIN CVS ON
AD.Guid=CVS.Guid 
WHERE AD.SurName LIKE @searchterm
ORDER BY AD.Surname, AD.Firstname
GO
</code></pre>

<p>Many thanks in advance.</p>
","<p>I am speculating again.<br>
Do you have multiple datareaders open by any chance?</p>

<p>Add MARS_Connection=yes; OR MultipleActiveResultSets=true to the connection string, if that helps.<br>
Also, your usage of connection &amp; datareader is not a recommended way of doing things<br></p>

<p>a simpler way to write it could be</p>

<pre>
<code>
using (connection cnn = new Connection(...)
{
using (SqlDataReader rdr = ....
{
//some code which deals with datareader
}
}
</code>
</pre>

<p>This will close the connection and datareader once the operation is complete.</p>
"
784,351340,0,4,sql,What's the shortest TSQL to concatenate a person's name which may contain nulls,"<p>3 fields: FirstName, MiddleName, LastName</p>

<p>Any field can be null, but I don't want extra spaces. Format should be ""First Middle Last"", ""First Last"", ""Last"", etc.</p>
","<p><code>LTrim(RTrim(Replace(IsNull(Firstname + ' ', '') + 
    isNull(MiddleName, '')  + 
    IsNull(' ' + LastName, ''), '  ', ' ')))</code></p>
"
456,197220,0,4,sql,SqlDataReader.HasRows returns false since SQL 2008 upgrade,"<p>I've got an ASP.NET 2.0 website that connects to a SQL database. I've upgraded the SQL server from 2000 to 2008 and since then, one page refuses to work. </p>

<p>I've worked out the problem is that the call to SqlDataReader.HasRows is returning false even though the dataset is not empty and removing the check allows the loop through reader.Read() to access the expected data. </p>

<pre><code>    _connectionString = WebConfigurationManager.ConnectionStrings[""SQLServer""].ConnectionString;
    SqlConnection connection = new SqlConnection(_connectionString);
    SqlCommand command = new SqlCommand(searchtype, connection);
    SqlParameter _parSeachTerm = new SqlParameter(""@searchterm"", SqlDbType.VarChar, 255);
    _parSeachTerm.Value = searchterm;
    command.Parameters.Add(_parSeachTerm);
    command.CommandType = CommandType.StoredProcedure;
    try
    {
        connection.Open();
        SqlDataReader reader = command.ExecuteReader();
        if (reader.HasRows) //this always returns false!?
        {
            while (reader.Read())
            {...
</code></pre>

<p>Does anybody have any idea what's going on? There are similar code blocks on other pages where HasRows returns the correct value.</p>

<p>EDIT- Just to clarify, the stored procedure DOES return results which I have confirmed because the loop runs through fine if I remove the HasRows check. Changing just the name of the SQL server in the connection string to an identical database running on SQL 2000 makes the problem go away. I've checked that NOCOUNT is off, so what else could make HasRows return false when that's not the case??</p>

<p>EDIT2- Here's the SP</p>

<pre><code>CREATE PROCEDURE StaffEnquirySurnameSearch

@searchterm varchar(255)

AS

SELECT  AD.Name, AD.Company, AD.telephoneNumber, AD.manager, CVS.Position, CVS.CompanyArea, CVS.Location, CVS.Title, AD.guid AS guid,
AD.firstname, AD.surname
FROM ADCVS AD
LEFT OUTER JOIN CVS ON
AD.Guid=CVS.Guid 
WHERE AD.SurName LIKE @searchterm
ORDER BY AD.Surname, AD.Firstname
GO
</code></pre>

<p>Many thanks in advance.</p>
","<p>I think you've got NOCOUNT backwards.
I believe NOCOUNT needs to be on for this to work.</p>

<p>In your stored procedure add
SET NOCOUNT ON
after the AS and before any code.
Otherwise it returns two result sets.
One with the count and one with the actual data.
You only want the result set with the actual data.</p>
"
457,200810,1,4,sql,How can I do access control via an SQL table?,"<p>I'm trying to create an access control system. </p>

<p>Here's a stripped down example of what the table I'm trying to control access to looks like:</p>

<pre><code>things table:
id   group_id   name
1    1          thing 1
2    1          thing 2
3    1          thing 3
4    1          thing 4
5    2          thing 5
</code></pre>

<p>And the access control table looks like this:</p>

<pre><code>access table:
user_id  type   object_id  access
1        group  1          50
1        thing  1          10
1        thing  2          100
</code></pre>

<p>Access can be granted either by specifying the id of the 'thing' directly, or granted for an entire group of things by specifying a group id. In the above example, user 1 has been granted an access level of 50 to group 1, which should apply unless there are any other rules granting more specific access to an individual thing.</p>

<p>I need a query that returns a list of things (ids only is okay) along with the access level for a specific user. So using the example above I'd want something like this for user id 1:</p>

<pre><code>desired result:
thing_id   access
1          10
2          100
3          50   (things 3 and 4 have no specific access rule,
4          50   so this '50' is from the group rule)
5               (thing 5 has no rules at all, so although I 
                still want it in the output, there's no access
		level for it)
</code></pre>

<p>The closest I can come up with is this:</p>

<pre><code>SELECT * 
FROM things 
LEFT JOIN access ON 
	user_id = 1
	AND (
		(access.type = 'group' AND access.object_id = things.group_id)
		OR (access.type = 'thing' AND access.object_id = things.id)
	)
</code></pre>

<p>But that returns multiple rows, when I only want one for each row in the 'things' table. I'm not sure how to get down to a single row for each 'thing', or how to prioritise 'thing' rules over 'group' rules.</p>

<p>If it helps, the database I'm using is PostgreSQL.</p>

<p>Please feel free to leave a comment if there's any information I've missed out. </p>

<p>Thanks in advance!</p>
","<p>I just read a paper last night on this.  It has some ideas on how to do this.  If you can't  use the link on the title try using Google Scholar on <a href=""http://portal.acm.org/citation.cfm?id=1316701"" rel=""nofollow"">Limiting Disclosure in Hippocratic Databases.</a></p>
"
458,200810,1,4,sql,How can I do access control via an SQL table?,"<p>I'm trying to create an access control system. </p>

<p>Here's a stripped down example of what the table I'm trying to control access to looks like:</p>

<pre><code>things table:
id   group_id   name
1    1          thing 1
2    1          thing 2
3    1          thing 3
4    1          thing 4
5    2          thing 5
</code></pre>

<p>And the access control table looks like this:</p>

<pre><code>access table:
user_id  type   object_id  access
1        group  1          50
1        thing  1          10
1        thing  2          100
</code></pre>

<p>Access can be granted either by specifying the id of the 'thing' directly, or granted for an entire group of things by specifying a group id. In the above example, user 1 has been granted an access level of 50 to group 1, which should apply unless there are any other rules granting more specific access to an individual thing.</p>

<p>I need a query that returns a list of things (ids only is okay) along with the access level for a specific user. So using the example above I'd want something like this for user id 1:</p>

<pre><code>desired result:
thing_id   access
1          10
2          100
3          50   (things 3 and 4 have no specific access rule,
4          50   so this '50' is from the group rule)
5               (thing 5 has no rules at all, so although I 
                still want it in the output, there's no access
		level for it)
</code></pre>

<p>The closest I can come up with is this:</p>

<pre><code>SELECT * 
FROM things 
LEFT JOIN access ON 
	user_id = 1
	AND (
		(access.type = 'group' AND access.object_id = things.group_id)
		OR (access.type = 'thing' AND access.object_id = things.id)
	)
</code></pre>

<p>But that returns multiple rows, when I only want one for each row in the 'things' table. I'm not sure how to get down to a single row for each 'thing', or how to prioritise 'thing' rules over 'group' rules.</p>

<p>If it helps, the database I'm using is PostgreSQL.</p>

<p>Please feel free to leave a comment if there's any information I've missed out. </p>

<p>Thanks in advance!</p>
","<p>I don't know the Postgres SQL dialect, but maybe something like:</p>

<pre><code>select thing.*, coalesce ( ( select access
                             from   access
                             where  userid = 1
                             and    type = 'thing'
                             and    object_id = thing.id
                           ),
                           ( select access
                             from   access
                             where  userid = 1
                             and    type = 'group'
                             and    object_id = thing.group_id
                           )
                         )
from things
</code></pre>

<p>Incidentally, I don't like the design.  I would prefer the access table to be split into two:</p>

<pre><code>thing_access (user_id, thing_id, access)
group_access (user_id, group_id, access)
</code></pre>

<p>My query then becomes:</p>

<pre><code>select thing.*, coalesce ( ( select access
                             from   thing_access
                             where  userid = 1
                             and    thing_id = thing.id
                           ),
                           ( select access
                             from   group_access
                             where  userid = 1
                             and    group_id = thing.group_id
                           )
                         )
from things
</code></pre>

<p>I prefer this because foreign keys can now be used in the access tables.    </p>
"
568,252230,0,4,sql,Stored procedures or inline queries?,"<p>First of all there is a <a href=""http://stackoverflow.com/questions/59880/are-stored-procedures-more-efficient-in-general-than-inline-statements-on-moder"">partial question</a> regarding this, but it is not exactly what I'm asking, so, bear with me and go for it.</p>

<p>My question is, after looking at what <a href=""http://subsonicproject.com/"" rel=""nofollow"">SubSonic</a> does and the excellent videos from Rob Connery I need to ask: <strong>Shall we use a tool like this and do Inline queries or</strong> shall we do the queries <strong>using</strong> a call to the <strong>stored procedure?</strong></p>

<p>I don't want to minimize any work from Rob (which I think it's amazing) but I just want your opinion on this cause I need to start a new project and I'm in the middle of the line; shall I use SubSonic (or other like tool, like NHibernate) or I just continue my method that is always call a stored procedure even if it's a simple as</p>

<pre><code>Select this, that from myTable where myStuff = StackOverflow;
</code></pre>
","<p>I prefer inline sql unless the stored procedure has actual logic (variables, cursors, etc) involved. I have been using LINQ to SQL lately, and taking the generated classes and adding partial classes that have some predefined, common linq queries. I feel this makes for faster development.</p>

<p><em>Edit: I know I'm going to get downmodded for this. If you ever talk down on foreign keys or stored procedures, you will get downmodded. DBAs need job security I guess...</em></p>
"
598,265850,3,4,sql,How to query range of data in DB2 with highest performance?,"<p>Usually, I need to retrieve data from a table in some range; for example, a separate page for each search result. In MySQL I use LIMIT keyword but in DB2 I don't know. Now I use this query for retrieve range of data.</p>

<pre><code>SELECT * 
FROM(
   SELECT  
      SMALLINT(RANK() OVER(ORDER BY NAME DESC)) AS RUNNING_NO
      , DATA_KEY_VALUE
      , SHOW_PRIORITY
   FROM 
      EMPLOYEE
   WHERE 
      NAME LIKE 'DEL%'
   ORDER BY
      NAME DESC
   FETCH FIRST 20 ROWS ONLY
) AS TMP
ORDER BY 
  TMP.RUNNING_NO ASC
FETCH FIRST 10 ROWS ONLY
</code></pre>

<p>but I know it's bad style. So, how to query for highest performance?</p>
","<p>Not sure why you are creating the TMP table.  Isn't RUNNING_NO aready in ascending sequence?  I would think:</p>

<pre><code>SELECT SMALLINT(RANK() OVER(ORDER BY NAME DESC)) AS RUNNING_NO,
       DATA_KEY_VALUE,
       SHOW_PRIORITY
  FROM EMPLOYEE
 WHERE NAME LIKE 'DEL%'
 ORDER BY NAME DESC
 FETCH FIRST 10 ROWS ONLY</code></pre>

<p>would give the same results.</p>

<p>Having an INDEX over NAME on the EMPLOYEE table will boost performance of this query.</p>
"
883,398680,0,4,sql,Data Access Library Return DataSet or Object,"<p>Is there a general consensus out there for when working with library's that call stored procedures?  Return datasets or use sqldatareader to populate custom objects?</p>

<p>Is the cost of serialization your Data Transport Object less then a DataSet?</p>
","<p>At some point, it depends on the purpose of the library, or I sould say, the functionality of the library. Since the OOP hype, the ""general consensus"" is to first retrieve/fetch the data in the DAL using datareaders as they are faster, then load up your objects and close your readers, however, this is not always the case. To keep simplicity, some pass back the dataset so that gridviews can be bounded and paging/sorting can be enabled with minimal code. Remember simple is best.</p>

<p>In reporting application however, I've noticed a likeness for datasets, especially if the data is exposed by webservices. </p>

<p>The cost of serilization will be based on the usage of the application and also experience. An inexperience developer may return 3000 to 50000 rows of un-necessary data in a dataset. Remember the dataset is an animal, but with a lot of functionality. Use wisely.</p>

<p>Most ORM does serialization behind the scenes (I stand corrected here)so it could be fair to say that it wouldn't cost that much, but then again it depends on the application.</p>
"
884,398680,1,4,sql,Data Access Library Return DataSet or Object,"<p>Is there a general consensus out there for when working with library's that call stored procedures?  Return datasets or use sqldatareader to populate custom objects?</p>

<p>Is the cost of serialization your Data Transport Object less then a DataSet?</p>
","<p>Personally, I use a SqlDataAdapter with DataTables. DataTables have <em>WAY</em> less overhead than DataSets. My entity objects only contain business rules, they aren't used to transport data across tiers.</p>
"
885,398680,1,4,sql,Data Access Library Return DataSet or Object,"<p>Is there a general consensus out there for when working with library's that call stored procedures?  Return datasets or use sqldatareader to populate custom objects?</p>

<p>Is the cost of serialization your Data Transport Object less then a DataSet?</p>
","<p>You may want to think about skipping the Data-Access Library; instead, have your business objects automatically there for you, populated with data, when you need them. <a href=""http://en.wikipedia.org/wiki/NHibernate"" rel=""nofollow"">NHibernate</a>.</p>
"
886,398680,1,4,sql,Data Access Library Return DataSet or Object,"<p>Is there a general consensus out there for when working with library's that call stored procedures?  Return datasets or use sqldatareader to populate custom objects?</p>

<p>Is the cost of serialization your Data Transport Object less then a DataSet?</p>
","<p>I'd have to agree with Justice, not necessarily about NHibernate (altho it's a great option) I would definately look at using some sort of ORM like NHibernate, Subsonic, Linq-to-sql, llblgen or any other one of the ORMs around.</p>

<p>As <a href=""http://codebetter.com/blogs/jeremy.miller/archive/2008/11/07/how-to-design-your-data-connectivity-strategy.aspx"" rel=""nofollow"">Jeremy Miller states:</a></p>

<blockquote>
  <p>if you're writing ADO.Net code by
  hand, you're stealing from your
  employer or client.</p>
</blockquote>

<p>and to that end, I'd have to recommend returning objects as opposed to datasets or datatables.</p>

<p>Also, if you're returning datasets, unless you strongly type each dataset, you're going to have to write a lot of ""lifting"" code in your library to get the values out of the datasets. With an ORM and objects all that heavy lifting is done for you.</p>

<p>Finally, with Linq in c# you now get much better functionality for working with collections (aggregates, grouping, sorting, filtering etc) that may have given datasets the advantage.</p>
"
459,200810,1,4,sql,How can I do access control via an SQL table?,"<p>I'm trying to create an access control system. </p>

<p>Here's a stripped down example of what the table I'm trying to control access to looks like:</p>

<pre><code>things table:
id   group_id   name
1    1          thing 1
2    1          thing 2
3    1          thing 3
4    1          thing 4
5    2          thing 5
</code></pre>

<p>And the access control table looks like this:</p>

<pre><code>access table:
user_id  type   object_id  access
1        group  1          50
1        thing  1          10
1        thing  2          100
</code></pre>

<p>Access can be granted either by specifying the id of the 'thing' directly, or granted for an entire group of things by specifying a group id. In the above example, user 1 has been granted an access level of 50 to group 1, which should apply unless there are any other rules granting more specific access to an individual thing.</p>

<p>I need a query that returns a list of things (ids only is okay) along with the access level for a specific user. So using the example above I'd want something like this for user id 1:</p>

<pre><code>desired result:
thing_id   access
1          10
2          100
3          50   (things 3 and 4 have no specific access rule,
4          50   so this '50' is from the group rule)
5               (thing 5 has no rules at all, so although I 
                still want it in the output, there's no access
		level for it)
</code></pre>

<p>The closest I can come up with is this:</p>

<pre><code>SELECT * 
FROM things 
LEFT JOIN access ON 
	user_id = 1
	AND (
		(access.type = 'group' AND access.object_id = things.group_id)
		OR (access.type = 'thing' AND access.object_id = things.id)
	)
</code></pre>

<p>But that returns multiple rows, when I only want one for each row in the 'things' table. I'm not sure how to get down to a single row for each 'thing', or how to prioritise 'thing' rules over 'group' rules.</p>

<p>If it helps, the database I'm using is PostgreSQL.</p>

<p>Please feel free to leave a comment if there's any information I've missed out. </p>

<p>Thanks in advance!</p>
","<p>While there are several good answers, the most efficient would probably be something like this:</p>

<pre><code>SELECT things.id, things.group_id, things.name, max(access) 
FROM things 
LEFT JOIN access ON 
        user_id = 1 
        AND (
                (access.type = 'group' AND access.object_id = things.group_id)
                OR (access.type = 'thing' AND access.object_id = things.id)
        )
group by things.id, things.group_id, things.name
</code></pre>

<p>Which simply uses summarization added to you query to get what you're looking for.</p>
"
577,259650,4,4,sql,Is there danger of corruption in SQL Server 2000 databases when using SQL Server 2005 Management Studio?,"<p>In an interview for a SQL DBA position a while back, I mentioned I prefer the SQL 2005 Management Studio app vs. the old 2000 versions of Enterprise Manager / Query Analyzer. The DBA who was interviewing me said that they had experienced some sort of database corruption in their 2000 databases when making changes from the 2005 MS, so they always use Enterprise Manager now. </p>

<p>He was a bit vague, but I got the impression he was talking about some sort of corruption experienced when making server-wide or database-level setting changes, and not just routine SQL updates or something.</p>

<p>Anyone heard of anything like this? I didn't end up taking that position, so I can't follow up to get more info.</p>
","<p>I have never encountered this, in almost three years of using SQL Management Studio 2005 to manage SQL 2000 databases. There are a few tasks I still bounce back into EntMan for, but I've never had a database encounter even the minutest bit of corruption. (And background: As a consultant, I'm managing about 45 different databases for both client and internal projects; most are heavily hit, and only about a dozen are SQL2005 databases.)</p>
"
576,259650,9,4,sql,Is there danger of corruption in SQL Server 2000 databases when using SQL Server 2005 Management Studio?,"<p>In an interview for a SQL DBA position a while back, I mentioned I prefer the SQL 2005 Management Studio app vs. the old 2000 versions of Enterprise Manager / Query Analyzer. The DBA who was interviewing me said that they had experienced some sort of database corruption in their 2000 databases when making changes from the 2005 MS, so they always use Enterprise Manager now. </p>

<p>He was a bit vague, but I got the impression he was talking about some sort of corruption experienced when making server-wide or database-level setting changes, and not just routine SQL updates or something.</p>

<p>Anyone heard of anything like this? I didn't end up taking that position, so I can't follow up to get more info.</p>
","<p>Sounds like he was just was using that as an excuse for lack of experience with SQL 2005 Management Studio.  DBA's hate change.  lol.</p>
"
787,351340,0,4,sql,What's the shortest TSQL to concatenate a person's name which may contain nulls,"<p>3 fields: FirstName, MiddleName, LastName</p>

<p>Any field can be null, but I don't want extra spaces. Format should be ""First Middle Last"", ""First Last"", ""Last"", etc.</p>
","<pre><code>'""' + ltrim(rtrim(isnull(FirstName,''))) + ' ' + ltrim(rtrim(isnull(MiddleName,''))) + 
' ' + ltrim(rtrim(isnull(LastName,''))) + '"",""' + ltrim(rtrim(isnull(FirstName,''))) + 
' ' + ltrim(rtrim(isnull(LastName,''))) + '"",""' + ltrim(rtrim(isnull(LastName,''))) + 
'""'
</code></pre>

<p>ETC</p>
"
786,351340,7,4,sql,What's the shortest TSQL to concatenate a person's name which may contain nulls,"<p>3 fields: FirstName, MiddleName, LastName</p>

<p>Any field can be null, but I don't want extra spaces. Format should be ""First Middle Last"", ""First Last"", ""Last"", etc.</p>
","<p>Assuming by ""extra spaces"", you mean extra spaces inserted during the concatenation (which is a reasonable assumption, I think. If you have extra spaces in your data, you should clean it up):</p>

<pre><code>ISNULL(FirstName + ' ', '')  + ISNULL(MiddleName + ' ', '') + ISNULL(LastName, '')
</code></pre>

<p>works, since you'll add a space to the name - which if it's NULL yields NULL - which yields empty string.</p>

<p>Edit: If you don't count the SET OPTION - which can be a connection or db option:</p>

<pre><code>SET CONCAT_NULL_YIELDS_NULL OFF
LTRIM(FirstName + ' ' + NULLIF(MiddleName + ' ', ' ') + LastName)
</code></pre>

<p>is a tiny bit shorter, but a large bit uglier.</p>

<p>Edit2: Since you accepted the UDF answer - IMO, that's a bit of a cheat - here's some in the same vein:</p>

<pre><code>SELECT a FROM b
</code></pre>

<p>b is a view. ;) Or. a stored proc,</p>

<pre><code>EXEC c
</code></pre>

<p>But, since EXEC is optional:</p>

<pre><code>c
</code></pre>
"
785,351340,4,4,sql,What's the shortest TSQL to concatenate a person's name which may contain nulls,"<p>3 fields: FirstName, MiddleName, LastName</p>

<p>Any field can be null, but I don't want extra spaces. Format should be ""First Middle Last"", ""First Last"", ""Last"", etc.</p>
","<p>use a UDF: </p>

<pre><code>`Select udfConcatName(First, Middle, Last) from foo`
</code></pre>

<p>That way all your logic for concatenating names is in one place and once you've gotten it written it's short to call.</p>
"
460,200810,0,4,sql,How can I do access control via an SQL table?,"<p>I'm trying to create an access control system. </p>

<p>Here's a stripped down example of what the table I'm trying to control access to looks like:</p>

<pre><code>things table:
id   group_id   name
1    1          thing 1
2    1          thing 2
3    1          thing 3
4    1          thing 4
5    2          thing 5
</code></pre>

<p>And the access control table looks like this:</p>

<pre><code>access table:
user_id  type   object_id  access
1        group  1          50
1        thing  1          10
1        thing  2          100
</code></pre>

<p>Access can be granted either by specifying the id of the 'thing' directly, or granted for an entire group of things by specifying a group id. In the above example, user 1 has been granted an access level of 50 to group 1, which should apply unless there are any other rules granting more specific access to an individual thing.</p>

<p>I need a query that returns a list of things (ids only is okay) along with the access level for a specific user. So using the example above I'd want something like this for user id 1:</p>

<pre><code>desired result:
thing_id   access
1          10
2          100
3          50   (things 3 and 4 have no specific access rule,
4          50   so this '50' is from the group rule)
5               (thing 5 has no rules at all, so although I 
                still want it in the output, there's no access
		level for it)
</code></pre>

<p>The closest I can come up with is this:</p>

<pre><code>SELECT * 
FROM things 
LEFT JOIN access ON 
	user_id = 1
	AND (
		(access.type = 'group' AND access.object_id = things.group_id)
		OR (access.type = 'thing' AND access.object_id = things.id)
	)
</code></pre>

<p>But that returns multiple rows, when I only want one for each row in the 'things' table. I'm not sure how to get down to a single row for each 'thing', or how to prioritise 'thing' rules over 'group' rules.</p>

<p>If it helps, the database I'm using is PostgreSQL.</p>

<p>Please feel free to leave a comment if there's any information I've missed out. </p>

<p>Thanks in advance!</p>
","<p>Tony:</p>

<p>Not a bad solution, I like it, seems to work. Here's your query after minor tweaking:</p>

<pre><code>SELECT 
    things.*, 
    coalesce ( 
        (   SELECT access 
            FROM access 
            WHERE user_id = 1 
                AND type = 'thing' 
                AND object_id = things.id
        ), 
        (   SELECT access 
            FROM access 
            WHERE user_id = 1 
                AND type = 'group' 
                AND object_id = things.group_id 
        ) 
    ) AS access
    FROM things;
</code></pre>

<p>And the results look correct:</p>

<pre><code> id | group_id |  name   | access 
----+----------+---------+--------
  1 |        1 | thing 1 |     10
  2 |        1 | thing 2 |    100
  3 |        1 | thing 3 |     50
  4 |        1 | thing 4 |     50
  5 |        2 | thing 5 |
</code></pre>

<p>I do <em>completely</em> take the point about it not being an ideal schema. However, I am stuck with it to some extent.</p>

<p><hr /></p>

<p>Josef:</p>

<p>Your solution is very similar to the stuff I was playing with, and my instincts (such as they are) tell me that it should be possible to do it that way. Unfortunately it doesn't produce completely correct results:</p>

<pre><code> id | group_id |  name   | max 
----+----------+---------+-----
  1 |        1 | thing 1 |  50
  2 |        1 | thing 2 | 100
  3 |        1 | thing 3 |  50
  4 |        1 | thing 4 |  50
  5 |        2 | thing 5 |
</code></pre>

<p>The access level for 'thing 1' has taken the higher 'group' access value, rather than the more specific 'thing' access value of 10, which is what I'm after. I don't think there's a way to fix that within a <code>GROUP BY</code>, but if anyone has any suggestions I'm more than happy to be proven incorrect on that point.</p>
"
783,351340,10,4,sql,What's the shortest TSQL to concatenate a person's name which may contain nulls,"<p>3 fields: FirstName, MiddleName, LastName</p>

<p>Any field can be null, but I don't want extra spaces. Format should be ""First Middle Last"", ""First Last"", ""Last"", etc.</p>
","<pre><code>    LTRIM(RTRIM(
    LTRIM(RTRIM(ISNULL(FirstName, ''))) + ' ' + 
    LTRIM(RTRIM(ISNULL(MiddleName, ''))) + ' ' + 
    LTRIM(ISNULL(LastName, ''))
    ))
</code></pre>

<p>NOTE: This won't leave trailing or leading spaces. That's why it's a little bit uglier than other solutions.</p>
"
572,254410,2,4,sql,Storing video duration time in sql server,"<p>What's the most appropriate type used to store the duration time information of a video in sql server?</p>
","<p>It depends on how granular you need and if you have any constraints on a maximum time.  For example, would you need to know down to the millisecond of time duration or is 1 second granular enough?  The other thing to consider is how much data do you (or can you) store.</p>

<p>For SQL Server 2005, you have these constraints:</p>

<p>tinyint </p>

<ul>
<li>min = 0</li>
<li>max =255</li>
<li>Size = 1 byte</li>
</ul>

<p>smallint </p>

<ul>
<li>min = -2^15 (-32,768)</li>
<li>max= 2^15 - 1 (32,767)</li>
<li>Size = 2 bytes</li>
</ul>

<p>int </p>

<ul>
<li>min = -2^31 (-2,147,483,648)</li>
<li>max = 2^31 - 1 (2,147,483,647)</li>
<li>Size = 4 bytes</li>
</ul>

<p>bigint </p>

<ul>
<li>min = -2^63
(-9,223,372,036,854,775,808)</li>
<li>Max = 2^63 - 1
(9,223,372,036,854,775,807)</li>
<li>Size = 8 bytes</li>
</ul>
"
569,252230,0,4,sql,Stored procedures or inline queries?,"<p>First of all there is a <a href=""http://stackoverflow.com/questions/59880/are-stored-procedures-more-efficient-in-general-than-inline-statements-on-moder"">partial question</a> regarding this, but it is not exactly what I'm asking, so, bear with me and go for it.</p>

<p>My question is, after looking at what <a href=""http://subsonicproject.com/"" rel=""nofollow"">SubSonic</a> does and the excellent videos from Rob Connery I need to ask: <strong>Shall we use a tool like this and do Inline queries or</strong> shall we do the queries <strong>using</strong> a call to the <strong>stored procedure?</strong></p>

<p>I don't want to minimize any work from Rob (which I think it's amazing) but I just want your opinion on this cause I need to start a new project and I'm in the middle of the line; shall I use SubSonic (or other like tool, like NHibernate) or I just continue my method that is always call a stored procedure even if it's a simple as</p>

<pre><code>Select this, that from myTable where myStuff = StackOverflow;
</code></pre>
","<p>With Subsonic you will use inline, views and stored procedures. Subsonic makes data access easier, but you can't do everthing in a subsonic query. Though the latest version, 2.1 is getting better.</p>

<p>For basic CRUD operations, inline SQL will be straight forward. For more complex data needs, a view will need to be made and then you will do a Subsonic query on the view.</p>

<p>Stored procs are good for harder data computations and data retrieval. Set based retrieval is usually always faster then procedural processing.</p>

<p>Current Subsonic application uses all three options with great results.</p>
"
195,89820,-1,4,sql,How to reference a custom field in SQL,"<p>I am using mssql and am having trouble using a subquery. The real query is quite complicated, but it has the same structure as this:</p>

<pre><code>select 
  customerName, 
  customerId,
  (
    select count(*) 
    from Purchases 
    where Purchases.customerId=customerData.customerId
  ) as numberTransactions
from customerData
</code></pre>

<p>And what I want to do is order the table by the number of transactions, but when I use</p>

<pre><code>order by numberTransactions
</code></pre>

<p>It tells me there is no such field. Is it possible to do this? Should I be using some sort of special keyword, such as <code>this</code>, or <code>self</code>?</p>
","<p>You need to duplicate your logic. SQL Server isn't very smart at columns that you've named but aren't part of the dataset in your FROM statement.</p>

<p>So use</p>

<pre><code>select 
  customerName, 
  customerId,
  (
    select count(*) 
    from Purchases p
    where p.customerId = c.customerId
  ) as numberTransactions
from customerData c
order by (select count(*) from purchases p where p.customerID = c.customerid)
</code></pre>

<p>Also, use aliases, they make your code easier to read and maintain. ;)</p>
"
194,89820,4,4,sql,How to reference a custom field in SQL,"<p>I am using mssql and am having trouble using a subquery. The real query is quite complicated, but it has the same structure as this:</p>

<pre><code>select 
  customerName, 
  customerId,
  (
    select count(*) 
    from Purchases 
    where Purchases.customerId=customerData.customerId
  ) as numberTransactions
from customerData
</code></pre>

<p>And what I want to do is order the table by the number of transactions, but when I use</p>

<pre><code>order by numberTransactions
</code></pre>

<p>It tells me there is no such field. Is it possible to do this? Should I be using some sort of special keyword, such as <code>this</code>, or <code>self</code>?</p>
","<p>Do an inner join.  It's much easier and more readable.</p>

<pre><code>select 
customerName,
customerID,
count(*) as numberTransactions
from
    customerdata c inner join purchases p on c.customerID = p.customerID
group by customerName,customerID
order by numberTransactions

</code></pre>EDIT:  Hey Nathan,

You realize you can inner join this whole table as a sub right?

<pre><code>Select T.*, T2.*
From T inner join 
(select 
customerName,
customerID,
count(*) as numberTransactions
from
    customerdata c inner join purchases p on c.customerID = p.customerID
group by customerName,customerID
) T2 on T.CustomerID = T2.CustomerID
order by T2.numberTransactions
</code></pre>

<p>Or if that's no good you can construct your queries using temporary tables (#T1 etc)</p>
"
882,398680,0,4,sql,Data Access Library Return DataSet or Object,"<p>Is there a general consensus out there for when working with library's that call stored procedures?  Return datasets or use sqldatareader to populate custom objects?</p>

<p>Is the cost of serialization your Data Transport Object less then a DataSet?</p>
","<p>I also use the dataReader, but be aware, if you do, you must be careful to close it (and the connection it is using) as quickly as possible after you are done populating the custom object(s)...  One gotcha to watch for is that when you call OpenReader(), make sure you pass the optional parameter called CommandBehavior set to CommandBehavior.CloseConenction, or, even if you close the reader, the underlying connection will not be closed and released to the pool until it gets picked up by the GC, which can easily cause you to run out of available connections if you're calling multiple reader objects in a loop.</p>
"
193,89820,7,4,sql,How to reference a custom field in SQL,"<p>I am using mssql and am having trouble using a subquery. The real query is quite complicated, but it has the same structure as this:</p>

<pre><code>select 
  customerName, 
  customerId,
  (
    select count(*) 
    from Purchases 
    where Purchases.customerId=customerData.customerId
  ) as numberTransactions
from customerData
</code></pre>

<p>And what I want to do is order the table by the number of transactions, but when I use</p>

<pre><code>order by numberTransactions
</code></pre>

<p>It tells me there is no such field. Is it possible to do this? Should I be using some sort of special keyword, such as <code>this</code>, or <code>self</code>?</p>
","<p>use the field number, in this case:</p>

<pre><code>order by 3
</code></pre>
"
1048,486270,2,4,sql,What's the most efficient way to check the presence of a row in a table?,"<p>Say I want to check if a record in a MySQL table exists. I'd run a query, check the number of rows returned. If 0 rows do this, otherwise do that.</p>

<pre><code>SELECT * FROM table WHERE id=5
SELECT id FROM table WHERE id=5
</code></pre>

<p>Is there any difference at all between these two queries? Is effort spent in returning every column, or is effort spent in filtering out the columns we don't care about?</p>

<pre><code>SELECT COUNT(*) FROM table WHERE id=5
</code></pre>

<p>Is a whole new question. Would the server grab all the values and then count the values (harder than usual), or would it not bother grabbing anything and just increment a variable each time it finds a match (easier than usual)?</p>

<p>I think I'm making a lot of false assumptions about how MySQL works, but that's the meat of the question! Where am I wrong? Educate me, Stack Overflow!</p>
","<p>I would think this </p>

<pre><code>SELECT null FROM table WHERE id = 5 LIMIT 1;
</code></pre>

<p>would be faster than this</p>

<pre><code>SELECT 1 FROM table WHERE id = 5 LIMIT 1;
</code></pre>

<p>but the timer says the winner is ""SELECT 1"".</p>
"
1049,486270,4,4,sql,What's the most efficient way to check the presence of a row in a table?,"<p>Say I want to check if a record in a MySQL table exists. I'd run a query, check the number of rows returned. If 0 rows do this, otherwise do that.</p>

<pre><code>SELECT * FROM table WHERE id=5
SELECT id FROM table WHERE id=5
</code></pre>

<p>Is there any difference at all between these two queries? Is effort spent in returning every column, or is effort spent in filtering out the columns we don't care about?</p>

<pre><code>SELECT COUNT(*) FROM table WHERE id=5
</code></pre>

<p>Is a whole new question. Would the server grab all the values and then count the values (harder than usual), or would it not bother grabbing anything and just increment a variable each time it finds a match (easier than usual)?</p>

<p>I think I'm making a lot of false assumptions about how MySQL works, but that's the meat of the question! Where am I wrong? Educate me, Stack Overflow!</p>
","<p>The most explicit way would be</p>

<p>SELECT WHEN EXISTS (SELECT 1 FROM table WHERE id = 5) THEN 1 ELSE 0 END</p>

<p>If there is an index on (or starting with) id, it will only search, with maximum efficiency, for the first entry in the index it can find with that value. It won't read the record.</p>

<p>If you SELECT COUNT(*) (or COUNT anything else) it will, under the same circumstances, count the index entries, but not read the records.</p>

<p>If you SELECT *, it will read all the records.</p>
"
571,254410,1,4,sql,Storing video duration time in sql server,"<p>What's the most appropriate type used to store the duration time information of a video in sql server?</p>
","<p>I would store it as an INT representing the number of seconds, but I suppose it all depends what you need to do with the information in your database (you wouldn't want to have to convert it to HH:MM:SS or something else in your DB)</p>
"
782,351340,3,4,sql,What's the shortest TSQL to concatenate a person's name which may contain nulls,"<p>3 fields: FirstName, MiddleName, LastName</p>

<p>Any field can be null, but I don't want extra spaces. Format should be ""First Middle Last"", ""First Last"", ""Last"", etc.</p>
","<pre><code>LTRIM(RTRIM(ISNULL(FirstName, '') + ' ' + LTRIM(ISNULL(MiddleName, '') + ' ' + 
    ISNULL(LastName, ''))))
</code></pre>
"
574,254410,2,4,sql,Storing video duration time in sql server,"<p>What's the most appropriate type used to store the duration time information of a video in sql server?</p>
","<p>Just store it as a DateTime - you get sorting, formatting and calculations built-in.</p>
"
573,254410,2,4,sql,Storing video duration time in sql server,"<p>What's the most appropriate type used to store the duration time information of a video in sql server?</p>
","<p>There are <a href=""http://www.sqlteam.com/article/working-with-time-spans-and-durations-in-sql-server"" rel=""nofollow"">several options</a>, including using the builtin DateTime or Time data type with offset from a particular fixed zero (which will allow you to use the built-in date/time function to get hours, minutes and seconds, etc.</p>

<p>If you were on pre-SQL Server 2005, you could combine it with a <a href=""http://weblogs.sqlteam.com/jeffs/archive/2004/12/02/2959.aspx"" rel=""nofollow"">user-defined data type technique</a> (if your spans are less than 24 hours) to constrain the date part to be guaranteed not to wander.</p>
"
351,150610,0,3,sql,Selecting unique rows in a set of two possibilities,"<p>The problem itself is simple, but I can't figure out a solution that does it in one query, and here's my ""abstraction"" of the problem to allow for a simpler explanation:</p>

<p><strong>I will let my original explenation stand, but here's a set of sample data and the result i expect:</strong></p>

<p>Ok, so here's some sample data, i separated pairs by a blank line</p>

<pre><code>-------------
| Key |  Col | (Together they from a Unique Pair)
--------------
|  1     Foo |
|  1     Bar |
|            |
|  2     Foo |
|            |
|  3     Bar |
|            |
|  4     Foo |
|  4     Bar |
--------------
</code></pre>

<p>And the result I would expect, <strong>after running the query once</strong>, it need to be able to select this result set in one query:</p>

<pre><code>1 - Foo
2 - Foo
3 - Bar
4 - Foo
</code></pre>

<p><em>Original explenation:</em></p>

<p>I have a table, call it <code>TABLE</code> where I have a two columns say <code>ID</code> and <code>NAME</code> which together form the primary key of the table. Now I want to select something where <code>ID=1</code> and then first checks if it can find a row where <code>NAME</code> has the value ""John"", if ""John"" does not exist it should look for a row where <code>NAME</code> is ""Bruce"" - but only return ""John"" if both ""Bruce"" and ""John"" exists or only ""John"" exists of course.</p>

<p>Also note that it should be able to return several rows per query that match the above criteria but with different ID/Name-combinations of course, and that the above explanation is just a simplification of the real problem.</p>

<p>I could be completely blinded by my own code and line of thought but I just can't figure this out. </p>
","<p>Ok, so here's some sample data, i separated pairs by a blank line</p>

<pre><code>-------------
| Key |  Col | (Together they from a Unique Pair)
--------------
|  1     Foo |
|  1     Bar |
|            |
|  2     Foo |
|            |
|  3     Bar |
|            |
|  4     Foo |
|  4     Bar |
--------------
</code></pre>

<p>And the result I would expect:</p>

<pre><code>1 - Foo
2 - Foo
3 - Bar
4 - Foo
</code></pre>

<p>I did solve it above, but that query is horribly inefficient for lager tables, any other way?</p>
"
106,38680,0,3,sql,How to provide next page of updated content?,"<p>Feel free to edit the title if you know how to formulate the question better. (Tagging is a problem as well.) The problem may be too difficult in this general form, so let us consider a concrete example.</p>

<p>You get a screenful of stackoverflow questions by requesting <code>/questions ?sort=newest</code> page. Next page link leads to <code>/questions?page=2 &amp;sort=newest</code>. I suppose that at server side, the request is translated into an SQL query with LIMIT clause. Problem with this approach is, that if new question were added while user browses first page, his second page will start with some questions he already saw. (If he has 10 question per page, and 10 new questions happened to be added, hell get exactly the same content second time!)</p>

<p>Is there an elegant way to solve this common problem? I realize that it is not that big a problem, at least not for stackoverflow, but still.</p>

<p>The best idea I have (apart from storing request history per client) is to use <code>/questions?answer_id=NNN</code> format. Server returns a page that starts with the requested answer, and puts the id of the first answer on the next page into next page link. There must be a way to write SQL for that, right? </p>

<p>Is it how it usually done? Or there is a better way?</p>
","<p>Tag each question with its time entered into the database, carry the time the frontpage was last loaded as a cookie or part of the URL, and limit the search to items <code>n</code> through <code>n+displaynum</code> as you go forward.</p>

<p>But I wouldn't bother. This behavior is uniform enough that most users expect it, and it serves as a flag for when new data is becoming available. You can even open a new tab/window that starts back at the top of the list to see what has come up.</p>
"
350,150610,0,3,sql,Selecting unique rows in a set of two possibilities,"<p>The problem itself is simple, but I can't figure out a solution that does it in one query, and here's my ""abstraction"" of the problem to allow for a simpler explanation:</p>

<p><strong>I will let my original explenation stand, but here's a set of sample data and the result i expect:</strong></p>

<p>Ok, so here's some sample data, i separated pairs by a blank line</p>

<pre><code>-------------
| Key |  Col | (Together they from a Unique Pair)
--------------
|  1     Foo |
|  1     Bar |
|            |
|  2     Foo |
|            |
|  3     Bar |
|            |
|  4     Foo |
|  4     Bar |
--------------
</code></pre>

<p>And the result I would expect, <strong>after running the query once</strong>, it need to be able to select this result set in one query:</p>

<pre><code>1 - Foo
2 - Foo
3 - Bar
4 - Foo
</code></pre>

<p><em>Original explenation:</em></p>

<p>I have a table, call it <code>TABLE</code> where I have a two columns say <code>ID</code> and <code>NAME</code> which together form the primary key of the table. Now I want to select something where <code>ID=1</code> and then first checks if it can find a row where <code>NAME</code> has the value ""John"", if ""John"" does not exist it should look for a row where <code>NAME</code> is ""Bruce"" - but only return ""John"" if both ""Bruce"" and ""John"" exists or only ""John"" exists of course.</p>

<p>Also note that it should be able to return several rows per query that match the above criteria but with different ID/Name-combinations of course, and that the above explanation is just a simplification of the real problem.</p>

<p>I could be completely blinded by my own code and line of thought but I just can't figure this out. </p>
","<p>I came up with a solution myself, but it's kind of complex and slow - nor does it expand well to more advanced queries:</p>

<pre><code>SELECT *
FROM users
WHERE name = ""bruce""
OR (
    name = ""john""
    AND NOT id
    IN (
        SELECT id
        FROM posts
        WHERE name = ""bruce""
    )
)
</code></pre>

<p>No alternatives without heavy joins, etc. ?</p>
"
346,150610,-1,3,sql,Selecting unique rows in a set of two possibilities,"<p>The problem itself is simple, but I can't figure out a solution that does it in one query, and here's my ""abstraction"" of the problem to allow for a simpler explanation:</p>

<p><strong>I will let my original explenation stand, but here's a set of sample data and the result i expect:</strong></p>

<p>Ok, so here's some sample data, i separated pairs by a blank line</p>

<pre><code>-------------
| Key |  Col | (Together they from a Unique Pair)
--------------
|  1     Foo |
|  1     Bar |
|            |
|  2     Foo |
|            |
|  3     Bar |
|            |
|  4     Foo |
|  4     Bar |
--------------
</code></pre>

<p>And the result I would expect, <strong>after running the query once</strong>, it need to be able to select this result set in one query:</p>

<pre><code>1 - Foo
2 - Foo
3 - Bar
4 - Foo
</code></pre>

<p><em>Original explenation:</em></p>

<p>I have a table, call it <code>TABLE</code> where I have a two columns say <code>ID</code> and <code>NAME</code> which together form the primary key of the table. Now I want to select something where <code>ID=1</code> and then first checks if it can find a row where <code>NAME</code> has the value ""John"", if ""John"" does not exist it should look for a row where <code>NAME</code> is ""Bruce"" - but only return ""John"" if both ""Bruce"" and ""John"" exists or only ""John"" exists of course.</p>

<p>Also note that it should be able to return several rows per query that match the above criteria but with different ID/Name-combinations of course, and that the above explanation is just a simplification of the real problem.</p>

<p>I could be completely blinded by my own code and line of thought but I just can't figure this out. </p>
","<p>You can use joins instead of the exists and this may improve the query plan in cases where the optimizer is not smart enough:</p>

<pre><code>SELECT f1.id
  ,f1.col
FROM foo f1 
LEFT JOIN foo f2
  ON f1.id = f2.id
  AND f2.col = 'Foo'
WHERE f1.col = 'Foo' 
  OR ( f1.col = 'Bar' AND f2.id IS NULL )
</code></pre>
"
347,150610,0,3,sql,Selecting unique rows in a set of two possibilities,"<p>The problem itself is simple, but I can't figure out a solution that does it in one query, and here's my ""abstraction"" of the problem to allow for a simpler explanation:</p>

<p><strong>I will let my original explenation stand, but here's a set of sample data and the result i expect:</strong></p>

<p>Ok, so here's some sample data, i separated pairs by a blank line</p>

<pre><code>-------------
| Key |  Col | (Together they from a Unique Pair)
--------------
|  1     Foo |
|  1     Bar |
|            |
|  2     Foo |
|            |
|  3     Bar |
|            |
|  4     Foo |
|  4     Bar |
--------------
</code></pre>

<p>And the result I would expect, <strong>after running the query once</strong>, it need to be able to select this result set in one query:</p>

<pre><code>1 - Foo
2 - Foo
3 - Bar
4 - Foo
</code></pre>

<p><em>Original explenation:</em></p>

<p>I have a table, call it <code>TABLE</code> where I have a two columns say <code>ID</code> and <code>NAME</code> which together form the primary key of the table. Now I want to select something where <code>ID=1</code> and then first checks if it can find a row where <code>NAME</code> has the value ""John"", if ""John"" does not exist it should look for a row where <code>NAME</code> is ""Bruce"" - but only return ""John"" if both ""Bruce"" and ""John"" exists or only ""John"" exists of course.</p>

<p>Also note that it should be able to return several rows per query that match the above criteria but with different ID/Name-combinations of course, and that the above explanation is just a simplification of the real problem.</p>

<p>I could be completely blinded by my own code and line of thought but I just can't figure this out. </p>
","<p>try this:</p>

<pre><code>select top 1 * from (
SELECT 1 as num, * FROM TABLE WHERE ID = 1 AND NAME = 'John'
union 
SELECT 2 as num, * FROM TABLE WHERE ID = 1 AND NAME = 'Bruce'
) t
order by num
</code></pre>
"
349,150610,-1,3,sql,Selecting unique rows in a set of two possibilities,"<p>The problem itself is simple, but I can't figure out a solution that does it in one query, and here's my ""abstraction"" of the problem to allow for a simpler explanation:</p>

<p><strong>I will let my original explenation stand, but here's a set of sample data and the result i expect:</strong></p>

<p>Ok, so here's some sample data, i separated pairs by a blank line</p>

<pre><code>-------------
| Key |  Col | (Together they from a Unique Pair)
--------------
|  1     Foo |
|  1     Bar |
|            |
|  2     Foo |
|            |
|  3     Bar |
|            |
|  4     Foo |
|  4     Bar |
--------------
</code></pre>

<p>And the result I would expect, <strong>after running the query once</strong>, it need to be able to select this result set in one query:</p>

<pre><code>1 - Foo
2 - Foo
3 - Bar
4 - Foo
</code></pre>

<p><em>Original explenation:</em></p>

<p>I have a table, call it <code>TABLE</code> where I have a two columns say <code>ID</code> and <code>NAME</code> which together form the primary key of the table. Now I want to select something where <code>ID=1</code> and then first checks if it can find a row where <code>NAME</code> has the value ""John"", if ""John"" does not exist it should look for a row where <code>NAME</code> is ""Bruce"" - but only return ""John"" if both ""Bruce"" and ""John"" exists or only ""John"" exists of course.</p>

<p>Also note that it should be able to return several rows per query that match the above criteria but with different ID/Name-combinations of course, and that the above explanation is just a simplification of the real problem.</p>

<p>I could be completely blinded by my own code and line of thought but I just can't figure this out. </p>
","<p>In PostgreSQL, I believe it would be this:</p>

<pre><code>SELECT DISTINCT ON (id) id, name
FROM mytable
ORDER BY id, name = 'John' DESC;
</code></pre>

<p>Update - false sorts before true - I had it backwards originally. Note that DISTINCT ON is a PostgreSQL feature and not part of standard SQL. What happens here is that it only shows you the first row for any given id that it comes across. Since we order by weather the name is John, rows named John will be selected over all other names.</p>

<p>With your second example, it would be:</p>

<pre><code>SELECT DISTINCT ON (key) key, col
FROM mytable
ORDER BY key, col = 'Foo' DESC;
</code></pre>

<p>This will give you:</p>

<pre><code>1 - Foo
2 - Foo
3 - Bar
4 - Foo
</code></pre>
"
348,150610,1,3,sql,Selecting unique rows in a set of two possibilities,"<p>The problem itself is simple, but I can't figure out a solution that does it in one query, and here's my ""abstraction"" of the problem to allow for a simpler explanation:</p>

<p><strong>I will let my original explenation stand, but here's a set of sample data and the result i expect:</strong></p>

<p>Ok, so here's some sample data, i separated pairs by a blank line</p>

<pre><code>-------------
| Key |  Col | (Together they from a Unique Pair)
--------------
|  1     Foo |
|  1     Bar |
|            |
|  2     Foo |
|            |
|  3     Bar |
|            |
|  4     Foo |
|  4     Bar |
--------------
</code></pre>

<p>And the result I would expect, <strong>after running the query once</strong>, it need to be able to select this result set in one query:</p>

<pre><code>1 - Foo
2 - Foo
3 - Bar
4 - Foo
</code></pre>

<p><em>Original explenation:</em></p>

<p>I have a table, call it <code>TABLE</code> where I have a two columns say <code>ID</code> and <code>NAME</code> which together form the primary key of the table. Now I want to select something where <code>ID=1</code> and then first checks if it can find a row where <code>NAME</code> has the value ""John"", if ""John"" does not exist it should look for a row where <code>NAME</code> is ""Bruce"" - but only return ""John"" if both ""Bruce"" and ""John"" exists or only ""John"" exists of course.</p>

<p>Also note that it should be able to return several rows per query that match the above criteria but with different ID/Name-combinations of course, and that the above explanation is just a simplification of the real problem.</p>

<p>I could be completely blinded by my own code and line of thought but I just can't figure this out. </p>
","<p>You can join the initial table to itself with an OUTER JOIN like this:</p>

<pre><code>create table #mytest
   (
   id           int,
   Name         varchar(20)
   );
go

insert into #mytest values (1,'Foo');
insert into #mytest values (1,'Bar');
insert into #mytest values (2,'Foo');
insert into #mytest values (3,'Bar');
insert into #mytest values (4,'Foo');
insert into #mytest values (4,'Bar');
go

select distinct
   sc.id,
   isnull(fc.Name, sc.Name) sel_name
from
   #mytest sc

   LEFT OUTER JOIN #mytest fc
      on (fc.id = sc.id
          and fc.Name = 'Foo')
</code></pre>

<p>like that.</p>
"
267,122990,2,3,sql,"how to determine if a record in every source, represents the same person","<p>I have several sources of tables with personal data, like this:</p>

<pre><code>SOURCE 1
ID, FIRST_NAME, LAST_NAME, FIELD1, ...
1, jhon, gates ...

SOURCE 2
ID, FIRST_NAME, LAST_NAME, ANOTHER_FIELD1, ...
1, jon, gate ...

SOURCE 3
ID, FIRST_NAME, LAST_NAME, ANOTHER_FIELD1, ...
2, jhon, ballmer ...
</code></pre>

<p>So, assuming that records with ID 1, from sources 1 and 2, are the same person, my problem <strong>is how to determine if a record in every source, represents the same person</strong>. Additionally, sure not every records exists in all sources. All the names, are written in spanish, mainly.</p>

<p>In this case, the exact matching needs to be relaxed because we assume <em>the data sources has not been rigurously checked</em> against the official bureau of identification of the country. Also we need to assume <em>typos are common</em>, because the nature of the processes to collect the data. What is more, the amount of records is around 2 or 3 millions in every source...</p>

<p>Our team had thought in something like this: first, force exact matching in selected fields like ID NUMBER, and NAMES to know how hard the problem can be. Second, relaxing the matching criteria, and count how much records more can be matched, but is here where the problem arises: <strong>how to do to relax the matching criteria without generating too noise neither restricting too much?</strong></p>

<p>What tool can be more effective to handle this?, for example, do you know about some especific extension in some database engine to support this matching?
Do you know about clever algorithms like <a href=""http://en.wikipedia.org/wiki/Soundex"" rel=""nofollow"">soundex</a> to handle this approximate matching, but for spanish texts?</p>

<p>Any help would be appreciated!</p>

<p>Thanks.</p>
","<p>SSIS , try using the Fuzzy Lookup transformation</p>
"
268,122990,3,3,sql,"how to determine if a record in every source, represents the same person","<p>I have several sources of tables with personal data, like this:</p>

<pre><code>SOURCE 1
ID, FIRST_NAME, LAST_NAME, FIELD1, ...
1, jhon, gates ...

SOURCE 2
ID, FIRST_NAME, LAST_NAME, ANOTHER_FIELD1, ...
1, jon, gate ...

SOURCE 3
ID, FIRST_NAME, LAST_NAME, ANOTHER_FIELD1, ...
2, jhon, ballmer ...
</code></pre>

<p>So, assuming that records with ID 1, from sources 1 and 2, are the same person, my problem <strong>is how to determine if a record in every source, represents the same person</strong>. Additionally, sure not every records exists in all sources. All the names, are written in spanish, mainly.</p>

<p>In this case, the exact matching needs to be relaxed because we assume <em>the data sources has not been rigurously checked</em> against the official bureau of identification of the country. Also we need to assume <em>typos are common</em>, because the nature of the processes to collect the data. What is more, the amount of records is around 2 or 3 millions in every source...</p>

<p>Our team had thought in something like this: first, force exact matching in selected fields like ID NUMBER, and NAMES to know how hard the problem can be. Second, relaxing the matching criteria, and count how much records more can be matched, but is here where the problem arises: <strong>how to do to relax the matching criteria without generating too noise neither restricting too much?</strong></p>

<p>What tool can be more effective to handle this?, for example, do you know about some especific extension in some database engine to support this matching?
Do you know about clever algorithms like <a href=""http://en.wikipedia.org/wiki/Soundex"" rel=""nofollow"">soundex</a> to handle this approximate matching, but for spanish texts?</p>

<p>Any help would be appreciated!</p>

<p>Thanks.</p>
","<p>This sounds like a <a href=""http://en.wikipedia.org/wiki/Customer_Data_Integration"" rel=""nofollow"">Customer Data Integration</a> problem. Search on that term and you might find some more information. Also, have a poke around inside <a href=""http://www.tdwi.org/"" rel=""nofollow"">The Data Warehousing Institude</a>, and you might find some answers there as well.</p>

<p><strong>Edit:</strong> In addition, <a href=""http://www.javalobby.org/java/forums/t16936.html"" rel=""nofollow"">here's</a> an article that might interest you on spanish phonetic matching.</p>
"
269,122990,3,3,sql,"how to determine if a record in every source, represents the same person","<p>I have several sources of tables with personal data, like this:</p>

<pre><code>SOURCE 1
ID, FIRST_NAME, LAST_NAME, FIELD1, ...
1, jhon, gates ...

SOURCE 2
ID, FIRST_NAME, LAST_NAME, ANOTHER_FIELD1, ...
1, jon, gate ...

SOURCE 3
ID, FIRST_NAME, LAST_NAME, ANOTHER_FIELD1, ...
2, jhon, ballmer ...
</code></pre>

<p>So, assuming that records with ID 1, from sources 1 and 2, are the same person, my problem <strong>is how to determine if a record in every source, represents the same person</strong>. Additionally, sure not every records exists in all sources. All the names, are written in spanish, mainly.</p>

<p>In this case, the exact matching needs to be relaxed because we assume <em>the data sources has not been rigurously checked</em> against the official bureau of identification of the country. Also we need to assume <em>typos are common</em>, because the nature of the processes to collect the data. What is more, the amount of records is around 2 or 3 millions in every source...</p>

<p>Our team had thought in something like this: first, force exact matching in selected fields like ID NUMBER, and NAMES to know how hard the problem can be. Second, relaxing the matching criteria, and count how much records more can be matched, but is here where the problem arises: <strong>how to do to relax the matching criteria without generating too noise neither restricting too much?</strong></p>

<p>What tool can be more effective to handle this?, for example, do you know about some especific extension in some database engine to support this matching?
Do you know about clever algorithms like <a href=""http://en.wikipedia.org/wiki/Soundex"" rel=""nofollow"">soundex</a> to handle this approximate matching, but for spanish texts?</p>

<p>Any help would be appreciated!</p>

<p>Thanks.</p>
","<p>I've had to do something similar before and what I did was use a <a href=""http://en.wikipedia.org/wiki/Double_Metaphone"" rel=""nofollow"">double metaphone</a> phonetic search on the names.  </p>

<p>Before I compared the names though, I tried to normalize away any name/nickname differences by looking up the name in a nick name table I created. (I populated the table with census data I found online)  So people called Bob became Robert, Alex became Alexander, Bill became William, etc.  </p>

<p><strong>Edit</strong>: Double Metaphone was specifically designed to be better than Soundex and work in languages other than English.</p>
"
270,122990,3,3,sql,"how to determine if a record in every source, represents the same person","<p>I have several sources of tables with personal data, like this:</p>

<pre><code>SOURCE 1
ID, FIRST_NAME, LAST_NAME, FIELD1, ...
1, jhon, gates ...

SOURCE 2
ID, FIRST_NAME, LAST_NAME, ANOTHER_FIELD1, ...
1, jon, gate ...

SOURCE 3
ID, FIRST_NAME, LAST_NAME, ANOTHER_FIELD1, ...
2, jhon, ballmer ...
</code></pre>

<p>So, assuming that records with ID 1, from sources 1 and 2, are the same person, my problem <strong>is how to determine if a record in every source, represents the same person</strong>. Additionally, sure not every records exists in all sources. All the names, are written in spanish, mainly.</p>

<p>In this case, the exact matching needs to be relaxed because we assume <em>the data sources has not been rigurously checked</em> against the official bureau of identification of the country. Also we need to assume <em>typos are common</em>, because the nature of the processes to collect the data. What is more, the amount of records is around 2 or 3 millions in every source...</p>

<p>Our team had thought in something like this: first, force exact matching in selected fields like ID NUMBER, and NAMES to know how hard the problem can be. Second, relaxing the matching criteria, and count how much records more can be matched, but is here where the problem arises: <strong>how to do to relax the matching criteria without generating too noise neither restricting too much?</strong></p>

<p>What tool can be more effective to handle this?, for example, do you know about some especific extension in some database engine to support this matching?
Do you know about clever algorithms like <a href=""http://en.wikipedia.org/wiki/Soundex"" rel=""nofollow"">soundex</a> to handle this approximate matching, but for spanish texts?</p>

<p>Any help would be appreciated!</p>

<p>Thanks.</p>
","<p>The crux of the problem is to compute one or more measures of distance between each pair of entries and then consider them to be the same when one of the distances is less than a certain acceptable threshold.  The key is to setup the analysis and then vary the acceptable distance until you reach what you consider to be the best trade-off between false-positives and false-negatives.</p>

<p>One distance measurement could be phonetic.  Another you might consider is the <a href=""http://en.wikipedia.org/wiki/Levenshtein_distance"" rel=""nofollow"">Levenshtein or edit distance</a> between the entires, which would attempt to measure typos.</p>

<p>If you have a reasonable idea of how many persons you should have, then your goal is to find the sweet spot where you are getting about the right number of persons.  Make your matching too fuzzy and you'll have too few.  Make it to restrictive and you'll have too many.</p>

<p>If you know roughly how many entries a person should have, then you can use that as the metric to see when you are getting close.  Or you can divide the number of records into the average number of records for each person and get a rough number of persons that you're shooting for.</p>

<p>If you don't have any numbers to use, then you're left picking out groups of records from your analysis and checking by hand whether they look like the same person or not.  So it's guess and check.</p>

<p>I hope that helps.</p>
"
271,122990,1,3,sql,"how to determine if a record in every source, represents the same person","<p>I have several sources of tables with personal data, like this:</p>

<pre><code>SOURCE 1
ID, FIRST_NAME, LAST_NAME, FIELD1, ...
1, jhon, gates ...

SOURCE 2
ID, FIRST_NAME, LAST_NAME, ANOTHER_FIELD1, ...
1, jon, gate ...

SOURCE 3
ID, FIRST_NAME, LAST_NAME, ANOTHER_FIELD1, ...
2, jhon, ballmer ...
</code></pre>

<p>So, assuming that records with ID 1, from sources 1 and 2, are the same person, my problem <strong>is how to determine if a record in every source, represents the same person</strong>. Additionally, sure not every records exists in all sources. All the names, are written in spanish, mainly.</p>

<p>In this case, the exact matching needs to be relaxed because we assume <em>the data sources has not been rigurously checked</em> against the official bureau of identification of the country. Also we need to assume <em>typos are common</em>, because the nature of the processes to collect the data. What is more, the amount of records is around 2 or 3 millions in every source...</p>

<p>Our team had thought in something like this: first, force exact matching in selected fields like ID NUMBER, and NAMES to know how hard the problem can be. Second, relaxing the matching criteria, and count how much records more can be matched, but is here where the problem arises: <strong>how to do to relax the matching criteria without generating too noise neither restricting too much?</strong></p>

<p>What tool can be more effective to handle this?, for example, do you know about some especific extension in some database engine to support this matching?
Do you know about clever algorithms like <a href=""http://en.wikipedia.org/wiki/Soundex"" rel=""nofollow"">soundex</a> to handle this approximate matching, but for spanish texts?</p>

<p>Any help would be appreciated!</p>

<p>Thanks.</p>
","<p>Just to add some details to solve this issue, I'd found this modules for Postgresql 8.3</p>

<ul>
<li><a href=""http://www.postgresql.org/docs/8.3/static/fuzzystrmatch.html"" rel=""nofollow"">Fuzzy String Match</a></li>
<li><a href=""http://www.postgresql.org/docs/8.3/static/pgtrgm.html"" rel=""nofollow"">Trigrams</a></li>
</ul>
"
546,246080,3,3,sql,EBNF to fluent interface,"<p>I have recently had the need to write a fluent interface for C# that will essentially mirror SQL.  Yes, I am aware of LINQ to SQL, but I'm interesting in getting ""closer to the metal""--having something that essentially provides nothing more than an Intellisensified SQL shim <em>within</em> C#.</p>

<p>E.g.,</p>

<pre><code>var fq = new FluentQuery();
Expression&lt;Action&gt; =
    () =&gt; fq.SELECT.DISTINCT(Foo.ID).FROM(Foo).WHERE(Foo.Age &gt; 22);
</code></pre>

<p>Now, I was thinking that this concept could be generalised--that is, how about a general EBNF to fluent interface generator?  Does anyone know if such a beast exists?</p>
","<p>I like it, but you have to make sure to return types like HasFromAndSelect or something like that so you don't end up with <code>fq.SELECT(Foo.ID).SELECT(Foo.Age).WHERE(Foo.Age &gt; 22)</code> or <code>fq.WHERE(Foo.Age &gt; 22).SELECT(Foo.ID)</code>, etc.</p>

<p>There's much more thought that needs to go into this, including the fact that the CAPS LOCK MODE is hurting my eyes :)</p>
"
272,122990,0,3,sql,"how to determine if a record in every source, represents the same person","<p>I have several sources of tables with personal data, like this:</p>

<pre><code>SOURCE 1
ID, FIRST_NAME, LAST_NAME, FIELD1, ...
1, jhon, gates ...

SOURCE 2
ID, FIRST_NAME, LAST_NAME, ANOTHER_FIELD1, ...
1, jon, gate ...

SOURCE 3
ID, FIRST_NAME, LAST_NAME, ANOTHER_FIELD1, ...
2, jhon, ballmer ...
</code></pre>

<p>So, assuming that records with ID 1, from sources 1 and 2, are the same person, my problem <strong>is how to determine if a record in every source, represents the same person</strong>. Additionally, sure not every records exists in all sources. All the names, are written in spanish, mainly.</p>

<p>In this case, the exact matching needs to be relaxed because we assume <em>the data sources has not been rigurously checked</em> against the official bureau of identification of the country. Also we need to assume <em>typos are common</em>, because the nature of the processes to collect the data. What is more, the amount of records is around 2 or 3 millions in every source...</p>

<p>Our team had thought in something like this: first, force exact matching in selected fields like ID NUMBER, and NAMES to know how hard the problem can be. Second, relaxing the matching criteria, and count how much records more can be matched, but is here where the problem arises: <strong>how to do to relax the matching criteria without generating too noise neither restricting too much?</strong></p>

<p>What tool can be more effective to handle this?, for example, do you know about some especific extension in some database engine to support this matching?
Do you know about clever algorithms like <a href=""http://en.wikipedia.org/wiki/Soundex"" rel=""nofollow"">soundex</a> to handle this approximate matching, but for spanish texts?</p>

<p>Any help would be appreciated!</p>

<p>Thanks.</p>
","<p>You might try to cannonicalise the names by comparing them with a dicionary.<br />
This would allow you to spot some common typos and correct them.  </p>
"
820,358630,5,3,sql,How to Search date in SQL?,"<p>I am having an Event Management System in which i want,</p>

<p>If an event is registered for 5 days (21 jan 2009 to 26 Jan 2009) Then if another person wants to register an event between 22 jan 2009 to 24 jan 2009 then it will not allow to register. I want to check this using SQL query, so please tell me how can i do this.</p>
","<p>Just a to complete other answers, you have a good article on <strong><a href=""http://www.devarticles.com/c/a/SQL-Server/Date-and-Time-Values-Using-SQL-Server-2000/"" rel=""nofollow"">How to Search for Date and Time Values Using SQL Server 2000</a></strong> </p>

<p>It reminds you about how date/time values are stored (two date/time data types: datetime and smalldatetime)</p>

<p>It also points out Datetime and smalldatetime are like the floating-point data types, float and real, in that theyre approximate numerics. That means the value retrieved from SQL Server may be different from the value that was originally stored.</p>

<p>Plus, it warns about Database designers who dont always use date/time columns appropriately. At the time the database is designed, each date/time column should be identified as to whether it will store both dates and times, dates only, or times only.</p>

<p>It closes with <a href=""http://www.devarticles.com/c/a/SQL-Server/Date-and-Time-Values-Using-SQL-Server-2000/6/"" rel=""nofollow"">practical queries on data/time</a>.</p>

<p>You also have a good description of <a href=""http://searchsqlserver.techtarget.com/tip/0,289483,sid87_gci1333669,00.html#"" rel=""nofollow"">DATEADD and DATEDIFF here</a>.</p>
"
324,147670,5,3,sql,Get list of available servers in SQL server group,"<p>How can I extract the list of available SQL servers in an SQL server group? I'm planning to put that list in a combo box in VB.NET.</p>
","<p>If you didn't want to be tied to SQL SMO, which is what Ben's article uses, you can do something like this to discover all SQL servers on your network:</p>

<pre><code>Private Sub cmbServer_DropDown(ByVal sender As Object, ByVal e As System.EventArgs) Handles cmbServer.DropDown
    Dim oTable As Data.DataTable
    Dim lstServers As List(Of String)
    Try
        If cmbServer.Items.Count = 0 Then
            System.Windows.Forms.Cursor.Current = System.Windows.Forms.Cursors.WaitCursor
            oTable = System.Data.Sql.SqlDataSourceEnumerator.Instance.GetDataSources

            For Each oRow As DataRow In oTable.Rows
                If oRow(""InstanceName"").ToString = """" Then
                    cmbServer.Items.Add(oRow(""ServerName""))
                Else
                    cmbServer.Items.Add(oRow(""ServerName"").ToString &amp; ""\"" &amp; oRow(""InstanceName"").ToString)
                End If
            Next oRow
        End If
    Catch ex As Exception
        ErrHandler(""frmLogin"", ""cmbServer_DropDown"", ex.Source, ex.Message, Ex.InnerException)
    Finally
        System.Windows.Forms.Cursor.Current = System.Windows.Forms.Cursors.Default

        If oTable IsNot Nothing Then
            oTable.Dispose()
        End If
    End Try
End Sub
</code></pre>

<p>The SqlDataSourceEnumerator class is nice because it gives you SQL server discovery right out of the 2.0 framework.</p>
"
323,147670,0,3,sql,Get list of available servers in SQL server group,"<p>How can I extract the list of available SQL servers in an SQL server group? I'm planning to put that list in a combo box in VB.NET.</p>
","<p>In C# I've used calls to odbc32.dll</p>

<p>For example:</p>

<pre><code>[DllImport(""odbc32.dll"", CharSet = CharSet.Ansi)]

private static extern short SQLBrowseConnect(
IntPtr hconn, StringBuilder inString,
short inStringLength, StringBuilder outString, short outStringLength, out short 
outLengthNeeded);
</code></pre>

<p>Documentation for that function is on <a href=""http://msdn.microsoft.com/en-us/library/ms130926.aspx"" rel=""nofollow"">MSDN</a> </p>
"
234,104330,2,3,sql,SQL Query Help: Transforming Dates In A Non-Trivial Way,"<p>I have a table with a ""Date"" column, and I would like to do a query that does the following:</p>

<p>If the date is a <strong>Monday</strong>, <strong>Tuesday</strong>, <strong>Wednesday</strong>, or <strong>Thursday</strong>, the displayed date should be shifted up by 1 day, as in <pre>DATEADD(day, 1, [Date])</pre>  On the other hand, if it is a <strong>Friday</strong>, the displayed date should be incremented by 3 days (i.e. so it becomes the following <em>Monday</em>).</p>

<p>How do I do this in my SELECT statement?  As in,</p>

<pre>SELECT somewayofdoingthis([Date]) FROM myTable</pre>

<p>(This is SQL Server 2000.)</p>
","<p>I'm assuming that you also want Saturday and Sunday to shift forward to the following Monday. If that is not the case, take the 1 out of (1,2,3,4,5) and remove the last when clause.</p>

<pre><code>case
   --Sunday thru Thursday are shifted forward 1 day
   when datepart(weekday, [Date]) in (1,2,3,4,5) then dateadd(day, 1, [Date]) 
   --Friday is shifted forward to Monday
   when datepart(weekday, [Date]) = 6  then dateadd(day, 3, [Date])
   --Saturday is shifted forward to Monday
   when datepart(weekday, [Date]) = 7  then dateadd(day, 2, [Date])
end
</code></pre>

<p>You can also do it in one line:<BR></p>

<pre><code>select dateadd(day, 1 + (datepart(weekday, [Date])/6) * (8-datepart(weekday, [Date])), [Date])
</code></pre>
"
233,104330,-2,3,sql,SQL Query Help: Transforming Dates In A Non-Trivial Way,"<p>I have a table with a ""Date"" column, and I would like to do a query that does the following:</p>

<p>If the date is a <strong>Monday</strong>, <strong>Tuesday</strong>, <strong>Wednesday</strong>, or <strong>Thursday</strong>, the displayed date should be shifted up by 1 day, as in <pre>DATEADD(day, 1, [Date])</pre>  On the other hand, if it is a <strong>Friday</strong>, the displayed date should be incremented by 3 days (i.e. so it becomes the following <em>Monday</em>).</p>

<p>How do I do this in my SELECT statement?  As in,</p>

<pre>SELECT somewayofdoingthis([Date]) FROM myTable</pre>

<p>(This is SQL Server 2000.)</p>
","<pre><code>create table #dates (dt datetime)
insert into #dates (dt) values ('1/1/2001')
insert into #dates (dt) values ('1/2/2001')
insert into #dates (dt) values ('1/3/2001')
insert into #dates (dt) values ('1/4/2001')
insert into #dates (dt) values ('1/5/2001')

    select
        dt, day(dt), dateadd(dd,1,dt)
    from
        #dates
    where
        day(dt) between 1 and 4

    union all

    select
        dt, day(dt), dateadd(dd,3,dt)
    from
        #dates
    where
        day(dt) = 5

    drop table #dates
</code></pre>
"
353,150610,0,3,sql,Selecting unique rows in a set of two possibilities,"<p>The problem itself is simple, but I can't figure out a solution that does it in one query, and here's my ""abstraction"" of the problem to allow for a simpler explanation:</p>

<p><strong>I will let my original explenation stand, but here's a set of sample data and the result i expect:</strong></p>

<p>Ok, so here's some sample data, i separated pairs by a blank line</p>

<pre><code>-------------
| Key |  Col | (Together they from a Unique Pair)
--------------
|  1     Foo |
|  1     Bar |
|            |
|  2     Foo |
|            |
|  3     Bar |
|            |
|  4     Foo |
|  4     Bar |
--------------
</code></pre>

<p>And the result I would expect, <strong>after running the query once</strong>, it need to be able to select this result set in one query:</p>

<pre><code>1 - Foo
2 - Foo
3 - Bar
4 - Foo
</code></pre>

<p><em>Original explenation:</em></p>

<p>I have a table, call it <code>TABLE</code> where I have a two columns say <code>ID</code> and <code>NAME</code> which together form the primary key of the table. Now I want to select something where <code>ID=1</code> and then first checks if it can find a row where <code>NAME</code> has the value ""John"", if ""John"" does not exist it should look for a row where <code>NAME</code> is ""Bruce"" - but only return ""John"" if both ""Bruce"" and ""John"" exists or only ""John"" exists of course.</p>

<p>Also note that it should be able to return several rows per query that match the above criteria but with different ID/Name-combinations of course, and that the above explanation is just a simplification of the real problem.</p>

<p>I could be completely blinded by my own code and line of thought but I just can't figure this out. </p>
","<p>Here's an example that works in SQL Server 2005 and later.  It's a useful pattern where you want to choose the top row (or top n rows) based on a custom ordering.  This will let you not just choose among two values with custom priorities, but any number.  You can use the ROW_NUMBER() function and a CASE expression:</p>

<pre><code>CREATE TABLE T (id int, col varchar(10));

INSERT T VALUES (1, 'Foo')
INSERT T VALUES (1, 'Bar')
INSERT T VALUES (2, 'Foo')
INSERT T VALUES (3, 'Bar')
INSERT T VALUES (4, 'Foo')
INSERT T VALUES (4, 'Bar')

SELECT id,col
FROM 
(SELECT id, col,
    ROW_NUMBER() OVER (
    PARTITION BY id 
    ORDER BY 
    CASE col 
    WHEN 'Foo' THEN 1
    WHEN 'Bar' THEN 2 
    ELSE 3 END
    ) AS RowNum 
    FROM T
) AS X
WHERE RowNum = 1
ORDER BY id
</code></pre>
"
235,104330,0,3,sql,SQL Query Help: Transforming Dates In A Non-Trivial Way,"<p>I have a table with a ""Date"" column, and I would like to do a query that does the following:</p>

<p>If the date is a <strong>Monday</strong>, <strong>Tuesday</strong>, <strong>Wednesday</strong>, or <strong>Thursday</strong>, the displayed date should be shifted up by 1 day, as in <pre>DATEADD(day, 1, [Date])</pre>  On the other hand, if it is a <strong>Friday</strong>, the displayed date should be incremented by 3 days (i.e. so it becomes the following <em>Monday</em>).</p>

<p>How do I do this in my SELECT statement?  As in,</p>

<pre>SELECT somewayofdoingthis([Date]) FROM myTable</pre>

<p>(This is SQL Server 2000.)</p>
","<p>This is mostly like Brian's except it didn't compile due to mismatched parens and I changed the IF to not have the select in it.  It is important to note that we use DateNAME here rather than datePART because datePART is dependent on the value set by SET DATEFIRST, which sets the first day of the week.</p>

<pre><code>CREATE FUNCTION dbo.GetNextWDay(@Day datetime)
RETURNS DATETIME
AS
BEGIN
    DECLARE @ReturnDate DateTime

    set @ReturnDate = dateadd(dd, 1, @Day)
    if datename(dw, @ReturnDate) = 'Saturday'
        set @ReturnDate = dateadd(dd, 2, @ReturnDate)
    if datename(dw, @ReturnDate) = 'Sunday'
        set @ReturnDate = dateadd(dd, 1, @ReturnDate)
    RETURN @ReturnDate
END
</code></pre>
"
232,104330,2,3,sql,SQL Query Help: Transforming Dates In A Non-Trivial Way,"<p>I have a table with a ""Date"" column, and I would like to do a query that does the following:</p>

<p>If the date is a <strong>Monday</strong>, <strong>Tuesday</strong>, <strong>Wednesday</strong>, or <strong>Thursday</strong>, the displayed date should be shifted up by 1 day, as in <pre>DATEADD(day, 1, [Date])</pre>  On the other hand, if it is a <strong>Friday</strong>, the displayed date should be incremented by 3 days (i.e. so it becomes the following <em>Monday</em>).</p>

<p>How do I do this in my SELECT statement?  As in,</p>

<pre>SELECT somewayofdoingthis([Date]) FROM myTable</pre>

<p>(This is SQL Server 2000.)</p>
","<p>Try</p>

<pre><code>select case  when datepart(dw,[Date]) between 2 and 5 then DATEADD(dd, 1, [Date])
when datepart(dw,[Date]) = 6 then DATEADD(dd, 3, [Date]) else [Date] end as [Date]
</code></pre>
"
236,104330,1,3,sql,SQL Query Help: Transforming Dates In A Non-Trivial Way,"<p>I have a table with a ""Date"" column, and I would like to do a query that does the following:</p>

<p>If the date is a <strong>Monday</strong>, <strong>Tuesday</strong>, <strong>Wednesday</strong>, or <strong>Thursday</strong>, the displayed date should be shifted up by 1 day, as in <pre>DATEADD(day, 1, [Date])</pre>  On the other hand, if it is a <strong>Friday</strong>, the displayed date should be incremented by 3 days (i.e. so it becomes the following <em>Monday</em>).</p>

<p>How do I do this in my SELECT statement?  As in,</p>

<pre>SELECT somewayofdoingthis([Date]) FROM myTable</pre>

<p>(This is SQL Server 2000.)</p>
","<p>How about taking a page from the <a href=""http://en.wikipedia.org/wiki/Data_warehouse"" rel=""nofollow"">Data Warehouse</a> guys and make a table. In DW terms, this would be a date dimension. A <a href=""http://www.ipcdesigns.com/dim_date/"" rel=""nofollow"">standard date dimension</a> would have things like various names for a date (""MON"", ""Monday"", ""August 22, 1998""), or indicators like end-of-month and start-of-month.  However, you can also have columns that only make sense in your environment.</p>

<p>For instance, based on the question, yours might have a next-work-day column that would point to the key for the day in question. That way you can customize it further to take into account holidays or other non-working days. </p>

<p>The DW folks are adamant about using meaningless keys (that is, don't just use a truncated date as the key, use a generated key), but you can decide that for yourself. </p>

<p>The <a href=""http://www.ipcdesigns.com/dim_date/"" rel=""nofollow"">Date Dimension Toolkit</a> has code to generate your own tables in various DBMS and it has CSV data for several years worth of dates.</p>
"
281,127780,2,3,sql,Is every DDL SQL command reversible? [database version control],"<p>I want to setup a mechanism for tracking DB schema changes, such the one described in <a href=""http://stackoverflow.com/questions/1607/mechanisms-for-tracking-db-schema-changes#1666"">this answer</a>:</p>

<blockquote>
  <p>For every change you make to the
  database, you write a new migration.
  Migrations typically have two methods:
  an ""up"" method in which the changes
  are applied and a ""down"" method in
  which the changes are undone. A single
  command brings the database up to
  date, and can also be used to bring
  the database to a specific version of
  the schema.</p>
</blockquote>

<p>My question is the following: Is every DDL command in an ""up"" method reversible? In other words, can we always provide a ""down"" method? Can you imagine any DDL command that can not be ""down""ed? </p>

<p>Please, do not consider the typical data migration problem where during the ""up"" method we have loss of data: e.g. changing a field type from <code>datetime</code> (<code>DateOfBirth</code>) to <code>int</code> (<code>YearOfBirth</code>) we are losing data that can not be restored.</p>
","<p>Yes, you've identified cases where you lose data, either by transforming it or simply DROP COLUMN in the ""up"" migration.</p>

<p>Another example is that you could drop a SEQUENCE object, thus losing its state.  The ""down"" migration would recreate the sequence, but it would start over at 1.  This could cause duplicate values to be generated by the sequence.  Not a problem if you're performing a migration on an empty database, and you want the sequence to start at 1 anyway, but if you have some number of rows of data, you'd want the sequence to be reset to the greatest value currently in use, which is hard to do reliably, unless you have an exclusive lock on that table.</p>

<p>Any other DDL that is dependent on the state of data in the database has similar problems.  That's probably not a good schema design in the first place, I'm just trying to think of any cases that fit your question.</p>
"
280,127780,2,3,sql,Is every DDL SQL command reversible? [database version control],"<p>I want to setup a mechanism for tracking DB schema changes, such the one described in <a href=""http://stackoverflow.com/questions/1607/mechanisms-for-tracking-db-schema-changes#1666"">this answer</a>:</p>

<blockquote>
  <p>For every change you make to the
  database, you write a new migration.
  Migrations typically have two methods:
  an ""up"" method in which the changes
  are applied and a ""down"" method in
  which the changes are undone. A single
  command brings the database up to
  date, and can also be used to bring
  the database to a specific version of
  the schema.</p>
</blockquote>

<p>My question is the following: Is every DDL command in an ""up"" method reversible? In other words, can we always provide a ""down"" method? Can you imagine any DDL command that can not be ""down""ed? </p>

<p>Please, do not consider the typical data migration problem where during the ""up"" method we have loss of data: e.g. changing a field type from <code>datetime</code> (<code>DateOfBirth</code>) to <code>int</code> (<code>YearOfBirth</code>) we are losing data that can not be restored.</p>
","<p>Other than loss of data, every migration I've ever done is reversible.   That said, Rails offers a way to mark a migration as ""destructive"":</p>

<blockquote>
  <p>Some transformations are destructive
  in a manner that cannot be reversed.
  Migrations of that kind should raise
  an ActiveRecord::IrreversibleMigration
  exception in their down method.</p>
</blockquote>

<p>See the API documentation <a href=""http://api.rubyonrails.org/classes/ActiveRecord/Migration.html"" rel=""nofollow"">here</a>.</p>
"
279,127780,4,3,sql,Is every DDL SQL command reversible? [database version control],"<p>I want to setup a mechanism for tracking DB schema changes, such the one described in <a href=""http://stackoverflow.com/questions/1607/mechanisms-for-tracking-db-schema-changes#1666"">this answer</a>:</p>

<blockquote>
  <p>For every change you make to the
  database, you write a new migration.
  Migrations typically have two methods:
  an ""up"" method in which the changes
  are applied and a ""down"" method in
  which the changes are undone. A single
  command brings the database up to
  date, and can also be used to bring
  the database to a specific version of
  the schema.</p>
</blockquote>

<p>My question is the following: Is every DDL command in an ""up"" method reversible? In other words, can we always provide a ""down"" method? Can you imagine any DDL command that can not be ""down""ed? </p>

<p>Please, do not consider the typical data migration problem where during the ""up"" method we have loss of data: e.g. changing a field type from <code>datetime</code> (<code>DateOfBirth</code>) to <code>int</code> (<code>YearOfBirth</code>) we are losing data that can not be restored.</p>
","<p>in sql server every DDL command that i know of is an up/down pair.</p>
"
273,122990,0,3,sql,"how to determine if a record in every source, represents the same person","<p>I have several sources of tables with personal data, like this:</p>

<pre><code>SOURCE 1
ID, FIRST_NAME, LAST_NAME, FIELD1, ...
1, jhon, gates ...

SOURCE 2
ID, FIRST_NAME, LAST_NAME, ANOTHER_FIELD1, ...
1, jon, gate ...

SOURCE 3
ID, FIRST_NAME, LAST_NAME, ANOTHER_FIELD1, ...
2, jhon, ballmer ...
</code></pre>

<p>So, assuming that records with ID 1, from sources 1 and 2, are the same person, my problem <strong>is how to determine if a record in every source, represents the same person</strong>. Additionally, sure not every records exists in all sources. All the names, are written in spanish, mainly.</p>

<p>In this case, the exact matching needs to be relaxed because we assume <em>the data sources has not been rigurously checked</em> against the official bureau of identification of the country. Also we need to assume <em>typos are common</em>, because the nature of the processes to collect the data. What is more, the amount of records is around 2 or 3 millions in every source...</p>

<p>Our team had thought in something like this: first, force exact matching in selected fields like ID NUMBER, and NAMES to know how hard the problem can be. Second, relaxing the matching criteria, and count how much records more can be matched, but is here where the problem arises: <strong>how to do to relax the matching criteria without generating too noise neither restricting too much?</strong></p>

<p>What tool can be more effective to handle this?, for example, do you know about some especific extension in some database engine to support this matching?
Do you know about clever algorithms like <a href=""http://en.wikipedia.org/wiki/Soundex"" rel=""nofollow"">soundex</a> to handle this approximate matching, but for spanish texts?</p>

<p>Any help would be appreciated!</p>

<p>Thanks.</p>
","<p>Sounds to me you have a <a href=""http://www.answers.com/topic/record-linkage"" rel=""nofollow"">record linkage</a> problem. You can use the references in the link.</p>
"
231,104330,1,3,sql,SQL Query Help: Transforming Dates In A Non-Trivial Way,"<p>I have a table with a ""Date"" column, and I would like to do a query that does the following:</p>

<p>If the date is a <strong>Monday</strong>, <strong>Tuesday</strong>, <strong>Wednesday</strong>, or <strong>Thursday</strong>, the displayed date should be shifted up by 1 day, as in <pre>DATEADD(day, 1, [Date])</pre>  On the other hand, if it is a <strong>Friday</strong>, the displayed date should be incremented by 3 days (i.e. so it becomes the following <em>Monday</em>).</p>

<p>How do I do this in my SELECT statement?  As in,</p>

<pre>SELECT somewayofdoingthis([Date]) FROM myTable</pre>

<p>(This is SQL Server 2000.)</p>
","<p>Look up the CASE statement and the DATEPART statement.  You will want to use the dw argument with DATEPART to get back an integer that represents the day of week.</p>
"
230,104330,4,3,sql,SQL Query Help: Transforming Dates In A Non-Trivial Way,"<p>I have a table with a ""Date"" column, and I would like to do a query that does the following:</p>

<p>If the date is a <strong>Monday</strong>, <strong>Tuesday</strong>, <strong>Wednesday</strong>, or <strong>Thursday</strong>, the displayed date should be shifted up by 1 day, as in <pre>DATEADD(day, 1, [Date])</pre>  On the other hand, if it is a <strong>Friday</strong>, the displayed date should be incremented by 3 days (i.e. so it becomes the following <em>Monday</em>).</p>

<p>How do I do this in my SELECT statement?  As in,</p>

<pre>SELECT somewayofdoingthis([Date]) FROM myTable</pre>

<p>(This is SQL Server 2000.)</p>
","<pre><code>CREATE FUNCTION dbo.GetNextWDay(@Day datetime)
RETURNS DATETIME
AS
BEGIN 
    DECLARE @ReturnDate DateTime

    set @ReturnDate = dateadd(dd, 1, @Day)

    if (select datename(@ReturnDate))) = 'Saturday'
        set @ReturnDate = dateadd(dd, 2, @ReturnDate)

    if (select datename(@ReturnDate) = 'Sunday'
        set @ReturnDate = dateadd(dd, 1, @ReturnDate)

    RETURN @ReturnDate
END
</code></pre>
"
229,104330,5,3,sql,SQL Query Help: Transforming Dates In A Non-Trivial Way,"<p>I have a table with a ""Date"" column, and I would like to do a query that does the following:</p>

<p>If the date is a <strong>Monday</strong>, <strong>Tuesday</strong>, <strong>Wednesday</strong>, or <strong>Thursday</strong>, the displayed date should be shifted up by 1 day, as in <pre>DATEADD(day, 1, [Date])</pre>  On the other hand, if it is a <strong>Friday</strong>, the displayed date should be incremented by 3 days (i.e. so it becomes the following <em>Monday</em>).</p>

<p>How do I do this in my SELECT statement?  As in,</p>

<pre>SELECT somewayofdoingthis([Date]) FROM myTable</pre>

<p>(This is SQL Server 2000.)</p>
","<p>Here is how I would do it. I do recommend a function like above if you will be using this in other places.</p>

<pre><code>CASE
WHEN
	DATEPART(dw, [Date]) IN (2,3,4,5)
THEN
	DATEADD(d, 1, [Date])
WHEN
	DATEPART(dw, [Date]) = 6
THEN
	DATEADD(d, 3, [Date])
ELSE
	[Date]
END AS [ConvertedDate]
</code></pre>
"
818,358630,4,3,sql,How to Search date in SQL?,"<p>I am having an Event Management System in which i want,</p>

<p>If an event is registered for 5 days (21 jan 2009 to 26 Jan 2009) Then if another person wants to register an event between 22 jan 2009 to 24 jan 2009 then it will not allow to register. I want to check this using SQL query, so please tell me how can i do this.</p>
","<p>SELECT *<br />
FROM events e<br />
WHERE (@startDate BETWEEN e.startDate and e.endDate)<br />
OR (@endDate BETWEEN e.startDate and e.endDate)<br />
OR (@startDate &lt; e.startDate AND @endDate > e.endDate)  </p>
"
819,358630,1,3,sql,How to Search date in SQL?,"<p>I am having an Event Management System in which i want,</p>

<p>If an event is registered for 5 days (21 jan 2009 to 26 Jan 2009) Then if another person wants to register an event between 22 jan 2009 to 24 jan 2009 then it will not allow to register. I want to check this using SQL query, so please tell me how can i do this.</p>
","<p>Lookup DATEDIFF in SQL help.</p>
"
758,348900,1,3,sql,Another LINQ Pivot Problem - Convert SQL Script to LINQ,"<p>There are a few questions on SO already regarding LINQ pivots and while a couple of them outline my exact problem, I can't successfully translate them to a working solution.  I feel that this is mostly due to a join in my tables.</p>

<p>So for the benefit of all the LINQ junkies out there who love a problem, here's another puzzle for you to work out.  Please help me out (and earn some reputation points and much respect from me) by converting the following SQL stored proc script to LINQ:</p>

<pre><code>ALTER PROCEDURE [dbo].[GetTimesheetForWeekById]
    @timesheetid int,
    @begindate VarChar(20),
    @enddate VarChar(20)
AS
BEGIN

    SELECT T.TaskName,
    	SUM(
    		case DATEPART(weekday, TE.StartTime)
    			WHEN 1 THEN DATEDIFF(minute, TE.StartTime, TE.EndTime) ELSE 0 END
    		) AS Sunday,
    	SUM(
    		case DATEPART(weekday, TE.StartTime)
    			when 2 THEN DATEDIFF(minute, TE.StartTime, TE.EndTime) ELSE 0 END
    		) AS Monday,
    	SUM(
    		case DATEPART(weekday, TE.StartTime)
    			when 3 THEN DATEDIFF(minute, TE.StartTime, TE.EndTime) ELSE 0 END
    		) AS Tuesday,
    	SUM(
    		case DATEPART(weekday, TE.StartTime)
    			when 4 THEN DATEDIFF(minute, TE.StartTime, TE.EndTime) ELSE 0 END
    		) AS Wednesday,
    	SUM(
    		case DATEPART(weekday, TE.StartTime)
    			when 5 THEN DATEDIFF(minute, TE.StartTime, TE.EndTime) ELSE 0 END
    		) AS Thursday,
    	SUM(
    		case DATEPART(weekday, TE.StartTime)
    			when 6 THEN DATEDIFF(minute, TE.StartTime, TE.EndTime) ELSE 0 END
    		) AS Friday,
    	SUM(
    		case DATEPART(weekday, TE.StartTime)
    			when 6 THEN DATEDIFF(minute, TE.StartTime, TE.EndTime) ELSE 0 END
    		) AS Saturday

    FROM Tasks T
    INNER JOIN TimeEntries TE on T.TaskID = TE.TaskID
    WHERE TE.StartTime BETWEEN 
    	(CONVERT(datetime, @begindate, 103)) AND (CONVERT(datetime, @enddate, 103))
    AND TE.TimesheetID = @timesheetid
    GROUP BY T.TaskName
END
</code></pre>
","<p>Well, assuming that the foreign key has an object representation, something like:</p>

<pre><code>        int timesheetId = ...
        DateTime start = ..., end = ...
        var qry = from timeEntry in ctx.TimeEntries
              let date = timeEntry.StartTime.Date
              where timeEntry.TimesheetId == timesheetId
                &amp;&amp; date &gt;= start
                &amp;&amp; date &lt;= end
              group timeEntry by timeEntry.Task.TaskName into grp
              select new {
                  TaskName = grp.Key,
                  Monday = grp.Where(x =&gt; x.StartTime.DayOfWeek == DayOfWeek.Monday).Count(),
                  Tuesday = grp.Where(x =&gt; x.StartTime.DayOfWeek == DayOfWeek.Tuesday).Count(),
                  Wednesday = grp.Where(x =&gt; x.StartTime.DayOfWeek == DayOfWeek.Wednesday).Count(),
                  Thursday = grp.Where(x =&gt; x.StartTime.DayOfWeek == DayOfWeek.Thursday).Count(),
                  Friday = grp.Where(x =&gt; x.StartTime.DayOfWeek == DayOfWeek.Friday).Count()
              };
</code></pre>

<p>Unfortunately, some of the specifics depend on the SQL provider - i.e. which functions (like DayOfWeek etc) it can map successfully as TSQL. Let me know if you get problems...</p>
"
228,104330,1,3,sql,SQL Query Help: Transforming Dates In A Non-Trivial Way,"<p>I have a table with a ""Date"" column, and I would like to do a query that does the following:</p>

<p>If the date is a <strong>Monday</strong>, <strong>Tuesday</strong>, <strong>Wednesday</strong>, or <strong>Thursday</strong>, the displayed date should be shifted up by 1 day, as in <pre>DATEADD(day, 1, [Date])</pre>  On the other hand, if it is a <strong>Friday</strong>, the displayed date should be incremented by 3 days (i.e. so it becomes the following <em>Monday</em>).</p>

<p>How do I do this in my SELECT statement?  As in,</p>

<pre>SELECT somewayofdoingthis([Date]) FROM myTable</pre>

<p>(This is SQL Server 2000.)</p>
","<p>you could use this:</p>

<pre><code>select dayname,newdayname =
    CASE dayname
    WHEN 'Monday' THEN 'Tuesday'
    WHEN 'Tuesday' THEN 'Wednesday'
    WHEN 'Wednesday' THEN 'Thursday'
    WHEN 'Thursday' THEN 'Friday'
    WHEN 'Friday' THEN 'Monday'
    WHEN 'Saturday' THEN 'Monday'
    WHEN 'Sunday' THEN 'Monday'
END
FROM UDO_DAYS
</code></pre>

<pre>
results:
Monday       Tuesday
Tuesday      Wednesday
Wednesday    Thursday
Thursday     Friday
Friday       Monday
Saturday     Monday
Sunday       Monday

table data:
Monday
Tuesday
Wednesday
Thursday
Friday
Saturday
Sunday
</pre>
"
227,104330,1,3,sql,SQL Query Help: Transforming Dates In A Non-Trivial Way,"<p>I have a table with a ""Date"" column, and I would like to do a query that does the following:</p>

<p>If the date is a <strong>Monday</strong>, <strong>Tuesday</strong>, <strong>Wednesday</strong>, or <strong>Thursday</strong>, the displayed date should be shifted up by 1 day, as in <pre>DATEADD(day, 1, [Date])</pre>  On the other hand, if it is a <strong>Friday</strong>, the displayed date should be incremented by 3 days (i.e. so it becomes the following <em>Monday</em>).</p>

<p>How do I do this in my SELECT statement?  As in,</p>

<pre>SELECT somewayofdoingthis([Date]) FROM myTable</pre>

<p>(This is SQL Server 2000.)</p>
","<p>This is off the top of my head and can be clearly cleaned up  but use it as a starting point:</p>

<pre><code>select case when DATENAME(dw, [date]) = 'Monday' then DATEADD(dw, 1, [Date])
                when DATENAME(dw, [date]) = 'Tuesday' then DATEADD(dw, 1, [Date])
                when DATENAME(dw, [date]) = 'Wednesday' then DATEADD(dw, 1, [Date])
                when DATENAME(dw, [date]) = 'Thursday' then DATEADD(dw, 1, [Date])
                when  DATENAME(dw, [date]) = 'Friday' then DATEADD(dw, 3, [Date])
          end as nextDay
    ...
</code></pre>
"
226,104330,1,3,sql,SQL Query Help: Transforming Dates In A Non-Trivial Way,"<p>I have a table with a ""Date"" column, and I would like to do a query that does the following:</p>

<p>If the date is a <strong>Monday</strong>, <strong>Tuesday</strong>, <strong>Wednesday</strong>, or <strong>Thursday</strong>, the displayed date should be shifted up by 1 day, as in <pre>DATEADD(day, 1, [Date])</pre>  On the other hand, if it is a <strong>Friday</strong>, the displayed date should be incremented by 3 days (i.e. so it becomes the following <em>Monday</em>).</p>

<p>How do I do this in my SELECT statement?  As in,</p>

<pre>SELECT somewayofdoingthis([Date]) FROM myTable</pre>

<p>(This is SQL Server 2000.)</p>
","<p>Sounds like a CASE expression.  I don't know the proper data manipulations for SQL Server, but basically it would look like this:</p>

<pre><code>CASE
  WHEN [Date] is a Friday THEN DATEADD( day, 3, [Date] )
  ELSE DATEADD( day, 1, [Date] )
END
</code></pre>

<p>If you wanted to check for weekend days you could add additional WHEN clauses before the ELSE.</p>
"
225,104330,0,3,sql,SQL Query Help: Transforming Dates In A Non-Trivial Way,"<p>I have a table with a ""Date"" column, and I would like to do a query that does the following:</p>

<p>If the date is a <strong>Monday</strong>, <strong>Tuesday</strong>, <strong>Wednesday</strong>, or <strong>Thursday</strong>, the displayed date should be shifted up by 1 day, as in <pre>DATEADD(day, 1, [Date])</pre>  On the other hand, if it is a <strong>Friday</strong>, the displayed date should be incremented by 3 days (i.e. so it becomes the following <em>Monday</em>).</p>

<p>How do I do this in my SELECT statement?  As in,</p>

<pre>SELECT somewayofdoingthis([Date]) FROM myTable</pre>

<p>(This is SQL Server 2000.)</p>
","<p>you need to create a SQL Function that does this transformation for you.  </p>
"
322,147670,5,3,sql,Get list of available servers in SQL server group,"<p>How can I extract the list of available SQL servers in an SQL server group? I'm planning to put that list in a combo box in VB.NET.</p>
","<p>The only way I knew to do it was using the command line:</p>

<pre><code>osql -L
</code></pre>

<p>But I found the below article which seems to solve your specific goal filling a combobox:</p>

<p><a href=""http://www.sqldbatips.com/showarticle.asp?ID=45"" rel=""nofollow"">http://www.sqldbatips.com/showarticle.asp?ID=45</a></p>
"
874,387850,2,3,sql,How can I make this Ruby on Rails page more efficient?,"<p>I'm building a site where users can track their collection of figures for Dungeons &amp; Dragons (www.ddmdb.com).  The models/relationships involved in this funcitonality are the following:</p>

<p><strong>User:</strong></p>

<ul>
<li>id</li>
<li>login (username)</li>
<li><em>a bunch of other fields</em></li>
</ul>

<p><strong>Miniature:</strong></p>

<ul>
<li>id</li>
<li>name</li>
<li>number (# in the set, not count)</li>
<li>release_id (foreign key)</li>
<li><em>a bunch of other fields and foreign keys</em></li>
</ul>

<p><strong>Ownership:</strong></p>

<ul>
<li>id (is this really even needed?)</li>
<li>user_id</li>
<li>miniature_id</li>
<li>have_count</li>
<li>favorite (boolean)</li>
</ul>

<p>The pertinent relationships I have set up are as follows:</p>

<p><strong>User:</strong></p>

<ul>
<li>has_many :ownerships</li>
<li>has_many :miniatures, :through => :ownerships, :uniq => true, :conditions => ""ownerships.have_count > 0""</li>
<li>has_many :favorites, :through => :ownerships, :source => :miniature, :uniq => true, :conditions => ""ownerships.favorite = true""</li>
</ul>

<p><strong>Miniatures:</strong></p>

<ul>
<li>has_many :ownerships</li>
<li>has_many :owners, :through => :ownerships, :source => :user, :uniq => true, :conditions => ""ownerships.have_count > 0""</li>
</ul>

<p><strong>Ownership:</strong></p>

<ul>
<li>belongs_to :user</li>
<li>belongs_to :miniature</li>
</ul>

<p>I have a page where user's can both view and update their collection, as well as view other user's collections.  It contains a list of all the miniatures on the site and a text box next to each where the user can enter how many of each miniature they have.  This functionality also exists in sub-lists of miniatures (filtered by type, release, size, rarity, etc.)</p>

<p>When a user creates an account they have no entries in the ownership.  When they use the collection page or sub-list of miniatures to update their collection, I create entries in the ownership table for only the miniatures on the submitting page.  So if it's the full Collection list I update all minis (even if the count is 0) or if it's a sub-list, I only update those miniatures.  So at any time a particular user I may have:
  - no entries in ownership
  - entries for some of the miniatures
  - entries for all the miniatures.</p>

<p>The problem I'm having is that I don't know how to query the database with a LEFT JOIN using a ""Rails method"" so that if a user doesn't have an entry for a miniature in Ownerships it defaults to a have_count of 0.  Currently I query for each user_id/miniature_id combination individually as I loop through all miniatures and it's obviously really inefficient.</p>

<p><strong>View:</strong></p>

<pre><code>&lt;% for miniature in @miniatures %&gt;
  &lt;td&gt;&lt;%= link_to miniature.name, miniature %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= text_field_tag ""counts[#{miniature.id}]"", get_user_miniature_count(current_user, miniature), :size =&gt; 2 %&gt;&lt;/td&gt;
&lt;% end %&gt;
</code></pre>

<p><strong>Helper:</strong></p>

<pre><code>def get_user_miniature_count(user, miniature)
  ownerships = user.ownerships
  ownership = user.ownerships.find_by_miniature_id(miniature.id)
  if ownership.nil?
    return 0
  else
    return ownership.have_count
  end
end
</code></pre>

<p>An alternate solution would be creating entries for all miniatures when a user signs up, but then I would also have to add a 0 have_count for all users when a new miniature is added to the database after they sign up.  That seems like it could get a bit complex, but perhaps it's the right way to go?</p>

<p>Is there a way to do the join and supply a default value for miniatures where there's no entries in the Ownership table for that particular user?</p>
","<p>The first thing I would say is that the User model should own the code that works out how many of a given miniature the user owns, since it seems like ""business logic"" rather than view formatting.</p>

<p>My suggestion would be to add a method to your User model:</p>

<pre><code>def owns(miniature_id)
  o = ownerships.detect { |o| o.miniature_id == miniature_id }
  (o &amp;&amp; o.have_count) || 0
end
</code></pre>

<p>Dry-coded, ymmv.</p>

<p>Edit:  Note that ownerships is cached by Rails once loaded and detect is not overridden by ActiveRecord like find is, and so acts as you would expect it to on an Array (ie no database operations).</p>
"
105,38680,0,3,sql,How to provide next page of updated content?,"<p>Feel free to edit the title if you know how to formulate the question better. (Tagging is a problem as well.) The problem may be too difficult in this general form, so let us consider a concrete example.</p>

<p>You get a screenful of stackoverflow questions by requesting <code>/questions ?sort=newest</code> page. Next page link leads to <code>/questions?page=2 &amp;sort=newest</code>. I suppose that at server side, the request is translated into an SQL query with LIMIT clause. Problem with this approach is, that if new question were added while user browses first page, his second page will start with some questions he already saw. (If he has 10 question per page, and 10 new questions happened to be added, hell get exactly the same content second time!)</p>

<p>Is there an elegant way to solve this common problem? I realize that it is not that big a problem, at least not for stackoverflow, but still.</p>

<p>The best idea I have (apart from storing request history per client) is to use <code>/questions?answer_id=NNN</code> format. Server returns a page that starts with the requested answer, and puts the id of the first answer on the next page into next page link. There must be a way to write SQL for that, right? </p>

<p>Is it how it usually done? Or there is a better way?</p>
","<p>Most web sites I've seen don't solve this problem - they show you a page including some content you've already seen.</p>

<p>You might consider that a feature - when you click ""next"" and see some content you're seen before, it's a signal that you want to go back to the front again because there's some new content.</p>
"
352,150610,4,3,sql,Selecting unique rows in a set of two possibilities,"<p>The problem itself is simple, but I can't figure out a solution that does it in one query, and here's my ""abstraction"" of the problem to allow for a simpler explanation:</p>

<p><strong>I will let my original explenation stand, but here's a set of sample data and the result i expect:</strong></p>

<p>Ok, so here's some sample data, i separated pairs by a blank line</p>

<pre><code>-------------
| Key |  Col | (Together they from a Unique Pair)
--------------
|  1     Foo |
|  1     Bar |
|            |
|  2     Foo |
|            |
|  3     Bar |
|            |
|  4     Foo |
|  4     Bar |
--------------
</code></pre>

<p>And the result I would expect, <strong>after running the query once</strong>, it need to be able to select this result set in one query:</p>

<pre><code>1 - Foo
2 - Foo
3 - Bar
4 - Foo
</code></pre>

<p><em>Original explenation:</em></p>

<p>I have a table, call it <code>TABLE</code> where I have a two columns say <code>ID</code> and <code>NAME</code> which together form the primary key of the table. Now I want to select something where <code>ID=1</code> and then first checks if it can find a row where <code>NAME</code> has the value ""John"", if ""John"" does not exist it should look for a row where <code>NAME</code> is ""Bruce"" - but only return ""John"" if both ""Bruce"" and ""John"" exists or only ""John"" exists of course.</p>

<p>Also note that it should be able to return several rows per query that match the above criteria but with different ID/Name-combinations of course, and that the above explanation is just a simplification of the real problem.</p>

<p>I could be completely blinded by my own code and line of thought but I just can't figure this out. </p>
","<p>This is fairly similar to what you wrote, but should be fairly speedy as NOT EXISTS is more efficient, in this case, than NOT IN...</p>

<pre><code>mysql&gt; select * from foo;
+----+-----+
| id | col |
+----+-----+
|  1 | Bar | 
|  1 | Foo | 
|  2 | Foo | 
|  3 | Bar | 
|  4 | Bar | 
|  4 | Foo | 
+----+-----+

SELECT id
     , col
  FROM foo f1 
 WHERE col = 'Foo' 
  OR ( col = 'Bar' AND NOT EXISTS( SELECT * 
                                     FROM foo f2
                                    WHERE f1.id  = f2.id 
                                      AND f2.col = 'Foo' 
                                 ) 
     ); 

+----+-----+
| id | col |
+----+-----+
|  1 | Foo | 
|  2 | Foo | 
|  3 | Bar | 
|  4 | Foo | 
+----+-----+
</code></pre>
"
873,387850,0,3,sql,How can I make this Ruby on Rails page more efficient?,"<p>I'm building a site where users can track their collection of figures for Dungeons &amp; Dragons (www.ddmdb.com).  The models/relationships involved in this funcitonality are the following:</p>

<p><strong>User:</strong></p>

<ul>
<li>id</li>
<li>login (username)</li>
<li><em>a bunch of other fields</em></li>
</ul>

<p><strong>Miniature:</strong></p>

<ul>
<li>id</li>
<li>name</li>
<li>number (# in the set, not count)</li>
<li>release_id (foreign key)</li>
<li><em>a bunch of other fields and foreign keys</em></li>
</ul>

<p><strong>Ownership:</strong></p>

<ul>
<li>id (is this really even needed?)</li>
<li>user_id</li>
<li>miniature_id</li>
<li>have_count</li>
<li>favorite (boolean)</li>
</ul>

<p>The pertinent relationships I have set up are as follows:</p>

<p><strong>User:</strong></p>

<ul>
<li>has_many :ownerships</li>
<li>has_many :miniatures, :through => :ownerships, :uniq => true, :conditions => ""ownerships.have_count > 0""</li>
<li>has_many :favorites, :through => :ownerships, :source => :miniature, :uniq => true, :conditions => ""ownerships.favorite = true""</li>
</ul>

<p><strong>Miniatures:</strong></p>

<ul>
<li>has_many :ownerships</li>
<li>has_many :owners, :through => :ownerships, :source => :user, :uniq => true, :conditions => ""ownerships.have_count > 0""</li>
</ul>

<p><strong>Ownership:</strong></p>

<ul>
<li>belongs_to :user</li>
<li>belongs_to :miniature</li>
</ul>

<p>I have a page where user's can both view and update their collection, as well as view other user's collections.  It contains a list of all the miniatures on the site and a text box next to each where the user can enter how many of each miniature they have.  This functionality also exists in sub-lists of miniatures (filtered by type, release, size, rarity, etc.)</p>

<p>When a user creates an account they have no entries in the ownership.  When they use the collection page or sub-list of miniatures to update their collection, I create entries in the ownership table for only the miniatures on the submitting page.  So if it's the full Collection list I update all minis (even if the count is 0) or if it's a sub-list, I only update those miniatures.  So at any time a particular user I may have:
  - no entries in ownership
  - entries for some of the miniatures
  - entries for all the miniatures.</p>

<p>The problem I'm having is that I don't know how to query the database with a LEFT JOIN using a ""Rails method"" so that if a user doesn't have an entry for a miniature in Ownerships it defaults to a have_count of 0.  Currently I query for each user_id/miniature_id combination individually as I loop through all miniatures and it's obviously really inefficient.</p>

<p><strong>View:</strong></p>

<pre><code>&lt;% for miniature in @miniatures %&gt;
  &lt;td&gt;&lt;%= link_to miniature.name, miniature %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= text_field_tag ""counts[#{miniature.id}]"", get_user_miniature_count(current_user, miniature), :size =&gt; 2 %&gt;&lt;/td&gt;
&lt;% end %&gt;
</code></pre>

<p><strong>Helper:</strong></p>

<pre><code>def get_user_miniature_count(user, miniature)
  ownerships = user.ownerships
  ownership = user.ownerships.find_by_miniature_id(miniature.id)
  if ownership.nil?
    return 0
  else
    return ownership.have_count
  end
end
</code></pre>

<p>An alternate solution would be creating entries for all miniatures when a user signs up, but then I would also have to add a 0 have_count for all users when a new miniature is added to the database after they sign up.  That seems like it could get a bit complex, but perhaps it's the right way to go?</p>

<p>Is there a way to do the join and supply a default value for miniatures where there's no entries in the Ownership table for that particular user?</p>
","<p>Maybe I'm missing something, but the way you've specified the relationships seems sufficient for rails to figure out the counts on its own? Have you tried that?</p>

<p>edit:
Re the discussion in the comments...how about this:</p>

<pre><code>&lt;% ownerships=current_user.ownerships %&gt; 
&lt;% for miniature in @miniatures %&gt;
  &lt;td&gt;&lt;%= link_to miniature.name, miniature %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= text_field_tag ""counts[#{miniature.id}]"", get_miniature_count(ownerships, miniature), :size =&gt; 2 %&gt;&lt;/td&gt;
&lt;% end %&gt;
</code></pre>

<p>Where <code>get_miniature_count()</code> just iterates through the supplied ownerships and returns 0 or the count if the miniature appears in the list? I think this will avoid going back to the DB again in each iteration of the 'for'.</p>

<p>edit 2: I'd also suggest firing up script/console and trying to do what you want in ruby directly, i.e. test for the miniatures membership in the ownerships list thinking in terms of ruby not SQL. Often, rails and activerecord is smart enough to do the necessary SQL black magic for you behind the scenes, given it knows the relationships. If you find a user and then do user.methods you'll see what is available.</p>
"
1087,496070,0,3,sql,Should I use Top(1) in a SubQuery,"<p>Example Query:</p>

<pre><code>select * 
from A join B on A.ID = B.SOMEVALUE
where A.VALUE=""something"" and
B.ID = 
       (select ID from B where SOMEVALUE = A.ID and 
              THISDATE = (select max(SOMEDATE) from B where ...))
</code></pre>

<p>so, if you can read SQL you should see that I am doing a couple correlated subqueries to narrow down the results of the join . (and yes, this is horribly over-simplified).</p>

<p>In certain cases the subquery:</p>

<pre><code>select ID from B where SOMEVALUE = A.ID and 
    THISDATE = (select max(SOMEDATE) from B where ...)
</code></pre>

<p>can return more than 1 value, which causes an error </p>

<blockquote>
  <p>""Subquery returned more than 1 value.
  This is not permitted when the
  subquery follows =, !=, &lt;, &lt;= , >, >=
  or when the subquery is used as an
  expression.""</p>
</blockquote>

<p>which I fully expect.  This is obviously not a good thing and I have code in place to (hopefully) prevent these duplicates from getting into the database in the first place (ie table B <em>should</em> only have 1 row that matches the </p>

<pre><code>SOMEVALUE = A.ID and max(SOMEDATE)
</code></pre>

<p>criteria), however end-users are nothing if not creative in finding ways I can't think of to break software.</p>

<p>So now to my question:</p>

<p>Would it be better to change the first subquery to </p>

<pre><code>select top 1 * from B ...
</code></pre>

<p>to prevent the user from seeing an error when/if (hopefully never) this situation arises or let the error come through.  I'm leaning to not adding the top statement and letting the error come through rather then let the user see potentially incorrect data.  I'm wondering if anyone has any thoughts on Best Practices in a situation like this...</p>
","<p>Why not use <code>LIMIT 1</code> at the end of your sub-select?</p>
"
901,407320,7,3,sql,"Strange SQL2005 problem. ""SqlConnection does not support parallel transactions""","<p>I have a problem that seems like its a result of a deadlock-situation. 
Whe are now searching for the root of the problem but meantime we wanted to restart the server and get the customer going.</p>

<p>And now everytime we start the program it just says ""SqlConnection does not support parallel transactions"". We have not changed anything in the program, its compiled and on the customers server, but after the ""possible deadlock""-situation it want go online again.</p>

<p>We have 7 clients (computers) running the program, each client is talking to a webservice on a local server, and the webservice is talking to the sql-server (same machine as webserver). </p>

<p>We have restarted both the sql-server and the iis-server, but not rebooted the server because of other important services running on the server so its the last thing we do.
We can se no locks or anything in the management tab. </p>

<p>So my question is, why does the ""SqlConnection does not support parallel transactions"" error comming from one time to another without changing anything in the program and it still lives between sql-restart.</p>

<p>It seems like it happens at the first db-request the program does when it start.</p>

<p>If you need more information just ask. Im puzzled...</p>

<p><strong>More information:</strong>
I dont think I have ""long"" running transactions. The scenario is often that I have a dataset with 20-100 rows (ContractRows) in that Ill do a .Update on the tableAdapter. I also loop throug those 20-100 rows and for some of them Ill create ad-hook-sql-querys (for example if a rented product is marked as returned I create a sql-query to mark the product as returned in the database)</p>

<p>So I do this very simplified:</p>

<pre><code>Create objTransactionObject
Create objtableadapter (objTransactionObject)
for each row in contractDS.contractrows
  if row.isreturned then
    strSQL &amp;= ""update product set instock=1 where prodid="" &amp; row.productid &amp; vbcrlf
 End if
next
objtableadapter.update(contractDS)
objData.ExecuteQuery(strSQL, objTransactionObject)    
if succsesfull 
  objtransactionobject.commit
else
  objtransactionobject.rollback
end if
objTran.Dispose()
</code></pre>

<p>And then Im doing commit or rollback depending on if It went well or not.</p>

<p>Edit: None of the answers have solved the problem, but I'll thank you for the good trouble shooting pointers.</p>

<p>The ""SqlConnection does not support parallel transactions"" dissapeared suddenly and now the sql-server just ""goes down"" 4-5 times a day, I guess its a deadlock that does that but I have not the right knowledge to find out and are short on sql-experts who can monitor this for me at the moment. I just restart the sql-server and everything works again. 1 of 10 times I also have to restart the computer. Its really bugging me (and my customers of course).</p>

<p>Anyone knowing a person with <strong>good</strong> knowledge in analyzing troubles with deadlocks or other sql problems in sweden (or everywhere in the world,english speaking)  are free to contact me. I know this is'nt a contact site but I take my chanse to ask the question because I have run out of options, I have spent 3 days and nights optimizing the clients to be sure we close connections and dont do too much stupid things there. Without luck.</p>
","<p>It seems to be that you are sharing connections and creating new transactions on the same open connection (this is the parallel part of the exception you are seeing).</p>

<p>Your example seems to support this as you have no mention of how you acquire the connection in it.</p>

<p>You should do a review of your code and make sure that you are only opening a connection and then disposing of it when you are done (and by all means, use the using statement to make sure that you close the connection), as it seems like you are leaving one open somewhere.</p>
"
380,170440,2,3,sql,Stored procedure not being executed within another stored procedure,"<p>I have found that SP2 doesn't execute from within SP1 when SP1 is executed.</p>

<p>Below is the structure of SP1:</p>

<pre><code>ALTER PROCEDURE SP1 AS BEGIN

Declare c1 cursor....

open c1 fetch next from c1 ...

while @@fetch_status = 0 Begin

...

Fetch Next from c1 end

close c1

deallocate c1

exec sp2

end
</code></pre>

<hr>

<p>I see non of the PRINT statement outputs if they are printed in the 'Output window' in SQL Server 2005 management studio as the 'Output Window'is empty.</p>
","<p>What happens if you run the Stored Procedure code as a single query? If you put a <code>PRINT</code> statement before and after the exec, do you see both outputs?</p>

<ul>
<li>If you do, then the stored procedure must have been executed. Probably it's not doing what you would like.</li>
<li>If you don't see any print output, then there's something wrong in the cycle</li>
<li>If you don't see the second output but you see the first, there's something wrong in the second Stored Procedure.</li>
</ul>
"
381,170440,0,3,sql,Stored procedure not being executed within another stored procedure,"<p>I have found that SP2 doesn't execute from within SP1 when SP1 is executed.</p>

<p>Below is the structure of SP1:</p>

<pre><code>ALTER PROCEDURE SP1 AS BEGIN

Declare c1 cursor....

open c1 fetch next from c1 ...

while @@fetch_status = 0 Begin

...

Fetch Next from c1 end

close c1

deallocate c1

exec sp2

end
</code></pre>

<hr>

<p>I see non of the PRINT statement outputs if they are printed in the 'Output window' in SQL Server 2005 management studio as the 'Output Window'is empty.</p>
","<p>I am not sure if it helps you, but from my experience the most popular reasons are:</p>

<ol>
<li><code>sp2</code> gets some parameter which makes it <code>null</code> value -- i.e. you build its name from the strings and one of them is <code>null</code>.</li>
<li><code>sp2</code> has some conditions inside and none of them is true, so <code>sp2</code> executes no code at all -- i.e. one of the parameters is type <code>varchar</code>, you pass value <code>VALUE</code>, check for it inside, but the real value passed to <code>sp2</code> is <code>V</code> (because there are no varchar length defined).</li>
<li><code>sp2</code> builds query from parameters where one of them is <code>null</code> and the whole query becomes <code>null</code> too.</li>
</ol>

<p>Do you see any output if you put <code>PRINT</code> <em>before</em> and <em>after</em> call of <code>sp2</code>?</p>
"
1088,496070,10,3,sql,Should I use Top(1) in a SubQuery,"<p>Example Query:</p>

<pre><code>select * 
from A join B on A.ID = B.SOMEVALUE
where A.VALUE=""something"" and
B.ID = 
       (select ID from B where SOMEVALUE = A.ID and 
              THISDATE = (select max(SOMEDATE) from B where ...))
</code></pre>

<p>so, if you can read SQL you should see that I am doing a couple correlated subqueries to narrow down the results of the join . (and yes, this is horribly over-simplified).</p>

<p>In certain cases the subquery:</p>

<pre><code>select ID from B where SOMEVALUE = A.ID and 
    THISDATE = (select max(SOMEDATE) from B where ...)
</code></pre>

<p>can return more than 1 value, which causes an error </p>

<blockquote>
  <p>""Subquery returned more than 1 value.
  This is not permitted when the
  subquery follows =, !=, &lt;, &lt;= , >, >=
  or when the subquery is used as an
  expression.""</p>
</blockquote>

<p>which I fully expect.  This is obviously not a good thing and I have code in place to (hopefully) prevent these duplicates from getting into the database in the first place (ie table B <em>should</em> only have 1 row that matches the </p>

<pre><code>SOMEVALUE = A.ID and max(SOMEDATE)
</code></pre>

<p>criteria), however end-users are nothing if not creative in finding ways I can't think of to break software.</p>

<p>So now to my question:</p>

<p>Would it be better to change the first subquery to </p>

<pre><code>select top 1 * from B ...
</code></pre>

<p>to prevent the user from seeing an error when/if (hopefully never) this situation arises or let the error come through.  I'm leaning to not adding the top statement and letting the error come through rather then let the user see potentially incorrect data.  I'm wondering if anyone has any thoughts on Best Practices in a situation like this...</p>
","<p>Normally TOP 1 is a good idea.</p>

<p>Consider a large table with millions of rows with no index on the column you are matching, however you are only looking for a single row.</p>

<p>SELECT TOP 1 will mean the table scan stops as soon as the one item is found.</p>

<p>Without the TOP 1, the table scan will continue right through to the end.</p>

<p>As with anything that involves scanning (or brute force) to do the search. Using TOP 1, it should on average be 50% quicker than not using TOP 1.</p>

<p>However, Depending on what you need to return back, A real performance gain can normally be made by using EXISTS.</p>

<p>Instead of writing</p>

<pre><code>SELECT * FROM table t
WHERE t.id = (SELECT TOP 1 foreignid from table2)
</code></pre>

<p>You can use</p>

<pre><code>SELECT * FROM table t
WHERE EXISTS (SELECT 1 from table2 WHERE foreignid = t.id)
</code></pre>
"
517,221040,3,3,sql,Record level permissions,"<p><p>In a database I am designing I have implemented profile based object level security.
<p>Each user can view, edit, insert, update database tables according to the profiles (roles) he is a member of.
<p>Now there is a need to implement ""External Users"" who can view only the relevant records and edit some of them (but not the bulk of the database).</p>

<p><p>I am working on an ""record ownership"" model.
<p>Are there any ideas on how to restrict the users belonging to an ""External Users"" profile to see and work with some records of each table, but not all.</p>
","<p>You could create a VIEW, or you could create select stored procedures and only assign rights to those.</p>

<p>The VIEW is the way to go for a simple security model - if it is complex, go with the stored procedure(s).</p>
"
516,221040,3,3,sql,Record level permissions,"<p><p>In a database I am designing I have implemented profile based object level security.
<p>Each user can view, edit, insert, update database tables according to the profiles (roles) he is a member of.
<p>Now there is a need to implement ""External Users"" who can view only the relevant records and edit some of them (but not the bulk of the database).</p>

<p><p>I am working on an ""record ownership"" model.
<p>Are there any ideas on how to restrict the users belonging to an ""External Users"" profile to see and work with some records of each table, but not all.</p>
","<p>You should probably create a VIEW which limits the records and then apply the proper rights on the view. </p>
"
875,387850,1,3,sql,How can I make this Ruby on Rails page more efficient?,"<p>I'm building a site where users can track their collection of figures for Dungeons &amp; Dragons (www.ddmdb.com).  The models/relationships involved in this funcitonality are the following:</p>

<p><strong>User:</strong></p>

<ul>
<li>id</li>
<li>login (username)</li>
<li><em>a bunch of other fields</em></li>
</ul>

<p><strong>Miniature:</strong></p>

<ul>
<li>id</li>
<li>name</li>
<li>number (# in the set, not count)</li>
<li>release_id (foreign key)</li>
<li><em>a bunch of other fields and foreign keys</em></li>
</ul>

<p><strong>Ownership:</strong></p>

<ul>
<li>id (is this really even needed?)</li>
<li>user_id</li>
<li>miniature_id</li>
<li>have_count</li>
<li>favorite (boolean)</li>
</ul>

<p>The pertinent relationships I have set up are as follows:</p>

<p><strong>User:</strong></p>

<ul>
<li>has_many :ownerships</li>
<li>has_many :miniatures, :through => :ownerships, :uniq => true, :conditions => ""ownerships.have_count > 0""</li>
<li>has_many :favorites, :through => :ownerships, :source => :miniature, :uniq => true, :conditions => ""ownerships.favorite = true""</li>
</ul>

<p><strong>Miniatures:</strong></p>

<ul>
<li>has_many :ownerships</li>
<li>has_many :owners, :through => :ownerships, :source => :user, :uniq => true, :conditions => ""ownerships.have_count > 0""</li>
</ul>

<p><strong>Ownership:</strong></p>

<ul>
<li>belongs_to :user</li>
<li>belongs_to :miniature</li>
</ul>

<p>I have a page where user's can both view and update their collection, as well as view other user's collections.  It contains a list of all the miniatures on the site and a text box next to each where the user can enter how many of each miniature they have.  This functionality also exists in sub-lists of miniatures (filtered by type, release, size, rarity, etc.)</p>

<p>When a user creates an account they have no entries in the ownership.  When they use the collection page or sub-list of miniatures to update their collection, I create entries in the ownership table for only the miniatures on the submitting page.  So if it's the full Collection list I update all minis (even if the count is 0) or if it's a sub-list, I only update those miniatures.  So at any time a particular user I may have:
  - no entries in ownership
  - entries for some of the miniatures
  - entries for all the miniatures.</p>

<p>The problem I'm having is that I don't know how to query the database with a LEFT JOIN using a ""Rails method"" so that if a user doesn't have an entry for a miniature in Ownerships it defaults to a have_count of 0.  Currently I query for each user_id/miniature_id combination individually as I loop through all miniatures and it's obviously really inefficient.</p>

<p><strong>View:</strong></p>

<pre><code>&lt;% for miniature in @miniatures %&gt;
  &lt;td&gt;&lt;%= link_to miniature.name, miniature %&gt;&lt;/td&gt;
  &lt;td&gt;&lt;%= text_field_tag ""counts[#{miniature.id}]"", get_user_miniature_count(current_user, miniature), :size =&gt; 2 %&gt;&lt;/td&gt;
&lt;% end %&gt;
</code></pre>

<p><strong>Helper:</strong></p>

<pre><code>def get_user_miniature_count(user, miniature)
  ownerships = user.ownerships
  ownership = user.ownerships.find_by_miniature_id(miniature.id)
  if ownership.nil?
    return 0
  else
    return ownership.have_count
  end
end
</code></pre>

<p>An alternate solution would be creating entries for all miniatures when a user signs up, but then I would also have to add a 0 have_count for all users when a new miniature is added to the database after they sign up.  That seems like it could get a bit complex, but perhaps it's the right way to go?</p>

<p>Is there a way to do the join and supply a default value for miniatures where there's no entries in the Ownership table for that particular user?</p>
","<p>Using fd's suggestion and information found at <a href=""http://www.ruby-forum.com/topic/52385"" rel=""nofollow"">http://www.ruby-forum.com/topic/52385</a>, I created the following method:</p>

<pre><code>def miniature_count(miniature_id)
  if @counts.nil?
    @counts = Hash.new
    ownerships.collect{|o| @counts[o.miniature_id] = o.have_count }
  end
  count = @counts[miniature_id] || 0
end
</code></pre>

<p>This ends up being faster than the <em>detect</em> approach.</p>

<p>I picked *miniature_count* over <em>owns</em> for the name because <em>owns</em> sounds like a method that should return a boolean instead of an integer.</p>

<p><strong>Query Every Entry</strong></p>

<p>Completed in 2.61783 (0 reqs/sec) | Rendering: 1.14116 (43%) | DB: 1.34131 (51%) | 200 OK [<a href=""http://ddmdb/collection/1"" rel=""nofollow"">http://ddmdb/collection/1</a>]</p>

<p><strong>Detect Methods</strong></p>

<p>Completed in 2.20406 (0 reqs/sec) | Rendering: 1.87113 (84%) | DB: 0.21206 (9%) | 200 OK [<a href=""http://ddmdb/collection/1"" rel=""nofollow"">http://ddmdb/collection/1</a>]</p>

<p><strong>Hash Method</strong></p>

<p>Completed in 0.41957 (2 reqs/sec) | Rendering: 0.19290 (45%) | DB: 0.10735 (25%) | 200 OK [<a href=""http://ddmdb/collection/1"" rel=""nofollow"">http://ddmdb/collection/1</a>]</p>

<p>I will definitely need to add caching, but this is definitely an improvement.  I also suspect I am prematurely optimizing this code, but it's a small site and a 2.5 second load time was not making me happy.</p>
"
670,293600,3,3,sql,"If I'm posting a question about Oracle SQL query performance, what should I include in my question?","<p>If I am posting a question about a query against an Oracle database, what should I include in my question so that people have a chance to answer me?  How should I get this information?</p>

<p>Simply providing the poorly performing query may not be enough.</p>
","<p>Ideally, get the full query plan using DBMS_XPLAN.DISPLAY_CURSOR using the sql_id and child_cursor_id from v$sql. Failing that (ie on older versions), try v$sql_plan and include filter and access predicates. EXPLAIN PLAN is fine if it actually shows the plan that was used.</p>

<p>DB version and edition (Express/Standard/Enterprise). Maybe the OS too.
SELECT * FROM V$VERSION</p>

<p>If you have any non-standard database parameters, it is useful to know (especially anything optimizer related).
select * from v$parameter where rownum &lt; 5 and isdefault != 'TRUE';
*If you do a 
    alter session set events '10053 trace name context forever, level 1'
and parse a query, there'll be a log file that will include all the parameters used when optimizing a query * </p>

<p>Real world table sizes and column distributions (eg it is a million row table, with 30% of rows being ""Red"" etc). And the relevant stats off USER_TABLES, USER_TAB_COLUMNS.</p>

<p>How long it actually look, plus any SQL stats you have available (consistent gets, physical reads) from v$sql.</p>

<p>Also, who do you THINK it should be able to run faster. Do you think there's a better plan, or are you just crossing your fingers.</p>
"
669,293600,4,3,sql,"If I'm posting a question about Oracle SQL query performance, what should I include in my question?","<p>If I am posting a question about a query against an Oracle database, what should I include in my question so that people have a chance to answer me?  How should I get this information?</p>

<p>Simply providing the poorly performing query may not be enough.</p>
","<ul>
<li>The schema definition of the tables involved.</li>
<li>The indexes defined on those tables.</li>
<li>The query you are executing.</li>
<li>The resulting query execution plan</li>
</ul>
"
668,293600,3,3,sql,"If I'm posting a question about Oracle SQL query performance, what should I include in my question?","<p>If I am posting a question about a query against an Oracle database, what should I include in my question so that people have a chance to answer me?  How should I get this information?</p>

<p>Simply providing the poorly performing query may not be enough.</p>
","<p>The query plan is always useful</p>
"
514,216480,1,3,sql,NHibernate custom SQL object creation,"<p>Somewhat-simplified example situation: I have entities A and B which are incredibly ""heavy"" domain objects. Loading one from the database is a pretty big deal. Then I have an entity C, which is a very simple object that has a label string, one A, and one B -- both lazy.</p>

<p>I'm doing some low-level querying to create huge lists of C, so I know exactly what IDs I need to save for C.A and C.B, but I <em>don't</em> want to load up entire objects and set them to the properties, because the overhead is insane.</p>

<p>Instead, I want to just insert the IDs directly into my C entities, and then let the A and B properties on it be fully loaded later only if needed.</p>

<p>I see the <code>&lt;sql-insert/&gt;</code> tag in the documentation, but the section is <em>really</em> sparse. </p>

<p>Is there any way to do what I want to do inside the NHibernate framework, or should I just do raw SQL? I'm trying to keep database portability if possible, which makes me shy away from the raw option. Seems like there's got to be a better way I'm missing.</p>
","<p>Dan -- not sure if this will work without testing, but its worth a shot.  I guess your already have the Ids that you want to add to your C -- so set your associations (many-to-one I'm assuming) to insert=""false"" and update=""false"" (maybe cascade=""none"" would work alternatively as well).  Then create an ""empty copy"" of your A and B entities, add the Ids to them, add them to C and try to save C (Session.SaveOrUpdateCopy(C)).  Hopefully NHibernate will not attempt to add a new A and B object into their respective table, but will simply set the correct Ids within the C table -- this way you don't have to load the A and B entities.</p>

<p>The bad part is, if you have to save or update A and B, you'll have to do it directly. The other bad part is that I don't have time to test this, so I don't know if it will work.</p>
"
1180,529850,2,3,sql,MDX Calculating Time Between Events,"<p>I have a Cube which draws its data from 4 fact/dim tables. </p>

<ol>
<li><code>FactCaseEvents (EventID,CaseID,TimeID)</code>  </li>
<li><code>DimEvents (EventID, EventName)</code>  </li>
<li><code>DimCases (CaseID,StateID,ClientID)</code>  </li>
<li><code>DimTime (TimeID,FullDate)</code></li>
</ol>

<p>Events would be: <code>CaseReceived,CaseOpened,CaseClientContacted,CaseClosed</code></p>

<p>DimTime holds an entry for every hour.</p>

<p>I would like to write an MDX statement that will get me 2 columns: ""<code>CaseRecievedToCaseOpenedOver5</code>"" and ""<code>CaseClientContactedToCaseClosedOver5</code>""</p>

<p><code>CaseRecievedToCaseOpenedOver5</code> would hold the number of cases that had a time difference over 5 hours for the time between <code>CaseReceived</code> and <code>CaseOpened</code>.</p>

<p>I'm guessing that ""<code>CaseRecievedToCaseOpenedOver5</code>"" and ""<code>CaseClientContactedToCaseClosedOver5</code>"" would be calculated members, but I need some help figuring out how to create them.</p>

<p>Thanks in advance.</p>
","<p>This looks like a good place to use an accumulating snapshot type fact table and calculate the time it takes to move from one stage of the pipeline to the next in the ETL process.</p>
"
513,216480,1,3,sql,NHibernate custom SQL object creation,"<p>Somewhat-simplified example situation: I have entities A and B which are incredibly ""heavy"" domain objects. Loading one from the database is a pretty big deal. Then I have an entity C, which is a very simple object that has a label string, one A, and one B -- both lazy.</p>

<p>I'm doing some low-level querying to create huge lists of C, so I know exactly what IDs I need to save for C.A and C.B, but I <em>don't</em> want to load up entire objects and set them to the properties, because the overhead is insane.</p>

<p>Instead, I want to just insert the IDs directly into my C entities, and then let the A and B properties on it be fully loaded later only if needed.</p>

<p>I see the <code>&lt;sql-insert/&gt;</code> tag in the documentation, but the section is <em>really</em> sparse. </p>

<p>Is there any way to do what I want to do inside the NHibernate framework, or should I just do raw SQL? I'm trying to keep database portability if possible, which makes me shy away from the raw option. Seems like there's got to be a better way I'm missing.</p>
","<p>I don't know if NHibernate allows this (separate objects on same base data) but usually I make ""digest"" objects which can be upconverted into the full-blown objects (even with lazy loading on the full-blown objects).  I usually do this with code-gen'd or manual ORM layers.</p>

<p>Large collections are usually of digests, and then if the properties or methods needed aren't exposed by the digest, they are upconverted into complete objects for the call, or to be passed etc.</p>
"
900,407320,0,3,sql,"Strange SQL2005 problem. ""SqlConnection does not support parallel transactions""","<p>I have a problem that seems like its a result of a deadlock-situation. 
Whe are now searching for the root of the problem but meantime we wanted to restart the server and get the customer going.</p>

<p>And now everytime we start the program it just says ""SqlConnection does not support parallel transactions"". We have not changed anything in the program, its compiled and on the customers server, but after the ""possible deadlock""-situation it want go online again.</p>

<p>We have 7 clients (computers) running the program, each client is talking to a webservice on a local server, and the webservice is talking to the sql-server (same machine as webserver). </p>

<p>We have restarted both the sql-server and the iis-server, but not rebooted the server because of other important services running on the server so its the last thing we do.
We can se no locks or anything in the management tab. </p>

<p>So my question is, why does the ""SqlConnection does not support parallel transactions"" error comming from one time to another without changing anything in the program and it still lives between sql-restart.</p>

<p>It seems like it happens at the first db-request the program does when it start.</p>

<p>If you need more information just ask. Im puzzled...</p>

<p><strong>More information:</strong>
I dont think I have ""long"" running transactions. The scenario is often that I have a dataset with 20-100 rows (ContractRows) in that Ill do a .Update on the tableAdapter. I also loop throug those 20-100 rows and for some of them Ill create ad-hook-sql-querys (for example if a rented product is marked as returned I create a sql-query to mark the product as returned in the database)</p>

<p>So I do this very simplified:</p>

<pre><code>Create objTransactionObject
Create objtableadapter (objTransactionObject)
for each row in contractDS.contractrows
  if row.isreturned then
    strSQL &amp;= ""update product set instock=1 where prodid="" &amp; row.productid &amp; vbcrlf
 End if
next
objtableadapter.update(contractDS)
objData.ExecuteQuery(strSQL, objTransactionObject)    
if succsesfull 
  objtransactionobject.commit
else
  objtransactionobject.rollback
end if
objTran.Dispose()
</code></pre>

<p>And then Im doing commit or rollback depending on if It went well or not.</p>

<p>Edit: None of the answers have solved the problem, but I'll thank you for the good trouble shooting pointers.</p>

<p>The ""SqlConnection does not support parallel transactions"" dissapeared suddenly and now the sql-server just ""goes down"" 4-5 times a day, I guess its a deadlock that does that but I have not the right knowledge to find out and are short on sql-experts who can monitor this for me at the moment. I just restart the sql-server and everything works again. 1 of 10 times I also have to restart the computer. Its really bugging me (and my customers of course).</p>

<p>Anyone knowing a person with <strong>good</strong> knowledge in analyzing troubles with deadlocks or other sql problems in sweden (or everywhere in the world,english speaking)  are free to contact me. I know this is'nt a contact site but I take my chanse to ask the question because I have run out of options, I have spent 3 days and nights optimizing the clients to be sure we close connections and dont do too much stupid things there. Without luck.</p>
","<p>Have you tried doing a backup of your transaction log?  That might clear it out as well if I remember a previous, similar experience correctly.</p>
"
367,157020,1,3,sql,iSeries SQL Procedure - Check if already exists,"<p>I have an script that falls over if any of the procedures it is trying to create already exists. How can I check/drop if this procedure is already created?</p>
","<p>I would guess something along the lines of:</p>

<pre><code>IF EXISTS
(
    SELECT *
    FROM SYSPROCS
    WHERE SPECIFIC_SCHEMA = ???
      AND SPECIFIC_NAME = ???
      AND ROUTINE_SCHEMA = ???
      AND ROUTINE_NAME = ???
)
    DROP PROCEDURE ???
</code></pre>

<p>I don't know if you actually need the SPECIFIC_* information or not and I don't know how to handle cases where you have two procedures with the same name but different call signatures, but hopefully this gets you on the right track.</p>
"
899,407320,2,3,sql,"Strange SQL2005 problem. ""SqlConnection does not support parallel transactions""","<p>I have a problem that seems like its a result of a deadlock-situation. 
Whe are now searching for the root of the problem but meantime we wanted to restart the server and get the customer going.</p>

<p>And now everytime we start the program it just says ""SqlConnection does not support parallel transactions"". We have not changed anything in the program, its compiled and on the customers server, but after the ""possible deadlock""-situation it want go online again.</p>

<p>We have 7 clients (computers) running the program, each client is talking to a webservice on a local server, and the webservice is talking to the sql-server (same machine as webserver). </p>

<p>We have restarted both the sql-server and the iis-server, but not rebooted the server because of other important services running on the server so its the last thing we do.
We can se no locks or anything in the management tab. </p>

<p>So my question is, why does the ""SqlConnection does not support parallel transactions"" error comming from one time to another without changing anything in the program and it still lives between sql-restart.</p>

<p>It seems like it happens at the first db-request the program does when it start.</p>

<p>If you need more information just ask. Im puzzled...</p>

<p><strong>More information:</strong>
I dont think I have ""long"" running transactions. The scenario is often that I have a dataset with 20-100 rows (ContractRows) in that Ill do a .Update on the tableAdapter. I also loop throug those 20-100 rows and for some of them Ill create ad-hook-sql-querys (for example if a rented product is marked as returned I create a sql-query to mark the product as returned in the database)</p>

<p>So I do this very simplified:</p>

<pre><code>Create objTransactionObject
Create objtableadapter (objTransactionObject)
for each row in contractDS.contractrows
  if row.isreturned then
    strSQL &amp;= ""update product set instock=1 where prodid="" &amp; row.productid &amp; vbcrlf
 End if
next
objtableadapter.update(contractDS)
objData.ExecuteQuery(strSQL, objTransactionObject)    
if succsesfull 
  objtransactionobject.commit
else
  objtransactionobject.rollback
end if
objTran.Dispose()
</code></pre>

<p>And then Im doing commit or rollback depending on if It went well or not.</p>

<p>Edit: None of the answers have solved the problem, but I'll thank you for the good trouble shooting pointers.</p>

<p>The ""SqlConnection does not support parallel transactions"" dissapeared suddenly and now the sql-server just ""goes down"" 4-5 times a day, I guess its a deadlock that does that but I have not the right knowledge to find out and are short on sql-experts who can monitor this for me at the moment. I just restart the sql-server and everything works again. 1 of 10 times I also have to restart the computer. Its really bugging me (and my customers of course).</p>

<p>Anyone knowing a person with <strong>good</strong> knowledge in analyzing troubles with deadlocks or other sql problems in sweden (or everywhere in the world,english speaking)  are free to contact me. I know this is'nt a contact site but I take my chanse to ask the question because I have run out of options, I have spent 3 days and nights optimizing the clients to be sure we close connections and dont do too much stupid things there. Without luck.</p>
","<p>Do you have <a href=""http://msdn.microsoft.com/en-us/library/ms188317.aspx"" rel=""nofollow"">implicit transactions</a> turned on somewhere, so that there are some transactions where you wouldn't have expected them? Have you opened Activity Monitor to see if there are any unexpected transactions?</p>
"
898,407320,2,3,sql,"Strange SQL2005 problem. ""SqlConnection does not support parallel transactions""","<p>I have a problem that seems like its a result of a deadlock-situation. 
Whe are now searching for the root of the problem but meantime we wanted to restart the server and get the customer going.</p>

<p>And now everytime we start the program it just says ""SqlConnection does not support parallel transactions"". We have not changed anything in the program, its compiled and on the customers server, but after the ""possible deadlock""-situation it want go online again.</p>

<p>We have 7 clients (computers) running the program, each client is talking to a webservice on a local server, and the webservice is talking to the sql-server (same machine as webserver). </p>

<p>We have restarted both the sql-server and the iis-server, but not rebooted the server because of other important services running on the server so its the last thing we do.
We can se no locks or anything in the management tab. </p>

<p>So my question is, why does the ""SqlConnection does not support parallel transactions"" error comming from one time to another without changing anything in the program and it still lives between sql-restart.</p>

<p>It seems like it happens at the first db-request the program does when it start.</p>

<p>If you need more information just ask. Im puzzled...</p>

<p><strong>More information:</strong>
I dont think I have ""long"" running transactions. The scenario is often that I have a dataset with 20-100 rows (ContractRows) in that Ill do a .Update on the tableAdapter. I also loop throug those 20-100 rows and for some of them Ill create ad-hook-sql-querys (for example if a rented product is marked as returned I create a sql-query to mark the product as returned in the database)</p>

<p>So I do this very simplified:</p>

<pre><code>Create objTransactionObject
Create objtableadapter (objTransactionObject)
for each row in contractDS.contractrows
  if row.isreturned then
    strSQL &amp;= ""update product set instock=1 where prodid="" &amp; row.productid &amp; vbcrlf
 End if
next
objtableadapter.update(contractDS)
objData.ExecuteQuery(strSQL, objTransactionObject)    
if succsesfull 
  objtransactionobject.commit
else
  objtransactionobject.rollback
end if
objTran.Dispose()
</code></pre>

<p>And then Im doing commit or rollback depending on if It went well or not.</p>

<p>Edit: None of the answers have solved the problem, but I'll thank you for the good trouble shooting pointers.</p>

<p>The ""SqlConnection does not support parallel transactions"" dissapeared suddenly and now the sql-server just ""goes down"" 4-5 times a day, I guess its a deadlock that does that but I have not the right knowledge to find out and are short on sql-experts who can monitor this for me at the moment. I just restart the sql-server and everything works again. 1 of 10 times I also have to restart the computer. Its really bugging me (and my customers of course).</p>

<p>Anyone knowing a person with <strong>good</strong> knowledge in analyzing troubles with deadlocks or other sql problems in sweden (or everywhere in the world,english speaking)  are free to contact me. I know this is'nt a contact site but I take my chanse to ask the question because I have run out of options, I have spent 3 days and nights optimizing the clients to be sure we close connections and dont do too much stupid things there. Without luck.</p>
","<p>Yours doesn't appear to be an unusual problem.  Google found a lot of hits when I pasted your error string into the query box.</p>

<p>Reading past answers, it sounds like it has something to do with interleaving transactions improperly or isolation level.</p>

<p>How long are connections held open?  Do you have long-running transactions?</p>
"
471,204050,4,3,sql,MSSQL2000: get list of role members,"<p>I know a role name and want to find all users in this role. 
How do I acheive this in SQL Server 2000 (in the SQL script, not in Management Studio or other tool)?</p>
","<p>You can use the following stored procedures:</p>

<p>For fixed server roles, the stored procedure is <a href=""http://msdn.microsoft.com/en-us/library/ms188772.aspx"" rel=""nofollow"">sp_helpsrvrolemember</a>:</p>

<pre><code>exec sp_helpsrvrolemember 'role'
</code></pre>

<p>For general roles, the stored procedure is <a href=""http://msdn.microsoft.com/en-us/library/ms178021.aspx"" rel=""nofollow"">sp_helprolemember</a>:</p>

<pre><code>exec sp_helprolemember 'role'
</code></pre>
"
472,204050,0,3,sql,MSSQL2000: get list of role members,"<p>I know a role name and want to find all users in this role. 
How do I acheive this in SQL Server 2000 (in the SQL script, not in Management Studio or other tool)?</p>
","<p>Just use SQL-DMO:
Replace <em>rolename</em> with your role</p>

<pre><code>exec sp_helprolemember rolename
</code></pre>
"
107,38680,0,3,sql,How to provide next page of updated content?,"<p>Feel free to edit the title if you know how to formulate the question better. (Tagging is a problem as well.) The problem may be too difficult in this general form, so let us consider a concrete example.</p>

<p>You get a screenful of stackoverflow questions by requesting <code>/questions ?sort=newest</code> page. Next page link leads to <code>/questions?page=2 &amp;sort=newest</code>. I suppose that at server side, the request is translated into an SQL query with LIMIT clause. Problem with this approach is, that if new question were added while user browses first page, his second page will start with some questions he already saw. (If he has 10 question per page, and 10 new questions happened to be added, hell get exactly the same content second time!)</p>

<p>Is there an elegant way to solve this common problem? I realize that it is not that big a problem, at least not for stackoverflow, but still.</p>

<p>The best idea I have (apart from storing request history per client) is to use <code>/questions?answer_id=NNN</code> format. Server returns a page that starts with the requested answer, and puts the id of the first answer on the next page into next page link. There must be a way to write SQL for that, right? </p>

<p>Is it how it usually done? Or there is a better way?</p>
","<p>I believe the SQL (for MySQL) would be: </p>

<pre><code>SELECT * 
FROM   entries 
WHERE  entry_id &gt;= @last_viewed_entry_id 
ORDER BY entry_id 
LIMIT 50
</code></pre>
"
108,38680,1,3,sql,How to provide next page of updated content?,"<p>Feel free to edit the title if you know how to formulate the question better. (Tagging is a problem as well.) The problem may be too difficult in this general form, so let us consider a concrete example.</p>

<p>You get a screenful of stackoverflow questions by requesting <code>/questions ?sort=newest</code> page. Next page link leads to <code>/questions?page=2 &amp;sort=newest</code>. I suppose that at server side, the request is translated into an SQL query with LIMIT clause. Problem with this approach is, that if new question were added while user browses first page, his second page will start with some questions he already saw. (If he has 10 question per page, and 10 new questions happened to be added, hell get exactly the same content second time!)</p>

<p>Is there an elegant way to solve this common problem? I realize that it is not that big a problem, at least not for stackoverflow, but still.</p>

<p>The best idea I have (apart from storing request history per client) is to use <code>/questions?answer_id=NNN</code> format. Server returns a page that starts with the requested answer, and puts the id of the first answer on the next page into next page link. There must be a way to write SQL for that, right? </p>

<p>Is it how it usually done? Or there is a better way?</p>
","<p>This can't be done an easy way. For instance, the ""Unanswered"" list here at stackoverflow is sorted by number of votes. So if you'd save the last ID of the page you're viewing (in a cookie, request, session, whereever) and someone upvotes a post while you're browsing page 2, page 3 isn't complete since the recently upvoted post could have been moved to page 1 or 2.</p>

<p>Only way to do it is to load the complete list in someones session. Please don't...</p>

<p>As already mentioned, let's hope people are used to this by now.</p>
"
109,38940,11,3,sql,Generate field in MySQL SELECT,"<p>If I've got a table containing Field1 and Field2 can I generate a new field in the select statement? For example, a normal query would be:</p>

<pre><code>SELECT Field1, Field2 FROM Table
</code></pre>

<p>And I want to also create Field3 and have that returned in the resultset... something along the lines of this would be ideal:</p>

<pre><code>SELECT Field1, Field2, Field3 = 'Value' FROM Table
</code></pre>

<p>Is this possible at all?</p>
","<pre><code>SELECT Field1, Field2, 'Value' Field3 FROM Table
</code></pre>

<p>or for clarity</p>

<pre><code>SELECT Field1, Field2, 'Value' AS Field3 FROM Table
</code></pre>
"
110,38940,5,3,sql,Generate field in MySQL SELECT,"<p>If I've got a table containing Field1 and Field2 can I generate a new field in the select statement? For example, a normal query would be:</p>

<pre><code>SELECT Field1, Field2 FROM Table
</code></pre>

<p>And I want to also create Field3 and have that returned in the resultset... something along the lines of this would be ideal:</p>

<pre><code>SELECT Field1, Field2, Field3 = 'Value' FROM Table
</code></pre>

<p>Is this possible at all?</p>
","<p>Yes - it's very possible, in fact you almost had it!
Try:</p>

<pre><code>SELECT Field1, Field2, 'Value' AS `Field3` FROM Table
</code></pre>
"
876,391000,8,3,sql,How do I trim date in PLSQL?,"<p>I have a date variable as 24-dec-08
I want only the 08 component from it.
How do I do it in a select statement?</p>

<p>e.g.:</p>

<pre><code>select db||sysdate 
(this is the component where I want only 08 from the date) 
from gct;
</code></pre>

<p>How do i do it?</p>
","<p>The easiest way is to use the <code>to_char</code> function this way:</p>

<pre><code>to_char(sysdate, 'YY')
</code></pre>

<p>as <a href=""http://www.techonthenet.com/oracle/functions/to_char.php"" rel=""nofollow"">documented here</a>.</p>

<p>If you need the integer value, you could use the <code>extract</code> function for dates too. Take a look <a href=""http://www.techonthenet.com/oracle/functions/extract.php"" rel=""nofollow"">here</a> for a detailed description of the <code>extract</code> syntax.</p>

<p>For example:</p>

<pre><code>extract(YEAR FROM DATE '2008-12-24')
</code></pre>

<p>would return <em>2008</em>. </p>

<p>If you just need the value of the last two digits, you could apply the <a href=""http://www.techonthenet.com/oracle/functions/mod.php"" rel=""nofollow"">modulo function</a> <code>MOD</code>:</p>

<pre><code>mod(extract(YEAR FROM DATE '2008-12-24'), 100)
</code></pre>

<p>would return <em>8</em>.</p>
"
877,391000,1,3,sql,How do I trim date in PLSQL?,"<p>I have a date variable as 24-dec-08
I want only the 08 component from it.
How do I do it in a select statement?</p>

<p>e.g.:</p>

<pre><code>select db||sysdate 
(this is the component where I want only 08 from the date) 
from gct;
</code></pre>

<p>How do i do it?</p>
","<p>The normal way to do this in Oracle is:</p>

<pre><code>select db||to_char(sysdate,'YY')
from gct;
</code></pre>
"
140,53670,3,3,sql,How to efficiently SQL select newest entries from a MySQL database?,"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/49404/sql-query-to-get-latest-price"">SQL Query to get latest price</a>  </p>
</blockquote>



<p>I have a database containing stock price history. I want to select most recent prices for every stock that is listed. I know PostreSQL has a <a href=""http://stackoverflow.com/questions/25224/joining-latest-of-various-usermetadata-tags-to-user-rows#27159"">DISTINCT ON</a> statement that would suit ideally here.</p>

<p>Table columns are <code>name</code>, <code>closingPrice</code> and <code>date</code>; <code>name</code> and <code>date</code> together form a unique index.</p>

<p>The <em>easiest</em> (and very uneffective) way is</p>

<pre><code>SELECT * FROM stockPrices s
WHERE s.date =
(SELECT MAX(date) FROM stockPrices si WHERE si.name = s.name);
</code></pre>

<p>Much better approach I found is</p>

<pre><code>SELECT *
FROM stockPrices s JOIN (
  SELECT name, MAX(date) AS date
  FROM stockPrices si
  GROUP BY name
) lastEntry ON s.name = lastEntry.name AND s.date = lastEntry.date;
</code></pre>

<p>What would be an efficient way to do this? What indexes should I create?</p>

<blockquote>
  <p>duplicate of:<br>
  <a href=""http://stackoverflow.com/questions/49404/sql-query-to-get-latest-price"">SQL Query to get latest price</a></p>
</blockquote>
","<p>See <a href=""http://stackoverflow.com/questions/49404/sql-query-to-get-latest-price"" rel=""nofollow"">similar post</a></p>
"
141,53670,0,3,sql,How to efficiently SQL select newest entries from a MySQL database?,"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/49404/sql-query-to-get-latest-price"">SQL Query to get latest price</a>  </p>
</blockquote>



<p>I have a database containing stock price history. I want to select most recent prices for every stock that is listed. I know PostreSQL has a <a href=""http://stackoverflow.com/questions/25224/joining-latest-of-various-usermetadata-tags-to-user-rows#27159"">DISTINCT ON</a> statement that would suit ideally here.</p>

<p>Table columns are <code>name</code>, <code>closingPrice</code> and <code>date</code>; <code>name</code> and <code>date</code> together form a unique index.</p>

<p>The <em>easiest</em> (and very uneffective) way is</p>

<pre><code>SELECT * FROM stockPrices s
WHERE s.date =
(SELECT MAX(date) FROM stockPrices si WHERE si.name = s.name);
</code></pre>

<p>Much better approach I found is</p>

<pre><code>SELECT *
FROM stockPrices s JOIN (
  SELECT name, MAX(date) AS date
  FROM stockPrices si
  GROUP BY name
) lastEntry ON s.name = lastEntry.name AND s.date = lastEntry.date;
</code></pre>

<p>What would be an efficient way to do this? What indexes should I create?</p>

<blockquote>
  <p>duplicate of:<br>
  <a href=""http://stackoverflow.com/questions/49404/sql-query-to-get-latest-price"">SQL Query to get latest price</a></p>
</blockquote>
","<p>I think that your second approach is very efficient. What's its problem?</p>

<p>You have to add indexes to name and date.</p>
"
368,157020,1,3,sql,iSeries SQL Procedure - Check if already exists,"<p>I have an script that falls over if any of the procedures it is trying to create already exists. How can I check/drop if this procedure is already created?</p>
","<pre><code>IF  EXISTS (SELECT * FROM dbo.sysobjects WHERE id = OBJECT_ID(N'[dbo].[Procedure_Name]') AND OBJECTPROPERTY(id,N'IsProcedure') = 1)
DROP PROCEDURE [dbo].[Procedure_Name]
</code></pre>

<p>I think this would help you</p>
"
382,170440,0,3,sql,Stored procedure not being executed within another stored procedure,"<p>I have found that SP2 doesn't execute from within SP1 when SP1 is executed.</p>

<p>Below is the structure of SP1:</p>

<pre><code>ALTER PROCEDURE SP1 AS BEGIN

Declare c1 cursor....

open c1 fetch next from c1 ...

while @@fetch_status = 0 Begin

...

Fetch Next from c1 end

close c1

deallocate c1

exec sp2

end
</code></pre>

<hr>

<p>I see non of the PRINT statement outputs if they are printed in the 'Output window' in SQL Server 2005 management studio as the 'Output Window'is empty.</p>
","<p>you could use @@error to see if there was an error when executing the previous statement.</p>
"
518,221040,0,3,sql,Record level permissions,"<p><p>In a database I am designing I have implemented profile based object level security.
<p>Each user can view, edit, insert, update database tables according to the profiles (roles) he is a member of.
<p>Now there is a need to implement ""External Users"" who can view only the relevant records and edit some of them (but not the bulk of the database).</p>

<p><p>I am working on an ""record ownership"" model.
<p>Are there any ideas on how to restrict the users belonging to an ""External Users"" profile to see and work with some records of each table, but not all.</p>
","<p><p>I have my first draft. It goes like that:
<p>The app is a Project Management/Issue Tracking/Event Management/Collaboration Web app.
<p>I created a Role ""External User"". By default a user in that role </p>

<ul>
<li>can SELECT FROM Persons 
<li>can SELECT FROM Units (organizational units-companies-depts etc)
<li>can SELECT Projects assigned to him
<li>can SELECT Tasks assigned to him
<li>can not SELECT any other Projects & Tasks
</ul>

<p><p>The administrator can create a user group ""External Partner"" and assign to that some Projects and Products (with Issues)
<p>The members of this group can SELECT the assigned Objects.</p>

<p><p>It is a complicated solution, but the only one that solves my customers problem (they don't want external partners to have access to all their project database).</p>
"
1035,484040,-1,3,sql,Swapping two rows in MS SQLServer retaining the original primary key and without manual update,"<p>I have the following problem : I have rows like </p>

<pre><code>ID   CODE     NAME            .........
1    h1100h1  Cool example1   .........
2    h654441  Another cool1   .........
</code></pre>

<p>I would like to swap them retaining all old primary keys and constraints. Of course, I can easily solve this manually by updating the rows. I am kind of wondering whether anybody has any excellent solution for this kind of problem instead of just executing update command manually. I really really appreciate any suggestions or recommendations.</p>
","<p>self join with an update is your only safe bet</p>
"
357,151800,7,3,sql,Sqlite update field if it contains,"<p>Given a database field named ""widget_ids"", containing data like ""67/797/124/"" or ""45/"", where the numbers are slash separated widget_ids... how would you make an update statement with SQL that would say:
""if the widget_ids of the row with id X contains the text ""somenumber/"" do nothing, otherwise append ""somenumber/"" to it's current value""</p>

<p>Can you do something like that with SQL, or more specifically, sqlite? Is that something that is better done in the program for some reason or is there support for ""if-then"" like syntax in SQL?</p>
","<p>Updates are kind of like if-thens themselves, and there is also if-then support of some sort in most SQL implementations. A simple solution might be:</p>

<pre><code>update &lt;tablename&gt;
  set widget_id = widget_id + ""somenumber/""
  where row_id = X
    and widget_id not like ""%/somenumber/%""
    and widget_id not like ""somenumber/%"";
</code></pre>
"
358,151800,3,3,sql,Sqlite update field if it contains,"<p>Given a database field named ""widget_ids"", containing data like ""67/797/124/"" or ""45/"", where the numbers are slash separated widget_ids... how would you make an update statement with SQL that would say:
""if the widget_ids of the row with id X contains the text ""somenumber/"" do nothing, otherwise append ""somenumber/"" to it's current value""</p>

<p>Can you do something like that with SQL, or more specifically, sqlite? Is that something that is better done in the program for some reason or is there support for ""if-then"" like syntax in SQL?</p>
","<p>First, get rid of the symbol-separated list.  Use another table, with one widget id per row.</p>

<pre><code>CREATE TABLE ThingieWidgets (
  thingie_id INT REFERENCES Thingies,
  widget_id INT REFERENCES Widgets,
  PRIMARY KEY(thingie_id, widget_id)
);
</code></pre>

<p>Fill the table with values from the slash-separated list:</p>

<pre><code>INSERT INTO ThingieWidgets (thingie_id, widget_id)
  VALUES (1234, 67), (1234, 797), (1234, 124);
</code></pre>

<p>Now you can test if Thingie 1234 references Widget 45:</p>

<pre><code>SELECT * FROM ThingieWidgets
WHERE thingie_id = 1234 AND widget_id = 45;
</code></pre>

<p>You can try to insert and recover if there's a duplicate key error:</p>

<pre><code>INSERT INTO ThingieWidgets (thingie_id, widget_id)
  VALUES (1234, 45);
</code></pre>
"
360,155220,3,3,sql,Dynamic SQL - Search Query - Variable Number of Keywords,"<p>We are trying to update our classic asp search engine to protect it from SQL injection.  We have a VB 6 function which builds a query dynamically by concatenating a query together based on the various search parameters.  We have converted this to a stored procedure using dynamic sql for all parameters except for the keywords.</p>

<p>The problem with keywords is that there are a variable number words supplied by the user and we want to search several columns for each keyword. Since we cannot create a separate parameter for each keyword, how can we build a safe query?</p>

<p>Example</p>

<p>@CustomerId AS INT
@Keywords AS NVARCHAR(MAX)</p>

<p>@sql = 'SELECT event_name FROM calendar WHERE customer_id = @CustomerId '</p>

<p>--(loop through each keyword passed in and concatenate)</p>

<p>@sql = @sql + 'AND (event_name LIKE ''%' + @Keywords + '%'' OR event_details LIKE ''%' + @Keywords + '%'')'</p>

<p>EXEC sp_executesql @sql N'@CustomerId INT, @CustomerId = @CustomerId</p>

<p>What is the best way to handle this and maintaining protection from SQL injection? </p>
","<p>You may not like to hear this, but it might be better for you to go back to dynamically constructing your SQL query in code before issuing against the database. If you use parameter placeholders in the SQL string you get the protection against SQL injection attacks.</p>

<p>Example:</p>

<pre><code>string sql  = ""SELECT Name, Title FROM Staff WHERE UserName=@UserId"";
using (SqlCommand cmd = new SqlCommand(sql))
{
  cmd.Parameters.Add(""@UserId"", SqlType.VarChar).Value = ""smithj"";
</code></pre>

<p>You can build the SQL string depending on the set of columns you need to query and then add the parameter values once the string is complete. This is a bit of a pain to do, but I think it is much easier than having really complicated TSQL which unpicks lots of possible permutations of possible inputs.</p>
"
361,155220,1,3,sql,Dynamic SQL - Search Query - Variable Number of Keywords,"<p>We are trying to update our classic asp search engine to protect it from SQL injection.  We have a VB 6 function which builds a query dynamically by concatenating a query together based on the various search parameters.  We have converted this to a stored procedure using dynamic sql for all parameters except for the keywords.</p>

<p>The problem with keywords is that there are a variable number words supplied by the user and we want to search several columns for each keyword. Since we cannot create a separate parameter for each keyword, how can we build a safe query?</p>

<p>Example</p>

<p>@CustomerId AS INT
@Keywords AS NVARCHAR(MAX)</p>

<p>@sql = 'SELECT event_name FROM calendar WHERE customer_id = @CustomerId '</p>

<p>--(loop through each keyword passed in and concatenate)</p>

<p>@sql = @sql + 'AND (event_name LIKE ''%' + @Keywords + '%'' OR event_details LIKE ''%' + @Keywords + '%'')'</p>

<p>EXEC sp_executesql @sql N'@CustomerId INT, @CustomerId = @CustomerId</p>

<p>What is the best way to handle this and maintaining protection from SQL injection? </p>
","<p>You have 3 options here. </p>

<ol>
<li><p>Use a <a href=""http://www.sommarskog.se/arrays-in-sql-2005.html"" rel=""nofollow"">function that converts lists tables</a> and join into it. So you will have something like this.</p>

<p>SELECT * FROM calendar c
JOIN dbo.fnListToTable(@Keywords) k ON c.keyword = k.keyword  </p></li>
<li><p>Have a fixed set of params, and only allow the maximum of N keywords to be searched on</p>

<p>CREATE PROC spTest
   @Keyword1 varchar(100),
   @Keyword2 varchar(100),
   .... </p></li>
<li><p>Write an escaping string function in TSQL and escape your keywords. </p></li>
</ol>
"
362,155220,0,3,sql,Dynamic SQL - Search Query - Variable Number of Keywords,"<p>We are trying to update our classic asp search engine to protect it from SQL injection.  We have a VB 6 function which builds a query dynamically by concatenating a query together based on the various search parameters.  We have converted this to a stored procedure using dynamic sql for all parameters except for the keywords.</p>

<p>The problem with keywords is that there are a variable number words supplied by the user and we want to search several columns for each keyword. Since we cannot create a separate parameter for each keyword, how can we build a safe query?</p>

<p>Example</p>

<p>@CustomerId AS INT
@Keywords AS NVARCHAR(MAX)</p>

<p>@sql = 'SELECT event_name FROM calendar WHERE customer_id = @CustomerId '</p>

<p>--(loop through each keyword passed in and concatenate)</p>

<p>@sql = @sql + 'AND (event_name LIKE ''%' + @Keywords + '%'' OR event_details LIKE ''%' + @Keywords + '%'')'</p>

<p>EXEC sp_executesql @sql N'@CustomerId INT, @CustomerId = @CustomerId</p>

<p>What is the best way to handle this and maintaining protection from SQL injection? </p>
","<ul>
<li><p>Unless you need it, you could simply strip out any character that's not in [a-zA-Z ] - most of those things won't be in searches and you should not be able to be injected that way, nor do you have to worry about keywords or anything like that.  If you allow quotes, however, you will need to be more careful.</p></li>
<li><p>Similar to sambo99's #1, you can insert the keywords into a temporary table or table variable and join to it (even using wildcards) without danger of injection:</p></li>
</ul>

<p>This isn't really dynamic:</p>

<pre><code>SELECT DISTINCT event_name
FROM calendar
INNER JOIN #keywords
    ON event_name LIKE '%' + #keywords.keyword + '%'
    OR event_description LIKE '%' + #keywords.keyword + '%'
</code></pre>

<ul>
<li><p>You can actually generate an SP with a large number of parameters instead of coding it by hand (set the defaults to '' or NULL depending on your preference in coding your searches).  If you found you needed more parameters, it would be simple to increase the number of parameters it generated.</p></li>
<li><p>You can move the search to a full-text index outside the database like Lucene and then use the Lucene results to pull the matching database rows.</p></li>
</ul>
"
1036,484040,6,3,sql,Swapping two rows in MS SQLServer retaining the original primary key and without manual update,"<p>I have the following problem : I have rows like </p>

<pre><code>ID   CODE     NAME            .........
1    h1100h1  Cool example1   .........
2    h654441  Another cool1   .........
</code></pre>

<p>I would like to swap them retaining all old primary keys and constraints. Of course, I can easily solve this manually by updating the rows. I am kind of wondering whether anybody has any excellent solution for this kind of problem instead of just executing update command manually. I really really appreciate any suggestions or recommendations.</p>
","<p>I haven't tested this, but I think it will work. I'm assuming that id is a single-column Primary Key. If that's not the case then you will need to adjust this code slightly to handle the PK.</p>

<pre><code>UPDATE
     T1
SET
     column_1 = T2.column_1,
     column_2 = T2.column_2,
     ...
FROM
     dbo.My_Table T1
INNER JOIN dbo.My_Table T2 ON
     T2.id =
          CASE
               WHEN T1.id = @id_1 THEN @id_2
               WHEN T1.id = @id_2 THEN @id_1
               ELSE NULL
          END
WHERE
     T1.id IN (@id_1, @id_2)
</code></pre>
"
1092,496070,4,3,sql,Should I use Top(1) in a SubQuery,"<p>Example Query:</p>

<pre><code>select * 
from A join B on A.ID = B.SOMEVALUE
where A.VALUE=""something"" and
B.ID = 
       (select ID from B where SOMEVALUE = A.ID and 
              THISDATE = (select max(SOMEDATE) from B where ...))
</code></pre>

<p>so, if you can read SQL you should see that I am doing a couple correlated subqueries to narrow down the results of the join . (and yes, this is horribly over-simplified).</p>

<p>In certain cases the subquery:</p>

<pre><code>select ID from B where SOMEVALUE = A.ID and 
    THISDATE = (select max(SOMEDATE) from B where ...)
</code></pre>

<p>can return more than 1 value, which causes an error </p>

<blockquote>
  <p>""Subquery returned more than 1 value.
  This is not permitted when the
  subquery follows =, !=, &lt;, &lt;= , >, >=
  or when the subquery is used as an
  expression.""</p>
</blockquote>

<p>which I fully expect.  This is obviously not a good thing and I have code in place to (hopefully) prevent these duplicates from getting into the database in the first place (ie table B <em>should</em> only have 1 row that matches the </p>

<pre><code>SOMEVALUE = A.ID and max(SOMEDATE)
</code></pre>

<p>criteria), however end-users are nothing if not creative in finding ways I can't think of to break software.</p>

<p>So now to my question:</p>

<p>Would it be better to change the first subquery to </p>

<pre><code>select top 1 * from B ...
</code></pre>

<p>to prevent the user from seeing an error when/if (hopefully never) this situation arises or let the error come through.  I'm leaning to not adding the top statement and letting the error come through rather then let the user see potentially incorrect data.  I'm wondering if anyone has any thoughts on Best Practices in a situation like this...</p>
","<p>Coding Practice: Placing top1 in a subquery which is required to return a single value.</p>

<p>Pros:</p>

<ul>
<li>Allows execution to continue.</li>
<li>Allows the query to ignore insigificant Extra Values.</li>
<li>Stops looking for new values when the first Value has been found (performant).</li>
</ul>

<p>Cons:</p>

<ul>
<li>Prevents the query from complaining about significant Extra Values.</li>
<li>If order is not specified in the query, there is no control over which element top1 will select.  This can cause a different result when the query is executed a second time.</li>
</ul>
"
1091,496070,1,3,sql,Should I use Top(1) in a SubQuery,"<p>Example Query:</p>

<pre><code>select * 
from A join B on A.ID = B.SOMEVALUE
where A.VALUE=""something"" and
B.ID = 
       (select ID from B where SOMEVALUE = A.ID and 
              THISDATE = (select max(SOMEDATE) from B where ...))
</code></pre>

<p>so, if you can read SQL you should see that I am doing a couple correlated subqueries to narrow down the results of the join . (and yes, this is horribly over-simplified).</p>

<p>In certain cases the subquery:</p>

<pre><code>select ID from B where SOMEVALUE = A.ID and 
    THISDATE = (select max(SOMEDATE) from B where ...)
</code></pre>

<p>can return more than 1 value, which causes an error </p>

<blockquote>
  <p>""Subquery returned more than 1 value.
  This is not permitted when the
  subquery follows =, !=, &lt;, &lt;= , >, >=
  or when the subquery is used as an
  expression.""</p>
</blockquote>

<p>which I fully expect.  This is obviously not a good thing and I have code in place to (hopefully) prevent these duplicates from getting into the database in the first place (ie table B <em>should</em> only have 1 row that matches the </p>

<pre><code>SOMEVALUE = A.ID and max(SOMEDATE)
</code></pre>

<p>criteria), however end-users are nothing if not creative in finding ways I can't think of to break software.</p>

<p>So now to my question:</p>

<p>Would it be better to change the first subquery to </p>

<pre><code>select top 1 * from B ...
</code></pre>

<p>to prevent the user from seeing an error when/if (hopefully never) this situation arises or let the error come through.  I'm leaning to not adding the top statement and letting the error come through rather then let the user see potentially incorrect data.  I'm wondering if anyone has any thoughts on Best Practices in a situation like this...</p>
","<p>I'd recommend the TOP 1 approach. It will probably help performance (not likely to hurt it). </p>

<p>The notion that without it you'll catch errors is honorable but a little misplaced. If an error occurs here months from now, it will NOT be intuitive at all why it occurred or what's going on. Instead, I'd focus on enforcing data integrity elsewhere.</p>
"
1090,496070,4,3,sql,Should I use Top(1) in a SubQuery,"<p>Example Query:</p>

<pre><code>select * 
from A join B on A.ID = B.SOMEVALUE
where A.VALUE=""something"" and
B.ID = 
       (select ID from B where SOMEVALUE = A.ID and 
              THISDATE = (select max(SOMEDATE) from B where ...))
</code></pre>

<p>so, if you can read SQL you should see that I am doing a couple correlated subqueries to narrow down the results of the join . (and yes, this is horribly over-simplified).</p>

<p>In certain cases the subquery:</p>

<pre><code>select ID from B where SOMEVALUE = A.ID and 
    THISDATE = (select max(SOMEDATE) from B where ...)
</code></pre>

<p>can return more than 1 value, which causes an error </p>

<blockquote>
  <p>""Subquery returned more than 1 value.
  This is not permitted when the
  subquery follows =, !=, &lt;, &lt;= , >, >=
  or when the subquery is used as an
  expression.""</p>
</blockquote>

<p>which I fully expect.  This is obviously not a good thing and I have code in place to (hopefully) prevent these duplicates from getting into the database in the first place (ie table B <em>should</em> only have 1 row that matches the </p>

<pre><code>SOMEVALUE = A.ID and max(SOMEDATE)
</code></pre>

<p>criteria), however end-users are nothing if not creative in finding ways I can't think of to break software.</p>

<p>So now to my question:</p>

<p>Would it be better to change the first subquery to </p>

<pre><code>select top 1 * from B ...
</code></pre>

<p>to prevent the user from seeing an error when/if (hopefully never) this situation arises or let the error come through.  I'm leaning to not adding the top statement and letting the error come through rather then let the user see potentially incorrect data.  I'm wondering if anyone has any thoughts on Best Practices in a situation like this...</p>
","<p>Why are you joining table A and B... then selecting from B in the sub query... and comparing to a column in A???</p>

<p>Wouldn't this be equivalent:</p>

<pre><code>select * 
from A join B on A.ID = B.SOMEVALUE
where A.VALUE=""something"" and
THISDATE = (select max(SOMEDATE) from B where ...))
</code></pre>

<p>Also, if you are expecting to get one row total from this entire query... wouldn't this work:</p>

<pre><code>select top 1 * 
from A join B on A.ID = B.SOMEVALUE
where A.VALUE=""something"" 
Order by B.SOMEDATE DESC
</code></pre>
"
1089,496070,0,3,sql,Should I use Top(1) in a SubQuery,"<p>Example Query:</p>

<pre><code>select * 
from A join B on A.ID = B.SOMEVALUE
where A.VALUE=""something"" and
B.ID = 
       (select ID from B where SOMEVALUE = A.ID and 
              THISDATE = (select max(SOMEDATE) from B where ...))
</code></pre>

<p>so, if you can read SQL you should see that I am doing a couple correlated subqueries to narrow down the results of the join . (and yes, this is horribly over-simplified).</p>

<p>In certain cases the subquery:</p>

<pre><code>select ID from B where SOMEVALUE = A.ID and 
    THISDATE = (select max(SOMEDATE) from B where ...)
</code></pre>

<p>can return more than 1 value, which causes an error </p>

<blockquote>
  <p>""Subquery returned more than 1 value.
  This is not permitted when the
  subquery follows =, !=, &lt;, &lt;= , >, >=
  or when the subquery is used as an
  expression.""</p>
</blockquote>

<p>which I fully expect.  This is obviously not a good thing and I have code in place to (hopefully) prevent these duplicates from getting into the database in the first place (ie table B <em>should</em> only have 1 row that matches the </p>

<pre><code>SOMEVALUE = A.ID and max(SOMEDATE)
</code></pre>

<p>criteria), however end-users are nothing if not creative in finding ways I can't think of to break software.</p>

<p>So now to my question:</p>

<p>Would it be better to change the first subquery to </p>

<pre><code>select top 1 * from B ...
</code></pre>

<p>to prevent the user from seeing an error when/if (hopefully never) this situation arises or let the error come through.  I'm leaning to not adding the top statement and letting the error come through rather then let the user see potentially incorrect data.  I'm wondering if anyone has any thoughts on Best Practices in a situation like this...</p>
","<p>If you're looking to return just a single row you could do one of two things.  The first is to change your equality check to instead check containment like so</p>

<pre><code>select ID from B where SOMEVALUE = A.ID and 
THISDATE IN (select max(SOMEDATE) from B where ...)
</code></pre>

<p>(Notice the IN)</p>

<p>Secondly you could do</p>

<pre><code>select TOP 1 ID from B where SOMEVALUE = A.ID and 
THISDATE IN (select max(SOMEDATE) from B where ...)
</code></pre>

<p>if you're only looking for one value only.</p>

<p>Or as you said, you could change the sub-query to SELECT TOP 1 which is okay, in my opinion, because as long as the WHERE clause isn't dependant on the outer-query it will probably execute the nested query only once and rely on a statically stored value from there on out like so</p>

<pre><code>select ID from B where SOMEVALUE = A.ID and 
THISDATE = (select TOP 1 * from B where ...)
</code></pre>

<p>So there's a few options, but I'm not entirely sure of their efficiency.</p>
"
1001,460300,0,2,sql,Storing Queries in C# or use Stored Functions in Postgres?,"<p>Should I be storing the raw SQL queries in my c# code, or should I be delegating them to stored functions in the Postgres Backend?</p>

<p>If I should be storing them in code, since they can get quite long, what is the optimal way to store them (ie. as constants in a separate static class)?</p>

<p>Does using stored functions have any impact on deployability/updatability of an application?</p>

<p>Thanks</p>
","<p>From the normal deployability/updatability considerations, storing SQL queries in code will limit your options, as source code is less likely to be recompiled when deployed, in comparison with the usual modifications/hotfixes of SQL stored procedures.</p>

<p>Of course it also depends on how big the your ""update"" would be. This point would be mood if there are significant changes of business logics or a database switch is required</p>
"
937,435540,3,2,sql,SQL Sub-Query vs Join Confusion,"<p>I have a database which is in Access (you can get it <a href=""http://cid-84dd6ce2da273835.skydrive.live.com/self.aspx/.Public/Unisa.accdb"" rel=""nofollow"">link text</a>). If I run</p>

<pre><code>SELECT DISTINCT Spl.Spl_No, Spl.Spl_Name
FROM Spl INNER JOIN Del 
   ON Spl.Spl_No = Del.Spl_No
WHERE Del.Item_Name &lt;&gt; 'Compass'
</code></pre>

<p>It provides the names of the suppliers that have never delivered a compass. However you can supposedly do this with a sub-query. So far myself and a few others have not been able to get it right.</p>

<p>I did come close with the following, until we added more suppliers then it stopped working</p>

<pre><code>SELECT SPL.SPL_Name
FROM SPL
LEFT JOIN DEL ON Del.SPL_No = SPL.SPL_No
WHERE (DEL.Item_Name&lt;&gt;""Compass"") OR (DEL.Item_Name IS NULL)
GROUP BY SPL.SPL_Name
HAVING COUNT(DEL.SPL_No) = 0
</code></pre>

<p>So the question: Is this possible to do with a sub-query.</p>
","<p>I think I would go for:</p>

<pre><code>SELECT SELECT Spl_No, Spl_Name
FROM Spl
WHERE Spl_No NOT IN 
  (SELECT Spl_No FROM Del
   WHERE Item_Name = 'Compass')
</code></pre>
"
1019,473610,0,2,sql,Export Excel range/sheet to formatted text file,"<p>I have been tasked with creating a reusable process for our Finance Dept to upload our payroll to the State(WI) for reporting. I need to create something that takes a sheet or range in Excel and creates a specifically formatted text file.</p>

<p><strong><em>THE FORMAT</em></strong></p>

<ul>
<li>Column 1 - A Static Number, never changes, position 1-10</li>
<li>Column 2 - A Dynamic Param filled at runtime for Quarter/Year, position 11-13</li>
<li>Column 3 - SSN, no hyphens or spaces,
filled from column A, position 14-22</li>
<li>Column 4 - Last Name, filled from
column B, Truncated at 10, Left
Justify &amp; fill with blanks, position
23-32</li>
<li>Column 5 - First Name, filled from C,
Truncate at 8, Left Justify &amp; fill
with blanks, position 33-40</li>
<li>Column 6 - Total Gross Wages/Quarter,
filled from D, strip all formatting,
Right Justify Zero Fill, position
41-49</li>
<li>Column 7 - A Static Code, never
changes, position 50-51</li>
<li>Column 8 - BLANKS, Fill with blanks,
position 52-80</li>
</ul>

<p>I have, I assume, 3 options:</p>

<ol>
<li>VBA</li>
<li>.NET</li>
<li>SQL</li>
</ol>

<p>I had explored the .NET method first but I just couldn't find decent documentation to get me going.  I still like this one but I digress.</p>

<p>Next I have some VBA that will dump a Sheet to a fixed width Text.  I am currently pursuing this which leads, finally, to my actual question.</p>

<p>How do I transform a Range of text in Excel?  Do I need to coy it over to another sheet and then pass over that data with the neccesarry formatting functions the run my Dump to text routine?  I currently had planned to have a function for each column but I am having trouble figuring out how to take the next step.  I am fairly new at Office programming and developing in general so any insight will be greatly appreciated.</p>

<p>The SQL option would be my fall back as I have done similar exports from SQL in the past.  I just prefer the other two on the, <em>""I don't want to be responsible for running this,""</em> principle.</p>

<p>Thanks in advance for any time given.</p>
","<p>Thinking about this strictly from the viewpoint of what's easiest for you, and if you are comfortable with SQL, in the context of Access, you could use Access to attach to the spreadsheet as an external datasource. It would look like a table in Access, and work from there.</p>
"
851,377840,1,2,sql,How to truncate and shrink log files?,"<p>How to truncate and shrink large log files in SQL Server 2005? How to apply truncation at regular intervals?</p>

<p>Is there any difference between truncation and shrinking?</p>

<p>Thanks in advance</p>
","<p>Reliable shrinking is achieved by </p>

<ul>
<li>Backup (can be truncate only)</li>
<li>Checkpoint</li>
<li>Shrink</li>
</ul>
"
1003,460300,0,2,sql,Storing Queries in C# or use Stored Functions in Postgres?,"<p>Should I be storing the raw SQL queries in my c# code, or should I be delegating them to stored functions in the Postgres Backend?</p>

<p>If I should be storing them in code, since they can get quite long, what is the optimal way to store them (ie. as constants in a separate static class)?</p>

<p>Does using stored functions have any impact on deployability/updatability of an application?</p>

<p>Thanks</p>
","<p>I think it's better to use stored procedures because of its using gives performance. In case if it's possible.</p>

<p>I mean - queries and source code, local variables, etc are enough 'independent' - it doesn't requires much 'preparation' and you can just send some variables to a stored procedure as parameters.</p>
"
826,358760,0,2,sql,"When adding new items to a database with foreign keys, should I use SQL triggers to create the related rows in other tables?","<p>I am implementing a database design that has a vehicle table, vehicle engine and vehicle gear table with SQL 2005.</p>

<p>Each table has an ID that is a SQL identity number, and each engine and gear has a relation with the vehicle ID.
So before I create a vehicle I must create an engine and gear.</p>

<p>How could I know the vehicle identity number when creating the engine and gear? The vehicle row hasn't yet been created because of the foreign key constraint with the engine and gear tables?</p>

<p>Should I implement an automatic trigger that on a creation of a vehicle creates an empty row for the engine and gear linked to the vehicle? But again how could I know the vehicle ID?</p>
","<p>These kind of things are solved with any persistence framework out there. In a typical O/R mapper scenario, you simply create the entities required (indirectly for example) and the O/R mapper saves them in the right order and syncs the FK/PK fields automatically. </p>

<p>If you're fighting with these kind of problems, you really lose time (and thus money) over things which are already solved for you and you can't spend that time on the problem for the customer. So do yourself and your customer a favor and at least look at some of the persistence frameworks out there. </p>

<p>(disclaimer: I'm the lead developer of an o/r mapper framework)</p>
"
827,358760,0,2,sql,"When adding new items to a database with foreign keys, should I use SQL triggers to create the related rows in other tables?","<p>I am implementing a database design that has a vehicle table, vehicle engine and vehicle gear table with SQL 2005.</p>

<p>Each table has an ID that is a SQL identity number, and each engine and gear has a relation with the vehicle ID.
So before I create a vehicle I must create an engine and gear.</p>

<p>How could I know the vehicle identity number when creating the engine and gear? The vehicle row hasn't yet been created because of the foreign key constraint with the engine and gear tables?</p>

<p>Should I implement an automatic trigger that on a creation of a vehicle creates an empty row for the engine and gear linked to the vehicle? But again how could I know the vehicle ID?</p>
","<blockquote>
  <p>But again how could I know the vehicle
  ID?</p>
</blockquote>

<p>There is a table called <a href=""http://msdn.microsoft.com/en-us/library/ms191300.aspx"" rel=""nofollow"">INSERTED</a> which is available in insert triggers. You will find the vehicle ID there.</p>
"
1002,460300,3,2,sql,Storing Queries in C# or use Stored Functions in Postgres?,"<p>Should I be storing the raw SQL queries in my c# code, or should I be delegating them to stored functions in the Postgres Backend?</p>

<p>If I should be storing them in code, since they can get quite long, what is the optimal way to store them (ie. as constants in a separate static class)?</p>

<p>Does using stored functions have any impact on deployability/updatability of an application?</p>

<p>Thanks</p>
","<p>As a rule we do all of our database interactions via stored procedures instead of direct SQL statements; this allows a lot of flexibility for adjusting to schema changes and performance issues without having to rebuild or redeploy binary images or configuration files to all targets.</p>
"
828,358760,-1,2,sql,"When adding new items to a database with foreign keys, should I use SQL triggers to create the related rows in other tables?","<p>I am implementing a database design that has a vehicle table, vehicle engine and vehicle gear table with SQL 2005.</p>

<p>Each table has an ID that is a SQL identity number, and each engine and gear has a relation with the vehicle ID.
So before I create a vehicle I must create an engine and gear.</p>

<p>How could I know the vehicle identity number when creating the engine and gear? The vehicle row hasn't yet been created because of the foreign key constraint with the engine and gear tables?</p>

<p>Should I implement an automatic trigger that on a creation of a vehicle creates an empty row for the engine and gear linked to the vehicle? But again how could I know the vehicle ID?</p>
","<p>If you really can't create each entity at diferent moments, you should create them within a transaction, explicitly showing at are the necessary steps to create each entity.</p>

<p>The trigger solution, which is many times the easier to implement, would be the hardest to mantain, because it ""hides"" behind the curtins important business rules.</p>

<p>Well .... in either case, you really should take a look at your problem definition, as this kind of questions usually arrise from bad business domain definition.</p>

<p><strong>Bottom line: each trigger you have would be another headache for the next project iteraction.</strong></p>
"
936,435540,1,2,sql,SQL Sub-Query vs Join Confusion,"<p>I have a database which is in Access (you can get it <a href=""http://cid-84dd6ce2da273835.skydrive.live.com/self.aspx/.Public/Unisa.accdb"" rel=""nofollow"">link text</a>). If I run</p>

<pre><code>SELECT DISTINCT Spl.Spl_No, Spl.Spl_Name
FROM Spl INNER JOIN Del 
   ON Spl.Spl_No = Del.Spl_No
WHERE Del.Item_Name &lt;&gt; 'Compass'
</code></pre>

<p>It provides the names of the suppliers that have never delivered a compass. However you can supposedly do this with a sub-query. So far myself and a few others have not been able to get it right.</p>

<p>I did come close with the following, until we added more suppliers then it stopped working</p>

<pre><code>SELECT SPL.SPL_Name
FROM SPL
LEFT JOIN DEL ON Del.SPL_No = SPL.SPL_No
WHERE (DEL.Item_Name&lt;&gt;""Compass"") OR (DEL.Item_Name IS NULL)
GROUP BY SPL.SPL_Name
HAVING COUNT(DEL.SPL_No) = 0
</code></pre>

<p>So the question: Is this possible to do with a sub-query.</p>
","<p>It's pretty close to exactly how you would say it in English</p>

<p>""Give me the suppliers who have not made a delivery of Compasses."" </p>

<pre><code>Select [Stuff]
From Spl S
Where Not Exists
   (Select * From Del
    Where Spl_no = S.Spl_no 
       And Item_name  = 'Compass')
</code></pre>

<p>EDIT:
   Without Exists, you can use Count(*) = 0</p>

<pre><code>Select [Stuff]
From Spl S
Where 
   (Select Count(*) From Del
    Where Spl_no = S.Spl_no 
       And Item_name  = 'Compass') = 0
</code></pre>
"
830,358760,0,2,sql,"When adding new items to a database with foreign keys, should I use SQL triggers to create the related rows in other tables?","<p>I am implementing a database design that has a vehicle table, vehicle engine and vehicle gear table with SQL 2005.</p>

<p>Each table has an ID that is a SQL identity number, and each engine and gear has a relation with the vehicle ID.
So before I create a vehicle I must create an engine and gear.</p>

<p>How could I know the vehicle identity number when creating the engine and gear? The vehicle row hasn't yet been created because of the foreign key constraint with the engine and gear tables?</p>

<p>Should I implement an automatic trigger that on a creation of a vehicle creates an empty row for the engine and gear linked to the vehicle? But again how could I know the vehicle ID?</p>
","<p>Thanks for all the answers.</p>

<p>Actually I meant:
Vehicle: (ID, other Vehicle data, ...)
Engine (ID, VehicleID, other engine data)
Gear (ID, VehicleID, other gear data)</p>

<p>So each vehicle can have multiple engines and gears (Yes I know that in the real world an engine can fit multiple cars but thats not my target)</p>

<p>I wasn't aware of the enforce foreign key constraint that by default is set to YES in SQL 2005.</p>

<p>So set it to NO and know its working just fine.</p>

<p>Thanks again,</p>

<p>Omri.</p>
"
829,358760,1,2,sql,"When adding new items to a database with foreign keys, should I use SQL triggers to create the related rows in other tables?","<p>I am implementing a database design that has a vehicle table, vehicle engine and vehicle gear table with SQL 2005.</p>

<p>Each table has an ID that is a SQL identity number, and each engine and gear has a relation with the vehicle ID.
So before I create a vehicle I must create an engine and gear.</p>

<p>How could I know the vehicle identity number when creating the engine and gear? The vehicle row hasn't yet been created because of the foreign key constraint with the engine and gear tables?</p>

<p>Should I implement an automatic trigger that on a creation of a vehicle creates an empty row for the engine and gear linked to the vehicle? But again how could I know the vehicle ID?</p>
","<p>The fact that you have foreign key relationships between your tables does not mean that you have to create your data in a particular order. Normally, one would expect the Vehicle record to be created first, and then have engines and gears assigned to it later, but this does not have to be the case.</p>

<p>If, in your scenario, it is possible for engines or gears to be recorded in the database, before being assigned to a vehicle, then you will need to make the FK columns which reference Vehicle ID allow nulls. These can then be linked to a vehicle id once the vehicle row has been created.</p>

<p>Alternatively, you can create your Vehicle record, then assign engine and gear records to it as they are created.</p>
"
825,358760,0,2,sql,"When adding new items to a database with foreign keys, should I use SQL triggers to create the related rows in other tables?","<p>I am implementing a database design that has a vehicle table, vehicle engine and vehicle gear table with SQL 2005.</p>

<p>Each table has an ID that is a SQL identity number, and each engine and gear has a relation with the vehicle ID.
So before I create a vehicle I must create an engine and gear.</p>

<p>How could I know the vehicle identity number when creating the engine and gear? The vehicle row hasn't yet been created because of the foreign key constraint with the engine and gear tables?</p>

<p>Should I implement an automatic trigger that on a creation of a vehicle creates an empty row for the engine and gear linked to the vehicle? But again how could I know the vehicle ID?</p>
","<p>I have to say that personally I believe this scenario doesn't make sense, really.</p>

<p>In order for a gear or engine to exist, you need a vehicle.  Your business rules/Domain Model should really enforce that, and the foreign key relationships are then just a way of validating this is the case.</p>

<p>Alternatively it might be better to think of the engine-vehicle relationship as a many-many.  For this you need an additional table to link the vehicle and engine.  This would mean you can have foreign key constraints, but it also means that an engine can be linked to many cars, and vice versa.  This more realistically models the real-world, where the same engine is used in many models of car, and a car may have a variety of engines to chose from.</p>
"
850,377840,6,2,sql,How to truncate and shrink log files?,"<p>How to truncate and shrink large log files in SQL Server 2005? How to apply truncation at regular intervals?</p>

<p>Is there any difference between truncation and shrinking?</p>

<p>Thanks in advance</p>
","<p>Use DBCC SHRINKFILE and schedule it as a job that runs regularly (preferably during off-hours).  </p>

<p>Just be aware that there is a performance hit from regularly growing and shrinking the log file.  If you have the space, you may want to set the file size to the maximum that it normally grows to and just leave it.</p>
"
1000,460300,0,2,sql,Storing Queries in C# or use Stored Functions in Postgres?,"<p>Should I be storing the raw SQL queries in my c# code, or should I be delegating them to stored functions in the Postgres Backend?</p>

<p>If I should be storing them in code, since they can get quite long, what is the optimal way to store them (ie. as constants in a separate static class)?</p>

<p>Does using stored functions have any impact on deployability/updatability of an application?</p>

<p>Thanks</p>
","<p>Either way! But case by case,</p>

<p>SQL at code level as constant,</p>

<ul>
<li>Value is evaluated at compile time, this optimizes the performance.</li>
<li>It is safe, it can not be modified after code compiled or deployed. </li>
<li>Some draw back on performance by sending all the SQL text to the sql server over the wire. </li>
<li>Some drawback on security if SQL was dynamically created.</li>
</ul>

<p>SQL at SQL function level</p>

<ul>
<li>More Secure since parameters are
typed.</li>
<li>Easier to maintain against database schema. e.g. table can not dropped if one function is referencing it.</li>
<li>Better performance by just sending
through function names and parameters
to the SQL server.</li>
<li>Easier to apply hotfix at function level since it is not compiled.
People can see &amp; modify your code since it exposes as plain text.</li>
<li>Some drawback to maintain the versions between application and the sql function.</li>
</ul>
"
933,435540,1,2,sql,SQL Sub-Query vs Join Confusion,"<p>I have a database which is in Access (you can get it <a href=""http://cid-84dd6ce2da273835.skydrive.live.com/self.aspx/.Public/Unisa.accdb"" rel=""nofollow"">link text</a>). If I run</p>

<pre><code>SELECT DISTINCT Spl.Spl_No, Spl.Spl_Name
FROM Spl INNER JOIN Del 
   ON Spl.Spl_No = Del.Spl_No
WHERE Del.Item_Name &lt;&gt; 'Compass'
</code></pre>

<p>It provides the names of the suppliers that have never delivered a compass. However you can supposedly do this with a sub-query. So far myself and a few others have not been able to get it right.</p>

<p>I did come close with the following, until we added more suppliers then it stopped working</p>

<pre><code>SELECT SPL.SPL_Name
FROM SPL
LEFT JOIN DEL ON Del.SPL_No = SPL.SPL_No
WHERE (DEL.Item_Name&lt;&gt;""Compass"") OR (DEL.Item_Name IS NULL)
GROUP BY SPL.SPL_Name
HAVING COUNT(DEL.SPL_No) = 0
</code></pre>

<p>So the question: Is this possible to do with a sub-query.</p>
","<pre><code>SELECT Spl_No
     , Spl_Name
  FROM Spl
 WHERE NOT EXISTS( SELECT *
                     FROM Del
                    WHERE Del.Spl_no = Spl.Spl_no
                      AND Item_name  = 'Compass' )
</code></pre>
"
1027,480730,3,2,sql,How do I get a count of items in one column that match items in another column?,"<p>Assume I have two data tables and a linking table as such:</p>

<pre>

A         B         A_B_Link          
-----     -----     -----
ID        ID        A_ID
Name      Name      B_ID

</pre>

<p>2 Questions:</p>

<ol>
<li><p>I would like to write a query so that I have all of A's columns and a count of how many B's are linked to A, what is the best way to do this?</p></li>
<li><p>Is there a way to have a query return a row with all of the columns from A and a column containing <em>all</em> of linked names from B (maybe separated by some delimiter?)</p></li>
</ol>

<p>Note that <strong>the query must return distinct rows from A</strong>, so a simple left outer join is not going to work here...I'm guessing I'll need nested select statements?</p>
","<p>For #1</p>

<pre><code>SELECT A.*, 
(SELECT COUNT(*) FROM A_B_Link WHERE A_B_Link.A_ID = AOuter.A_ID)
FROM A as AOuter
</code></pre>
"
935,435540,1,2,sql,SQL Sub-Query vs Join Confusion,"<p>I have a database which is in Access (you can get it <a href=""http://cid-84dd6ce2da273835.skydrive.live.com/self.aspx/.Public/Unisa.accdb"" rel=""nofollow"">link text</a>). If I run</p>

<pre><code>SELECT DISTINCT Spl.Spl_No, Spl.Spl_Name
FROM Spl INNER JOIN Del 
   ON Spl.Spl_No = Del.Spl_No
WHERE Del.Item_Name &lt;&gt; 'Compass'
</code></pre>

<p>It provides the names of the suppliers that have never delivered a compass. However you can supposedly do this with a sub-query. So far myself and a few others have not been able to get it right.</p>

<p>I did come close with the following, until we added more suppliers then it stopped working</p>

<pre><code>SELECT SPL.SPL_Name
FROM SPL
LEFT JOIN DEL ON Del.SPL_No = SPL.SPL_No
WHERE (DEL.Item_Name&lt;&gt;""Compass"") OR (DEL.Item_Name IS NULL)
GROUP BY SPL.SPL_Name
HAVING COUNT(DEL.SPL_No) = 0
</code></pre>

<p>So the question: Is this possible to do with a sub-query.</p>
","<p>If Access has Exists.....</p>

<p>SELECT SPL.SPL_Name
FROM SPL
WHERE NOT EXISTS (SELECT 1 FROM DEL WHERE Del.SPL_No = SPL.SPL_No
              AND  (DEL.Item_Name='Compass')
)</p>
"
934,435540,2,2,sql,SQL Sub-Query vs Join Confusion,"<p>I have a database which is in Access (you can get it <a href=""http://cid-84dd6ce2da273835.skydrive.live.com/self.aspx/.Public/Unisa.accdb"" rel=""nofollow"">link text</a>). If I run</p>

<pre><code>SELECT DISTINCT Spl.Spl_No, Spl.Spl_Name
FROM Spl INNER JOIN Del 
   ON Spl.Spl_No = Del.Spl_No
WHERE Del.Item_Name &lt;&gt; 'Compass'
</code></pre>

<p>It provides the names of the suppliers that have never delivered a compass. However you can supposedly do this with a sub-query. So far myself and a few others have not been able to get it right.</p>

<p>I did come close with the following, until we added more suppliers then it stopped working</p>

<pre><code>SELECT SPL.SPL_Name
FROM SPL
LEFT JOIN DEL ON Del.SPL_No = SPL.SPL_No
WHERE (DEL.Item_Name&lt;&gt;""Compass"") OR (DEL.Item_Name IS NULL)
GROUP BY SPL.SPL_Name
HAVING COUNT(DEL.SPL_No) = 0
</code></pre>

<p>So the question: Is this possible to do with a sub-query.</p>
","<p>Do you mean something like this?</p>

<pre><code>SELECT SPL.SPL_Name
FROM SPL
WHERE NOT SPL.SPL_no IN 
 (SELECT SPL_no FROM DEL WHERE DEL.Item_Name = ""Compass"")
</code></pre>
"
1028,480730,2,2,sql,How do I get a count of items in one column that match items in another column?,"<p>Assume I have two data tables and a linking table as such:</p>

<pre>

A         B         A_B_Link          
-----     -----     -----
ID        ID        A_ID
Name      Name      B_ID

</pre>

<p>2 Questions:</p>

<ol>
<li><p>I would like to write a query so that I have all of A's columns and a count of how many B's are linked to A, what is the best way to do this?</p></li>
<li><p>Is there a way to have a query return a row with all of the columns from A and a column containing <em>all</em> of linked names from B (maybe separated by some delimiter?)</p></li>
</ol>

<p>Note that <strong>the query must return distinct rows from A</strong>, so a simple left outer join is not going to work here...I'm guessing I'll need nested select statements?</p>
","<pre><code>SELECT A.*, COUNT(B_ID)
FROM A
LEFT JOIN A_B_Link ab ON ab.A_ID=A.ID
</code></pre>
"
1020,473610,4,2,sql,Export Excel range/sheet to formatted text file,"<p>I have been tasked with creating a reusable process for our Finance Dept to upload our payroll to the State(WI) for reporting. I need to create something that takes a sheet or range in Excel and creates a specifically formatted text file.</p>

<p><strong><em>THE FORMAT</em></strong></p>

<ul>
<li>Column 1 - A Static Number, never changes, position 1-10</li>
<li>Column 2 - A Dynamic Param filled at runtime for Quarter/Year, position 11-13</li>
<li>Column 3 - SSN, no hyphens or spaces,
filled from column A, position 14-22</li>
<li>Column 4 - Last Name, filled from
column B, Truncated at 10, Left
Justify &amp; fill with blanks, position
23-32</li>
<li>Column 5 - First Name, filled from C,
Truncate at 8, Left Justify &amp; fill
with blanks, position 33-40</li>
<li>Column 6 - Total Gross Wages/Quarter,
filled from D, strip all formatting,
Right Justify Zero Fill, position
41-49</li>
<li>Column 7 - A Static Code, never
changes, position 50-51</li>
<li>Column 8 - BLANKS, Fill with blanks,
position 52-80</li>
</ul>

<p>I have, I assume, 3 options:</p>

<ol>
<li>VBA</li>
<li>.NET</li>
<li>SQL</li>
</ol>

<p>I had explored the .NET method first but I just couldn't find decent documentation to get me going.  I still like this one but I digress.</p>

<p>Next I have some VBA that will dump a Sheet to a fixed width Text.  I am currently pursuing this which leads, finally, to my actual question.</p>

<p>How do I transform a Range of text in Excel?  Do I need to coy it over to another sheet and then pass over that data with the neccesarry formatting functions the run my Dump to text routine?  I currently had planned to have a function for each column but I am having trouble figuring out how to take the next step.  I am fairly new at Office programming and developing in general so any insight will be greatly appreciated.</p>

<p>The SQL option would be my fall back as I have done similar exports from SQL in the past.  I just prefer the other two on the, <em>""I don't want to be responsible for running this,""</em> principle.</p>

<p>Thanks in advance for any time given.</p>
","<p>Using VBA seems like the way to go to me. This lets you write a macro that takes care of all of the various formatting options and should, hopefully, be simple enough for your finance people to run themselves.</p>

<p>You said you need something that takes a sheet or range in Excel. The first column never changes so we can store that in the macro, columns 3-7 come from the spreadsheet and column 8 is just blank. That leaves column 2 (the quarter/year as QYY) as an issue. If the quarter/year is specified somewhere in the workbook (e.g. stored in a cell, as a worksheet name, as part of the workbook title) then we can just read it in. Otherwise you will need to find some method for specifying the quarter/year when the macro runs (e.g. pop up a dialog box and ask the user to input it)</p>

<p>Some simple code (we'll worry about how to call this later):</p>

<pre><code>Sub ProduceStatePayrollReportFile(rngPayrollData As Range, strCompanyNo As String, _
    strQuarterYear As String, strRecordCode As String, strOutputFile As String)
</code></pre>

<p>The parameters are fairly obvious: the range that holds the data, the company number for column 1, the quarter/year for column 2, the fixed code for column 7 and the file we want to output the results to</p>

<pre><code>' Store the file handle for the output file
Dim fnOutPayrollReport As Integer
' Store each line of the output file
Dim strPayrollReportLine As String
' Use to work through each row in the range
Dim indexRow As Integer
</code></pre>

<p>To output to a file in VBA we need to get a file handle so we need a variable to store that in. We'll build up each line of the report in the report line string and use the row index to work through the range</p>

<pre><code>' Store the raw SSN, last name, first name and wages data
Dim strRawSSN As String
Dim strRawLastName As String
Dim strRawFirstName As String
Dim strRawWages As String
Dim currencyRawWages As Currency

' Store the corrected SSN, last name, first name and wages data
Dim strCleanSSN As String
Dim strCleanLastName As String
Dim strCleanFirstName As String
Dim strCleanWages As String
</code></pre>

<p>These sets of variables store the raw data from the worksheet and the cleaned data to be output to the file respectively. Naming them ""raw"" and ""clean"" makes it easier to spot errors where you accidentally output raw data instead of cleaned data. We will need to change the raw wages from a string value to a numeric value to help with the formatting</p>

<pre><code>' Open up the output file
fnOutPayrollReport = FreeFile()
Open strOutputFile For Output As #fnOutPayrollReport
</code></pre>

<p>FreeFile() gets the next available file handle and we use that to link to the file</p>

<pre><code>' Work through each row in the range
For indexRow = 1 To rngPayrollData.Rows.Count
    ' Reset the output report line to be empty
    strPayrollReportLine = """"
    ' Add the company number to the report line (assumption: already correctly formatted)
    strPayrollReportLine = strPayrollReportLine &amp; strCompanyNo
    ' Add in the quarter/year (assumption: already correctly formatted)
    strPayrollReportLine = strPayrollReportLine &amp; strQuarterYear
</code></pre>

<p>In our loop to work through each row, we start by clearing out the output string and then adding in the values for columns 1 and 2</p>

<pre><code>' Get the raw SSN data, clean it and append to the report line
strRawSSN = rngPayrollData.Cells(indexRow, 1)
strCleanSSN = cleanFromRawSSN(strRawSSN)
strPayrollReportLine = strPayrollReportLine &amp; strCleanSSN
</code></pre>

<p>The <code>.Cells(indexRow, 1)</code> part just means the left-most column of the range at the row specified by indexRow. If the ranges starts in column A (which does not have to be the case) then this just means A. We'll need to write the <code>cleanFromRawSSN</code> function ourselves later</p>

<pre><code>' Get the raw last and first names, clean them and append them
strRawLastName = rngPayrollData.Cells(indexRow, 2)
strCleanLastName = Format(Left$(strRawLastName, 10), ""!@@@@@@@@@@"")
strPayrollReportLine = strPayrollReportLine &amp; strCleanLastName

strRawFirstName = rngPayrollData.Cells(indexRow, 3)
strCleanFirstName = Format(Left$(strRawFirstName, 8), ""!@@@@@@@@"")
strPayrollReportLine = strPayrollReportLine &amp; strCleanFirstName
</code></pre>

<p><code>Left$(string, length)</code> truncates the string to the given length. The format picture <code>!@@@@@@@@@@</code> formats a string as exactly ten characters long, left justified (the ! signifies left justify) and padded with spaces</p>

<pre><code>' Read in the wages data, convert to numeric data, lose the decimal, clean it and append it
strRawWages = rngPayrollData.Cells(indexRow, 4)
currencyRawWages = CCur(strRawWages)
currencyRawWages = currencyRawWages * 100
strCleanWages = Format(currencyRawWages, ""000000000"")
strPayrollReportLine = strPayrollReportLine &amp; strCleanWages
</code></pre>

<p>We convert it to currency so that we can multiply by 100 to move the cents value to the left of the decimal point. This makes it much easier to use <code>Format</code> to generate the correct value. This will not produce correct output for wages >= $10 million but that's a limitation of the file format used for reporting. The <code>0</code> in the format picture pads with 0s surprisingly enough</p>

<pre><code>' Append the fixed code for column 7 and the spaces for column 8
strPayrollReportLine = strPayrollReportLine &amp; strRecordCode
strPayrollReportLine = strPayrollReportLine &amp; CStr(String(29, "" ""))

' Output the line to the file
Print #fnOutPayrollReport, strPayrollReportLine
</code></pre>

<p>The <code>String(number, char)</code> function produces a Variant with a sequence of <code>number</code> of the specified <code>char</code>. <code>CStr</code> turns the Variant into a string. The <code>Print #</code> statement outputs to the file without any additional formatting</p>

<pre><code>Next indexRow

' Close the file
Close #fnOutPayrollReport

End Sub
</code></pre>

<p>Loop round to the next row in the range and repeat. When we have processed all of the rows, close the file and end the macro</p>

<p>We still need two things: a cleanFromRawSSN function and a way to call the macro with the relevant data.</p>

<pre><code>Function cleanFromRawSSN(strRawSSN As String) As String

' Used to index the raw SSN so we can process it one character at a time
Dim indexRawChar As Integer

' Set the return string to be empty
cleanFromRawSSN = """"

' Loop through the raw data and extract the correct characters
For indexRawChar = 1 To Len(strRawSSN)
    ' Check for hyphen
    If (Mid$(strRawSSN, indexRawChar, 1) = ""-"") Then
        ' do nothing
    ' Check for space
    ElseIf (Mid$(strRawSSN, indexRawChar, 1) = "" "") Then
        ' do nothing
    Else
        ' Output character
        cleanFromRawSSN = cleanFromRawSSN &amp; Mid$(strRawSSN, indexRawChar, 1)
    End If
Next indexRawChar

' Check for correct length and return empty string if incorrect
If (Len(cleanFromRawSSN) &lt;&gt; 9) Then
    cleanFromRawSSN = """"
End If

End Function
</code></pre>

<p><code>Len</code> returns the length of a string and <code>Mid$(string, start, length)</code> returns <code>length</code> characters from <code>string</code> beginning at <code>start</code>. This function could be improved as it doesn't currently check for non-numeric data</p>

<p>To call the macro:</p>

<pre><code>Sub CallPayrollReport()

ProduceStatePayrollReportFile Application.Selection, ""1234560007"", ""109"", ""01"", ""C:\payroll109.txt""

End Sub
</code></pre>

<p>This is the simplest way to call it. The Range is whatever the user has selected on the active worksheet in the active workbook and the other values are hard-coded. The user should select the range they want to output to the file then go Tools > Macro > Run and choose <code>CallPayrollReport</code>. For this to work, the macro would either need to be part of the workbook containg the data or in a different workbook which had been loaded before the user calls the macro.</p>

<p>Someone would need to change the hard-coded value of the quarter/year before each quarter's report was generated. As stated earlier, if the quarter/year is already stored in the workbook somewhere then it's better to read that in rather than hard-coding it</p>

<p>Hope that makes sense and is of some use</p>
"
1029,480730,3,2,sql,How do I get a count of items in one column that match items in another column?,"<p>Assume I have two data tables and a linking table as such:</p>

<pre>

A         B         A_B_Link          
-----     -----     -----
ID        ID        A_ID
Name      Name      B_ID

</pre>

<p>2 Questions:</p>

<ol>
<li><p>I would like to write a query so that I have all of A's columns and a count of how many B's are linked to A, what is the best way to do this?</p></li>
<li><p>Is there a way to have a query return a row with all of the columns from A and a column containing <em>all</em> of linked names from B (maybe separated by some delimiter?)</p></li>
</ol>

<p>Note that <strong>the query must return distinct rows from A</strong>, so a simple left outer join is not going to work here...I'm guessing I'll need nested select statements?</p>
","<p>For your first question:</p>

<pre><code>SELECT A.ID, A.Name, COUNT(ab.B_ID) AS bcount
FROM A LEFT JOIN A_B_Link ab ON (ab.A_ID = A.ID)
GROUP BY A.ID, A.Name;
</code></pre>

<p>This outputs one row per row of A, with the count of matching B's.  Note that you must list all columns of A in the GROUP BY statement; there's no way to use a wildcard here.</p>

<p>An alternate solution is to use a correlated subquery, as @Ray Booysen shows:</p>

<pre><code>SELECT A.*, 
  (SELECT COUNT(*) FROM A_B_Link 
   WHERE A_B_Link.A_ID = A.A_ID) AS bcount
FROM A;
</code></pre>

<p>This works, but correlated subqueries aren't very good for performance.</p>

<p>For your second question, you need something like MySQL's <code>GROUP_CONCAT()</code> aggregate function.  In MySQL, you can get a comma-separated list of <code>B.Name</code> per row of A like this:</p>

<pre><code>SELECT A.*, GROUP_CONCAT(B.Name) AS bname_list
FROM A 
  LEFT OUTER JOIN A_B_Link ab ON (A.ID = ab.A_ID)
  LEFT OUTER JOIN B ON (ab.B_ID = B.ID)
GROUP BY A.ID;
</code></pre>

<p>There's no easy equivalent in Microsoft SQL Server.  Check here for another question on SO about this:
""<a href=""http://stackoverflow.com/questions/451415/simulating-groupconcat-mysql-function-in-ms-sql-server-2005"">Simulating group_concat MySQL function in MS SQL Server 2005?</a>""</p>

<p>Or Google for '<a href=""http://www.google.com/search?q=microsoft+sql+server+%22group_concat%22"" rel=""nofollow"">microsoft SQL server ""group_concat""</a>' for a variety of other solutions.</p>
"
821,358760,0,2,sql,"When adding new items to a database with foreign keys, should I use SQL triggers to create the related rows in other tables?","<p>I am implementing a database design that has a vehicle table, vehicle engine and vehicle gear table with SQL 2005.</p>

<p>Each table has an ID that is a SQL identity number, and each engine and gear has a relation with the vehicle ID.
So before I create a vehicle I must create an engine and gear.</p>

<p>How could I know the vehicle identity number when creating the engine and gear? The vehicle row hasn't yet been created because of the foreign key constraint with the engine and gear tables?</p>

<p>Should I implement an automatic trigger that on a creation of a vehicle creates an empty row for the engine and gear linked to the vehicle? But again how could I know the vehicle ID?</p>
","<p>Will you only ever have one engine and one gear for each vehicle? If that's the case, then why are they in different tables?</p>

<p>If you must have them in two tables, you can create an INSTEAD OF INSERT trigger as described here: <a href=""http://msdn.microsoft.com/en-us/library/ms175089.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms175089.aspx</a></p>
"
932,435540,0,2,sql,SQL Sub-Query vs Join Confusion,"<p>I have a database which is in Access (you can get it <a href=""http://cid-84dd6ce2da273835.skydrive.live.com/self.aspx/.Public/Unisa.accdb"" rel=""nofollow"">link text</a>). If I run</p>

<pre><code>SELECT DISTINCT Spl.Spl_No, Spl.Spl_Name
FROM Spl INNER JOIN Del 
   ON Spl.Spl_No = Del.Spl_No
WHERE Del.Item_Name &lt;&gt; 'Compass'
</code></pre>

<p>It provides the names of the suppliers that have never delivered a compass. However you can supposedly do this with a sub-query. So far myself and a few others have not been able to get it right.</p>

<p>I did come close with the following, until we added more suppliers then it stopped working</p>

<pre><code>SELECT SPL.SPL_Name
FROM SPL
LEFT JOIN DEL ON Del.SPL_No = SPL.SPL_No
WHERE (DEL.Item_Name&lt;&gt;""Compass"") OR (DEL.Item_Name IS NULL)
GROUP BY SPL.SPL_Name
HAVING COUNT(DEL.SPL_No) = 0
</code></pre>

<p>So the question: Is this possible to do with a sub-query.</p>
","<p>Is this what you're looking for?</p>

<pre><code>SELECT
   SPL.SPL_name
FROM
   SPL
WHERE
   SPL.SPL_No NOT IN
   (
      SELECT SPL_No FROM DEL WHERE DEL.Item_Name &lt;&gt; ""Compass""
   )
</code></pre>
"
999,460300,1,2,sql,Storing Queries in C# or use Stored Functions in Postgres?,"<p>Should I be storing the raw SQL queries in my c# code, or should I be delegating them to stored functions in the Postgres Backend?</p>

<p>If I should be storing them in code, since they can get quite long, what is the optimal way to store them (ie. as constants in a separate static class)?</p>

<p>Does using stored functions have any impact on deployability/updatability of an application?</p>

<p>Thanks</p>
","<p>I quite like storing SQL in text files embedded as resources into the assembly (when I absolutely <em>have</em> to have a significant number of them; I'm an ORM man normally).</p>

<p>Quite how you format that text file is up to you, of course. You could have double-line-break delimited:</p>

<pre><code>UpdateCustomer:
UPDATE CUSTOMER SET NAME=@Name WHERE ID=@ID

FindCustomer:
SELECT NAME, ADDRESS FROM CUSTOMER
WHERE ID=@Id

etc
</code></pre>

<p>It's not hard to then have a class which loads that into a <code>Dictionary&lt;string,string&gt;</code> in a type initialier, or even a <code>Dictionary&lt;string,SqlStatementHelper&gt;</code> where the latter is a class to make it easy to prepare the statement with appropriate values. You could use any other format you want though, including XML - although if you didn't need anything else beyond the name/sql pairs, that would probably be overkill.</p>

<p>The downside of this is the disconnect between the SQL and the code that uses it - you can't instantly tell what the parameters are without looking at the text file. On the other hand (and I'm just thinking off the cuff here) you probably <em>could</em> autogenerate a class from the SQL (and a bit of metadata) with methods with strongly typed parameters.</p>

<p>The mixed blessing of stored procs is that they live in the database rather than in your code. The upside of this is that you're more likely to keep them in sync with DDL changes. The downside is that they're more effort to change (IME, anyway) than queries defined locally. (There are obviously plenty of other pros and cons, but I'm limiting myself to the convenience side here.)</p>

<p>As for maintenance - well, I suppose it's possible that you'd have a ""database only"" update of just tables and stored procs, without any clients having to know at all - in which case the stored procs would be a better move. In my experience (certainly with custom solutions where there are only a couple of applications accessing the database, so compatibility isn't <em>as</em> much of an issue) code changes are almost ubiquitous but database changes less so - at which point storing the queries with the application means you're less likely to have to do a database change when you update. Does any of that make sense? I haven't had coffee yet...</p>
"
931,435540,0,2,sql,SQL Sub-Query vs Join Confusion,"<p>I have a database which is in Access (you can get it <a href=""http://cid-84dd6ce2da273835.skydrive.live.com/self.aspx/.Public/Unisa.accdb"" rel=""nofollow"">link text</a>). If I run</p>

<pre><code>SELECT DISTINCT Spl.Spl_No, Spl.Spl_Name
FROM Spl INNER JOIN Del 
   ON Spl.Spl_No = Del.Spl_No
WHERE Del.Item_Name &lt;&gt; 'Compass'
</code></pre>

<p>It provides the names of the suppliers that have never delivered a compass. However you can supposedly do this with a sub-query. So far myself and a few others have not been able to get it right.</p>

<p>I did come close with the following, until we added more suppliers then it stopped working</p>

<pre><code>SELECT SPL.SPL_Name
FROM SPL
LEFT JOIN DEL ON Del.SPL_No = SPL.SPL_No
WHERE (DEL.Item_Name&lt;&gt;""Compass"") OR (DEL.Item_Name IS NULL)
GROUP BY SPL.SPL_Name
HAVING COUNT(DEL.SPL_No) = 0
</code></pre>

<p>So the question: Is this possible to do with a sub-query.</p>
","<p>Suppliers that have never delivered a compass:</p>

<pre><code>SELECT Spl.Spl_No, Spl.Spl_Name
FROM Spl
LEFT JOIN Del ON Del.Spl_No = Spl.Spl_No AND Del.Item_Name = 'Compass'
WHERE Del.Item_Name IS NULL
</code></pre>

<p>and using a sub query:</p>

<pre><code>SELECT Spl_No, Spl_Name
FROM Spl
WHERE Spl_No IN 
  (
    SELECT Spl_No
    FROM Del
    GROUP BY Spl_No, Item_Name
    WHERE Item_Name = 'Compass'
    HAVING COUNT(*) = 0
  )
</code></pre>
"
822,358760,1,2,sql,"When adding new items to a database with foreign keys, should I use SQL triggers to create the related rows in other tables?","<p>I am implementing a database design that has a vehicle table, vehicle engine and vehicle gear table with SQL 2005.</p>

<p>Each table has an ID that is a SQL identity number, and each engine and gear has a relation with the vehicle ID.
So before I create a vehicle I must create an engine and gear.</p>

<p>How could I know the vehicle identity number when creating the engine and gear? The vehicle row hasn't yet been created because of the foreign key constraint with the engine and gear tables?</p>

<p>Should I implement an automatic trigger that on a creation of a vehicle creates an empty row for the engine and gear linked to the vehicle? But again how could I know the vehicle ID?</p>
","<p>Are you sure you got the tables design right? I don't really understand what kind of relationships you have between you entities. For example: are you trying to create one to many or many to one relationship between Vehicle and Engine?</p>

<p>One option could be (if it meets your needs):</p>

<p>Vehicle: (ID, EngineID, GearID, ...)</p>

<p>Engine (ID, other engine data)</p>

<p>Gear (ID, other gear data)</p>
"
823,358760,0,2,sql,"When adding new items to a database with foreign keys, should I use SQL triggers to create the related rows in other tables?","<p>I am implementing a database design that has a vehicle table, vehicle engine and vehicle gear table with SQL 2005.</p>

<p>Each table has an ID that is a SQL identity number, and each engine and gear has a relation with the vehicle ID.
So before I create a vehicle I must create an engine and gear.</p>

<p>How could I know the vehicle identity number when creating the engine and gear? The vehicle row hasn't yet been created because of the foreign key constraint with the engine and gear tables?</p>

<p>Should I implement an automatic trigger that on a creation of a vehicle creates an empty row for the engine and gear linked to the vehicle? But again how could I know the vehicle ID?</p>
","<p>If you must have two separate tables, you could join them in a view then update/insert into the view ...</p>

<pre><code>CREATE VIEW VehicleComplete AS SELECT * FROM Vehicle INNER JOIN VehicleEngine USING(VehicleID)

UPDATE VehicleComplete SET Rego = 'ABC 123', EngineModel = '380' WHERE VehicleID = 1
</code></pre>
"
1018,473610,-1,2,sql,Export Excel range/sheet to formatted text file,"<p>I have been tasked with creating a reusable process for our Finance Dept to upload our payroll to the State(WI) for reporting. I need to create something that takes a sheet or range in Excel and creates a specifically formatted text file.</p>

<p><strong><em>THE FORMAT</em></strong></p>

<ul>
<li>Column 1 - A Static Number, never changes, position 1-10</li>
<li>Column 2 - A Dynamic Param filled at runtime for Quarter/Year, position 11-13</li>
<li>Column 3 - SSN, no hyphens or spaces,
filled from column A, position 14-22</li>
<li>Column 4 - Last Name, filled from
column B, Truncated at 10, Left
Justify &amp; fill with blanks, position
23-32</li>
<li>Column 5 - First Name, filled from C,
Truncate at 8, Left Justify &amp; fill
with blanks, position 33-40</li>
<li>Column 6 - Total Gross Wages/Quarter,
filled from D, strip all formatting,
Right Justify Zero Fill, position
41-49</li>
<li>Column 7 - A Static Code, never
changes, position 50-51</li>
<li>Column 8 - BLANKS, Fill with blanks,
position 52-80</li>
</ul>

<p>I have, I assume, 3 options:</p>

<ol>
<li>VBA</li>
<li>.NET</li>
<li>SQL</li>
</ol>

<p>I had explored the .NET method first but I just couldn't find decent documentation to get me going.  I still like this one but I digress.</p>

<p>Next I have some VBA that will dump a Sheet to a fixed width Text.  I am currently pursuing this which leads, finally, to my actual question.</p>

<p>How do I transform a Range of text in Excel?  Do I need to coy it over to another sheet and then pass over that data with the neccesarry formatting functions the run my Dump to text routine?  I currently had planned to have a function for each column but I am having trouble figuring out how to take the next step.  I am fairly new at Office programming and developing in general so any insight will be greatly appreciated.</p>

<p>The SQL option would be my fall back as I have done similar exports from SQL in the past.  I just prefer the other two on the, <em>""I don't want to be responsible for running this,""</em> principle.</p>

<p>Thanks in advance for any time given.</p>
","<p>Depending on the format of your document, I'd probably recommend exporting to .csv and working with that. If all you need is the numbers, this would be the easiest way to go.</p>
"
849,377840,1,2,sql,How to truncate and shrink log files?,"<p>How to truncate and shrink large log files in SQL Server 2005? How to apply truncation at regular intervals?</p>

<p>Is there any difference between truncation and shrinking?</p>

<p>Thanks in advance</p>
","<p>Use the <code>DBCC SHRINKFILE</code> statement.</p>
"
1022,473610,0,2,sql,Export Excel range/sheet to formatted text file,"<p>I have been tasked with creating a reusable process for our Finance Dept to upload our payroll to the State(WI) for reporting. I need to create something that takes a sheet or range in Excel and creates a specifically formatted text file.</p>

<p><strong><em>THE FORMAT</em></strong></p>

<ul>
<li>Column 1 - A Static Number, never changes, position 1-10</li>
<li>Column 2 - A Dynamic Param filled at runtime for Quarter/Year, position 11-13</li>
<li>Column 3 - SSN, no hyphens or spaces,
filled from column A, position 14-22</li>
<li>Column 4 - Last Name, filled from
column B, Truncated at 10, Left
Justify &amp; fill with blanks, position
23-32</li>
<li>Column 5 - First Name, filled from C,
Truncate at 8, Left Justify &amp; fill
with blanks, position 33-40</li>
<li>Column 6 - Total Gross Wages/Quarter,
filled from D, strip all formatting,
Right Justify Zero Fill, position
41-49</li>
<li>Column 7 - A Static Code, never
changes, position 50-51</li>
<li>Column 8 - BLANKS, Fill with blanks,
position 52-80</li>
</ul>

<p>I have, I assume, 3 options:</p>

<ol>
<li>VBA</li>
<li>.NET</li>
<li>SQL</li>
</ol>

<p>I had explored the .NET method first but I just couldn't find decent documentation to get me going.  I still like this one but I digress.</p>

<p>Next I have some VBA that will dump a Sheet to a fixed width Text.  I am currently pursuing this which leads, finally, to my actual question.</p>

<p>How do I transform a Range of text in Excel?  Do I need to coy it over to another sheet and then pass over that data with the neccesarry formatting functions the run my Dump to text routine?  I currently had planned to have a function for each column but I am having trouble figuring out how to take the next step.  I am fairly new at Office programming and developing in general so any insight will be greatly appreciated.</p>

<p>The SQL option would be my fall back as I have done similar exports from SQL in the past.  I just prefer the other two on the, <em>""I don't want to be responsible for running this,""</em> principle.</p>

<p>Thanks in advance for any time given.</p>
","<p>Just as an update:  I was able to mesh this with mine and all is well. </p>

<p>I added this to a Toolbar Menu for easy calling and changed the save portion to automatically find there Desktop and save the file Appending the value of the Quarter YEar variable that they enter through a filtered Input Box.  </p>

<p>I would like to try and get away from them having to Select the active area but depending on the work involved it may not be worth my time investment. (Solo shop and all)  Along those same lines it'd be nice to have more error catching as it is quite fragile at the moment but alas....</p>

<p>Thanks again!</p>
"
824,358760,4,2,sql,"When adding new items to a database with foreign keys, should I use SQL triggers to create the related rows in other tables?","<p>I am implementing a database design that has a vehicle table, vehicle engine and vehicle gear table with SQL 2005.</p>

<p>Each table has an ID that is a SQL identity number, and each engine and gear has a relation with the vehicle ID.
So before I create a vehicle I must create an engine and gear.</p>

<p>How could I know the vehicle identity number when creating the engine and gear? The vehicle row hasn't yet been created because of the foreign key constraint with the engine and gear tables?</p>

<p>Should I implement an automatic trigger that on a creation of a vehicle creates an empty row for the engine and gear linked to the vehicle? But again how could I know the vehicle ID?</p>
","<p>Whichever, there's no need to create rows in any of the tables for which you don't have data. It's fine to, for instance, have an engine row that is unmatched to a vehicle. You can add what's missing when you find it.</p>

<p>I think I understand the design. Each vehicle can have one engine and one transmission. But you may record the transmission or engine before you find the vehicle.</p>

<p>They really are separate entities, so treat them as such. You may easily end up with engines and transmissions which you never match to a vehicle.</p>

<p>Another more interesting question is whether you might end up with a transmission matched to an engine, but no vehicle. One often sees an engine and tramsission bolted together with no vehicle in sight. And they'll often be sold together as well.</p>

<p>In fact, you can imagine any of the three existing alone, or matched to one or two of the other entities.</p>

<p>Triggers have no role here. If used at all, triggers should be restricted to fine-grained referential integrity rules about the schema structure - not for business rules like this. There are no mandatory constraints - every foreign key is optional (nullable). And there are several different ways to set the FK fields up.</p>
"
1021,473610,0,2,sql,Export Excel range/sheet to formatted text file,"<p>I have been tasked with creating a reusable process for our Finance Dept to upload our payroll to the State(WI) for reporting. I need to create something that takes a sheet or range in Excel and creates a specifically formatted text file.</p>

<p><strong><em>THE FORMAT</em></strong></p>

<ul>
<li>Column 1 - A Static Number, never changes, position 1-10</li>
<li>Column 2 - A Dynamic Param filled at runtime for Quarter/Year, position 11-13</li>
<li>Column 3 - SSN, no hyphens or spaces,
filled from column A, position 14-22</li>
<li>Column 4 - Last Name, filled from
column B, Truncated at 10, Left
Justify &amp; fill with blanks, position
23-32</li>
<li>Column 5 - First Name, filled from C,
Truncate at 8, Left Justify &amp; fill
with blanks, position 33-40</li>
<li>Column 6 - Total Gross Wages/Quarter,
filled from D, strip all formatting,
Right Justify Zero Fill, position
41-49</li>
<li>Column 7 - A Static Code, never
changes, position 50-51</li>
<li>Column 8 - BLANKS, Fill with blanks,
position 52-80</li>
</ul>

<p>I have, I assume, 3 options:</p>

<ol>
<li>VBA</li>
<li>.NET</li>
<li>SQL</li>
</ol>

<p>I had explored the .NET method first but I just couldn't find decent documentation to get me going.  I still like this one but I digress.</p>

<p>Next I have some VBA that will dump a Sheet to a fixed width Text.  I am currently pursuing this which leads, finally, to my actual question.</p>

<p>How do I transform a Range of text in Excel?  Do I need to coy it over to another sheet and then pass over that data with the neccesarry formatting functions the run my Dump to text routine?  I currently had planned to have a function for each column but I am having trouble figuring out how to take the next step.  I am fairly new at Office programming and developing in general so any insight will be greatly appreciated.</p>

<p>The SQL option would be my fall back as I have done similar exports from SQL in the past.  I just prefer the other two on the, <em>""I don't want to be responsible for running this,""</em> principle.</p>

<p>Thanks in advance for any time given.</p>
","<p>Wow!  </p>

<p>I have to say, I am blown away.  You so far exceeded my expectations for an answer that I feel guilty that I can ONLY up vote you once and mark as excepted.  I had HOPED for so guidance towards which path was best and some formatting.  Well Happy Birthday to me!</p>

<p>The Format() and FreeFile() were especially new useful info.  Also, just to show that I was trying, my attempt is below.  I was quite close as I was just working out the formatting details but I believe I shall rework it with your input as it seems the more elegant approach.</p>

<p>As a final note.  I found this place thru Jeff Atwood's blog and I was truly excited by the idea.  As a new, inexperienced developer in a solo shop I had always wished there was someplace I could turn for mentorship.  Books and articles get you to a point but nothing equals the advice of someone who's done it or been there.  So far StackOverflow has delivered.  </p>

<p>For reference, I posted this exact same question on another very popular Code Forum and have yet to receive a single response in any way. </p>

<p>Now for my attempt:</p>

<p>The Module Code</p>

<pre><code>
    Sub StateANSIIExport()
    Dim Sizes As Variant
    Dim arr As Variant
    Dim aRow As Long, aCol As Long
    Dim rowLimit As Integer, colLimit As Integer
    Dim SpacesPerCell As Integer
    Dim fso As Object
    Dim ts As Object
    Dim TheLine As String
    Dim TestStr As String

    arr = ActiveSheet.UsedRange
    rowLimit = UBound(arr, 1)
    'colLimit = UBound(arr, 2)
    colLimit = 8
    SpacesPerCell = 20      'Set export text ""column"" width here

    Set fso = CreateObject(""Scripting.FileSystemObject"")
    Set ts = fso.CreateTextFile(GetDesktopPath() & ""EXCELTEXT.txt"", True)

    ' Loop thru the rows
    For aRow = 1 To rowLimit
        TheLine = Space(colLimit * SpacesPerCell)     ' your fixed-width output
        ' Loop thru the columns
        For aCol = 1 To colLimit
            Select Case aCol
                Case 1  ' Employer UI Account #
                    Mid(TheLine, aCol * SpacesPerCell - SpacesPerCell + 1, SpacesPerCell) = ""6979430002""
                Case 2  ' Reporting Period (QYY)
                    Mid(TheLine, aCol * SpacesPerCell - SpacesPerCell + 1, SpacesPerCell) = ""109""
                Case 3  ' SSN
                    Mid(TheLine, aCol * SpacesPerCell - SpacesPerCell + 1, SpacesPerCell) = Cells(aRow, ""A"")
                Case 4  ' Last Name
                    Mid(TheLine, aCol * SpacesPerCell - SpacesPerCell + 1, SpacesPerCell) = Cells(aRow, ""B"")
                Case 5  ' First Name
                    Mid(TheLine, aCol * SpacesPerCell - SpacesPerCell + 1, SpacesPerCell) = Cells(aRow, ""C"")
                Case 6  ' Employee Quartly Gross Wages
                    Mid(TheLine, aCol * SpacesPerCell - SpacesPerCell + 1, SpacesPerCell) = Cells(aRow, ""D"")
                Case 7   ' Record Code
                    Mid(TheLine, aCol * SpacesPerCell - SpacesPerCell + 1, SpacesPerCell) = ""01""
                Case 8  ' BLANK
                    Mid(TheLine, aCol * SpacesPerCell - SpacesPerCell + 1, SpacesPerCell) = ""                             ""
            End Select
        Next aCol
        ' Write the line to the file
        ts.WriteLine TheLine
    Next aRow

    ts.Close

    Set ts = Nothing
    Set fso = Nothing

    MsgBox ""Done""
End Sub

    Sub MacroToRunTwo()
    Dim S As String
    S = ""Hello World From Two:"" & vbCrLf & _
        ""This Add-In File Name: "" & ThisWorkbook.FullName
    MsgBox S
End Sub

Function GetDesktopPath() As String
'Return the current user's desktop path
GetDesktopPath = ""C:\Users\patrick\Desktop\""
'GetDesktopPath = Environ(""HOMEDRIVE"") & Environ(""HOMEPATH"") & ""\Desktop\""
End Function
</code></pre>

<p>And The WorkBook Code:</p>

<pre><code>
    Private Const C_TAG = ""Refracted Solutions"" ' C_TAG should be a string unique to this add-in.
Private Const C_TOOLS_MENU_ID As Long = 30007&

Private Sub Workbook_Open()
'''''''''''''''''''''''''''''''''''''''''''''''
' Workbook_Open
' Create a submenu on the Tools menu. The
' submenu has two controls on it.
'''''''''''''''''''''''''''''''''''''''''''''''
Dim ToolsMenu As Office.CommandBarControl
Dim ToolsMenuItem As Office.CommandBarControl
Dim ToolsMenuControl As Office.CommandBarControl

'''''''''''''''''''''''''''''''''''''''''''''''
' First delete any of our controls that
' may not have been properly deleted previously.
'''''''''''''''''''''''''''''''''''''''''''''''
DeleteControls

''''''''''''''''''''''''''''''''''''''''''''''
' Get a reference to the Tools menu.
''''''''''''''''''''''''''''''''''''''''''''''
Set ToolsMenu = Application.CommandBars.FindControl(ID:=C_TOOLS_MENU_ID)
If ToolsMenu Is Nothing Then
    MsgBox ""Unable to access Tools menu."", vbOKOnly
    Exit Sub
End If

''''''''''''''''''''''''''''''''''''''''''''''
' Create a item on the Tools menu.
''''''''''''''''''''''''''''''''''''''''''''''
Set ToolsMenuItem = ToolsMenu.Controls.Add(Type:=msoControlPopup, temporary:=True)
If ToolsMenuItem Is Nothing Then
    MsgBox ""Unable to add item to the Tools menu."", vbOKOnly
    Exit Sub
End If

With ToolsMenuItem
    .Caption = ""&WWCares""
    .BeginGroup = True
    .Tag = C_TAG
End With

''''''''''''''''''''''''''''''''''''''''''''''
' Create the first control on the new item
' in the Tools menu.
''''''''''''''''''''''''''''''''''''''''''''''
Set ToolsMenuControl = ToolsMenuItem.Controls.Add(Type:=msoControlButton, temporary:=True)
If ToolsMenuControl Is Nothing Then
    MsgBox ""Unable to add item to Tools menu item."", vbOKOnly
    Exit Sub
End If

With ToolsMenuControl
    ''''''''''''''''''''''''''''''''''''
    ' Set the display caption and the
    ' procedure to run when clicked.
    ''''''''''''''''''''''''''''''''''''
    .Caption = ""State ANSII E&xport""
    .OnAction = ""'"" & ThisWorkbook.Name & ""'!StateANSIIExport""
    .Tag = C_TAG
End With

''''''''''''''''''''''''''''''''''''''''''''''
' Create the second control on the new item
' in the Tools menu.
''''''''''''''''''''''''''''''''''''''''''''''
'Set ToolsMenuControl = ToolsMenuItem.Controls.Add(Type:=msoControlButton, temporary:=True)
'If ToolsMenuControl Is Nothing Then
'    MsgBox ""Unable to add item to Tools menu item."", vbOKOnly
'    Exit Sub
'End If

'With ToolsMenuControl
    ''''''''''''''''''''''''''''''''''''
    ' Set the display caption and the
    ' procedure to run when clicked.
    ''''''''''''''''''''''''''''''''''''
'    .Caption = ""Click Me &Two""
'    .OnAction = ""'"" & ThisWorkbook.Name & ""'!MacroToRunTwo""
'    .Tag = C_TAG
'End With

End Sub


Private Sub Workbook_BeforeClose(Cancel As Boolean)
''''''''''''''''''''''''''''''''''''''''''''''''''''
' Workbook_BeforeClose
' Before closing the add-in, clean up our controls.
''''''''''''''''''''''''''''''''''''''''''''''''''''
    DeleteControls
End Sub


Private Sub DeleteControls()
''''''''''''''''''''''''''''''''''''
' Delete controls whose Tag is
' equal to C_TAG.
''''''''''''''''''''''''''''''''''''
Dim Ctrl As Office.CommandBarControl

On Error Resume Next
Set Ctrl = Application.CommandBars.FindControl(Tag:=C_TAG)

Do Until Ctrl Is Nothing
    Ctrl.Delete
    Set Ctrl = Application.CommandBars.FindControl(Tag:=C_TAG)
Loop

End Sub

</code></pre>
"
606,270190,1,2,sql,Finding Unique Table/Column Combinations Across SQL Databases,"<p>I have 4 databases with similar schema's, and I'm trying to create a query to return just the table, column pairs that exist ONLY in database 1 and do not exist in database 2, 3, or 4.</p>

<p>Currently I can return the symmetric difference between database 1 and 2 via the following query...</p>

<pre><code>select table_name, column_name from (
    	select table_name, column_name from [Database1].information_schema.columns
    	union all
    	select table_name, column_name from [Database2].information_schema.columns) as tmp
    	group by table_name, column_name having count(*) = 1
</code></pre>

<p>However, in trying to isolate just those columns in database 1, and doing the same across all 4 databases, things are getting complicated. What is the cleanest solution for this query?</p>
","<pre><code>SELECT
     D1.table_name,
     D1.column_name
FROM
     Database1.information_schema.columns D1
LEFT OUTER JOIN Database2.information_schema.columns D2 ON
     D2.table_name = D1.table_name AND
     D2.column_name = D1.column_name
LEFT OUTER JOIN Database3.information_schema.columns D3 ON
     D3.table_name = D1.table_name AND
     D3.column_name = D1.column_name
LEFT OUTER JOIN Database4.information_schema.columns D4 ON
     D4.table_name = D1.table_name AND
     D4.column_name = D1.column_name
WHERE
     D2.table_name IS NULL AND
     D3.table_name IS NULL AND
     D4.table_name IS NULL
</code></pre>
"
104,37640,0,2,sql,Best GUI tool for documenting a SQL Server DB,"<p>What tool(s) do you use to generate documentation for a database (preferably into a .chm help file)?</p>
","<p>We use Redgate SQL Doc and we're very happy with the results. We've also had reasonably good results from Document! X from Innovasys (but we mainly use this for documenting COM interfaces). </p>
"
103,37640,0,2,sql,Best GUI tool for documenting a SQL Server DB,"<p>What tool(s) do you use to generate documentation for a database (preferably into a .chm help file)?</p>
","<p>We use a wiki so that all developers can/should update it and it is a team effort. A tool that is makes it hard to share, and requires a central ""document"" will be hard to maintain.</p>

<p>What really do you need? As long as you have a table with the DB schema, document the possible values of each column and their meaning (i.e 1=""on hold"", 2=""Canceled"") and then put a image of the main DB tables connected with the foreign keys (export from SQL Server 2005) you are good to go. </p>
"
101,37640,3,2,sql,Best GUI tool for documenting a SQL Server DB,"<p>What tool(s) do you use to generate documentation for a database (preferably into a .chm help file)?</p>
","<p><H1> SQL Doc </H1></p>

<p><strong>Document SQL Server 2000, 2005 and 2008 databases</strong></p>

<p><a href=""http://www.red-gate.com/products/SQL_Doc/index.htm"" rel=""nofollow""><img src=""http://www.red-gate.com/images/boxshots/large/sqldoc.gif"" alt=""alt text"" /></a></p>

<p><a href=""http://www.red-gate.com/products/SQL_Doc/video.htm"" rel=""nofollow"">Demo Video</a></p>

<p><H1>Apex SQL Doc</H1></p>

<p><a href=""http://www.apexsql.com/sql_tools_doc.asp"" rel=""nofollow""><img src=""http://www.apexsql.com/images/apex_doc_icon.jpg"" alt=""alt text"" /></a></p>
"
559,251050,3,2,sql,Is it possible to execute SQL commands and send MSMQ messages in a TransactionScope?,"<p>I'm investigating using MSMQ for my team's new project but I need to know if I can send MSMQ messages and execute SQL commands within a System.Transactions.TransactionScope and have them commit or rollback together. I can't find a reliable source online that says ""yes"" with code examples. </p>

<p>I need to send some messages to a single queue and insert some records in a single database, but I need to to succeed or fail together.</p>

<p>EDIT: I was not able to actually verify whether this works or not in my testing (I was pulled off this task quickly) but all the documentation states that TransactionScope does capture MSMQ messages and SQL commands in the same instance.</p>
","<p>From personal experience I know the TransactionScope works great with SQL. I'm not too familiar with MSMQ but a quick <a href=""http://www.google.com/search?q=msmq+transactionscope"" rel=""nofollow"">Google search</a> shows some examples (normally forum discussions) where it looks like it's working successfully. The System.Messaging.MessageQueue object also has a .Transactional property and the .Send() method has a MessageQueueTransaction parameter so I'd say it should all work together.</p>

<p>Here's the code example from one of the forums in the search (not my code):</p>

<pre><code>using (TransactionScope scope = new TransactionScope())  
{  
    using (MessageQueue myQueue = new MessageQueue(QUEUE_NAME))  
    {  
    if (myQueue.Transactional)  
        {  
        myQueue.Send(TicketTextBox.Text, ""Message"", MessageQueueTransactionType.Automatic);  
        }  
    }  
scope.Complete();  
}
</code></pre>

<p>Just throw your SQL code inside the using() block for the TransactionScope (before the .Complete()) and you should be good to go?</p>
"
570,252540,0,2,sql,When is SqlConnection.RetrieveStatistics() useful?,"<p>What are the problems that calling this method can help with?<br />
Do you ever use it in debugging you data access?</p>
","<p><a href=""http://msdn.microsoft.com/en-us/library/7h2ahss8(VS.80).aspx"" rel=""nofollow"">This page from MSDN has more information</a>. Seems like it contains useful debugging information but I must admit I've never used it.</p>
"
578,260010,2,2,sql,Is it possible to get the matching string from an SQL query?,"<p>If I have a query to return all matching entries in a DB that have ""news"" in the searchable column (i.e. <code>SELECT * FROM table WHERE column LIKE %news%</code>), and one particular row has an entry starting with ""In recent World news, Somalia was invaded by ..."", can I return a specific ""chunk"" of an SQL entry? Kind of like a teaser, if you will.</p>
","<p>You can use substring function in a SELECT part. Something like:</p>

<pre><code>SELECT SUBSTRING(column, 1,20) FROM table WHERE column LIKE %news%
</code></pre>

<p>This will return the first 20 characters from column <em>column</em></p>
"
579,260010,0,2,sql,Is it possible to get the matching string from an SQL query?,"<p>If I have a query to return all matching entries in a DB that have ""news"" in the searchable column (i.e. <code>SELECT * FROM table WHERE column LIKE %news%</code>), and one particular row has an entry starting with ""In recent World news, Somalia was invaded by ..."", can I return a specific ""chunk"" of an SQL entry? Kind of like a teaser, if you will.</p>
","<p>If you are using MSSQL you can perform all kinds VB-like of substring functions as part of your query.</p>
"
580,260010,7,2,sql,Is it possible to get the matching string from an SQL query?,"<p>If I have a query to return all matching entries in a DB that have ""news"" in the searchable column (i.e. <code>SELECT * FROM table WHERE column LIKE %news%</code>), and one particular row has an entry starting with ""In recent World news, Somalia was invaded by ..."", can I return a specific ""chunk"" of an SQL entry? Kind of like a teaser, if you will.</p>
","<pre><code>select substring(column,
                 CHARINDEX ('news',lower(column))-10,
                 20)
FROM table 
WHERE column LIKE %news%
</code></pre>

<p>basically substring the column starting 10 characters before where the word 'news' is and continuing for 20.</p>

<p>Edit:  You'll need to make sure that 'news' isn't in the first 10 characters and adjust the start position accordingly.</p>
"
581,260010,1,2,sql,Is it possible to get the matching string from an SQL query?,"<p>If I have a query to return all matching entries in a DB that have ""news"" in the searchable column (i.e. <code>SELECT * FROM table WHERE column LIKE %news%</code>), and one particular row has an entry starting with ""In recent World news, Somalia was invaded by ..."", can I return a specific ""chunk"" of an SQL entry? Kind of like a teaser, if you will.</p>
","<p>I had the same problem, I ended up loading the whole field into C#, then re-searched the text for the search string, then selected x characters either side.</p>

<p>This will work fine for LIKE, but not full text queries which use FORMS OF INFLECTION because that may match ""women"" when you search for ""woman"".</p>
"
604,269440,0,2,sql,How to Fix This MySQL Query So It Works?,"<p>I have the following query:</p>

<pre><code>UPDATE lessonstatus
INNER JOIN user ON lessonstatus.user_id = user.user_id
SET user_id = (SELECT user_id FROM user WHERE username = 'too_many_accounts')
WHERE last_name = 'stupid' 
AND first_name = 'user'
AND username != 'too_many_accounts'
AND lessonstatus.lesson_id NOT IN (SELECT lesson_id FROM lessonstatus WHERE user_id = 1);
</code></pre>

<p>However, I get the following error when trying to execute it:</p>

<pre><code>Error Code : 1093
You can't specify target table 'lessonstatus_rtab' for update in FROM clause
</code></pre>

<p>How would I fix this query so that it works?</p>
","<p>There are more errors (""user"" table and ""user_rtab"" alias do not match, use of non-qualified field names is not recommended), but UPDATE syntax itself should be similar:</p>

<pre><code>UPDATE lessonstatus
SET user_id = (SELECT TOP 1 user_id FROM user WHERE username = 'too_many_accounts')
FROM lessonstatus
    INNER JOIN user ON lessonstatus.user_id = user_rtab.user_id
WHERE last_name = 'stupid' 
    AND first_name = 'user'
    AND username != 'too_many_accounts'
    AND lessonstatus.lesson_id NOT IN (
        SELECT lesson_id FROM lessonstatus WHERE user_id = 1
    );
</code></pre>
"
605,269440,3,2,sql,How to Fix This MySQL Query So It Works?,"<p>I have the following query:</p>

<pre><code>UPDATE lessonstatus
INNER JOIN user ON lessonstatus.user_id = user.user_id
SET user_id = (SELECT user_id FROM user WHERE username = 'too_many_accounts')
WHERE last_name = 'stupid' 
AND first_name = 'user'
AND username != 'too_many_accounts'
AND lessonstatus.lesson_id NOT IN (SELECT lesson_id FROM lessonstatus WHERE user_id = 1);
</code></pre>

<p>However, I get the following error when trying to execute it:</p>

<pre><code>Error Code : 1093
You can't specify target table 'lessonstatus_rtab' for update in FROM clause
</code></pre>

<p>How would I fix this query so that it works?</p>
","<p>You can't <code>SELECT</code> from a table (even in a subquery) that you're updating in the same query.  That's what the error ""can't specify target table"" means.</p>

<p>But you can join <code>user</code> and <code>lessonstatus</code> multiple times in the <code>UPDATE</code> statement, and use the join criteria creatively to pick out the individual row you want.</p>

<p>The way to simulate <code>NOT IN</code> with a join is to do a <code>LEFT OUTER JOIN</code>.  Where the right side of that join is not matched, that's where <code>NOT IN</code> would be true.</p>

<pre><code>UPDATE lessonstatus l1
  INNER JOIN user u1 ON (l1.user_id = u1.user_id)
  INNER JOIN user u2 ON (u2.username = 'too_many_accounts')
  LEFT OUTER JOIN lessonstatus l2 
    ON (l1.lesson_id = l2.lesson_id AND l2.user_id = 1)
SET l1.user_id = u2.user_id
WHERE u1.last_name = 'stupid' AND u1.first_name = 'user'
  AND u1.username != 'too_many_accounts'
  AND l2.lesson_id IS NULL; -- equivalent to ""l NOT IN l2""
</code></pre>

<p><strong>nb:</strong> I have tested this query for syntax, but not with real data.  Anyway, it should get you started.</p>
"
192,83050,0,2,sql,Trip time calculation in relational databases?,"<p>I had this question in mind and since I just discovered this site I decided to post it here.</p>

<p>Let's say I have a table with a timestamp and a state for a given ""object"" (generic meaning, not OOP object); is there an optimal way to calculate the time between a state and the next occurrence of another (or same) state (what I call a ""trip"") with a single SQL statement (inner SELECTs and UNIONs aren't counted)?</p>

<p>Ex: For the following, the trip time between Initial and Done would be 6 days, but between Initial and Review it would be 2 days.  </p>

<blockquote>
  <p>2008-08-01 13:30:00 - Initial<br />
  2008-08-02 13:30:00 - Work<br />
  2008-08-03 13:30:00 - Review<br />
  2008-08-04 13:30:00 - Work<br />
  2008-08-05 13:30:00 - Review<br />
  2008-08-06 13:30:00 - Accepted<br />
  2008-08-07 13:30:00 - Done</p>
</blockquote>

<p>No need to be generic, just say what <a href=""http://stackoverflow.com/questions/980813/what-is-sgbd"">SGBD</a> your solution is specific to if not generic.</p>
","<p>Ok, this is a bit beyond geeky, but I built a web application to track my wife's contractions just before we had a baby so that I could see from work when it was getting close to time to go to the hospital.  Anyway, I built this basic thing fairly easily as two views.</p>

<pre><code>create table contractions time_date timestamp primary key;

create view contraction_time as
SELECT a.time_date, max(b.prev_time) AS prev_time
   FROM contractions a, ( SELECT contractions.time_date AS prev_time
           FROM contractions) b
  WHERE b.prev_time &lt; a.time_date
  GROUP BY a.time_date;

create view time_between as 
SELECT contraction_time.time_date, contraction_time.prev_time, contraction_time.time_date - contraction_time.prev_time
   FROM contraction_time;
</code></pre>

<p>This could be done as a subselect obviously as well, but I used the intermediate views for other things as well, and so  this worked out well.</p>
"
607,270190,1,2,sql,Finding Unique Table/Column Combinations Across SQL Databases,"<p>I have 4 databases with similar schema's, and I'm trying to create a query to return just the table, column pairs that exist ONLY in database 1 and do not exist in database 2, 3, or 4.</p>

<p>Currently I can return the symmetric difference between database 1 and 2 via the following query...</p>

<pre><code>select table_name, column_name from (
    	select table_name, column_name from [Database1].information_schema.columns
    	union all
    	select table_name, column_name from [Database2].information_schema.columns) as tmp
    	group by table_name, column_name having count(*) = 1
</code></pre>

<p>However, in trying to isolate just those columns in database 1, and doing the same across all 4 databases, things are getting complicated. What is the cleanest solution for this query?</p>
","<p>I can come up with this at first shot, which can be a head start. This hasn't been tested though, just another alternative maybe:</p>

<p>select table_name, column_name from [Database1].information_schema.columns d1
where table_name || '+' || column_name
not in
(select table_name || '+' || column_name from [Database2].information_schema.columns)</p>

<p>and table_name || '+' || column_name
not in
(select table_name || '+' || column_name from [Database3].information_schema.columns)</p>

<p>and table_name || '+' || column_name
not in
(select table_name || '+' || column_name from [Database4].information_schema.columns)</p>
"
1214,542760,4,2,sql,I have StartDate and EndDate for each record. Should I give NULL a special meaning when used in these 2 fields?,"<p>So, I have a table where StartDate and EndDate's are used to determine the activeness of a record. I thought of using NULLs to relieve the maintainers from having to manufacture some crazy dates for some of the records. For example, if NULL had defined as positive infinite when used in EndDate, the data maintainers wouldn't need to come up with something like 1-1-2100 for long-lived records. </p>

<p>I can speculate some of the trade offs on my own: defining NULL as infinities means cleaner data and elimination of periodic maintenance work, but it also means longer queries and stored procedures. So I was wondering how you guys in the real world weigh in on this. </p>

<p>EDIT: the opinions are about half-half. If I had clarified that the StartDate and EndDate are used solely for the purpose of determining the activeness of a record in the where clause, and never appears in the select list, would that tilt the scale? One subject I need to read on is probably indexing. Thanks'all. </p>
","<p>If either <code>StartDate</code> or <code>EndDate</code> of your record will be <code>NULL</code>, then the following condition:</p>

<pre><code>BETWEEN StartDate AND EndDate
</code></pre>

<p>will never match this record.</p>

<p>You'll need to do following:</p>

<pre><code>BETWEEN IFNULL(StartDate, '01.01.1000') AND IFNULL(EndDate, '01.01.3000')
</code></pre>

<p>, which, of course, is not good for indices.</p>

<p>Of course, you may create a function based index, but you'll need to provide a constant for it anyway.</p>

<p><em>Summary: if you want performance, use constants, do not use NULLs</em></p>
"
1213,542760,0,2,sql,I have StartDate and EndDate for each record. Should I give NULL a special meaning when used in these 2 fields?,"<p>So, I have a table where StartDate and EndDate's are used to determine the activeness of a record. I thought of using NULLs to relieve the maintainers from having to manufacture some crazy dates for some of the records. For example, if NULL had defined as positive infinite when used in EndDate, the data maintainers wouldn't need to come up with something like 1-1-2100 for long-lived records. </p>

<p>I can speculate some of the trade offs on my own: defining NULL as infinities means cleaner data and elimination of periodic maintenance work, but it also means longer queries and stored procedures. So I was wondering how you guys in the real world weigh in on this. </p>

<p>EDIT: the opinions are about half-half. If I had clarified that the StartDate and EndDate are used solely for the purpose of determining the activeness of a record in the where clause, and never appears in the select list, would that tilt the scale? One subject I need to read on is probably indexing. Thanks'all. </p>
","<p>If you do go with using a default ""system"" date for the End Date field (and even a Start Date field) just be sure to document the meaning of those dates somewhere in your code (and possibly database schema). It will make it easier for those that come after you to understand the meaning of an otherwise arbitrary date.</p>
"
183,83050,0,2,sql,Trip time calculation in relational databases?,"<p>I had this question in mind and since I just discovered this site I decided to post it here.</p>

<p>Let's say I have a table with a timestamp and a state for a given ""object"" (generic meaning, not OOP object); is there an optimal way to calculate the time between a state and the next occurrence of another (or same) state (what I call a ""trip"") with a single SQL statement (inner SELECTs and UNIONs aren't counted)?</p>

<p>Ex: For the following, the trip time between Initial and Done would be 6 days, but between Initial and Review it would be 2 days.  </p>

<blockquote>
  <p>2008-08-01 13:30:00 - Initial<br />
  2008-08-02 13:30:00 - Work<br />
  2008-08-03 13:30:00 - Review<br />
  2008-08-04 13:30:00 - Work<br />
  2008-08-05 13:30:00 - Review<br />
  2008-08-06 13:30:00 - Accepted<br />
  2008-08-07 13:30:00 - Done</p>
</blockquote>

<p>No need to be generic, just say what <a href=""http://stackoverflow.com/questions/980813/what-is-sgbd"">SGBD</a> your solution is specific to if not generic.</p>
","<p>I don't think you can get that answer with one SQL statement as you are trying to obtain one result from many records. The only way to achieve that in SQL is to get the timestamp field for two different records and calculate the difference (datediff). Therefore, UNIONS or Inner Joins are needed.</p>
"
398,181130,1,2,sql,Encrypted database query,"<p>I've just found out about Stack Overflow and I'm just checking if there are ideas for a constraint I'm having with some friends in a project, though this is more of a theoretical question to which I've been trying to find an answer for some time.</p>

<p>I'm not much given into cryptography but if I'm not clear enough I'll try to edit/comment to clarify any questions.</p>

<p>Trying to be brief, the environment is something like this:</p>

<ul>
<li><p>An application where the front-end as access to encrypt/decrypt keys and the back-end is just used for storage and queries.</p></li>
<li><p>Having a database to which you can't have access for a couple of fields for example let's say ""address"" which is text/varchar as usual.</p></li>
<li><p>You don't have access to the key for decrypting the information, and all information arrives to the database already encrypted.</p></li>
</ul>

<p>The main problem is something like this, how to consistently make queries on the database, it's impossible to do stuff like ""where address like '%FYU/~#JKSks23%'"". (IF there is anyone  feeling with an answer for this feel free to shoot it).</p>

<p>But is it ok to do <code>where address='!NNsj3~^-:'</code>? Or would it also completely eat up the database? </p>

<p>Another restrain that might apply is that the front end doesn't have much processing power available, so already encrypting/decrypting information starts to push it to its limits. (Saying this just to avoid replies like ""Exporting a join of tables to the front end and query it there"".)</p>

<p>Could someone point me in a direction to keep thinking about it?</p>

<hr>

<p>Well thanks for so fast replies at 4 AM, for a first time usage I'm really feeling impressed with this community. (Or maybe I'm it's just for the different time zone)</p>

<p>Just feeding some information:</p>

<p>The main problem is all around partial matching. As a mandatory requirement in most databases is to allow partial matches. The main constraint is actually <strong>the database owner would not be allowed to look inside the database for information</strong>. During the last 10 minutes I've come up with a possible solution which extends again to possible database problems, to which I'll add here:</p>

<p>Possible solution to allow semi partial matching:</p>

<ul>
<li>The password + a couple of public fields of the user are actually the key for encrypting. For authentication the idea is to encrypt a static value and compare it within the database.</li>
<li>Creating a new set of tables where information is stored in a parsed way, meaning something like: ""4th Street"" would become 2 encrypted rows (one for '4th' another for 'Street'). This would already allow semi-partial matching as a search could already be performed on the separate tables.</li>
</ul>

<p>New question:</p>

<ul>
<li>Would this probably eat up the database server again, or does anyone think it is a viable solution for the partial matching problem?</li>
</ul>

<p><em>Post Scriptum: I've unaccepted the answer from Cade Roux just to allow for further discussion and specially a possible answer to the new question.</em></p>
","<p>A few months ago I came across the same problem: the whole database (except for indexes) is encrypted and the problem on partial matches raised up.</p>

<p>I searched the Internet looking for a solution, but it seems that there's not much to do about this but a ""workaround"".</p>

<p>The solution I've finally adopted is:</p>

<ol>
<li><p>Create a temporary table with the data of the field against which the query is being performed, decrypted and another field that is the primary key of the table (obviously, this field doesn't have to be decrypted as is plain-text).</p></li>
<li><p>Perform the partial match agains that temporary table and retrieve the identifiers.</p></li>
<li><p>Query the real table for those identifiers and return the result.</p></li>
<li><p>Drop the temporary table.</p></li>
</ol>

<p>I am aware that this supposes a non-trivial overhead, but I haven't found another way to perform this task when it is mandatory that the database is fully encrypted.</p>

<p>Depending on each particular case, you may be able to filter the number of lines that are inserted into the temporary table without losing data for the result (only consider those rows which belong to the user that is performing the query, etc...).</p>
"
663,290610,0,2,sql,Updating sort keys after delete,"<p>I have a table which has a field <code>sort_id</code>. In this field there are numbers from 1 to n, that define the order of the data sets.
Now I want to delete some elements and afterwards I want to reorder the table. Therefore I need a query that ""finds"" the gaps and changes the <code>sort_id</code> field according to the modifications.</p>

<p>Sure, I could do something like this:</p>

<pre><code>SELECT sort_id FROM table WHERE id = 5
</code></pre>

<p>Then save the sort_id and afterwards:</p>

<pre><code>DELETE FROM table WHERE id = 5
UPDATE table SET sort_id = sort_id - 1 WHERE sort_id &gt; {id from above}
</code></pre>

<p>But I'd like to do the reordering process in one step.</p>
","<p>for sql server 2005:
this is how you get the new sequence:</p>

<pre><code>SELECT row_number() over(order by sort_id) as RN
FROM table
</code></pre>

<p>updating the table means you should join that select to your update:</p>

<pre><code>update t1
set sort_id = t2.RN
FROM table t1 
     join (SELECT row_number() over(order by sort_id) as RN FROM table) t2 
        on t1.UniqueId = t2.UniqueId
</code></pre>
"
664,290610,0,2,sql,Updating sort keys after delete,"<p>I have a table which has a field <code>sort_id</code>. In this field there are numbers from 1 to n, that define the order of the data sets.
Now I want to delete some elements and afterwards I want to reorder the table. Therefore I need a query that ""finds"" the gaps and changes the <code>sort_id</code> field according to the modifications.</p>

<p>Sure, I could do something like this:</p>

<pre><code>SELECT sort_id FROM table WHERE id = 5
</code></pre>

<p>Then save the sort_id and afterwards:</p>

<pre><code>DELETE FROM table WHERE id = 5
UPDATE table SET sort_id = sort_id - 1 WHERE sort_id &gt; {id from above}
</code></pre>

<p>But I'd like to do the reordering process in one step.</p>
","<p>I don't know MySQL syntax variations and cannot test query live, but something like next should give you at least an idea:</p>

<pre><code>update table t1
set sort_id = (select count * from table t2 where t2.sort_id &lt;= t1.sort_id)
</code></pre>
"
665,290610,3,2,sql,Updating sort keys after delete,"<p>I have a table which has a field <code>sort_id</code>. In this field there are numbers from 1 to n, that define the order of the data sets.
Now I want to delete some elements and afterwards I want to reorder the table. Therefore I need a query that ""finds"" the gaps and changes the <code>sort_id</code> field according to the modifications.</p>

<p>Sure, I could do something like this:</p>

<pre><code>SELECT sort_id FROM table WHERE id = 5
</code></pre>

<p>Then save the sort_id and afterwards:</p>

<pre><code>DELETE FROM table WHERE id = 5
UPDATE table SET sort_id = sort_id - 1 WHERE sort_id &gt; {id from above}
</code></pre>

<p>But I'd like to do the reordering process in one step.</p>
","<p>Mladen and Arvo have good ideas, but unfortunately in MySQL you can't <code>SELECT</code> and <code>UPDATE</code> the same table in the same statement (even in a subquery).  This is a known limitation of MySQL.</p>

<p>Here's a solution that uses MySQL user variables:</p>

<pre><code>SET @i := 0;
UPDATE mytable
SET sort_id = (@i := @i + 1)
ORDER BY sort_id;
</code></pre>

<p>For what it's worth, I wouldn't bother doing this anyway.  If your <code>sort_id</code> is used only for sorting and not as a kind of ""row number,"" then the rows are still in sorted order after you delete the row where <code>id=6</code>.  The values don't necessarily have to be consecutive for sorting.</p>
"
685,304430,1,2,sql,SQL DataReader missing a row in loop,"<p>When running the following code it leaves out one row. When I do a files.Count it says there are 4 rows but there is no data stored for the 4th row. When I run the stored procedure from within SQL Manager it returns all 4 rows and all the data. Any help?</p>

<pre><code>            List&lt;File&gt; files = new List&lt;File&gt;();
            SqlConnection active_connection = new SqlConnection(m_connection_string);
            SqlCommand cmd = new SqlCommand();
            SqlDataReader dr = null;

            try
            {
                active_connection.Open();
                cmd.Connection = active_connection;
                cmd.CommandType = CommandType.StoredProcedure;
                cmd.CommandText = ""dalsp_Select_Organization_Files"";

                SqlParameter param;

                param = cmd.Parameters.Add(""@p_organization_guid"", SqlDbType.UniqueIdentifier);
                param.Value = new Guid(organization_guid);

                param = cmd.Parameters.Add(""@p_file_type"", SqlDbType.NVarChar, 50);
                param.Value = file_type;

                dr = cmd.ExecuteReader(CommandBehavior.CloseConnection);

                if (dr.HasRows)                    
                {                    
                    while (dr.Read())
                    {
                        File file = new File();
                        file.OrganizationGuid = dr[""OrganizationGuid""].ToString();
                        file.FileGuid = dr[""FileGuid""].ToString();
                        file.FileLocation = dr[""FileLocation""].ToString();
                        file.FileName = dr[""FileName""].ToString();
                        file.FileType = (FileTypeEnum)Enum.Parse(typeof(FileTypeEnum), dr[""FileType""].ToString());
                        file.FileExtension = dr[""FileExtension""].ToString();
                        file.FileDescription = dr[""FileDescription""].ToString();
                        file.ThumbnailPath = dr[""ThumbnailPath""].ToString();
                        files.Add(file);
                    }       
                }
                dr.Close();
                dr = null;

                active_connection.Close();
                cmd = null;

            }
            catch (Exception)
            {
                throw;
            }
            finally
            {
                if (active_connection.State != ConnectionState.Closed)
                {
                    active_connection.Close();
                    active_connection.Dispose();
                }
            }

            return files;
</code></pre>
","<p>Have you tried stepping through this in a debugger, and checking your command params before you exec the reader? Do you get the same values in the result set as when you run the sproc direct on sql?</p>

<p>I could be wrong, cos there are a few ways of doing this, but something looks a little screwy in the way you are adding the params to the command.</p>

<p>I usually use a pattern more like:</p>

<pre><code>SqlParameter param = new SqlParameter();  
// set param stuff - here or in ctor   
cmd.Parameters.Add(param);
</code></pre>

<p>Is largely about what works for you....  </p>

<p>Most of the times that I have had problems with sprocs is when I pooched the parameters.</p>
"
102,37640,3,2,sql,Best GUI tool for documenting a SQL Server DB,"<p>What tool(s) do you use to generate documentation for a database (preferably into a .chm help file)?</p>
","<p>If you are on SQL Server 2000/2005 you can use <a href=""http://www.codeproject.com/KB/vb/DBdoc.aspx"" rel=""nofollow"">DBdoc</a></p>

<p>(SQL 2005 requires a patch that is listed in the comments below the article)</p>

<p>If you have money to spend, you can also use <a href=""http://www.red-gate.com/products/SQL_Doc/index.htm"" rel=""nofollow"">RedGate SQL doc</a> (1.3 is the latest version). It offers (from the homepage):</p>

<ul>
<li>Fast, simple database documentation</li>
<li>Document one or multiple databases,
down to object level</li>
<li>Write, edit, and export documentation in easy-to-read HTML files or .chm files for team distribution</li>
<li>Includes all cross-database dependencies</li>
</ul>
"
551,246870,3,2,sql,"""Simple"" SQL Query","<p>Each of my clients can have many todo items and every todo item has a due date.</p>

<p>What would be the query for discovering the next undone todo item by due date for each file?  In the event that a client has more than one todo, the one with the lowest id is the correct one.</p>

<p>Assuming the following minimal schema:</p>

<pre><code>clients (id, name)

todos (id, client_id, description, timestamp_due, timestamp_completed)
</code></pre>

<p>Thank you.</p>
","<p>I haven't tested this yet, so you may have to tweak it:</p>

<pre><code>SELECT
    TD1.client_id,
    TD1.id,
    TD1.description,
    TD1.timestamp_due
FROM
    Todos TD1
LEFT OUTER JOIN Todos TD2 ON
    TD2.client_id = TD1.client_id AND
    TD2.timestamp_completed IS NULL AND
    (
    	TD2.timestamp_due &lt; TD1.timestamp_due OR
    	(TD2.timestamp_due = TD1.timestamp_due AND TD2.id &lt; TD1.id)
    )
WHERE
    TD2.id IS NULL
</code></pre>

<p>Instead of trying to sort and aggregate, you're basically answering the question, ""Is there any other todo that would come before this one?"" (based on your definition of ""before""). If not, then this is the one that you want.</p>

<p>This should be valid on most SQL platforms.</p>
"
470,203200,2,2,sql,Undo changes to SQL Server 2005 database,"<p>I've ran some ""ALTER"" scripts on the database [SQL Server Server 2005], and overwrote some sprocs. Is there any way to undo changes and get my old sprocs back?</p>

<p>Is there a way to get the scripts that were executed out of the .LDf file? That way i can re-run my initial ""create"" script for my sprocs.</p>

<p>I don't have a backup file with old sprocs.</p>

<p>p.s. i backed the DB up as per <a href=""http://stackoverflow.com/users/4337/gulzar"">@Gulzar's</a> deleted answer, and looks like I'm ""hosed"".</p>

<p>@Pittsburgh DBA: thanx for the solution, but it doesn't seem to work after the backup.</p>

<p><strong>MORAL: Wait for 10 minutes before trying the suggested answers out</strong></p>

<p><hr></p>

<p><strong>Update from Gulzar</strong>: What I meant was a file backup before trying anything (to be safe). Not a SQL Server backup.</p>
","<p>In case anybody else has the same problem - Were you doing transaction log backups every X minutes?  If so, you can use Quest LiteSpeed's log reader or Quest Toad for SQL Server's log reader to read the log file backups.  It gives undo/redo scripts too for any transaction in the log backups or the ldf.</p>
"
550,246870,0,2,sql,"""Simple"" SQL Query","<p>Each of my clients can have many todo items and every todo item has a due date.</p>

<p>What would be the query for discovering the next undone todo item by due date for each file?  In the event that a client has more than one todo, the one with the lowest id is the correct one.</p>

<p>Assuming the following minimal schema:</p>

<pre><code>clients (id, name)

todos (id, client_id, description, timestamp_due, timestamp_completed)
</code></pre>

<p>Thank you.</p>
","<p>Some Jet SQL, I realize it is unlikely that the questioner is using Jet, however the reader may be.</p>

<pre><code>SELECT c.name, t.description, t.timestamp_due
FROM (clients c 
      INNER JOIN 
         (SELECT t.client_id, Min(t.id) AS MinOfid
          FROM todos t
          WHERE t.timestamp_completed Is Null
          GROUP BY t.client_id) AS tm 
ON c.id = tm.client_id) 
INNER JOIN todos t ON tm.MinOfid = t.id
</code></pre>
"
469,203200,1,2,sql,Undo changes to SQL Server 2005 database,"<p>I've ran some ""ALTER"" scripts on the database [SQL Server Server 2005], and overwrote some sprocs. Is there any way to undo changes and get my old sprocs back?</p>

<p>Is there a way to get the scripts that were executed out of the .LDf file? That way i can re-run my initial ""create"" script for my sprocs.</p>

<p>I don't have a backup file with old sprocs.</p>

<p>p.s. i backed the DB up as per <a href=""http://stackoverflow.com/users/4337/gulzar"">@Gulzar's</a> deleted answer, and looks like I'm ""hosed"".</p>

<p>@Pittsburgh DBA: thanx for the solution, but it doesn't seem to work after the backup.</p>

<p><strong>MORAL: Wait for 10 minutes before trying the suggested answers out</strong></p>

<p><hr></p>

<p><strong>Update from Gulzar</strong>: What I meant was a file backup before trying anything (to be safe). Not a SQL Server backup.</p>
","<p>And after that, look into using ApexSQLScript to script out your databases on a regular basis (and store in version control).</p>
"
468,203200,4,2,sql,Undo changes to SQL Server 2005 database,"<p>I've ran some ""ALTER"" scripts on the database [SQL Server Server 2005], and overwrote some sprocs. Is there any way to undo changes and get my old sprocs back?</p>

<p>Is there a way to get the scripts that were executed out of the .LDf file? That way i can re-run my initial ""create"" script for my sprocs.</p>

<p>I don't have a backup file with old sprocs.</p>

<p>p.s. i backed the DB up as per <a href=""http://stackoverflow.com/users/4337/gulzar"">@Gulzar's</a> deleted answer, and looks like I'm ""hosed"".</p>

<p>@Pittsburgh DBA: thanx for the solution, but it doesn't seem to work after the backup.</p>

<p><strong>MORAL: Wait for 10 minutes before trying the suggested answers out</strong></p>

<p><hr></p>

<p><strong>Update from Gulzar</strong>: What I meant was a file backup before trying anything (to be safe). Not a SQL Server backup.</p>
","<p>FIRST: DO NOT TAKE ANY BACKUPS JUST YET.</p>

<p>There are several tools on the market to do this sort of thing. </p>

<p>You might try this one:</p>

<p><a href=""http://www.apexsql.com/sql_tools_log.asp"" rel=""nofollow"">ApexSQL Log</a></p>
"
1217,542760,1,2,sql,I have StartDate and EndDate for each record. Should I give NULL a special meaning when used in these 2 fields?,"<p>So, I have a table where StartDate and EndDate's are used to determine the activeness of a record. I thought of using NULLs to relieve the maintainers from having to manufacture some crazy dates for some of the records. For example, if NULL had defined as positive infinite when used in EndDate, the data maintainers wouldn't need to come up with something like 1-1-2100 for long-lived records. </p>

<p>I can speculate some of the trade offs on my own: defining NULL as infinities means cleaner data and elimination of periodic maintenance work, but it also means longer queries and stored procedures. So I was wondering how you guys in the real world weigh in on this. </p>

<p>EDIT: the opinions are about half-half. If I had clarified that the StartDate and EndDate are used solely for the purpose of determining the activeness of a record in the where clause, and never appears in the select list, would that tilt the scale? One subject I need to read on is probably indexing. Thanks'all. </p>
","<p>I'd try to work with NULL values as long as possible.</p>

<p>My understanding of NULL in a column EndDate would be that there is not defined an end date as of now. That would be consistent with that record being valid from its start date to its end date.</p>

<p>I agree with Quassnoi that you can't directly specify </p>

<pre><code>BETWEEN StartDate AND EndDate
</code></pre>

<p>but instead of his suggestion (which makes using indices/indexes difficult), this one works as well:</p>

<pre><code>(somedate &gt;= StartDate or StartDate is null)
AND
(somedate &lt;= EndDate or EndDate is null)
</code></pre>

<p>AFAIK this would allow usage of an index, but check the execution plan for your specific circumstances.</p>

<p>The disadvantage of using ""special"" start/end dates instead is enforceability. If all your DB access is through a specific program language with more or less mandatory libraries, you may be able to make this work. If however, you have different access paths (direct SQL, different languages/libraries) this would be very hard to do. </p>

<p>There may be a third way: Using NULLs for DML statements and then have a trigger change that to a predefined min/max value. Then Selects might be easier. But using a trigger is opening another can of worms ...</p>

<p>My conclusion: This scenario is a decent use for a database NULL. In my experience, I have not yet run into serious performance problems. But I agreee that the extra NULL handling is a bit of nuisance.</p>
"
1216,542760,3,2,sql,I have StartDate and EndDate for each record. Should I give NULL a special meaning when used in these 2 fields?,"<p>So, I have a table where StartDate and EndDate's are used to determine the activeness of a record. I thought of using NULLs to relieve the maintainers from having to manufacture some crazy dates for some of the records. For example, if NULL had defined as positive infinite when used in EndDate, the data maintainers wouldn't need to come up with something like 1-1-2100 for long-lived records. </p>

<p>I can speculate some of the trade offs on my own: defining NULL as infinities means cleaner data and elimination of periodic maintenance work, but it also means longer queries and stored procedures. So I was wondering how you guys in the real world weigh in on this. </p>

<p>EDIT: the opinions are about half-half. If I had clarified that the StartDate and EndDate are used solely for the purpose of determining the activeness of a record in the where clause, and never appears in the select list, would that tilt the scale? One subject I need to read on is probably indexing. Thanks'all. </p>
","<p>NULL already has a meaning, adding an interpretation of NULL as a valid data value leads to ambiguity. When the query is run and data returned, what will be the meaning of a resulting NULL? How to differentiate between a fail state and valid Max state? </p>

<p>Define min and max constants and let Null be Null.</p>

<p>Great Comments:<br>
<b>@ Haoest</b> - you are right a Null is not the same as a set of Nulls and I was not clear. SQL's  behavior when processing Nulls will require more code for more checks. SQL's results when finding a Null may not match the programmers intuition <a href=""http://en.wikipedia.org/wiki/Null_(SQL)"" rel=""nofollow"">NULL(SQL)</a>.<br>
<b>@ MBCook</b> - great link, wish I had posted that myself - thanks</p>

<p>Update: Once a query or function has a Null for that date then you no longer know if the Null was assigned because of it means Max or because a Null was propagated up the query.  </p>
"
131,44780,2,2,sql,What's the best way to implement a SQL script that will grant permissions to a database role on all the user tables in a database?,"<p>What's the best way to implement a SQL script that will grant select, references, insert, update, and delete permissions to a database role on all the user tables in a database?</p>

<p>Ideally, this script could be run multiple times, as new tables were added to the database. SQL Server Management Studio generates scripts for individual database objects, but I'm looking for more of a ""fire-and-forget"" script.</p>
","<p>There's an undocumented MS procedure called sp_MSforeachtable that you could use which is definitely in 2000 and 2005. </p>

<p>To grant select permissions the usage would be: </p>

<pre><code>EXECUTE sp_MSforeachtable @command1=' Grant Select on ? to RoleName'
</code></pre>

<p>To grant the other permissions either have a new statement for each one or just add them to the command like this: </p>

<pre><code>EXECUTE sp_MSforeachtable @command1=' Grant Select on ? to RoleName; Grant Delete on ? to RoleName;'
</code></pre>

<p>With a bit of playing around it might be possible to turn the role name into a parameter as well.</p>
"
130,44780,0,2,sql,What's the best way to implement a SQL script that will grant permissions to a database role on all the user tables in a database?,"<p>What's the best way to implement a SQL script that will grant select, references, insert, update, and delete permissions to a database role on all the user tables in a database?</p>

<p>Ideally, this script could be run multiple times, as new tables were added to the database. SQL Server Management Studio generates scripts for individual database objects, but I'm looking for more of a ""fire-and-forget"" script.</p>
","<p>We use something similar where I work. Looping through every Tables, Views, Stored Procedures of the system. </p>

<pre><code>CREATE PROCEDURE dbo.SP_GrantFullAccess 
    @username varchar(300)
AS

DECLARE @on varchar(300) 
DECLARE @count int
SET @count = 0

PRINT 'Granting access to user ' + @username + ' on the following objects:'

DECLARE c CURSOR FOR 
SELECT name FROM sysobjects WHERE type IN('U', 'V', 'SP', 'P') ORDER BY name
OPEN c 
FETCH NEXT FROM c INTO @on 
WHILE @@FETCH_STATUS = 0 
BEGIN 
 SET @count = @count + 1
 EXEC('GRANT ALL ON [' + @on + '] TO [' + @username + ']') 
 --PRINT 'GRANT ALL ON [' + @on + '] TO ' + @username
 PRINT @on
 FETCH NEXT FROM c INTO @on 
END 
CLOSE c 
DEALLOCATE c

PRINT 'Granted access to ' + cast(@count as varchar(4)) + ' object(s).'
GO
</code></pre>
"
129,44780,1,2,sql,What's the best way to implement a SQL script that will grant permissions to a database role on all the user tables in a database?,"<p>What's the best way to implement a SQL script that will grant select, references, insert, update, and delete permissions to a database role on all the user tables in a database?</p>

<p>Ideally, this script could be run multiple times, as new tables were added to the database. SQL Server Management Studio generates scripts for individual database objects, but I'm looking for more of a ""fire-and-forget"" script.</p>
","<p>Dr Zimmerman is on the right track here. I'd be looking to write a stored procedure that has a cursor looping through user objects using execute immediate to affect the grant. Something like this:</p>

<pre><code> IF EXISTS (
    SELECT 1 FROM sysobjects
    WHERE name = 'sp_grantastic'
    AND type = 'P'
)
DROP PROCEDURE sp_grantastic
GO
CREATE PROCEDURE sp_grantastic
AS
DECLARE
 @object_name VARCHAR(30)
,@time       VARCHAR(8)
,@rights     VARCHAR(20)
,@role       VARCHAR(20)

DECLARE c_objects CURSOR FOR
    SELECT  name
    FROM    sysobjects
    WHERE   type IN ('P', 'U', 'V')
    FOR READ ONLY

BEGIN

    SELECT  @rights = 'ALL'
           ,@role = 'PUBLIC'

    OPEN c_objects
    WHILE (1=1)
    BEGIN
        FETCH c_objects INTO @object_name
        IF @@SQLSTATUS &lt;&gt; 0 BREAK

        SELECT @time = CONVERT(VARCHAR, GetDate(), 108)
        PRINT '[%1!] hitting up object %2!', @time, @object_name
        EXECUTE('GRANT '+ @rights +' ON '+ @object_name+' TO '+@role)

    END

    PRINT '[%1!] fin!', @time

    CLOSE c_objects
    DEALLOCATE CURSOR c_objects
END
GO
GRANT ALL ON sp_grantastic TO PUBLIC
GO
</code></pre>

<p>Then you can fire and forget:</p>

<pre><code>EXEC sp_grantastic
</code></pre>
"
128,44780,2,2,sql,What's the best way to implement a SQL script that will grant permissions to a database role on all the user tables in a database?,"<p>What's the best way to implement a SQL script that will grant select, references, insert, update, and delete permissions to a database role on all the user tables in a database?</p>

<p>Ideally, this script could be run multiple times, as new tables were added to the database. SQL Server Management Studio generates scripts for individual database objects, but I'm looking for more of a ""fire-and-forget"" script.</p>
","<p>I'm sure there is an easier way, but you could loop through the sysobjects table in the database and grant permissions to any user table objects that exist.  You could then run that multiple times whenever new tables are added.</p>
"
113,39240,1,2,sql,"""Similar Posts"" like functionality using MS SQL Server?","<p>I have lots of article store in MS SQL server 2005 database in a table called Articles-</p>

<pre><code>""Articles (ArticleID, ArticleTitle, ArticleContent)""
</code></pre>

<p>Now I want some SP or SQL query which could return me similar Article against any user's input (very much like ""Similar Posts"" in blogs OR ""Related Questions"" in stackoverflow). The matching should work on both ArticleTitle and ArticleContent. The query should be intelligent enough to sort the result on the basis on their relevancy.</p>

<p>Is it possible to do this in MS SQL Server 2005?</p>
","<p>Something like this might work, a kind of ranking system. You would probably have to split the string in your application to build a SQL string, but I have used similar to build an effective site search.</p>

<pre><code>Select
Top 10
ArticleID,
ArticleTitle,
ArticleContent
From
Articles
Order By
(Case When ArticleTitle = 'Article Title' Then 1 Else 0 End) Desc,
(Case When ArticleTitle = 'Article' Then 1 Else 0 End) Desc,
(Case When ArticleTitle = 'Title' Then 1 Else 0 End) Desc,
(Case When Soundex('Article Title') = Soundex(ArticleTitle) Then 1 Else 0 End) Desc,
(Case When Soundex('Article') = Soundex(ArticleTitle) Then 1 Else 0 End) Desc,
(Case When Soundex('Title') = Soundex(ArticleTitle) Then 1 Else 0 End) Desc,
(Case When PatIndex('%Article%Title%', ArticleTitle) &gt; 0 Then 1 Else 0 End) Desc,
(Case When PatIndex('%Article%', ArticleTitle) &gt; 0 Then 1 Else 0 End) Desc,
(Case When PatIndex('%Title%', ArticleTitle) &gt; 0 Then 1 Else 0 End) Desc,
(Case When PatIndex('%Article%Title%', ArticleContent) &gt; 0 Then 1 Else 0 End) Desc,
(Case When PatIndex('%Article%', ArticleContent) &gt; 0 Then 1 Else 0 End) Desc,
(Case When PatIndex('%Title%', ArticleContent) &gt; 0 Then 1 Else 0 End) Desc
</code></pre>

<p>You can then add/remove case statements from the order by clause to improve the list based on your data.</p>
"
112,39240,0,2,sql,"""Similar Posts"" like functionality using MS SQL Server?","<p>I have lots of article store in MS SQL server 2005 database in a table called Articles-</p>

<pre><code>""Articles (ArticleID, ArticleTitle, ArticleContent)""
</code></pre>

<p>Now I want some SP or SQL query which could return me similar Article against any user's input (very much like ""Similar Posts"" in blogs OR ""Related Questions"" in stackoverflow). The matching should work on both ArticleTitle and ArticleContent. The query should be intelligent enough to sort the result on the basis on their relevancy.</p>

<p>Is it possible to do this in MS SQL Server 2005?</p>
","<p>I think the question is what 'similar' means to you. If you create a field for user to input some kind of tags, it becomes much more easier to query.</p>
"
111,39240,0,2,sql,"""Similar Posts"" like functionality using MS SQL Server?","<p>I have lots of article store in MS SQL server 2005 database in a table called Articles-</p>

<pre><code>""Articles (ArticleID, ArticleTitle, ArticleContent)""
</code></pre>

<p>Now I want some SP or SQL query which could return me similar Article against any user's input (very much like ""Similar Posts"" in blogs OR ""Related Questions"" in stackoverflow). The matching should work on both ArticleTitle and ArticleContent. The query should be intelligent enough to sort the result on the basis on their relevancy.</p>

<p>Is it possible to do this in MS SQL Server 2005?</p>
","<p>First of all you need to define what article similarity means.<br />
For example you can associate some meta information with articles, like tags.<br />
To be able to find similar articles you need to extract some features from them, for example you can build full text index.</p>

<p>You can take advantage of full text search capability of MSSQL 2005</p>

<pre><code>-- Assuming @Title contains title of current articles you can find related articles runnig this query  
SELECT * FROM Acticles WHERE CONTAINS(ArticleTitle, @Title)
</code></pre>
"
410,186160,1,2,sql,How do I add to a list with Linq to SQL?,"<p>I have a table in the database that I'm retrieving using LINQ to SQL, and as a part of my processing I want to add to this list, then update the database with the new items + any changes I've made.</p>

<p>What I thought I could do was this:</p>

<pre><code>var list = (from item in db.Table
            select item).ToList();

[do processing where I modify items &amp; add to the list]

list = list.Distinct();

db.SubmitChanges();
</code></pre>

<p>What happens is that the modifications happed (ie. SQL updates) but any new items I add to the list don't get added.</p>

<p>Obviously I'm doing this wrong, what is the correct way to modify &amp; add to a list of DB entities, then commit all the updates &amp; inserts?</p>
","<p>You've got to tell LINQ to insert the new row on submit, using InsertOnSubmit:</p>

<pre><code>db.InsertOnSubmit(newrow);
db.SubmitChanges();
</code></pre>

<p>You do not need a new DataContext, you can use the one you are using for updates.</p>

<p>Same for delete DeleteOnSubmit(row). Modifications will be tracked, though.</p>
"
408,186160,1,2,sql,How do I add to a list with Linq to SQL?,"<p>I have a table in the database that I'm retrieving using LINQ to SQL, and as a part of my processing I want to add to this list, then update the database with the new items + any changes I've made.</p>

<p>What I thought I could do was this:</p>

<pre><code>var list = (from item in db.Table
            select item).ToList();

[do processing where I modify items &amp; add to the list]

list = list.Distinct();

db.SubmitChanges();
</code></pre>

<p>What happens is that the modifications happed (ie. SQL updates) but any new items I add to the list don't get added.</p>

<p>Obviously I'm doing this wrong, what is the correct way to modify &amp; add to a list of DB entities, then commit all the updates &amp; inserts?</p>
","<p>You have to add the new items via InsertOnSubmit.</p>
"
411,186160,3,2,sql,How do I add to a list with Linq to SQL?,"<p>I have a table in the database that I'm retrieving using LINQ to SQL, and as a part of my processing I want to add to this list, then update the database with the new items + any changes I've made.</p>

<p>What I thought I could do was this:</p>

<pre><code>var list = (from item in db.Table
            select item).ToList();

[do processing where I modify items &amp; add to the list]

list = list.Distinct();

db.SubmitChanges();
</code></pre>

<p>What happens is that the modifications happed (ie. SQL updates) but any new items I add to the list don't get added.</p>

<p>Obviously I'm doing this wrong, what is the correct way to modify &amp; add to a list of DB entities, then commit all the updates &amp; inserts?</p>
","<p>You can create an extension method for it:</p>

<pre><code>static void EnsureInsertedOnSubmit&lt;TEntity&gt;( this Table&lt;TEntity&gt;  table
                                            ,IEnumerable&lt;TEntity&gt; entities)
 { foreach(var entity in entities) 
    { if  (   table.GetModifiedMembers(entity).Length == 0     
           &amp;&amp; table.GetOriginalEntityState(entity) == default(TEntity))
       { table.InsertOnSubmit(entity);
       }
    }
 }
</code></pre>

<p>And then you can do this:</p>

<pre><code> var list = db.Table1.ToList();
 list.Add(new Item());
 db.Table1.EnsureInsertedOnSubmit(list);
 db.SubmitChanges();
</code></pre>
"
1215,542760,0,2,sql,I have StartDate and EndDate for each record. Should I give NULL a special meaning when used in these 2 fields?,"<p>So, I have a table where StartDate and EndDate's are used to determine the activeness of a record. I thought of using NULLs to relieve the maintainers from having to manufacture some crazy dates for some of the records. For example, if NULL had defined as positive infinite when used in EndDate, the data maintainers wouldn't need to come up with something like 1-1-2100 for long-lived records. </p>

<p>I can speculate some of the trade offs on my own: defining NULL as infinities means cleaner data and elimination of periodic maintenance work, but it also means longer queries and stored procedures. So I was wondering how you guys in the real world weigh in on this. </p>

<p>EDIT: the opinions are about half-half. If I had clarified that the StartDate and EndDate are used solely for the purpose of determining the activeness of a record in the where clause, and never appears in the select list, would that tilt the scale? One subject I need to read on is probably indexing. Thanks'all. </p>
","<p>if you use NULL dates in your DB, make sure you use DateTime? (nullable C#) in your code, that will make your life a lot easier :)</p>
"
532,235690,3,2,sql,Is it possible to change SQL user-defined data type?,"<p>I have a bunch of tables using user-defined data type for PK column. Is it possible to change this type Using SQL Server 2005?</p>
","<p>I would suggest that it is always possible to refactor poor or outmoded database designs, it simply depends on how much work you are willing to go to in order to do so.</p>

<p>If you are looking to replace the user-defined data with a surrogate key then you should be able to simply alter the existing table to contain a non-nullable identity column and this should cause all of the existing records to be assigned a new key automatically.</p>

<p>Once the new field is populated with unique id's, if you need to move out and replace foreign key references to this table, then I would simply alter those tables to contain the new field and use something like the following:</p>

<pre><code>UPDATE child_table 
SET new_fk_val = 
    SELECT new_pk_val 
    FROM parent_table
    WHERE parent_table.old_pk_val = child_table.old_fk_val
</code></pre>

<p>Once that step is complete, then you could drop the old foreign key constraint, drop the old foreign key column, drop the old primary key column, establish the new primary key constraint, and then establish the new foreign key constraint.</p>

<p>Of course, if the old version of the parent and child tables relationship was such that you have invalid records in the child table you may have to do something like the following:</p>

<pre><code>DELETE FROM child_table 
WHERE old_fk_val NOT IN 
    ( SELECT old_pk_val FROM parent_table)
</code></pre>
"
547,246870,-1,2,sql,"""Simple"" SQL Query","<p>Each of my clients can have many todo items and every todo item has a due date.</p>

<p>What would be the query for discovering the next undone todo item by due date for each file?  In the event that a client has more than one todo, the one with the lowest id is the correct one.</p>

<p>Assuming the following minimal schema:</p>

<pre><code>clients (id, name)

todos (id, client_id, description, timestamp_due, timestamp_completed)
</code></pre>

<p>Thank you.</p>
","<p>The following should get you close, first get the min time for each client, then lookup the client/todo information</p>

<pre><code>SELECT
    C.Id,
    C.Name,
    T.Id
    T.Description,
    T.timestamp_due
FROM
{
    SELECT
        client_id,
        MIN(timestamp_due) AS ""DueDate""
    FROM todos
    WHERE timestamp_completed IS NULL
    GROUP BY ClientId
} AS MinValues
    INNER JOIN Clients C
    ON (MinValues.client_id = C.Id)
    INNER JOIN todos T
    ON (MinValues.client_id = T.client_id
    	AND MinValues.DueDate = T.timestamp_due)
ORDER BY C.Name
</code></pre>

<p><strong>NOTE:</strong> Written assuming SQL Server</p>
"
548,246870,2,2,sql,"""Simple"" SQL Query","<p>Each of my clients can have many todo items and every todo item has a due date.</p>

<p>What would be the query for discovering the next undone todo item by due date for each file?  In the event that a client has more than one todo, the one with the lowest id is the correct one.</p>

<p>Assuming the following minimal schema:</p>

<pre><code>clients (id, name)

todos (id, client_id, description, timestamp_due, timestamp_completed)
</code></pre>

<p>Thank you.</p>
","<pre><code>SELECT c.name, MIN(t.id)
FROM clients c, todos t
WHERE c.id = t.client_id AND t.timestamp_complete IS NULL
GROUP BY c.id
HAVING t.timestamp_due &lt;= MIN(t.timestamp_due)
</code></pre>

<p>Avoids a subquery, correlated or otherwise but introduces a bunch of aggregate operations which aren't much better.</p>
"
549,246870,3,2,sql,"""Simple"" SQL Query","<p>Each of my clients can have many todo items and every todo item has a due date.</p>

<p>What would be the query for discovering the next undone todo item by due date for each file?  In the event that a client has more than one todo, the one with the lowest id is the correct one.</p>

<p>Assuming the following minimal schema:</p>

<pre><code>clients (id, name)

todos (id, client_id, description, timestamp_due, timestamp_completed)
</code></pre>

<p>Thank you.</p>
","<p>This question is the classic <strong><em>pick-a-winner for each group</em></strong>.  It gets posted about twice a day.</p>

<pre><code>SELECT *
FROM todos t
WHERE t.timestamp_completed is null
  and
(
  SELECT top 1 t2.id
  FROM todos t2
  WHERE t.client_id = t2.client_id
    and t2.timestamp_completed is null
     --there is no earlier record
    and
    (t.timestamp_due &gt; t2.timestamp_due
       or (t.timestamp_due = t2.timestamp_due and t.id &gt; t2.id)
    )
) is null
</code></pre>
"
397,181130,2,2,sql,Encrypted database query,"<p>I've just found out about Stack Overflow and I'm just checking if there are ideas for a constraint I'm having with some friends in a project, though this is more of a theoretical question to which I've been trying to find an answer for some time.</p>

<p>I'm not much given into cryptography but if I'm not clear enough I'll try to edit/comment to clarify any questions.</p>

<p>Trying to be brief, the environment is something like this:</p>

<ul>
<li><p>An application where the front-end as access to encrypt/decrypt keys and the back-end is just used for storage and queries.</p></li>
<li><p>Having a database to which you can't have access for a couple of fields for example let's say ""address"" which is text/varchar as usual.</p></li>
<li><p>You don't have access to the key for decrypting the information, and all information arrives to the database already encrypted.</p></li>
</ul>

<p>The main problem is something like this, how to consistently make queries on the database, it's impossible to do stuff like ""where address like '%FYU/~#JKSks23%'"". (IF there is anyone  feeling with an answer for this feel free to shoot it).</p>

<p>But is it ok to do <code>where address='!NNsj3~^-:'</code>? Or would it also completely eat up the database? </p>

<p>Another restrain that might apply is that the front end doesn't have much processing power available, so already encrypting/decrypting information starts to push it to its limits. (Saying this just to avoid replies like ""Exporting a join of tables to the front end and query it there"".)</p>

<p>Could someone point me in a direction to keep thinking about it?</p>

<hr>

<p>Well thanks for so fast replies at 4 AM, for a first time usage I'm really feeling impressed with this community. (Or maybe I'm it's just for the different time zone)</p>

<p>Just feeding some information:</p>

<p>The main problem is all around partial matching. As a mandatory requirement in most databases is to allow partial matches. The main constraint is actually <strong>the database owner would not be allowed to look inside the database for information</strong>. During the last 10 minutes I've come up with a possible solution which extends again to possible database problems, to which I'll add here:</p>

<p>Possible solution to allow semi partial matching:</p>

<ul>
<li>The password + a couple of public fields of the user are actually the key for encrypting. For authentication the idea is to encrypt a static value and compare it within the database.</li>
<li>Creating a new set of tables where information is stored in a parsed way, meaning something like: ""4th Street"" would become 2 encrypted rows (one for '4th' another for 'Street'). This would already allow semi-partial matching as a search could already be performed on the separate tables.</li>
</ul>

<p>New question:</p>

<ul>
<li>Would this probably eat up the database server again, or does anyone think it is a viable solution for the partial matching problem?</li>
</ul>

<p><em>Post Scriptum: I've unaccepted the answer from Cade Roux just to allow for further discussion and specially a possible answer to the new question.</em></p>
","<p>why not encrypt the disk holding the database tables, encrypt the database connections, and let the database operate normally?</p>

<p>[i don't really understand the context/contraints that require this level of paranoia]</p>

<p>EDIT: ""law constraints"" eh? I hope you're not involved in anything illegal, I'd hate to be an inadvertent accessory... ;-)</p>

<p>if the - ahem - legal constraints - force this solution, then that's all there is to be done - no LIKE matches, and slow response if the client machines can't handle it.</p>
"
396,181130,0,2,sql,Encrypted database query,"<p>I've just found out about Stack Overflow and I'm just checking if there are ideas for a constraint I'm having with some friends in a project, though this is more of a theoretical question to which I've been trying to find an answer for some time.</p>

<p>I'm not much given into cryptography but if I'm not clear enough I'll try to edit/comment to clarify any questions.</p>

<p>Trying to be brief, the environment is something like this:</p>

<ul>
<li><p>An application where the front-end as access to encrypt/decrypt keys and the back-end is just used for storage and queries.</p></li>
<li><p>Having a database to which you can't have access for a couple of fields for example let's say ""address"" which is text/varchar as usual.</p></li>
<li><p>You don't have access to the key for decrypting the information, and all information arrives to the database already encrypted.</p></li>
</ul>

<p>The main problem is something like this, how to consistently make queries on the database, it's impossible to do stuff like ""where address like '%FYU/~#JKSks23%'"". (IF there is anyone  feeling with an answer for this feel free to shoot it).</p>

<p>But is it ok to do <code>where address='!NNsj3~^-:'</code>? Or would it also completely eat up the database? </p>

<p>Another restrain that might apply is that the front end doesn't have much processing power available, so already encrypting/decrypting information starts to push it to its limits. (Saying this just to avoid replies like ""Exporting a join of tables to the front end and query it there"".)</p>

<p>Could someone point me in a direction to keep thinking about it?</p>

<hr>

<p>Well thanks for so fast replies at 4 AM, for a first time usage I'm really feeling impressed with this community. (Or maybe I'm it's just for the different time zone)</p>

<p>Just feeding some information:</p>

<p>The main problem is all around partial matching. As a mandatory requirement in most databases is to allow partial matches. The main constraint is actually <strong>the database owner would not be allowed to look inside the database for information</strong>. During the last 10 minutes I've come up with a possible solution which extends again to possible database problems, to which I'll add here:</p>

<p>Possible solution to allow semi partial matching:</p>

<ul>
<li>The password + a couple of public fields of the user are actually the key for encrypting. For authentication the idea is to encrypt a static value and compare it within the database.</li>
<li>Creating a new set of tables where information is stored in a parsed way, meaning something like: ""4th Street"" would become 2 encrypted rows (one for '4th' another for 'Street'). This would already allow semi-partial matching as a search could already be performed on the separate tables.</li>
</ul>

<p>New question:</p>

<ul>
<li>Would this probably eat up the database server again, or does anyone think it is a viable solution for the partial matching problem?</li>
</ul>

<p><em>Post Scriptum: I've unaccepted the answer from Cade Roux just to allow for further discussion and specially a possible answer to the new question.</em></p>
","<p>If you need to store sensitive data that you want to query later I'd recommend to store it in plain text, restricting access to that tables as much as you can.</p>

<p>If you can't do that, and you don't want overhead in the front end you can make a component in the back end, running in a server, that processes the encrypted data.</p>

<p>Making querys to encrypted data? If you're using a good encryption algorithm I can't imagine how to do that.</p>
"
395,181130,0,2,sql,Encrypted database query,"<p>I've just found out about Stack Overflow and I'm just checking if there are ideas for a constraint I'm having with some friends in a project, though this is more of a theoretical question to which I've been trying to find an answer for some time.</p>

<p>I'm not much given into cryptography but if I'm not clear enough I'll try to edit/comment to clarify any questions.</p>

<p>Trying to be brief, the environment is something like this:</p>

<ul>
<li><p>An application where the front-end as access to encrypt/decrypt keys and the back-end is just used for storage and queries.</p></li>
<li><p>Having a database to which you can't have access for a couple of fields for example let's say ""address"" which is text/varchar as usual.</p></li>
<li><p>You don't have access to the key for decrypting the information, and all information arrives to the database already encrypted.</p></li>
</ul>

<p>The main problem is something like this, how to consistently make queries on the database, it's impossible to do stuff like ""where address like '%FYU/~#JKSks23%'"". (IF there is anyone  feeling with an answer for this feel free to shoot it).</p>

<p>But is it ok to do <code>where address='!NNsj3~^-:'</code>? Or would it also completely eat up the database? </p>

<p>Another restrain that might apply is that the front end doesn't have much processing power available, so already encrypting/decrypting information starts to push it to its limits. (Saying this just to avoid replies like ""Exporting a join of tables to the front end and query it there"".)</p>

<p>Could someone point me in a direction to keep thinking about it?</p>

<hr>

<p>Well thanks for so fast replies at 4 AM, for a first time usage I'm really feeling impressed with this community. (Or maybe I'm it's just for the different time zone)</p>

<p>Just feeding some information:</p>

<p>The main problem is all around partial matching. As a mandatory requirement in most databases is to allow partial matches. The main constraint is actually <strong>the database owner would not be allowed to look inside the database for information</strong>. During the last 10 minutes I've come up with a possible solution which extends again to possible database problems, to which I'll add here:</p>

<p>Possible solution to allow semi partial matching:</p>

<ul>
<li>The password + a couple of public fields of the user are actually the key for encrypting. For authentication the idea is to encrypt a static value and compare it within the database.</li>
<li>Creating a new set of tables where information is stored in a parsed way, meaning something like: ""4th Street"" would become 2 encrypted rows (one for '4th' another for 'Street'). This would already allow semi-partial matching as a search could already be performed on the separate tables.</li>
</ul>

<p>New question:</p>

<ul>
<li>Would this probably eat up the database server again, or does anyone think it is a viable solution for the partial matching problem?</li>
</ul>

<p><em>Post Scriptum: I've unaccepted the answer from Cade Roux just to allow for further discussion and specially a possible answer to the new question.</em></p>
","<p>You want do use md5 hashing. Basically, it takes your string and turns it into a hash that cannot be reproduced. You can then use it to validate against things later. For example:</p>

<pre><code>$salt = ""123-=asd"";
$address = ""3412 g ave"";

$sql = ""INSERT INTO addresses (address) VALUES ('"" . md5($salt . $address) . ""')"";
mysql_query($sql);
</code></pre>

<p>Then, to validate an address in the future:</p>

<pre><code>$salt = ""123-=asd"";
$address = ""3412 g ave"";

$sql = ""SELECT address FROM addresses WHERE address = '"" . md5($salt . $address) . ""'"";
$res = mysql_query($sql);
if (mysql_fetch_row($res))
    // exists
else
    // does not
</code></pre>

<p>Now it is encrypted on the database side so nobody can find it out - even if they looked in your source code. However, finding the salt will help them decrypt it though.</p>

<p><a href=""http://en.wikipedia.org/wiki/MD5"" rel=""nofollow"">http://en.wikipedia.org/wiki/MD5</a></p>
"
394,181130,4,2,sql,Encrypted database query,"<p>I've just found out about Stack Overflow and I'm just checking if there are ideas for a constraint I'm having with some friends in a project, though this is more of a theoretical question to which I've been trying to find an answer for some time.</p>

<p>I'm not much given into cryptography but if I'm not clear enough I'll try to edit/comment to clarify any questions.</p>

<p>Trying to be brief, the environment is something like this:</p>

<ul>
<li><p>An application where the front-end as access to encrypt/decrypt keys and the back-end is just used for storage and queries.</p></li>
<li><p>Having a database to which you can't have access for a couple of fields for example let's say ""address"" which is text/varchar as usual.</p></li>
<li><p>You don't have access to the key for decrypting the information, and all information arrives to the database already encrypted.</p></li>
</ul>

<p>The main problem is something like this, how to consistently make queries on the database, it's impossible to do stuff like ""where address like '%FYU/~#JKSks23%'"". (IF there is anyone  feeling with an answer for this feel free to shoot it).</p>

<p>But is it ok to do <code>where address='!NNsj3~^-:'</code>? Or would it also completely eat up the database? </p>

<p>Another restrain that might apply is that the front end doesn't have much processing power available, so already encrypting/decrypting information starts to push it to its limits. (Saying this just to avoid replies like ""Exporting a join of tables to the front end and query it there"".)</p>

<p>Could someone point me in a direction to keep thinking about it?</p>

<hr>

<p>Well thanks for so fast replies at 4 AM, for a first time usage I'm really feeling impressed with this community. (Or maybe I'm it's just for the different time zone)</p>

<p>Just feeding some information:</p>

<p>The main problem is all around partial matching. As a mandatory requirement in most databases is to allow partial matches. The main constraint is actually <strong>the database owner would not be allowed to look inside the database for information</strong>. During the last 10 minutes I've come up with a possible solution which extends again to possible database problems, to which I'll add here:</p>

<p>Possible solution to allow semi partial matching:</p>

<ul>
<li>The password + a couple of public fields of the user are actually the key for encrypting. For authentication the idea is to encrypt a static value and compare it within the database.</li>
<li>Creating a new set of tables where information is stored in a parsed way, meaning something like: ""4th Street"" would become 2 encrypted rows (one for '4th' another for 'Street'). This would already allow semi-partial matching as a search could already be performed on the separate tables.</li>
</ul>

<p>New question:</p>

<ul>
<li>Would this probably eat up the database server again, or does anyone think it is a viable solution for the partial matching problem?</li>
</ul>

<p><em>Post Scriptum: I've unaccepted the answer from Cade Roux just to allow for further discussion and specially a possible answer to the new question.</em></p>
","<p>You can do it the way you describe - effectively querying the hash, say, but there's not many systems with that requirement, because at that point the security requirements are interfering with other requirements for the system to be usable - i.e. no partial matches, since the encryption rules that out.  It's the same problem with compression.  Years ago, in a very small environment, I had to compress the data before putting it in the data format.  Of course, those fields could not easily be searched.</p>

<p>In a more typical application, ultimately, the keys are going to be available to someone in the chain - probably the web server.</p>

<p>For end user traffic SSL protects that pipe.  Some network switches can protect it between web server and database, and storing encrypted data in the database is fine, but you're not going to query on encrypted data like that.</p>

<p>And once the data is displayed, it's out there on the machine, so any general purpose computing device can be circumvented at that point, and you have perimeter defenses outside of your application which really come into play.</p>
"
763,349460,3,2,sql,SQL statement problem,"<p>I have this code:</p>

<pre><code>SELECT    idcallhistory3, callid, starttime, answertime, endtime, duration,
          is_answ, is_fail, is_compl, is_fromoutside, mediatype, from_no,
          to_no, callerid, dialednumber, lastcallerid, lastdialednumber,
          group_no, line_no
FROM      ""public"".callhistory3
WHERE     (starttime &gt;= ?) AND (endtime &lt;= ?) AND (is_fromoutside = ?) 
          AND (from_no = ?) AND (to_no = ?)
</code></pre>

<p>The problem is I need to pass one value for ? and get all the result without filter, some thing like *</p>

<p>Any help?</p>
","<p>I like COALESCE.  </p>

<p>You just have to be careful with null values on the left hand side, if there can be nulls on the left hand side you can do something like the last line so that nulls will match.  Typically with anything like this though you will want to make sure your query still performs ok.</p>

<pre><code>SELECT    idcallhistory3, callid, starttime, answertime, endtime, duration,
          is_answ, is_fail, is_compl, is_fromoutside, mediatype, from_no,
          to_no, callerid, dialednumber, lastcallerid, lastdialednumber,
          group_no, line_no
FROM      ""public"".callhistory3
WHERE     (starttime &gt;= COALESCE(@starttime, starttime )) 
          AND (endtime &lt;= COALESCE(@endtime, endtime)) 
          AND (is_fromoutside = COALESCE(@is_fromoutside, is_fromoutside)) 
          AND (from_no = COALESCE(@from_no, from_no)) 
          AND (COALESCE(to_no, -1) = COALESCE(@to_no, to_no, -1)) -- make nulls match
</code></pre>
"
764,349460,0,2,sql,SQL statement problem,"<p>I have this code:</p>

<pre><code>SELECT    idcallhistory3, callid, starttime, answertime, endtime, duration,
          is_answ, is_fail, is_compl, is_fromoutside, mediatype, from_no,
          to_no, callerid, dialednumber, lastcallerid, lastdialednumber,
          group_no, line_no
FROM      ""public"".callhistory3
WHERE     (starttime &gt;= ?) AND (endtime &lt;= ?) AND (is_fromoutside = ?) 
          AND (from_no = ?) AND (to_no = ?)
</code></pre>

<p>The problem is I need to pass one value for ? and get all the result without filter, some thing like *</p>

<p>Any help?</p>
","<p>I agree with Jamal Hansen.  COALESCE is by far the best performing way to go, at least on SQL Server</p>
"
354,151190,2,2,sql,pl/sql dollar operator?,"<p>I encountered the following ddl in a pl/sql script this morning:</p>

<p>create index genuser.idx$$_0bdd0011
...</p>

<p>My initial thought was that the index name was generated by a tool...but I'm also not a pl/sql superstar so I could very well be incorrect. Does the double dollar sign have any special significance in this statement? </p>
","<p>No special meaning or significance.</p>

<pre><code>SQL&gt; create table t (col number)
  2  /

Table created.

SQL&gt; create index idx$$_0bdd0011 on t(col)
  2  /

Index created.
</code></pre>

<p>Note: CREATE INDEX is a DDL statement which is usually executed in a SQL script, not in PL/SQL.</p>
"
1212,542760,0,2,sql,I have StartDate and EndDate for each record. Should I give NULL a special meaning when used in these 2 fields?,"<p>So, I have a table where StartDate and EndDate's are used to determine the activeness of a record. I thought of using NULLs to relieve the maintainers from having to manufacture some crazy dates for some of the records. For example, if NULL had defined as positive infinite when used in EndDate, the data maintainers wouldn't need to come up with something like 1-1-2100 for long-lived records. </p>

<p>I can speculate some of the trade offs on my own: defining NULL as infinities means cleaner data and elimination of periodic maintenance work, but it also means longer queries and stored procedures. So I was wondering how you guys in the real world weigh in on this. </p>

<p>EDIT: the opinions are about half-half. If I had clarified that the StartDate and EndDate are used solely for the purpose of determining the activeness of a record in the where clause, and never appears in the select list, would that tilt the scale? One subject I need to read on is probably indexing. Thanks'all. </p>
","<p>I think using null is better than some arbitrary special value. If nothing else, seeing a null value makes you pause and think about what it might mean. </p>
"
1211,542760,1,2,sql,I have StartDate and EndDate for each record. Should I give NULL a special meaning when used in these 2 fields?,"<p>So, I have a table where StartDate and EndDate's are used to determine the activeness of a record. I thought of using NULLs to relieve the maintainers from having to manufacture some crazy dates for some of the records. For example, if NULL had defined as positive infinite when used in EndDate, the data maintainers wouldn't need to come up with something like 1-1-2100 for long-lived records. </p>

<p>I can speculate some of the trade offs on my own: defining NULL as infinities means cleaner data and elimination of periodic maintenance work, but it also means longer queries and stored procedures. So I was wondering how you guys in the real world weigh in on this. </p>

<p>EDIT: the opinions are about half-half. If I had clarified that the StartDate and EndDate are used solely for the purpose of determining the activeness of a record in the where clause, and never appears in the select list, would that tilt the scale? One subject I need to read on is probably indexing. Thanks'all. </p>
","<p>I would say your own speculations are quite correct.  It's really one of those trade-off type situations.</p>

<p>My own person preference is to disallow NULL's in Date-type fields, and always use a ""high value"" for something like an end date.  For me, this greatly simplifies all queries I'll have to do against a start/end date and prevents me from having lots and lots of NULL checking in multiple queries.</p>

<p>That said, it depends upon the application.  If I must have NULL's in date fields, I'll use them, but if I can get away with substituting a real date, I will.  Of course, the downside of using a real date is that it is just that, a <em>real</em> date, and ceases to have the standard database definition of a NULL, i.e. an <em>absence</em> of data.</p>
"
1210,542760,1,2,sql,I have StartDate and EndDate for each record. Should I give NULL a special meaning when used in these 2 fields?,"<p>So, I have a table where StartDate and EndDate's are used to determine the activeness of a record. I thought of using NULLs to relieve the maintainers from having to manufacture some crazy dates for some of the records. For example, if NULL had defined as positive infinite when used in EndDate, the data maintainers wouldn't need to come up with something like 1-1-2100 for long-lived records. </p>

<p>I can speculate some of the trade offs on my own: defining NULL as infinities means cleaner data and elimination of periodic maintenance work, but it also means longer queries and stored procedures. So I was wondering how you guys in the real world weigh in on this. </p>

<p>EDIT: the opinions are about half-half. If I had clarified that the StartDate and EndDate are used solely for the purpose of determining the activeness of a record in the where clause, and never appears in the select list, would that tilt the scale? One subject I need to read on is probably indexing. Thanks'all. </p>
","<p>I would tend to use defined Min and Max dates instead of nulls. Primarily because, at least in C#, when you get the data out of the DB then you have to start dealing with Nullable types, and I find that annoying. </p>

<p>It also tends to make it easier on queries. If I query with an end date of Max, then I get all dates with a max end date, plus all dates with an end date less than max, which is usually what I want. If I have nulls, then I have to do a join to get dates that are less than max and null values. Hope that makes sense. </p>

<p>I guess, bottom line, I approach these problems from a usability standpoint for developers, not db users, so that's where my perspective lies. </p>
"
793,353020,1,2,sql,SQL - Temp Table: Storing all columns in temp table versus only Primary key,"<p>I would need to create a temp table for paging purposes. I would be selecting all records into a temp table and then do further processing with it.</p>

<p>I am wondering which of the following is a better approach:</p>

<p>1) Select all the columns of my Primary Table into the Temp Table and then being able to select the rows I would need</p>

<p>OR</p>

<p>2) Select only the primary key of the Primary Table into the Temp Table and then joining with the Primary Table later on?</p>

<p>Is there any size consideration when working with approach 1 versus approach 2?</p>

<p>[EDIT]</p>

<p>I am asking because I would have done the first approach but looking at PROCEDURE [dbo].[aspnet_Membership_FindUsersByName], that was included with ASP.NET Membership, they are doing Approach 2</p>

<p>[EDIT2]</p>

<p>With people without access to the Stored procedure:</p>

<pre><code>  -- Insert into our temp table
INSERT INTO #PageIndexForUsers (UserId)
    SELECT u.UserId
    FROM   dbo.aspnet_Users u, dbo.aspnet_Membership m
    WHERE  u.ApplicationId = @ApplicationId AND m.UserId = u.UserId AND u.LoweredUserName LIKE LOWER(@UserNameToMatch)
    ORDER BY u.UserName


SELECT  u.UserName, m.Email, m.PasswordQuestion, m.Comment, m.IsApproved,
        m.CreateDate,
        m.LastLoginDate,
        u.LastActivityDate,
        m.LastPasswordChangedDate,
        u.UserId, m.IsLockedOut,
        m.LastLockoutDate
FROM   dbo.aspnet_Membership m, dbo.aspnet_Users u, #PageIndexForUsers p
WHERE  u.UserId = p.UserId AND u.UserId = m.UserId AND
       p.IndexId &gt;= @PageLowerBound AND p.IndexId &lt;= @PageUpperBound
ORDER BY u.UserName
</code></pre>
","<p>With approach 1, the data in the temp table may be out of step with the real data, i.e. if other sessions make changes to the real data.  This may be OK if you are just viewing a snapshot of the data taken at a certain point, but would be dangerous if you were also updating the real table based on changes made to the temporary copy.</p>
"
794,353020,2,2,sql,SQL - Temp Table: Storing all columns in temp table versus only Primary key,"<p>I would need to create a temp table for paging purposes. I would be selecting all records into a temp table and then do further processing with it.</p>

<p>I am wondering which of the following is a better approach:</p>

<p>1) Select all the columns of my Primary Table into the Temp Table and then being able to select the rows I would need</p>

<p>OR</p>

<p>2) Select only the primary key of the Primary Table into the Temp Table and then joining with the Primary Table later on?</p>

<p>Is there any size consideration when working with approach 1 versus approach 2?</p>

<p>[EDIT]</p>

<p>I am asking because I would have done the first approach but looking at PROCEDURE [dbo].[aspnet_Membership_FindUsersByName], that was included with ASP.NET Membership, they are doing Approach 2</p>

<p>[EDIT2]</p>

<p>With people without access to the Stored procedure:</p>

<pre><code>  -- Insert into our temp table
INSERT INTO #PageIndexForUsers (UserId)
    SELECT u.UserId
    FROM   dbo.aspnet_Users u, dbo.aspnet_Membership m
    WHERE  u.ApplicationId = @ApplicationId AND m.UserId = u.UserId AND u.LoweredUserName LIKE LOWER(@UserNameToMatch)
    ORDER BY u.UserName


SELECT  u.UserName, m.Email, m.PasswordQuestion, m.Comment, m.IsApproved,
        m.CreateDate,
        m.LastLoginDate,
        u.LastActivityDate,
        m.LastPasswordChangedDate,
        u.UserId, m.IsLockedOut,
        m.LastLockoutDate
FROM   dbo.aspnet_Membership m, dbo.aspnet_Users u, #PageIndexForUsers p
WHERE  u.UserId = p.UserId AND u.UserId = m.UserId AND
       p.IndexId &gt;= @PageLowerBound AND p.IndexId &lt;= @PageUpperBound
ORDER BY u.UserName
</code></pre>
","<p>A Table Variable would be preferred over a temp table, if its within your constraints. </p>

<p>Option 2 would use less resources, because there is less data duplication. </p>

<p>Tony's points about this being a dirty read are really something you should be considering.  </p>

<p>Can you explain how you are 'paging' with temp tables? Its not a paging method I am familiar with. </p>

<p>EDIT: 
After looking at your post edit, you should definately use a table variable in this case. Its less to cleanup and you wont blow out the tempdb so much. </p>

<p>Also, its kind of unclear what benefit this temp table gives. If your aim is to stop a user from accessing an object/applicaiton, then why are you adding the part about it being ""only restricted if on this particular data table page"". It seems kind of hole-y from a security perspective.</p>

<p>The temp table can be pretty much eliminated also, since it selects from the same tables.</p>
"
795,353020,0,2,sql,SQL - Temp Table: Storing all columns in temp table versus only Primary key,"<p>I would need to create a temp table for paging purposes. I would be selecting all records into a temp table and then do further processing with it.</p>

<p>I am wondering which of the following is a better approach:</p>

<p>1) Select all the columns of my Primary Table into the Temp Table and then being able to select the rows I would need</p>

<p>OR</p>

<p>2) Select only the primary key of the Primary Table into the Temp Table and then joining with the Primary Table later on?</p>

<p>Is there any size consideration when working with approach 1 versus approach 2?</p>

<p>[EDIT]</p>

<p>I am asking because I would have done the first approach but looking at PROCEDURE [dbo].[aspnet_Membership_FindUsersByName], that was included with ASP.NET Membership, they are doing Approach 2</p>

<p>[EDIT2]</p>

<p>With people without access to the Stored procedure:</p>

<pre><code>  -- Insert into our temp table
INSERT INTO #PageIndexForUsers (UserId)
    SELECT u.UserId
    FROM   dbo.aspnet_Users u, dbo.aspnet_Membership m
    WHERE  u.ApplicationId = @ApplicationId AND m.UserId = u.UserId AND u.LoweredUserName LIKE LOWER(@UserNameToMatch)
    ORDER BY u.UserName


SELECT  u.UserName, m.Email, m.PasswordQuestion, m.Comment, m.IsApproved,
        m.CreateDate,
        m.LastLoginDate,
        u.LastActivityDate,
        m.LastPasswordChangedDate,
        u.UserId, m.IsLockedOut,
        m.LastLockoutDate
FROM   dbo.aspnet_Membership m, dbo.aspnet_Users u, #PageIndexForUsers p
WHERE  u.UserId = p.UserId AND u.UserId = m.UserId AND
       p.IndexId &gt;= @PageLowerBound AND p.IndexId &lt;= @PageUpperBound
ORDER BY u.UserName
</code></pre>
","<p>This is exactly the approach I use for Paging on the server,</p>

<p>Create a Table Variable (why incur the overhead of transaction logging ?)  With just the key values.  (Create the table with an autonum Identity column Primary Key - this will be RowNum. )</p>

<p>Insert keys into the table based on users sort/filtering criteria.. Identity column is now a row number which can be used for paging.</p>

<p>Select from table variable joined to other tables with real data required, Joined on key value, </p>

<pre><code>Where RowNum Between ((PageNumber-1) * PageSize) + 1 And PageNumber * PageSize
</code></pre>
"
796,353020,0,2,sql,SQL - Temp Table: Storing all columns in temp table versus only Primary key,"<p>I would need to create a temp table for paging purposes. I would be selecting all records into a temp table and then do further processing with it.</p>

<p>I am wondering which of the following is a better approach:</p>

<p>1) Select all the columns of my Primary Table into the Temp Table and then being able to select the rows I would need</p>

<p>OR</p>

<p>2) Select only the primary key of the Primary Table into the Temp Table and then joining with the Primary Table later on?</p>

<p>Is there any size consideration when working with approach 1 versus approach 2?</p>

<p>[EDIT]</p>

<p>I am asking because I would have done the first approach but looking at PROCEDURE [dbo].[aspnet_Membership_FindUsersByName], that was included with ASP.NET Membership, they are doing Approach 2</p>

<p>[EDIT2]</p>

<p>With people without access to the Stored procedure:</p>

<pre><code>  -- Insert into our temp table
INSERT INTO #PageIndexForUsers (UserId)
    SELECT u.UserId
    FROM   dbo.aspnet_Users u, dbo.aspnet_Membership m
    WHERE  u.ApplicationId = @ApplicationId AND m.UserId = u.UserId AND u.LoweredUserName LIKE LOWER(@UserNameToMatch)
    ORDER BY u.UserName


SELECT  u.UserName, m.Email, m.PasswordQuestion, m.Comment, m.IsApproved,
        m.CreateDate,
        m.LastLoginDate,
        u.LastActivityDate,
        m.LastPasswordChangedDate,
        u.UserId, m.IsLockedOut,
        m.LastLockoutDate
FROM   dbo.aspnet_Membership m, dbo.aspnet_Users u, #PageIndexForUsers p
WHERE  u.UserId = p.UserId AND u.UserId = m.UserId AND
       p.IndexId &gt;= @PageLowerBound AND p.IndexId &lt;= @PageUpperBound
ORDER BY u.UserName
</code></pre>
","<p>Think about it this way. Suppose your query would return enough records to populate 1000 pages. How many users do you think would really look at all those pages? By returning only the ids, you aren't returning a lot of information you may or may not need to see. So it should save on network and server resources. And if they really do go through a lot of pages, it would take enough time that the data details might indeed need to be refreshed.</p>
"
1209,542760,1,2,sql,I have StartDate and EndDate for each record. Should I give NULL a special meaning when used in these 2 fields?,"<p>So, I have a table where StartDate and EndDate's are used to determine the activeness of a record. I thought of using NULLs to relieve the maintainers from having to manufacture some crazy dates for some of the records. For example, if NULL had defined as positive infinite when used in EndDate, the data maintainers wouldn't need to come up with something like 1-1-2100 for long-lived records. </p>

<p>I can speculate some of the trade offs on my own: defining NULL as infinities means cleaner data and elimination of periodic maintenance work, but it also means longer queries and stored procedures. So I was wondering how you guys in the real world weigh in on this. </p>

<p>EDIT: the opinions are about half-half. If I had clarified that the StartDate and EndDate are used solely for the purpose of determining the activeness of a record in the where clause, and never appears in the select list, would that tilt the scale? One subject I need to read on is probably indexing. Thanks'all. </p>
","<p>I'd definitely use null in this case.  The stored procedures and queries aren't that much of a big deal.</p>

<p>If you have a value in there like '2100-01-01', then just looking at it, I would assume that it is a valid value.  If I see NULL, I consider it to have special meaning (besides lack of value, although sometimes, that's all it is, and that's fine).</p>
"
1208,542760,2,2,sql,I have StartDate and EndDate for each record. Should I give NULL a special meaning when used in these 2 fields?,"<p>So, I have a table where StartDate and EndDate's are used to determine the activeness of a record. I thought of using NULLs to relieve the maintainers from having to manufacture some crazy dates for some of the records. For example, if NULL had defined as positive infinite when used in EndDate, the data maintainers wouldn't need to come up with something like 1-1-2100 for long-lived records. </p>

<p>I can speculate some of the trade offs on my own: defining NULL as infinities means cleaner data and elimination of periodic maintenance work, but it also means longer queries and stored procedures. So I was wondering how you guys in the real world weigh in on this. </p>

<p>EDIT: the opinions are about half-half. If I had clarified that the StartDate and EndDate are used solely for the purpose of determining the activeness of a record in the where clause, and never appears in the select list, would that tilt the scale? One subject I need to read on is probably indexing. Thanks'all. </p>
","<p>I've used NULL for this purpose before with no problems, but I haven't developed any large-scale applications.</p>
"
186,83050,0,2,sql,Trip time calculation in relational databases?,"<p>I had this question in mind and since I just discovered this site I decided to post it here.</p>

<p>Let's say I have a table with a timestamp and a state for a given ""object"" (generic meaning, not OOP object); is there an optimal way to calculate the time between a state and the next occurrence of another (or same) state (what I call a ""trip"") with a single SQL statement (inner SELECTs and UNIONs aren't counted)?</p>

<p>Ex: For the following, the trip time between Initial and Done would be 6 days, but between Initial and Review it would be 2 days.  </p>

<blockquote>
  <p>2008-08-01 13:30:00 - Initial<br />
  2008-08-02 13:30:00 - Work<br />
  2008-08-03 13:30:00 - Review<br />
  2008-08-04 13:30:00 - Work<br />
  2008-08-05 13:30:00 - Review<br />
  2008-08-06 13:30:00 - Accepted<br />
  2008-08-07 13:30:00 - Done</p>
</blockquote>

<p>No need to be generic, just say what <a href=""http://stackoverflow.com/questions/980813/what-is-sgbd"">SGBD</a> your solution is specific to if not generic.</p>
","<p>It is probably easier if you have a sequence number as well as the time-stamp: in most RDBMSs you can create an auto-increment column and not change any of the <code>INSERT</code> statements. Then you join the table with a copy of itself to get the deltas</p>

<pre><code>select after.moment - before.moment, before.state, after.state
from object_states before, object_states after
where after.sequence + 1 = before.sequence
</code></pre>

<p>(where the details of SQL syntax will vary according to which database system).</p>
"
187,83050,0,2,sql,Trip time calculation in relational databases?,"<p>I had this question in mind and since I just discovered this site I decided to post it here.</p>

<p>Let's say I have a table with a timestamp and a state for a given ""object"" (generic meaning, not OOP object); is there an optimal way to calculate the time between a state and the next occurrence of another (or same) state (what I call a ""trip"") with a single SQL statement (inner SELECTs and UNIONs aren't counted)?</p>

<p>Ex: For the following, the trip time between Initial and Done would be 6 days, but between Initial and Review it would be 2 days.  </p>

<blockquote>
  <p>2008-08-01 13:30:00 - Initial<br />
  2008-08-02 13:30:00 - Work<br />
  2008-08-03 13:30:00 - Review<br />
  2008-08-04 13:30:00 - Work<br />
  2008-08-05 13:30:00 - Review<br />
  2008-08-06 13:30:00 - Accepted<br />
  2008-08-07 13:30:00 - Done</p>
</blockquote>

<p>No need to be generic, just say what <a href=""http://stackoverflow.com/questions/980813/what-is-sgbd"">SGBD</a> your solution is specific to if not generic.</p>
","<pre><code>    -- Oracle SQl

    CREATE TABLE ObjectState
    (
        startdate date NOT NULL,
        state varchar2(10) NOT NULL
    );



   insert into ObjectState 
   select to_date('01-Aug-2008 13:30:00','dd-Mon-rrrr hh24:mi:ss'),'Initial' union all
   select to_date('02-Aug-2008 13:30:00','dd-Mon-rrrr hh24:mi:ss'),'Work' union all
   select to_date('03-Aug-2008 13:30:00','dd-Mon-rrrr hh24:mi:ss'),'Review' union all
   select to_date('04-Aug-2008 13:30:00','dd-Mon-rrrr hh24:mi:ss'),'Work' union all
   select to_date('05-Aug-2008 13:30:00','dd-Mon-rrrr hh24:mi:ss'),'Review' union all
   select to_date('06-Aug-2008 13:30:00','dd-Mon-rrrr hh24:mi:ss'),'Accepted' union all
   select to_date('07-Aug-2008 13:30:00','dd-Mon-rrrr hh24:mi:ss'),'Done';

-- Days in between two states

  select  o2.startdate - o1.startdate as days
  from ObjectState o1, ObjectState o2
  where o1.state = 'Initial'
  and o2.state = 'Review';
</code></pre>
"
278,125570,3,2,sql,SQL Job Status,"<p>I am actually working on SP in SQL 2005. Using SP i am creating a job and am scheduling it for a particular time. These jobs take atleast 5 to 10 min to complete as the database is very huge. But I am not aware of how to check the status of the Job. I want to know if it has got completed successfully or was there any error in execution. On exception i also return proper error code. But i am not aware of where i can check for this error code.</p>
","<p>This is what I could find, maybe it solves your problem:</p>

<ol>
<li>SP to get the current job activiity.</li>
</ol>

<blockquote>
<pre><code> exec msdb.dbo.sp_help_jobactivity  @job_id = (your job_id here)
</code></pre>
</blockquote>

<p>You can execute this SP and place the result in a temp table and get the required result from there.</p>

<p>Otherwise have a look at these tables:</p>

<ul>
<li><p>msdb.dbo.sysjobactivity</p></li>
<li><p>msdb.dbo.sysjobhistory</p></li>
</ul>

<p>Run the following to see the association between these tables. </p>

<blockquote>
  <p>exec sp_helptext sp_help_jobactivity</p>
</blockquote>
"
188,83050,0,2,sql,Trip time calculation in relational databases?,"<p>I had this question in mind and since I just discovered this site I decided to post it here.</p>

<p>Let's say I have a table with a timestamp and a state for a given ""object"" (generic meaning, not OOP object); is there an optimal way to calculate the time between a state and the next occurrence of another (or same) state (what I call a ""trip"") with a single SQL statement (inner SELECTs and UNIONs aren't counted)?</p>

<p>Ex: For the following, the trip time between Initial and Done would be 6 days, but between Initial and Review it would be 2 days.  </p>

<blockquote>
  <p>2008-08-01 13:30:00 - Initial<br />
  2008-08-02 13:30:00 - Work<br />
  2008-08-03 13:30:00 - Review<br />
  2008-08-04 13:30:00 - Work<br />
  2008-08-05 13:30:00 - Review<br />
  2008-08-06 13:30:00 - Accepted<br />
  2008-08-07 13:30:00 - Done</p>
</blockquote>

<p>No need to be generic, just say what <a href=""http://stackoverflow.com/questions/980813/what-is-sgbd"">SGBD</a> your solution is specific to if not generic.</p>
","<p>I think that your steps (each record of your trip can be seen as a step) can be somewhere grouped together as part of the same activity. It is then possible to group your data on it, as, for example:</p>

<pre><code>SELECT Min(Tbl_Step.dateTimeStep) as tripBegin, _   
       Max(Tbl_Step.dateTimeStep) as tripEnd _
FROM 
       Tbl_Step 
WHERE 
       id_Activity = 'AAAAAAA'
</code></pre>

<p>Using this principle, you can then calculate other aggregates like the number of steps in the activity and so on. But you will not find an SQL way to calculate values like gap between 2 steps, as such a data does not belong either to the first or to the second step. Some reporting tools use what they call ""running sums"" to calculate such intermediate data. Depending on your objectives, this might be a solution for you.</p>
"
189,83050,1,2,sql,Trip time calculation in relational databases?,"<p>I had this question in mind and since I just discovered this site I decided to post it here.</p>

<p>Let's say I have a table with a timestamp and a state for a given ""object"" (generic meaning, not OOP object); is there an optimal way to calculate the time between a state and the next occurrence of another (or same) state (what I call a ""trip"") with a single SQL statement (inner SELECTs and UNIONs aren't counted)?</p>

<p>Ex: For the following, the trip time between Initial and Done would be 6 days, but between Initial and Review it would be 2 days.  </p>

<blockquote>
  <p>2008-08-01 13:30:00 - Initial<br />
  2008-08-02 13:30:00 - Work<br />
  2008-08-03 13:30:00 - Review<br />
  2008-08-04 13:30:00 - Work<br />
  2008-08-05 13:30:00 - Review<br />
  2008-08-06 13:30:00 - Accepted<br />
  2008-08-07 13:30:00 - Done</p>
</blockquote>

<p>No need to be generic, just say what <a href=""http://stackoverflow.com/questions/980813/what-is-sgbd"">SGBD</a> your solution is specific to if not generic.</p>
","<p>Here's an Oracle methodology using an analytic function.</p>

<pre><code>with data as (
SELECT 1 trip_id, to_date('20080801 13:30:00','YYYYMMDD HH24:mi:ss') dt, 'Initial'  step from dual UNION ALL
SELECT 1 trip_id, to_date('20080802 13:30:00','YYYYMMDD HH24:mi:ss') dt, 'Work'     step from dual  UNION ALL
SELECT 1 trip_id, to_date('20080803 13:30:00','YYYYMMDD HH24:mi:ss') dt, 'Review'   step from dual  UNION ALL
SELECT 1 trip_id, to_date('20080804 13:30:00','YYYYMMDD HH24:mi:ss') dt, 'Work'     step from dual UNION ALL
SELECT 1 trip_id, to_date('20080805 13:30:00','YYYYMMDD HH24:mi:ss') dt, 'Review'   step from dual  UNION ALL
SELECT 1 trip_id, to_date('20080806 13:30:00','YYYYMMDD HH24:mi:ss') dt, 'Accepted' step from dual  UNION ALL
SELECT 1 trip_id, to_date('20080807 13:30:00','YYYYMMDD HH24:mi:ss') dt, 'Done'     step from dual )
select trip_id,
       step,
       dt - lag(dt) over (partition by trip_id order by dt) trip_time
from  data
/


1   Initial	
1   Work	    1
1   Review	    1
1   Work	    1
1   Review	    1
1   Accepted    1
1   Done	    1
</code></pre>

<p>These are very commonly used in situations where traditionally we might use a self-join.</p>
"
190,83050,1,2,sql,Trip time calculation in relational databases?,"<p>I had this question in mind and since I just discovered this site I decided to post it here.</p>

<p>Let's say I have a table with a timestamp and a state for a given ""object"" (generic meaning, not OOP object); is there an optimal way to calculate the time between a state and the next occurrence of another (or same) state (what I call a ""trip"") with a single SQL statement (inner SELECTs and UNIONs aren't counted)?</p>

<p>Ex: For the following, the trip time between Initial and Done would be 6 days, but between Initial and Review it would be 2 days.  </p>

<blockquote>
  <p>2008-08-01 13:30:00 - Initial<br />
  2008-08-02 13:30:00 - Work<br />
  2008-08-03 13:30:00 - Review<br />
  2008-08-04 13:30:00 - Work<br />
  2008-08-05 13:30:00 - Review<br />
  2008-08-06 13:30:00 - Accepted<br />
  2008-08-07 13:30:00 - Done</p>
</blockquote>

<p>No need to be generic, just say what <a href=""http://stackoverflow.com/questions/980813/what-is-sgbd"">SGBD</a> your solution is specific to if not generic.</p>
","<p>PostgreSQL syntax :</p>

<pre><code>DROP TABLE ObjectState;
CREATE TABLE ObjectState (
    object_id integer not null,--foreign key
    event_time timestamp NOT NULL,
    state varchar(10) NOT NULL,
    --Other fields 
    CONSTRAINT pk_ObjectState PRIMARY KEY (object_id,event_time)
);
</code></pre>

<p><strong>For given state find first folowing state of given type</strong></p>

<pre><code>select parent.object_id,parent.event_time,parent.state,min(child.event_time) as ch_event_time,min(child.event_time)-parent.event_time as step_time
from 
    ObjectState parent
    join ObjectState child on (parent.object_id=child.object_id and parent.event_time&lt;child.event_time)
where 
    --Starting state 
    parent.object_id=1 and parent.event_time=to_timestamp('01-Aug-2008 13:30:00','dd-Mon-yyyy hh24:mi:ss')
    --needed state
    and child.state='Review'
group by parent.object_id,parent.event_time,parent.state;
</code></pre>

<p>This query is not the shortest posible but it should be easy to understand and used as part of other queries :</p>

<p><strong>List events and their duration for given object</strong></p>

<pre><code>select parent.object_id,parent.event_time,parent.state,min(child.event_time) as ch_event_time,
       CASE WHEN parent.state&lt;&gt;'Done' and min(child.event_time) is null THEN (select localtimestamp)-parent.event_time ELSE min(child.event_time)-parent.event_time END  as step_time
from 
    ObjectState parent
    left outer join ObjectState child on (parent.object_id=child.object_id and parent.event_time&lt;child.event_time)
where parent.object_id=4    
group by parent.object_id,parent.event_time,parent.state
order by parent.object_id,parent.event_time,parent.state;
</code></pre>

<p><strong>List current states for objects that are not ""done""</strong></p>

<pre><code>select states.object_id,states.event_time,states.state,(select localtimestamp)-states.event_time as step_time
from
    (select parent.object_id,parent.event_time,parent.state,min(child.event_time) as ch_event_time,min(child.event_time)-parent.event_time as step_time
     from 
        ObjectState parent
        left outer join ObjectState child on (parent.object_id=child.object_id and parent.event_time&lt;child.event_time)       
     group by parent.object_id,parent.event_time,parent.state) states
where     
    states.object_id not in (select object_id from ObjectState where state='Done')
    and ch_event_time is null;
</code></pre>

<p>Test data</p>

<pre><code>insert into ObjectState (object_id,event_time,state)
select 1,to_timestamp('01-Aug-2008 13:30:00','dd-Mon-yyyy hh24:mi:ss'),'Initial' union    all
select 1,to_timestamp('02-Aug-2008 13:40:00','dd-Mon-yyyy hh24:mi:ss'),'Work' union all
select 1,to_timestamp('03-Aug-2008 13:50:00','dd-Mon-yyyy hh24:mi:ss'),'Review' union all
select 1,to_timestamp('04-Aug-2008 14:30:00','dd-Mon-yyyy hh24:mi:ss'),'Work' union all
select 1,to_timestamp('04-Aug-2008 16:20:00','dd-Mon-yyyy hh24:mi:ss'),'Review' union all
select 1,to_timestamp('06-Aug-2008 18:00:00','dd-Mon-yyyy hh24:mi:ss'),'Accepted' union all
select 1,to_timestamp('07-Aug-2008 21:30:00','dd-Mon-yyyy hh24:mi:ss'),'Done';


insert into ObjectState (object_id,event_time,state)
select 2,to_timestamp('01-Aug-2008 13:30:00','dd-Mon-yyyy hh24:mi:ss'),'Initial' union all
select 2,to_timestamp('02-Aug-2008 13:40:00','dd-Mon-yyyy hh24:mi:ss'),'Work' union all
select 2,to_timestamp('07-Aug-2008 13:50:00','dd-Mon-yyyy hh24:mi:ss'),'Review' union all
select 2,to_timestamp('14-Aug-2008 14:30:00','dd-Mon-yyyy hh24:mi:ss'),'Work' union all
select 2,to_timestamp('15-Aug-2008 16:20:00','dd-Mon-yyyy hh24:mi:ss'),'Review' union all
select 2,to_timestamp('16-Aug-2008 18:02:00','dd-Mon-yyyy hh24:mi:ss'),'Accepted' union all
select 2,to_timestamp('17-Aug-2008 22:10:00','dd-Mon-yyyy hh24:mi:ss'),'Done';

insert into ObjectState (object_id,event_time,state)
select 3,to_timestamp('12-Sep-2008 13:30:00','dd-Mon-yyyy hh24:mi:ss'),'Initial' union    all
select 3,to_timestamp('13-Sep-2008 13:40:00','dd-Mon-yyyy hh24:mi:ss'),'Work' union all
select 3,to_timestamp('14-Sep-2008 13:50:00','dd-Mon-yyyy hh24:mi:ss'),'Review' union   all
select 3,to_timestamp('15-Sep-2008 14:30:00','dd-Mon-yyyy hh24:mi:ss'),'Work' union all
select 3,to_timestamp('16-Sep-2008 16:20:00','dd-Mon-yyyy hh24:mi:ss'),'Review';


insert into ObjectState (object_id,event_time,state)
select 4,to_timestamp('21-Aug-2008 03:10:00','dd-Mon-yyyy hh24:mi:ss'),'Initial' union all
select 4,to_timestamp('22-Aug-2008 03:40:00','dd-Mon-yyyy hh24:mi:ss'),'Work' union all
select 4,to_timestamp('23-Aug-2008 03:20:00','dd-Mon-yyyy hh24:mi:ss'),'Review' union all
select 4,to_timestamp('24-Aug-2008 04:30:00','dd-Mon-yyyy hh24:mi:ss'),'Work';
</code></pre>
"
191,83050,0,2,sql,Trip time calculation in relational databases?,"<p>I had this question in mind and since I just discovered this site I decided to post it here.</p>

<p>Let's say I have a table with a timestamp and a state for a given ""object"" (generic meaning, not OOP object); is there an optimal way to calculate the time between a state and the next occurrence of another (or same) state (what I call a ""trip"") with a single SQL statement (inner SELECTs and UNIONs aren't counted)?</p>

<p>Ex: For the following, the trip time between Initial and Done would be 6 days, but between Initial and Review it would be 2 days.  </p>

<blockquote>
  <p>2008-08-01 13:30:00 - Initial<br />
  2008-08-02 13:30:00 - Work<br />
  2008-08-03 13:30:00 - Review<br />
  2008-08-04 13:30:00 - Work<br />
  2008-08-05 13:30:00 - Review<br />
  2008-08-06 13:30:00 - Accepted<br />
  2008-08-07 13:30:00 - Done</p>
</blockquote>

<p>No need to be generic, just say what <a href=""http://stackoverflow.com/questions/980813/what-is-sgbd"">SGBD</a> your solution is specific to if not generic.</p>
","<p>I tried to do this in MySQL. You would need to use a variable since there is no rank function in MySQL, so it would go like this:</p>

<pre><code>set @trip1 = 0; set @trip2 = 0;
SELECT trip1.`date` as startdate, datediff(trip2.`date`, trip1.`date`) length_of_trip
FROM
(SELECT @trip1 := @trip1 + 1 as rank1, `date` from trip where state='Initial') as trip1
INNER JOIN
(SELECT @trip2 := @trip2 + 1 as rank2, `date` from trip where state='Done') as trip2
ON rank1 = rank2;
</code></pre>

<p>I am assuming that you want to calculate the time between 'Initial' and 'Done' states.</p>

<pre><code>+---------------------+----------------+
| startdate           | length_of_trip |
+---------------------+----------------+
| 2008-08-01 13:30:00 |              6 |
+---------------------+----------------+
</code></pre>
"
762,349460,2,2,sql,SQL statement problem,"<p>I have this code:</p>

<pre><code>SELECT    idcallhistory3, callid, starttime, answertime, endtime, duration,
          is_answ, is_fail, is_compl, is_fromoutside, mediatype, from_no,
          to_no, callerid, dialednumber, lastcallerid, lastdialednumber,
          group_no, line_no
FROM      ""public"".callhistory3
WHERE     (starttime &gt;= ?) AND (endtime &lt;= ?) AND (is_fromoutside = ?) 
          AND (from_no = ?) AND (to_no = ?)
</code></pre>

<p>The problem is I need to pass one value for ? and get all the result without filter, some thing like *</p>

<p>Any help?</p>
","<p>For complex queries with multiple optional sections, you may find that it is better to create the SQL to suit. You can do this either at the caller (for example, in C#), or in the database (at least, with SQL Server) - but either way, you <em>must</em> ensure it remains parameterised. With the caller doing the work, it is just a case of adding suitable parameters to the command. If the db is generating the TSQL, then the approach depends on the RDBMS. With SQL-Server, <code>sp_ExecuteSql</code> is your friend - i.e. you might build a <code>@cmd</code> variable based on the query, then:</p>

<pre><code>EXEC sp_ExecuteSQL @cmd, N'@someArg int', @actualArg
</code></pre>

<p>Where <code>@someArg</code> is the declaration inside <code>@cmd</code>, and <code>@actualArg</code> is the value to pass in at execution time.</p>
"
761,349460,1,2,sql,SQL statement problem,"<p>I have this code:</p>

<pre><code>SELECT    idcallhistory3, callid, starttime, answertime, endtime, duration,
          is_answ, is_fail, is_compl, is_fromoutside, mediatype, from_no,
          to_no, callerid, dialednumber, lastcallerid, lastdialednumber,
          group_no, line_no
FROM      ""public"".callhistory3
WHERE     (starttime &gt;= ?) AND (endtime &lt;= ?) AND (is_fromoutside = ?) 
          AND (from_no = ?) AND (to_no = ?)
</code></pre>

<p>The problem is I need to pass one value for ? and get all the result without filter, some thing like *</p>

<p>Any help?</p>
","<p>Add the ""Where"" statement conditionally -- only if you need to filter the results</p>
"
760,349460,7,2,sql,SQL statement problem,"<p>I have this code:</p>

<pre><code>SELECT    idcallhistory3, callid, starttime, answertime, endtime, duration,
          is_answ, is_fail, is_compl, is_fromoutside, mediatype, from_no,
          to_no, callerid, dialednumber, lastcallerid, lastdialednumber,
          group_no, line_no
FROM      ""public"".callhistory3
WHERE     (starttime &gt;= ?) AND (endtime &lt;= ?) AND (is_fromoutside = ?) 
          AND (from_no = ?) AND (to_no = ?)
</code></pre>

<p>The problem is I need to pass one value for ? and get all the result without filter, some thing like *</p>

<p>Any help?</p>
","<pre><code>WHERE 
  (@start is null OR starttime &gt;= @start) AND 
  (@end is null OR endtime &lt;= @end) AND 
  (@fromOutside is null OR is_fromoutside = @fromOutside) AND 
  (@fromNo is null OR from_no = @fromNo) AND 
  (@toNo is null OR to_no = @toNo)
</code></pre>

<p>Pass nulls for all parameters (dang sql nulls; thanks GC).</p>
"
759,349460,1,2,sql,SQL statement problem,"<p>I have this code:</p>

<pre><code>SELECT    idcallhistory3, callid, starttime, answertime, endtime, duration,
          is_answ, is_fail, is_compl, is_fromoutside, mediatype, from_no,
          to_no, callerid, dialednumber, lastcallerid, lastdialednumber,
          group_no, line_no
FROM      ""public"".callhistory3
WHERE     (starttime &gt;= ?) AND (endtime &lt;= ?) AND (is_fromoutside = ?) 
          AND (from_no = ?) AND (to_no = ?)
</code></pre>

<p>The problem is I need to pass one value for ? and get all the result without filter, some thing like *</p>

<p>Any help?</p>
","<p>The typical way of doing this is something like:</p>

<pre><code>WHERE (? IS NULL OR starttime &gt;= ?)
</code></pre>

<p>and then pass in DBNull.Value. Obviously you need to do this for each parameter you want to be able to ""wildcard"" like this.</p>
"
686,304430,5,2,sql,SQL DataReader missing a row in loop,"<p>When running the following code it leaves out one row. When I do a files.Count it says there are 4 rows but there is no data stored for the 4th row. When I run the stored procedure from within SQL Manager it returns all 4 rows and all the data. Any help?</p>

<pre><code>            List&lt;File&gt; files = new List&lt;File&gt;();
            SqlConnection active_connection = new SqlConnection(m_connection_string);
            SqlCommand cmd = new SqlCommand();
            SqlDataReader dr = null;

            try
            {
                active_connection.Open();
                cmd.Connection = active_connection;
                cmd.CommandType = CommandType.StoredProcedure;
                cmd.CommandText = ""dalsp_Select_Organization_Files"";

                SqlParameter param;

                param = cmd.Parameters.Add(""@p_organization_guid"", SqlDbType.UniqueIdentifier);
                param.Value = new Guid(organization_guid);

                param = cmd.Parameters.Add(""@p_file_type"", SqlDbType.NVarChar, 50);
                param.Value = file_type;

                dr = cmd.ExecuteReader(CommandBehavior.CloseConnection);

                if (dr.HasRows)                    
                {                    
                    while (dr.Read())
                    {
                        File file = new File();
                        file.OrganizationGuid = dr[""OrganizationGuid""].ToString();
                        file.FileGuid = dr[""FileGuid""].ToString();
                        file.FileLocation = dr[""FileLocation""].ToString();
                        file.FileName = dr[""FileName""].ToString();
                        file.FileType = (FileTypeEnum)Enum.Parse(typeof(FileTypeEnum), dr[""FileType""].ToString());
                        file.FileExtension = dr[""FileExtension""].ToString();
                        file.FileDescription = dr[""FileDescription""].ToString();
                        file.ThumbnailPath = dr[""ThumbnailPath""].ToString();
                        files.Add(file);
                    }       
                }
                dr.Close();
                dr = null;

                active_connection.Close();
                cmd = null;

            }
            catch (Exception)
            {
                throw;
            }
            finally
            {
                if (active_connection.State != ConnectionState.Closed)
                {
                    active_connection.Close();
                    active_connection.Dispose();
                }
            }

            return files;
</code></pre>
","<p>If you are saying your files collection has 4 items, but the 4 item contains no value, what do you mean by that? Is it null, does the object have no data, or does it throw an index out of range exception?</p>

<p>Are you doing a files[4] or something like the following?</p>

<pre><code>for(int x = 1; x &lt; files.length; x++)
{
     files[x]
}
</code></pre>

<p>That won't work. Remember 0 based indexing in C#.</p>

<p>As a side note, you could do away with your try catch statments by doing something like:</p>

<pre><code>using (SqlConnection connection = new SqlConnection(conn_string))
{
    connection.Open();
    using (SqlCommand cmd = new SqlCommand(""SELECT * FROM MyTable"", connection))
    {
         using (SqlDataReader dr = cmd.ExecuteReader())
         {
             return result;
         }
    }
}
</code></pre>

<p>The using statement will guarantee disposal (and therefore the closing) of the reader and connection.</p>
"
687,304430,1,2,sql,SQL DataReader missing a row in loop,"<p>When running the following code it leaves out one row. When I do a files.Count it says there are 4 rows but there is no data stored for the 4th row. When I run the stored procedure from within SQL Manager it returns all 4 rows and all the data. Any help?</p>

<pre><code>            List&lt;File&gt; files = new List&lt;File&gt;();
            SqlConnection active_connection = new SqlConnection(m_connection_string);
            SqlCommand cmd = new SqlCommand();
            SqlDataReader dr = null;

            try
            {
                active_connection.Open();
                cmd.Connection = active_connection;
                cmd.CommandType = CommandType.StoredProcedure;
                cmd.CommandText = ""dalsp_Select_Organization_Files"";

                SqlParameter param;

                param = cmd.Parameters.Add(""@p_organization_guid"", SqlDbType.UniqueIdentifier);
                param.Value = new Guid(organization_guid);

                param = cmd.Parameters.Add(""@p_file_type"", SqlDbType.NVarChar, 50);
                param.Value = file_type;

                dr = cmd.ExecuteReader(CommandBehavior.CloseConnection);

                if (dr.HasRows)                    
                {                    
                    while (dr.Read())
                    {
                        File file = new File();
                        file.OrganizationGuid = dr[""OrganizationGuid""].ToString();
                        file.FileGuid = dr[""FileGuid""].ToString();
                        file.FileLocation = dr[""FileLocation""].ToString();
                        file.FileName = dr[""FileName""].ToString();
                        file.FileType = (FileTypeEnum)Enum.Parse(typeof(FileTypeEnum), dr[""FileType""].ToString());
                        file.FileExtension = dr[""FileExtension""].ToString();
                        file.FileDescription = dr[""FileDescription""].ToString();
                        file.ThumbnailPath = dr[""ThumbnailPath""].ToString();
                        files.Add(file);
                    }       
                }
                dr.Close();
                dr = null;

                active_connection.Close();
                cmd = null;

            }
            catch (Exception)
            {
                throw;
            }
            finally
            {
                if (active_connection.State != ConnectionState.Closed)
                {
                    active_connection.Close();
                    active_connection.Dispose();
                }
            }

            return files;
</code></pre>
","<p>The code looks correct to me. I think you'd definitely want to step through a debugger to see how many rows are returned from ExecuteReader. One comment I have is that the ""if (dr.HasRows)"" is kinda redundant since the ""while (dr.Read())"" will give you the same effect.</p>

<p>Another question I would have is do you know if you are missing the first or last record?</p>

<p>Brian</p>
"
688,304430,2,2,sql,SQL DataReader missing a row in loop,"<p>When running the following code it leaves out one row. When I do a files.Count it says there are 4 rows but there is no data stored for the 4th row. When I run the stored procedure from within SQL Manager it returns all 4 rows and all the data. Any help?</p>

<pre><code>            List&lt;File&gt; files = new List&lt;File&gt;();
            SqlConnection active_connection = new SqlConnection(m_connection_string);
            SqlCommand cmd = new SqlCommand();
            SqlDataReader dr = null;

            try
            {
                active_connection.Open();
                cmd.Connection = active_connection;
                cmd.CommandType = CommandType.StoredProcedure;
                cmd.CommandText = ""dalsp_Select_Organization_Files"";

                SqlParameter param;

                param = cmd.Parameters.Add(""@p_organization_guid"", SqlDbType.UniqueIdentifier);
                param.Value = new Guid(organization_guid);

                param = cmd.Parameters.Add(""@p_file_type"", SqlDbType.NVarChar, 50);
                param.Value = file_type;

                dr = cmd.ExecuteReader(CommandBehavior.CloseConnection);

                if (dr.HasRows)                    
                {                    
                    while (dr.Read())
                    {
                        File file = new File();
                        file.OrganizationGuid = dr[""OrganizationGuid""].ToString();
                        file.FileGuid = dr[""FileGuid""].ToString();
                        file.FileLocation = dr[""FileLocation""].ToString();
                        file.FileName = dr[""FileName""].ToString();
                        file.FileType = (FileTypeEnum)Enum.Parse(typeof(FileTypeEnum), dr[""FileType""].ToString());
                        file.FileExtension = dr[""FileExtension""].ToString();
                        file.FileDescription = dr[""FileDescription""].ToString();
                        file.ThumbnailPath = dr[""ThumbnailPath""].ToString();
                        files.Add(file);
                    }       
                }
                dr.Close();
                dr = null;

                active_connection.Close();
                cmd = null;

            }
            catch (Exception)
            {
                throw;
            }
            finally
            {
                if (active_connection.State != ConnectionState.Closed)
                {
                    active_connection.Close();
                    active_connection.Dispose();
                }
            }

            return files;
</code></pre>
","<p>You should ditch ""if (dr.HasRows)"", all it does is duplicate the check in the while loop.</p>

<p>You shouldn't ever be calling Close on a connection, nor should you set it to null. Instead you should wrap the connection in a ""using"" block like so:</p>

<pre><code>using (SqlCommand cmd = new SqlCommand()) {
   //use the connection
}
</code></pre>

<p>The same can be said for you data reader and SQL Command.</p>

<p>This next bit does nothing at all, delete it.</p>

<pre><code>  catch (Exception) { throw; }
</code></pre>
"
690,305780,3,2,sql,Avg on datetime in Access,"<p>I am porting some queries from Access to T-SQL and those who wrote the queries used the Avg aggregate function on datetime columns.  This is not supported in T-SQL and I can understand why - it doesn't make sense.  What is getting averaged?</p>

<p>So I was about to start reverse engineering what Access does when it aggregates datetime using Avg, but thought I would throw the question out here first.</p>
","<p>I'd imagine that Access is averaging the numeric representation of the dates.  You could do similar in T-SQL with the following...</p>

<pre><code>select AverageDate = cast(avg(cast(MyDateColumn as decimal(20, 10))) as datetime)
from    MyTable
</code></pre>
"
691,305780,1,2,sql,Avg on datetime in Access,"<p>I am porting some queries from Access to T-SQL and those who wrote the queries used the Avg aggregate function on datetime columns.  This is not supported in T-SQL and I can understand why - it doesn't make sense.  What is getting averaged?</p>

<p>So I was about to start reverse engineering what Access does when it aggregates datetime using Avg, but thought I would throw the question out here first.</p>
","<p>I'm more familiar with non-MS DBMS, but... Since you cannot add two DATETIME values, you cannot ordinarily average them.  However, you could do something similar to:</p>

<pre><code>SELECT AVG(datetime_column - TIMESTAMP '2000-01-01 00:00:00.000000') +
              TIMESTAMP '2000-01-01 00:00:00.000000'
    FROM table_containing_datetime_column;
</code></pre>

<p>This calculates the average interval between the start of 2000 and the actual datetime values, and then adds that interval to the start of 2000.  The choice of 'start of 2000' is arbitrary; as long as the datetime subtracted in the AVG() function is added back, you get a sensible answer.</p>

<p>This does assume that the DBMS used supports SQL standard 'timestamp' notation, and supports the INTERVAL types appropriately.  The difference between two DATETIME or TIMESTAMP values should be an INTERVAL (indeed, INTERVAL DAY(9) TO SECOND(6), to be moderately accurate, though the '9' is somewhat debatable).</p>

<p>When appropriately mangled for the DBMS I work with, the expression 'works':</p>

<pre><code>CREATE TEMP TABLE table_containing_datetime_column
(
    datetime_column DATETIME YEAR TO FRACTION(5) NOT NULL
);

INSERT INTO table_containing_datetime_column VALUES('2008-11-19 12:12:12.00000');
INSERT INTO table_containing_datetime_column VALUES('2008-11-19 22:22:22.00000');

SELECT AVG(datetime_column - DATETIME(2000-01-01 00:00:00.00000) YEAR TO FRACTION(5)) +
    DATETIME(2000-01-01 00:00:00.00000) YEAR TO FRACTION(5)
FROM table_containing_datetime_column;
</code></pre>

<p>Answer:</p>

<pre><code>2008-11-19 17:17:17.00000
</code></pre>
"
1107,505780,1,2,sql,How to get the next record in SQL table,"<p>I have a set of records in my MS SQL table. With Date as the primary key. But the Dates are only for working days and not the continues days. Eg:</p>

<p>1/3/2000 12:00:00 AM    5209.540000000	5384.660000000	5209.540000000	5375.110000000
1/4/2000 12:00:00 AM    5533.980000000	5533.980000000	5376.430000000	5491.010000000
1/5/2000 12:00:00 AM    5265.090000000	5464.350000000	5184.480000000	5357.000000000
1/6/2000 12:00:00 AM    5424.210000000	5489.860000000	5391.330000000	5421.530000000
1/7/2000 12:00:00 AM    5358.280000000	5463.250000000	5330.580000000	5414.480000000
1/10/2000 12:00:00 AM   5617.590000000	5668.280000000	5459.970000000	5518.390000000
1/11/2000 12:00:00 AM   5513.040000000	5537.690000000	5221.280000000	5296.300000000
1/12/2000 12:00:00 AM   5267.850000000	5494.300000000	5267.850000000	5491.200000000</p>

<p>In this i am trying to introduce a new column to the table and the value to it should be the value of the 3rd cloumn minus the value of 3rd column of the previous working day. Please help me in writing such a query. I am finding it difficult as the dates are not present for the week ends.</p>
","<p>Use a self-join and a case statement that takes advantage of SQLServers's built-in date function <code>datepart(dw,@Date)</code> .</p>

<p>I do feel duty-bound to note that making such a transformation in the first place is probably a bad idea.</p>
"
1106,505780,2,2,sql,How to get the next record in SQL table,"<p>I have a set of records in my MS SQL table. With Date as the primary key. But the Dates are only for working days and not the continues days. Eg:</p>

<p>1/3/2000 12:00:00 AM    5209.540000000	5384.660000000	5209.540000000	5375.110000000
1/4/2000 12:00:00 AM    5533.980000000	5533.980000000	5376.430000000	5491.010000000
1/5/2000 12:00:00 AM    5265.090000000	5464.350000000	5184.480000000	5357.000000000
1/6/2000 12:00:00 AM    5424.210000000	5489.860000000	5391.330000000	5421.530000000
1/7/2000 12:00:00 AM    5358.280000000	5463.250000000	5330.580000000	5414.480000000
1/10/2000 12:00:00 AM   5617.590000000	5668.280000000	5459.970000000	5518.390000000
1/11/2000 12:00:00 AM   5513.040000000	5537.690000000	5221.280000000	5296.300000000
1/12/2000 12:00:00 AM   5267.850000000	5494.300000000	5267.850000000	5491.200000000</p>

<p>In this i am trying to introduce a new column to the table and the value to it should be the value of the 3rd cloumn minus the value of 3rd column of the previous working day. Please help me in writing such a query. I am finding it difficult as the dates are not present for the week ends.</p>
","<p>There are a few ways of doing this.  Here is one.</p>

<pre><code>CREATE TABLE MyTable
(
    MyDate datetime NOT NULL PRIMARY KEY,
    Col2 decimal(14,4) NOT NULL,
    Col3 decimal(14,4) NOT NULL,
    Col4 decimal(14,4) NOT NULL,
    Col5 decimal(14,4) NOT NULL
)
GO

INSERT INTO MyTable
SELECT '1/3/2000 12:00:00 AM', 5209.540000000, 5384.660000000, 5209.540000000, 5375.110000000 
 UNION ALL 
SELECT '1/4/2000 12:00:00 AM', 5533.980000000, 5533.980000000, 5376.430000000, 5491.010000000
 UNION ALL 
SELECT '1/5/2000 12:00:00 AM', 5265.090000000, 5464.350000000, 5184.480000000, 5357.000000000
 UNION ALL 
SELECT '1/6/2000 12:00:00 AM', 5424.210000000, 5489.860000000, 5391.330000000, 5421.530000000 
 UNION ALL 
SELECT '1/7/2000 12:00:00 AM', 5358.280000000, 5463.250000000, 5330.580000000, 5414.480000000 
 UNION ALL 
SELECT '1/10/2000 12:00:00 AM', 5617.590000000, 5668.280000000, 5459.970000000, 5518.390000000 
 UNION ALL 
SELECT '1/11/2000 12:00:00 AM', 5513.040000000, 5537.690000000, 5221.280000000, 5296.300000000 
 UNION ALL 
SELECT '1/12/2000 12:00:00 AM', 5267.850000000, 5494.300000000, 5267.850000000, 5491.200000000
GO

CREATE VIEW MyView 
AS
SELECT T1.*,
    CalculatedColumn = Col3 - 
      (SELECT Col3 FROM MyTable Q2
       WHERE Q2.MyDate = (SELECT MAX(Q1.MyDate) 
                          FROM MyTable Q1 
                          WHERE Q1.MyDate &lt; T1.MyDate)
    )
FROM MyTable T1
GO

SELECT * FROM MyView
GO
</code></pre>

<p><strong>Results</strong></p>

<pre><code>MyDate                  Col2      Col3      Col4      Col5      CalculatedColumn
----------------------- --------- --------- --------- --------- ----------------
2000-01-03 00:00:00.000 5209.5400 5384.6600 5209.5400 5375.1100 NULL
2000-01-04 00:00:00.000 5533.9800 5533.9800 5376.4300 5491.0100 149.3200
2000-01-05 00:00:00.000 5265.0900 5464.3500 5184.4800 5357.0000 -69.6300
2000-01-06 00:00:00.000 5424.2100 5489.8600 5391.3300 5421.5300 25.5100
2000-01-07 00:00:00.000 5358.2800 5463.2500 5330.5800 5414.4800 -26.6100
2000-01-10 00:00:00.000 5617.5900 5668.2800 5459.9700 5518.3900 205.0300
2000-01-11 00:00:00.000 5513.0400 5537.6900 5221.2800 5296.3000 -130.5900
2000-01-12 00:00:00.000 5267.8500 5494.3000 5267.8500 5491.2000 -43.3900
</code></pre>
"
1105,505780,1,2,sql,How to get the next record in SQL table,"<p>I have a set of records in my MS SQL table. With Date as the primary key. But the Dates are only for working days and not the continues days. Eg:</p>

<p>1/3/2000 12:00:00 AM    5209.540000000	5384.660000000	5209.540000000	5375.110000000
1/4/2000 12:00:00 AM    5533.980000000	5533.980000000	5376.430000000	5491.010000000
1/5/2000 12:00:00 AM    5265.090000000	5464.350000000	5184.480000000	5357.000000000
1/6/2000 12:00:00 AM    5424.210000000	5489.860000000	5391.330000000	5421.530000000
1/7/2000 12:00:00 AM    5358.280000000	5463.250000000	5330.580000000	5414.480000000
1/10/2000 12:00:00 AM   5617.590000000	5668.280000000	5459.970000000	5518.390000000
1/11/2000 12:00:00 AM   5513.040000000	5537.690000000	5221.280000000	5296.300000000
1/12/2000 12:00:00 AM   5267.850000000	5494.300000000	5267.850000000	5491.200000000</p>

<p>In this i am trying to introduce a new column to the table and the value to it should be the value of the 3rd cloumn minus the value of 3rd column of the previous working day. Please help me in writing such a query. I am finding it difficult as the dates are not present for the week ends.</p>
","<p>You need to break this down into 2 parts. First is updating your existing data, and second is ensuring all new data has the correct value added.</p>

<p>For the first part, consider using a CURSOR. It will probably take a while to run, but at least you only run it once. Use a CURSOR like a FOR loop; iterate through each row in your data, ignoring the first row (since you haven't specified how to calculate the value for the new column when there is no previous date). Most likely you should sort by date ascending, just in case. </p>

<p>As you iterate through, use variables to store the values from this row. As you loop, copy those variables into previous row versions before you get the new row. For example, you have a variable called 'Col3' and another one called 'lastCol3'. Before you loop to the next row (ie the cursor moves to the next row) you copy the value of col3 into lastCol3 and then you get the new value for col3. Now you have your current and previous value on a per row basis, and can call 'update' to update the new column.</p>

<p>For new data going forward, you need to ensure the new value is provided, or if you want SQL Server to do it, use a stored procedure which selects the most recent row, col3, and uses the value to calculate the new value before inserting into the table.</p>
"
184,83050,0,2,sql,Trip time calculation in relational databases?,"<p>I had this question in mind and since I just discovered this site I decided to post it here.</p>

<p>Let's say I have a table with a timestamp and a state for a given ""object"" (generic meaning, not OOP object); is there an optimal way to calculate the time between a state and the next occurrence of another (or same) state (what I call a ""trip"") with a single SQL statement (inner SELECTs and UNIONs aren't counted)?</p>

<p>Ex: For the following, the trip time between Initial and Done would be 6 days, but between Initial and Review it would be 2 days.  </p>

<blockquote>
  <p>2008-08-01 13:30:00 - Initial<br />
  2008-08-02 13:30:00 - Work<br />
  2008-08-03 13:30:00 - Review<br />
  2008-08-04 13:30:00 - Work<br />
  2008-08-05 13:30:00 - Review<br />
  2008-08-06 13:30:00 - Accepted<br />
  2008-08-07 13:30:00 - Done</p>
</blockquote>

<p>No need to be generic, just say what <a href=""http://stackoverflow.com/questions/980813/what-is-sgbd"">SGBD</a> your solution is specific to if not generic.</p>
","<p>I'm not sure I understand the question exactly, but you can do something like the following which reads the table in one pass then uses a derived table to calculate it. SQL Server code:</p>

<pre><code>CREATE TABLE #testing
(
    eventdatetime datetime NOT NULL,
    state varchar(10) NOT NULL
)

INSERT INTO #testing (
    eventdatetime,
    state
) 
SELECT '20080801 13:30:00', 'Initial' UNION ALL
SELECT '20080802 13:30:00', 'Work' UNION ALL
SELECT '20080803 13:30:00', 'Review' UNION ALL
SELECT '20080804 13:30:00', 'Work' UNION ALL
SELECT '20080805 13:30:00', 'Review' UNION ALL
SELECT '20080806 13:30:00', 'Accepted' UNION ALL
SELECT '20080807 13:30:00', 'Done'

SELECT DATEDIFF(dd, Initial, Review)
FROM (
SELECT  MIN(CASE WHEN state='Initial' THEN eventdatetime END) AS Initial,
    	MIN(CASE WHEN state='Review' THEN eventdatetime END) AS Review
FROM #testing
) AS A

DROP TABLE #testing
</code></pre>
"
185,83050,0,2,sql,Trip time calculation in relational databases?,"<p>I had this question in mind and since I just discovered this site I decided to post it here.</p>

<p>Let's say I have a table with a timestamp and a state for a given ""object"" (generic meaning, not OOP object); is there an optimal way to calculate the time between a state and the next occurrence of another (or same) state (what I call a ""trip"") with a single SQL statement (inner SELECTs and UNIONs aren't counted)?</p>

<p>Ex: For the following, the trip time between Initial and Done would be 6 days, but between Initial and Review it would be 2 days.  </p>

<blockquote>
  <p>2008-08-01 13:30:00 - Initial<br />
  2008-08-02 13:30:00 - Work<br />
  2008-08-03 13:30:00 - Review<br />
  2008-08-04 13:30:00 - Work<br />
  2008-08-05 13:30:00 - Review<br />
  2008-08-06 13:30:00 - Accepted<br />
  2008-08-07 13:30:00 - Done</p>
</blockquote>

<p>No need to be generic, just say what <a href=""http://stackoverflow.com/questions/980813/what-is-sgbd"">SGBD</a> your solution is specific to if not generic.</p>
","<pre><code>create table A (
    At datetime not null,
    State varchar(20) not null
)
go
insert into A(At,State)
select '2008-08-01T13:30:00','Initial' union all
select '2008-08-02T13:30:00','Work' union all
select '2008-08-03T13:30:00','Review' union all
select '2008-08-04T13:30:00','Work' union all
select '2008-08-05T13:30:00','Review' union all
select '2008-08-06T13:30:00','Accepted' union all
select '2008-08-07T13:30:00','Done'
go
--Find trip time from Initial to Done
select DATEDIFF(day,t1.At,t2.At)
from
    A t1
    	inner join
    A t2
    	on
    		t1.State = 'Initial' and
    		t2.State = 'Review' and
    		t1.At &lt; t2.At
    	left join
    A t3
    	on
    		t3.State = 'Initial' and
    		t3.At &gt; t1.At and
    		t4.At &lt; t2.At
    	left join
    A t4
    	on
    		t4.State = 'Review' and
    		t4.At &lt; t2.At and
    		t4.At &gt; t1.At
where
    t3.At is null and
    t4.At is null
</code></pre>

<p>Didn't say whether joins were allowed or not. Joins to t3 and t4 (and their comparisons) let you say whether you want the earliest or latest occurrence of the start and end states (in this case, I'm asking for latest ""Initial"" and earliest ""Review"")</p>

<p>In real code, my start and end states would be parameters</p>

<p>Edit: Oops, need to include ""t3.At &lt; t2.At"" and ""t4.At > t1.At"", to fix some odd sequences of States (e.g. If we removed the second ""Review"" and then queried from ""Work"" to ""Review"", the original query will fail)</p>
"
723,328850,1,2,sql,Synchronizing databases,"<p>I am developing an Adobe AIR application which stores data locally using a SQLite database.
At any time, I want the end user to synchronize his/her local data to a central MySQL database.</p>

<p>Any tips, advice for getting this right?
Performance and stability is the key (besides security ;))</p>
","<p>I can think of a couple of ways:</p>

<ol>
<li><p>Periodically, Dump your MySQL database and create a new SQLite database from the dump. You can then serve the SQLite database (SQLite databases are contained in a single file) for your users client to download and replace the current database.</p></li>
<li><p>Create a diff script that generates the necessary statements to bring the current database up to speed (various INSERT, UPDATE and DELETE statements). To do this, you must record the time of each change continuously in your database (the time of creation and update for each row, and keep a history of deleted rows).
User's client will download the diff file (a text file of the various statements) and apply it on the local database.</p></li>
</ol>

<p>Both approaches have their own pros and cons - by dumping the entire database, you make sure all the data gets through. It is also much easier than creating the diff, however it might put more load on the server, depending on how often does the database gets updated between dumps. </p>

<p>On the other hand, diffing between the database will give you just the data that changed (hopefully), but it is more open to logical errors. It will incur an additional overhead on the client as well, since it will have to create/update all the necessary records instead of just copying a file.</p>
"
724,328850,1,2,sql,Synchronizing databases,"<p>I am developing an Adobe AIR application which stores data locally using a SQLite database.
At any time, I want the end user to synchronize his/her local data to a central MySQL database.</p>

<p>Any tips, advice for getting this right?
Performance and stability is the key (besides security ;))</p>
","<p>If you're just sync'ing from the server to client, Eran's solution should work.</p>

<p>If you're just sync'ing from the client to the server, just reverse it.</p>

<p>If you're sync'ing both ways, have fun. You'll at minimum probably want to keep change logs, and you'll need to figure out how to deal with conflicts.</p>
"
725,333750,0,2,sql,Fetching only rows that match all entries in a joined table (SQL),"<p>I have the following five tables:</p>

<ul>
<li>ISP</li>
<li>Product</li>
<li>Connection</li>
<li>AddOn</li>
<li>AddOn/Product (pivot table for many-to-many relationship).</li>
</ul>

<p>Each Product is linked to an ISP, each Connection is listed to a Product. Each product can have a number of add-ons, through the use of the pivot table (which simply has 2 fields, one for the product ID and one for the AddOn ID).</p>

<p>The result I am interested in is each connection with the addons listed (I am making use of MySQL's GROUP_CONCAT for this, to make a comma-separated list of the addon's <em>name</em> field). This works fine as is, the query looks something like this:</p>

<pre><code>SELECT i.name AS ispname, i.img_link, c.download, c.upload, c.monthly_price, c.link, 
GROUP_CONCAT(a.name) AS addons, SUM(pa.monthly_fee) AS addon_price
FROM isp i JOIN product p ON i.id = p.isp_id
JOIN `connection` c ON p.id = c.product_id LEFT JOIN product_addon pa ON pa.product_id = p.id AND pa.forced = 0
LEFT JOIN addon a ON pa.addon_id = a.id GROUP BY c.id
</code></pre>

<p>I am using LEFT JOINS as it is possible for products to have no addons at all.</p>

<p>My problem is that it is possible to select some addons that listed connections MUST have, presented as a list of addon IDs, like (1,14,237). If I put it in as an additional condition in the JOIN statements (*AND pa.addon_id IN (...)*), it will return all connections that have just one of the listed addons, but not necessarily all of them.</p>

<p>Is there some way to return all connections that as a <strong>minimum</strong> have all the addons (they can have additional as well) via SQL?</p>
","<p>You could add to the WHERE clause:</p>

<pre><code>AND NOT EXISTS (SELECT NULL FROM addon a2
                WHERE  a2.addon_id IN (1,14,237)
                AND NOT EXISTS
                ( SELECT NULL
                  FROM   product_addon pa2
                  WHERE  pa2.addon_id = a2.addon_id
                  AND    pa2.product_id = p.product_id
                )
               )
</code></pre>

<p>Or equivalently:</p>

<pre><code>AND NOT EXISTS (SELECT NULL FROM addon a2
                LEFT JOIN product_addon pa2
                  ON pa2.addon_id = a2.addon_id
                 AND pa2.product_id = p.product_id
                WHERE a2.addon_id IN (1,14,237)
                AND   pa2.product_id IS NULL
                )
               )
</code></pre>
"
726,333750,2,2,sql,Fetching only rows that match all entries in a joined table (SQL),"<p>I have the following five tables:</p>

<ul>
<li>ISP</li>
<li>Product</li>
<li>Connection</li>
<li>AddOn</li>
<li>AddOn/Product (pivot table for many-to-many relationship).</li>
</ul>

<p>Each Product is linked to an ISP, each Connection is listed to a Product. Each product can have a number of add-ons, through the use of the pivot table (which simply has 2 fields, one for the product ID and one for the AddOn ID).</p>

<p>The result I am interested in is each connection with the addons listed (I am making use of MySQL's GROUP_CONCAT for this, to make a comma-separated list of the addon's <em>name</em> field). This works fine as is, the query looks something like this:</p>

<pre><code>SELECT i.name AS ispname, i.img_link, c.download, c.upload, c.monthly_price, c.link, 
GROUP_CONCAT(a.name) AS addons, SUM(pa.monthly_fee) AS addon_price
FROM isp i JOIN product p ON i.id = p.isp_id
JOIN `connection` c ON p.id = c.product_id LEFT JOIN product_addon pa ON pa.product_id = p.id AND pa.forced = 0
LEFT JOIN addon a ON pa.addon_id = a.id GROUP BY c.id
</code></pre>

<p>I am using LEFT JOINS as it is possible for products to have no addons at all.</p>

<p>My problem is that it is possible to select some addons that listed connections MUST have, presented as a list of addon IDs, like (1,14,237). If I put it in as an additional condition in the JOIN statements (*AND pa.addon_id IN (...)*), it will return all connections that have just one of the listed addons, but not necessarily all of them.</p>

<p>Is there some way to return all connections that as a <strong>minimum</strong> have all the addons (they can have additional as well) via SQL?</p>
","<pre><code>GROUP BY set-of-column
HAVING SUM(CASE WHEN ISNULL(pa.addon_id, 0) IN (1,14,237) THEN 1 ELSE 0 END) = 3
</code></pre>
"
736,343220,2,2,sql,How to remove html tags from database text field,"<p>How do I remove html elements in a text field from SQL Server?</p>
","<p>I assume you mean removing html tags from a field stored in a database. If so, and if you can code the solution in .NET, I would have used the <a href=""http://www.codeplex.com/htmlagilitypack"" rel=""nofollow"">HTML agility pack</a> to traverse the html contents, and save the InnerText (i think that's the property name) of the elements in which you are interested to a variable. Then replace the contents of the field with the contents of the variable.</p>
"
737,343220,1,2,sql,How to remove html tags from database text field,"<p>How do I remove html elements in a text field from SQL Server?</p>
","<p>You could use a CLR Procedure (SQL Server 2005 and above) to decode the HTML , stripping out the tags. </p>

<p>This looks like an example of what you want to achieve.</p>

<p><a href=""http://www.sqlclr.net/Examples/tabid/55/articleType/ArticleView/articleId/31/Default.aspx"" rel=""nofollow"">SQL Server CLR Procedure</a></p>
"
356,151190,2,2,sql,pl/sql dollar operator?,"<p>I encountered the following ddl in a pl/sql script this morning:</p>

<p>create index genuser.idx$$_0bdd0011
...</p>

<p>My initial thought was that the index name was generated by a tool...but I'm also not a pl/sql superstar so I could very well be incorrect. Does the double dollar sign have any special significance in this statement? </p>
","<p>Regardless of where he name came from, it's contrary to Oracle's documented advice: <a href=""http://download.oracle.com/docs/cd/B19306_01/server.102/b14200/sql_elements008.htm#SQLRF00223"" rel=""nofollow"">http://download.oracle.com/docs/cd/B19306_01/server.102/b14200/sql_elements008.htm#SQLRF00223</a></p>

<blockquote>
  <p>Oracle strongly discourages you from using $ and # in nonquoted identifiers</p>
</blockquote>
"
355,151190,2,2,sql,pl/sql dollar operator?,"<p>I encountered the following ddl in a pl/sql script this morning:</p>

<p>create index genuser.idx$$_0bdd0011
...</p>

<p>My initial thought was that the index name was generated by a tool...but I'm also not a pl/sql superstar so I could very well be incorrect. Does the double dollar sign have any special significance in this statement? </p>
","<p>Your initial thought seems to be correct.  That would look to be an index name generated by a tool (but not assigned by Oracle because an index name wasn't specified).  Dollar signs don't have any particular meaning other than being valid symbols that are rarely used by human developers and so are handy to reduce the risk that a system-generated name conflicts with a human-generated name.</p>
"
409,186160,5,2,sql,How do I add to a list with Linq to SQL?,"<p>I have a table in the database that I'm retrieving using LINQ to SQL, and as a part of my processing I want to add to this list, then update the database with the new items + any changes I've made.</p>

<p>What I thought I could do was this:</p>

<pre><code>var list = (from item in db.Table
            select item).ToList();

[do processing where I modify items &amp; add to the list]

list = list.Distinct();

db.SubmitChanges();
</code></pre>

<p>What happens is that the modifications happed (ie. SQL updates) but any new items I add to the list don't get added.</p>

<p>Obviously I'm doing this wrong, what is the correct way to modify &amp; add to a list of DB entities, then commit all the updates &amp; inserts?</p>
","<p>The List is meaningless.  It's just happens to hold objects that the DataContext knows about.  We need to make sure that the DataContext knows about the new ones.  The important thing is that they don't have to be complete when we alert the DataContext to them:</p>

<pre><code>Item item;
if (needNewOne)
{
     item = new Item();
     db.InsertOnSubmit(item);
}
else
{
     item = list[i];
}
///  build new or modify existing item
///   :
db.SubmitChanges();
</code></pre>
"
1182,529870,1,1,sql,SQL Images -> byte arrays,"<p>So I am importing some images stored in SQL image columns, and I need to change them to Byte arrays since I store my images as varbinary(max) and recreate them. I would LOVE it if there was a program to do this, or a really easy way since I don't have a ton of time. </p>

<p>Any ideas out there?</p>
","<p>Have you looked into writing a quick script in PowerShell? It has access to the full .NET framework, so should be somewhat simple if you're using those technologies.</p>

<p>Of course it's not simple if you have to learn PowerShell in order to write the script, but learning's always good :)</p>
"
988,451060,2,1,sql,SQL nvl equivalent - without if/case statements & isnull & coalesce,"<p>Are there any nvl() equivalent functions in SQL?</p>

<p>Or something close enough to be used in the same way in certain scenarios?</p>

<p><hr>
UPDATE:
<br>no if statements<br>no case statements<br>no isnull<br>no coalesce<hr><br></p>

<pre><code>select nvl (purge_date,""SODIUFOSDIUFSDOIFUDSF"") from id_rec where id=36581;


(expression)

SODIUFOSDIUFSDOIFUDSF

1 row(s) retrieved.

select isnull (purge_date,""SODIUFOSDIUFSDOIFUDSF"") from id_rec where id=36581;

  674: Routine (isnull) can not be resolved.
Error in line 1
Near character position 8

select coalesce (purge_date,""SODIUFOSDIUFSDOIFUDSF"") from id_rec where id=36581;

  674: Routine (coalesce) can not be resolved.
Error in line 1
Near character position 8

select decode(purge_date, NULL, ""01/01/2009"", purge_date) from id_rec where id=74115;

  800: Corresponding types must be compatible in CASE expression.
Error in line 1
Near character position 57
</code></pre>
","<p>You seem to be using Informix.</p>

<p>AFAIK, there is DECODE there:</p>

<p><code>DECODE(field, NULL, 'it is null, man', field)</code> should give you same result as <code>NVL(field, 'it is null, man')</code></p>

<p>Please post exact name and version of the RDBMS you are using.</p>
"
993,452230,0,1,sql,Trying to build an SQL statement for complex search scenario,"<p>I am trying to build an SQL Statement for the following search scenario:</p>

<p>I have trying to return all of the columns for an individual record for Table A based on the value of the status column in Table B.  Each record in table A can have multiple rows in table B, making it a one to many relationship.  The status column is nullable with a data type of integer.</p>

<p>Here are the possible values for status in table B:</p>

<ul>
<li>NULL = Pending,</li>
<li>1 = Approved,</li>
<li>2 = Denied,</li>
<li>6 = Forced Approval,</li>
<li>7 = Forced Denial</li>
</ul>

<p>The end user can search on the following scenarios:</p>

<ul>
<li>Approved - All table B records must have a value of 1 or 6 for status.</li>
<li>Denied - One table B record must have a value of 2 or 5.  Any other records can have 1,6, or null.</li>
<li>Pending - All table B records can have a value of 1,6 or null.  One record must be null because it is not considered completed.</li>
</ul>

<p><b>UPDATE</b><br />
I consulted with one of our DBAs and he developed the following solution:</p>

<p>Approved:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status in (1,6) and b.status IS NOT NULL) AND
b.id NOT IN (SELECT id from TableB  WHERE status IS NULL)
AND b.id NOT IN (SELECT id from TableB WHERE status in (2,7))
</code></pre>

<p>Denied:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status in (2,7))
</code></pre>

<p>Pending:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status IN (1,6) OR b.status IS NULL)
AND b.id NOT IN (SELECT b.id FROM TableA a INNER JOIN TableB b ON b.id = a.id WHERE (b.status IN (1,6) AND b.status IS NOT NULL) AND b.id NOT IN (SELECT id from TableB WHERE status IS NULL))
AND b.id NOT IN (SELECT id FROM TableB WHERE status IN (2,7))
</code></pre>

<p><b>UPDATE 2:</b><br />
@Micth Wheat - How would I refactor the following solution using the EXIST/NOT EXIST t-sql keyword?</p>
","<p>Perhaps something like this</p>

<pre><code>select CASE WHEN SUM(CASE WHEN ISNULL(b.status, 0) IN (1,6) THEN 1 ELSE 0 END) = COUNT(*) THEN 'Approved'
    		WHEN SUM(CASE WHEN ISNULL(b.status, 0) IN (2,5) THEN 1 ELSE 0 END) &gt; 0 THEN 'Denied'
    		WHEN SUM(CASE WHEN ISNULL(b.status, 0) IN (1,0,6) THEN 1 ELSE 0 END) = COUNT(*)
    			AND SUM(CASE WHEN b.status IS NULL THEN 1 else 0 END) &gt; 0  THEN 'Pending'
    		ELSE '???' END as Status, &lt;a column list&gt;
FROM A 
INNER JOIN b ON a.id = b.id
group by &lt;a column list&gt;
</code></pre>
"
992,452230,2,1,sql,Trying to build an SQL statement for complex search scenario,"<p>I am trying to build an SQL Statement for the following search scenario:</p>

<p>I have trying to return all of the columns for an individual record for Table A based on the value of the status column in Table B.  Each record in table A can have multiple rows in table B, making it a one to many relationship.  The status column is nullable with a data type of integer.</p>

<p>Here are the possible values for status in table B:</p>

<ul>
<li>NULL = Pending,</li>
<li>1 = Approved,</li>
<li>2 = Denied,</li>
<li>6 = Forced Approval,</li>
<li>7 = Forced Denial</li>
</ul>

<p>The end user can search on the following scenarios:</p>

<ul>
<li>Approved - All table B records must have a value of 1 or 6 for status.</li>
<li>Denied - One table B record must have a value of 2 or 5.  Any other records can have 1,6, or null.</li>
<li>Pending - All table B records can have a value of 1,6 or null.  One record must be null because it is not considered completed.</li>
</ul>

<p><b>UPDATE</b><br />
I consulted with one of our DBAs and he developed the following solution:</p>

<p>Approved:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status in (1,6) and b.status IS NOT NULL) AND
b.id NOT IN (SELECT id from TableB  WHERE status IS NULL)
AND b.id NOT IN (SELECT id from TableB WHERE status in (2,7))
</code></pre>

<p>Denied:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status in (2,7))
</code></pre>

<p>Pending:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status IN (1,6) OR b.status IS NULL)
AND b.id NOT IN (SELECT b.id FROM TableA a INNER JOIN TableB b ON b.id = a.id WHERE (b.status IN (1,6) AND b.status IS NOT NULL) AND b.id NOT IN (SELECT id from TableB WHERE status IS NULL))
AND b.id NOT IN (SELECT id FROM TableB WHERE status IN (2,7))
</code></pre>

<p><b>UPDATE 2:</b><br />
@Micth Wheat - How would I refactor the following solution using the EXIST/NOT EXIST t-sql keyword?</p>
","<p>As an example for 'Approved':</p>

<pre><code>select 
    * 
from 
    A 
where
    (select count(*) from B where B.parent_id = A.id and B.status in (1,6)) &gt; 0
and (select count(*) from B where B.parent_id = A.id and B.status not in (1,6)) = 0
</code></pre>

<p>Refactored to use <em>exists</em> and <em>not exists</em>:</p>

<pre><code>select 
    * 
from 
    A 
where
    exists (select * from B where B.parent_id = A.id and B.status in (1,6)) 
and not exists (select * from B where B.parent_id = A.id and B.status not in (1,6))
</code></pre>

<p>If you have passed in a criteria, you can package it all up in one query like this, if it is more convenient:</p>

<pre><code>select 
    * 
from 
    A 
where     
    (@Criteria = 'Approved'
and (select count(*) from B where B.parent_id = A.id and B.status in (1,6)) &gt; 0
and (select count(*) from B where B.parent_id = A.id and B.status not in (1,6)) = 0
    )
or  (@Criteria = 'Denied'
and (select count(*) from B where B.parent_id = A.id and B.status in (2,7)) &gt; 0
    )
or  (@Criteria = 'Pending'
and (select count(*) from B where B.parent_id = A.id and B.status not in (2,7)) = 0
and (select count(*) from B where B.parent_id = A.id and B.status is null) &gt; 0
    )
</code></pre>

<p>Note, I changed the Denied example to be values of 2 and 7, rather than 2 and 5, based on your sample data.</p>

<p>Edit: You could also use <em>exists</em> and <em>not exists</em>, as Joe suggests.</p>

<p>Edit: The method using max(case ...), often also seen as sum(case ...) for counting values, does perform better in some cases (depends mostly on your volume of data whether the performance increase is noticeable - sometimes it can be a big difference).  I personally find the subqueries more readable, so I start with them, and if better performance is needed, I would benchmark both methods, and if max(case ...) works better, I would switch.</p>
"
1196,534530,0,1,sql,Multiple Parameter Search in SQL Server 2000,"<p>I have a search screen in a Visual Basic .Net App that has text boxes for:</p>

<ol>
<li>First Name Varchar(50)</li>
<li>Last Name  Varchar(50)</li>
<li>Middle Name Varchar(50)</li>
<li>DOB DateTime</li>
<li>Home Phone Varchar(10)</li>
<li>Work Phone Varchar(10)</li>
</ol>

<p>How would I create a stored procedure in SQL Server 2000 that would allow me to be able to search on all/some/one of the fields. If user only enters data on say first name and home phone number what would I need to do for the rest of the parameters where data was not entered. I tried the select statement below but it doesn't work properly.</p>

<pre><code>    Select Last_Name, First_Name, Mid_Name, DOB, Home_Phone, Work_Phone from dbo.tblClient
Where Last_Name Like '%@LastName' and
    First_Name Like '%@FirstName' and
    Mid_Name Like '%@MiddleName' and
    DOB Like '%DOB' and
    Home_Phone Like '%@HomePhone' and
    Work_Phone Like '%@WorkPhone'
</code></pre>
","<p>Just to clarify why your original SQL doesn't work;</p>

<p>You need to concatenate the % wildcard to the parameter value, but what you have written is creating a literal string that contains the wildcard and the name of the parameter e.g.</p>

<p><code>Work_Phone Like '%@WorkPhone'</code></p>

<p>should be written as</p>

<p><code>Work_Phone Like '%' + @WorkPhone</code></p>

<p>The SQL you have should work if you are returning an empty string for parameters that don't have a value entered (i.e. you are returning """", and not NULL) - the Like comparison for those fields will then only contain the % wildcard (i.e. match any value). However, this is not very efficient as ideally you only want to do a comparison on the fields that the user has entered a value. This would probably require some dynamically generated SQL , as shown in the article linked to by kenj. </p>

<p>If your tblClient table is not that large though, then what you have done might be sufficient.</p>
"
1197,534530,0,1,sql,Multiple Parameter Search in SQL Server 2000,"<p>I have a search screen in a Visual Basic .Net App that has text boxes for:</p>

<ol>
<li>First Name Varchar(50)</li>
<li>Last Name  Varchar(50)</li>
<li>Middle Name Varchar(50)</li>
<li>DOB DateTime</li>
<li>Home Phone Varchar(10)</li>
<li>Work Phone Varchar(10)</li>
</ol>

<p>How would I create a stored procedure in SQL Server 2000 that would allow me to be able to search on all/some/one of the fields. If user only enters data on say first name and home phone number what would I need to do for the rest of the parameters where data was not entered. I tried the select statement below but it doesn't work properly.</p>

<pre><code>    Select Last_Name, First_Name, Mid_Name, DOB, Home_Phone, Work_Phone from dbo.tblClient
Where Last_Name Like '%@LastName' and
    First_Name Like '%@FirstName' and
    Mid_Name Like '%@MiddleName' and
    DOB Like '%DOB' and
    Home_Phone Like '%@HomePhone' and
    Work_Phone Like '%@WorkPhone'
</code></pre>
","<p>How about using ISNULL() function to determine if a value has been passed into the stored procedure and if not, setting the WHERE clause field value to search for equal to itself in each case (<em>if someone can think of a better choice of words for describing this, I will update the answer</em>). </p>

<pre><code> SELECT 
     Last_Name, 
     First_Name, 
     Mid_Name, 
     DOB, 
     Home_Phone, 
     Work_Phone 
 FROM 
     dbo.tblClient
 WHERE 
    Last_Name LIKE '%' + ISNULL(@LastName, Last_Name) AND
    First_Name LIKE '%' + ISNULL(@FirstName, First_Name) AND
    Mid_Name LIKE '%' ISNULL(@MiddleName, Mid_Name) AND
    DOB LIKE '%' + ISNULL(@DOB, DOB) AND
    Home_Phone LIKE '%' + ISNULL(@HomePhone, Home_Phone) AND
    Work_Phone LIKE '%' + ISNULL(@WorkPhone, Work_Phone)
</code></pre>

<p>You could also set a NULL default value for each of your stored procedure parameters.</p>
"
1193,534530,3,1,sql,Multiple Parameter Search in SQL Server 2000,"<p>I have a search screen in a Visual Basic .Net App that has text boxes for:</p>

<ol>
<li>First Name Varchar(50)</li>
<li>Last Name  Varchar(50)</li>
<li>Middle Name Varchar(50)</li>
<li>DOB DateTime</li>
<li>Home Phone Varchar(10)</li>
<li>Work Phone Varchar(10)</li>
</ol>

<p>How would I create a stored procedure in SQL Server 2000 that would allow me to be able to search on all/some/one of the fields. If user only enters data on say first name and home phone number what would I need to do for the rest of the parameters where data was not entered. I tried the select statement below but it doesn't work properly.</p>

<pre><code>    Select Last_Name, First_Name, Mid_Name, DOB, Home_Phone, Work_Phone from dbo.tblClient
Where Last_Name Like '%@LastName' and
    First_Name Like '%@FirstName' and
    Mid_Name Like '%@MiddleName' and
    DOB Like '%DOB' and
    Home_Phone Like '%@HomePhone' and
    Work_Phone Like '%@WorkPhone'
</code></pre>
","<p>I use this pattern a lot:</p>

<p><code></p>

<pre><code>Select Last_Name, First_Name, Mid_Name, DOB, Home_Phone, Work_Phone from dbo.tblClient
Where (@LastName is null or Last_Name Like '%'+ @LastName)
and (@FirstName is null or First_Name Like '%'+ @FirstName)
and (@HomePhone is null or Home_Phone Like '%'+ @HomePhone)
-- etc...
</code></pre>

<p></code></p>

<p>It will ignore anything that's not supplied, while still giving good performance.  Better still, it doesn't resort to dynamic SQL to pull it off.</p>
"
1192,534530,0,1,sql,Multiple Parameter Search in SQL Server 2000,"<p>I have a search screen in a Visual Basic .Net App that has text boxes for:</p>

<ol>
<li>First Name Varchar(50)</li>
<li>Last Name  Varchar(50)</li>
<li>Middle Name Varchar(50)</li>
<li>DOB DateTime</li>
<li>Home Phone Varchar(10)</li>
<li>Work Phone Varchar(10)</li>
</ol>

<p>How would I create a stored procedure in SQL Server 2000 that would allow me to be able to search on all/some/one of the fields. If user only enters data on say first name and home phone number what would I need to do for the rest of the parameters where data was not entered. I tried the select statement below but it doesn't work properly.</p>

<pre><code>    Select Last_Name, First_Name, Mid_Name, DOB, Home_Phone, Work_Phone from dbo.tblClient
Where Last_Name Like '%@LastName' and
    First_Name Like '%@FirstName' and
    Mid_Name Like '%@MiddleName' and
    DOB Like '%DOB' and
    Home_Phone Like '%@HomePhone' and
    Work_Phone Like '%@WorkPhone'
</code></pre>
","<p>The quick way to do this would be something like</p>

<p>Where (Last_Name Like @LastName + '%' OR @LastName IS NULL) and
    (First_Name Like @FirstName + '%' OR @FirstName IS NULL) and
etc...</p>

<p>Erland Sommarskog has some great articles on different ways to do this and their performance implications <a href=""http://www.sommarskog.se/dyn-search.html"" rel=""nofollow"">here</a></p>
"
1201,540300,0,1,sql,Fix for 'return' in cakePHP to return Value from view controller function,"<p>I have a function inside of a view function inside of a model class in the model.php file that looks like this</p>

<pre><code>function sqlToUnix($date){
    $YMDThenHMS = explode("" "", $date);
    $YMD = explode(""-"", $YMDThenHMS[0]);
    $HMS = explode("":"", $YMDThenHMS[1]);
    $UnixTime = mktime($HMS[0], $HMS[1], $HMS[2], $YMD[1], $YMD[2], $YMD[0]);

    return $UnixTime;
}
</code></pre>

<p>The problem is, when it returns $UnixTime, The return value is usable inside the model controller specific view function but it won't render my view (stops script propogation)</p>

<p>Is there a place where I can build functions like this up for use ANYWHERE in ANY Controller?</p>

<p>Such as the function time() built into PHP itself, I want to be able to use sqlToUnix anywhere</p>
","<p>I was able to fix the problem by storing the function in the appController.php and called the function when need be using</p>

<pre><code>$this-&gt;sqlToUnix($SQLDate);
</code></pre>

<p>Sorry about asking the question but I just remembered the appController when I posted this >&lt;</p>
"
1202,540300,0,1,sql,Fix for 'return' in cakePHP to return Value from view controller function,"<p>I have a function inside of a view function inside of a model class in the model.php file that looks like this</p>

<pre><code>function sqlToUnix($date){
    $YMDThenHMS = explode("" "", $date);
    $YMD = explode(""-"", $YMDThenHMS[0]);
    $HMS = explode("":"", $YMDThenHMS[1]);
    $UnixTime = mktime($HMS[0], $HMS[1], $HMS[2], $YMD[1], $YMD[2], $YMD[0]);

    return $UnixTime;
}
</code></pre>

<p>The problem is, when it returns $UnixTime, The return value is usable inside the model controller specific view function but it won't render my view (stops script propogation)</p>

<p>Is there a place where I can build functions like this up for use ANYWHERE in ANY Controller?</p>

<p>Such as the function time() built into PHP itself, I want to be able to use sqlToUnix anywhere</p>
","<p>For your specific function, are you sure there are no builtin functions which return your UnixTime format?</p>

<blockquote>
  <p>Is there a place where I can build functions like this up for use ANYWHERE in ANY Controller?</p>
</blockquote>

<pre><code>class MyHelpers
{
    public static function sqlToUnix($SQLDate)
    {
        // code
        return $result;
    }
}

// call me this way, anywhere:
$result = MyHelpers::sqlToUnix($SQLDate);
</code></pre>
"
1188,530230,2,1,sql,Going from VisualStudio generated Database stuff to Programmer Generated,"<p>I'd like to be able to better access the database so I can execute queries (primarily because I don't understand/know the API for it, but I do know SQL). I don't want to remove everything Visual Studio has done because a lot is already built upon it, but how can I get an object that I can use to execute SQL queries.</p>

<p>This is Visual Studio 2008, C#, and MSSQL</p>
","<p>Personally, I would always use the free Ideablade DevForce:</p>

<p><a href=""http://www.ideablade.com/"" rel=""nofollow"">http://www.ideablade.com/</a></p>

<p>And use no SQL at all!</p>
"
1187,530230,2,1,sql,Going from VisualStudio generated Database stuff to Programmer Generated,"<p>I'd like to be able to better access the database so I can execute queries (primarily because I don't understand/know the API for it, but I do know SQL). I don't want to remove everything Visual Studio has done because a lot is already built upon it, but how can I get an object that I can use to execute SQL queries.</p>

<p>This is Visual Studio 2008, C#, and MSSQL</p>
","<p>You might also look into the <a href=""http://www.codersource.net/microsoft_data_access_application_block_azam.html"" rel=""nofollow"">Data Access Application Block</a> - just a DLL you install in your app, which allows you to execute SQL queries and such much more simply: </p>

<pre><code>DataSet ds = SqlHelper.ExecuteDataset(cs,CommandType.StoredProcedure,""SELECT_DATA"");
</code></pre>
"
1186,530230,1,1,sql,Going from VisualStudio generated Database stuff to Programmer Generated,"<p>I'd like to be able to better access the database so I can execute queries (primarily because I don't understand/know the API for it, but I do know SQL). I don't want to remove everything Visual Studio has done because a lot is already built upon it, but how can I get an object that I can use to execute SQL queries.</p>

<p>This is Visual Studio 2008, C#, and MSSQL</p>
","<p>Not 100% sure what you're really asking for :-), but assuming you're interested in knowing how to programatically execute a SQL query, you'll need (assuming SQL Server as the backend):</p>

<ul>
<li>a ""using System.Data;"" and ""using System.Data.SqlClient;"" using clause</li>
<li>a ""SqlConnection"" object to establish your connection to SQL Server (usually combined with a ConnectionString, stored in some form of a config file)</li>
<li>a ""SqlCommand"" object to formulate your SQL query and execute it</li>
<li>some way of dealing with possible results from that query</li>
</ul>

<p>You'll have something like:</p>

<pre><code>SqlConnection connection = new SqlConnection(-connection string-);

SqlCommand command = new SqlCommand(""...your sql query here..."", connection);

connection.Open();

command.ExecuteScalar / command.ExecuteReader / command.ExecuteNonQuery
(depending on your needs)

connection.Close();
</code></pre>

<p>plus of course, some error handling.... :-)</p>

<p>Does that help that at all??</p>
"
983,447200,2,1,sql,sql server bcp xml data,"<p>Hi
I have a table which has a column which is of type xml.
I have to extract data from this table and load the data into another environment.
i am using bcp to extract and laod the target table but there are some special characters that is causing some issues when i bcp them into the target table. are there any workarounds</p>

<p>thanks
Ben</p>
","<p>A custom CLR-SP provided me with the best solution.  Now I can write XML-typed data directly to a file from TSQL, provided the SQL service account has permission to the file.  This allows the simple syntax:</p>

<pre><code>exec dbo.clr_xml2file @xml, @path, @bool_overwrite
</code></pre>

<p>The SP:</p>

<pre><code>CREATE PROCEDURE [dbo].[clr_xml2file]
    @xml [xml],
    @file [nvarchar](max),
    @overwrite [bit]
WITH EXECUTE AS CALLER
AS
EXTERNAL NAME [CLR_FileIO].[FreddyB.FileIO].[Xml2File]
</code></pre>

<p>The C# for the CLR DLL:</p>

<pre><code>using System;
using System.Data.SqlClient;
using System.Data.SqlTypes;
using System.IO;
using System.Security.Principal;
using System.Text;
using System.Xml;
using System.Xml.XPath;
using Microsoft.SqlServer.Server;

namespace FreddyB
{  
  public class FileIO
  {
    public static void Xml2File(
	  SqlXml xml, 
	  SqlString sFile, 
	  SqlBoolean bOverwrite
	) {

      SqlPipe sqlpipe = SqlContext.Pipe;
      try
      {
        if (xml == null || xml.IsNull || xml.Value.Length == 0) {
          sqlpipe.Send(""Cannot write empty content to file : \n\t""
			+sFile.Value);
          return;
        }

        if (File.Exists(sFile.Value) &amp; bOverwrite.IsFalse) {
          sqlpipe.Send(""File already exists : \n\t""+sFile.Value);
          return;
        }

        int iFileSize = 0;
        FileStream fs = null;
        try {
          byte[] ba = Encoding.UTF8.GetBytes(xml.Value);
          iFileSize = ba.Length;

          fs = new FileStream(sFile.Value, FileMode.Create, FileAccess.Write);
          fs.Write(ba, 0, ba.Length);

          sqlpipe.Send(""Wrote ""
			+String.Format(""{0:0,0.0}"",iFileSize/1024)
			+"" KB to : \n\t""
			+sFile.Value);
        }
        catch (Exception ex) 
        {
          sqlpipe.Send(""Error as '""
		    +WindowsIdentity.GetCurrent().Name
			+""' during file write : \n\t""
			+ex.Message);
          sqlpipe.Send(""Stack trace : \n""+ex.StackTrace);
        }
        finally
        {
          if (fs != null) {
            fs.Close();
          }
        }
      }
      catch (Exception ex)
      {
        sqlpipe.Send(""Error writing to file : \n\t""
		  +ex.Message);
      }
    }
  }
}
</code></pre>
"
987,451060,5,1,sql,SQL nvl equivalent - without if/case statements & isnull & coalesce,"<p>Are there any nvl() equivalent functions in SQL?</p>

<p>Or something close enough to be used in the same way in certain scenarios?</p>

<p><hr>
UPDATE:
<br>no if statements<br>no case statements<br>no isnull<br>no coalesce<hr><br></p>

<pre><code>select nvl (purge_date,""SODIUFOSDIUFSDOIFUDSF"") from id_rec where id=36581;


(expression)

SODIUFOSDIUFSDOIFUDSF

1 row(s) retrieved.

select isnull (purge_date,""SODIUFOSDIUFSDOIFUDSF"") from id_rec where id=36581;

  674: Routine (isnull) can not be resolved.
Error in line 1
Near character position 8

select coalesce (purge_date,""SODIUFOSDIUFSDOIFUDSF"") from id_rec where id=36581;

  674: Routine (coalesce) can not be resolved.
Error in line 1
Near character position 8

select decode(purge_date, NULL, ""01/01/2009"", purge_date) from id_rec where id=74115;

  800: Corresponding types must be compatible in CASE expression.
Error in line 1
Near character position 57
</code></pre>
","<p><a href=""http://msdn.microsoft.com/en-us/library/ms184325.aspx"">ISNULL</a> (for a single replace)</p>

<p>or</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ms190349.aspx"">COALESCE</a> (Returns the first nonnull expression among its arguments.)</p>
"
1185,530230,5,1,sql,Going from VisualStudio generated Database stuff to Programmer Generated,"<p>I'd like to be able to better access the database so I can execute queries (primarily because I don't understand/know the API for it, but I do know SQL). I don't want to remove everything Visual Studio has done because a lot is already built upon it, but how can I get an object that I can use to execute SQL queries.</p>

<p>This is Visual Studio 2008, C#, and MSSQL</p>
","<p>Try something like <a href=""http://blog.biztalk-info.com/archive/2008/06/19/Execute_SQL_Query_from_within_a_C_function.aspx"" rel=""nofollow"">this</a>:</p>

<pre><code>using (SqlConnection conn = new SqlConnection(""Connection String Goes Here""))
{
    conn.Open();
    using (SqlCommand comm = new SqlCommand(""SELECT * FROM TABLE"", conn))
    {
        return command.ExecuteScalar() as string;
    }
}
</code></pre>

<p>Don't forget to add: </p>

<pre><code>using System.Data;
using System.Data.SqlClient;
</code></pre>
"
1184,530230,0,1,sql,Going from VisualStudio generated Database stuff to Programmer Generated,"<p>I'd like to be able to better access the database so I can execute queries (primarily because I don't understand/know the API for it, but I do know SQL). I don't want to remove everything Visual Studio has done because a lot is already built upon it, but how can I get an object that I can use to execute SQL queries.</p>

<p>This is Visual Studio 2008, C#, and MSSQL</p>
","<p>I'm not sure from your question what you've got going on, but if you just want to learn how to use a SqlConnection, SqlCommand, and a DataReader object to retrieve items from a database, check this out:</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/haa3afyz"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/haa3afyz</a>(VS.71).aspx</p>
"
1183,530230,1,1,sql,Going from VisualStudio generated Database stuff to Programmer Generated,"<p>I'd like to be able to better access the database so I can execute queries (primarily because I don't understand/know the API for it, but I do know SQL). I don't want to remove everything Visual Studio has done because a lot is already built upon it, but how can I get an object that I can use to execute SQL queries.</p>

<p>This is Visual Studio 2008, C#, and MSSQL</p>
","<p>Are you asking what .NET libraries you can use to execute SQL against a database? If so, start by looking at <code>SqlConnection</code> and <code>SqlCommand</code> (if you're using SQL Server, otherwise use <code>OleDbConnection</code> and <code>OleDbCommand</code>). <code>SqlCommand</code> has several Execute() methods that will do what you're looking for. </p>

<p>ADO.NET is a pretty big beast but there are tons of quickstarts and sample code out there.</p>
"
989,451060,3,1,sql,SQL nvl equivalent - without if/case statements & isnull & coalesce,"<p>Are there any nvl() equivalent functions in SQL?</p>

<p>Or something close enough to be used in the same way in certain scenarios?</p>

<p><hr>
UPDATE:
<br>no if statements<br>no case statements<br>no isnull<br>no coalesce<hr><br></p>

<pre><code>select nvl (purge_date,""SODIUFOSDIUFSDOIFUDSF"") from id_rec where id=36581;


(expression)

SODIUFOSDIUFSDOIFUDSF

1 row(s) retrieved.

select isnull (purge_date,""SODIUFOSDIUFSDOIFUDSF"") from id_rec where id=36581;

  674: Routine (isnull) can not be resolved.
Error in line 1
Near character position 8

select coalesce (purge_date,""SODIUFOSDIUFSDOIFUDSF"") from id_rec where id=36581;

  674: Routine (coalesce) can not be resolved.
Error in line 1
Near character position 8

select decode(purge_date, NULL, ""01/01/2009"", purge_date) from id_rec where id=74115;

  800: Corresponding types must be compatible in CASE expression.
Error in line 1
Near character position 57
</code></pre>
","<p>SQL Server:
IsNull or COALESCE
<a href=""http://msdn.microsoft.com/en-us/library/ms184325.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms184325.aspx</a></p>

<p>Sybase:
isnull function
<a href=""http://infocenter.sybase.com/help/index.jsp?topic=/com.sybase.help.ase_15.0.blocks/html/blocks/blocks162.htm"" rel=""nofollow"">http://infocenter.sybase.com/help/index.jsp?topic=/com.sybase.help.ase_15.0.blocks/html/blocks/blocks162.htm</a></p>

<p>Postgres:
I couldn't find one though haven't fully checked. Suggests to select where IS NULL and build from here
<a href=""http://archives.postgresql.org/pgsql-sql/1998-06/msg00142.php"" rel=""nofollow"">http://archives.postgresql.org/pgsql-sql/1998-06/msg00142.php</a></p>

<p>DB2 - COALESCE
<a href=""http://publib.boulder.ibm.com/infocenter/db2luw/v8/index.jsp?topic=/com.ibm.db2.udb.doc/admin/r0000780.htm"" rel=""nofollow"">http://publib.boulder.ibm.com/infocenter/db2luw/v8/index.jsp?topic=/com.ibm.db2.udb.doc/admin/r0000780.htm</a></p>
"
990,451060,2,1,sql,SQL nvl equivalent - without if/case statements & isnull & coalesce,"<p>Are there any nvl() equivalent functions in SQL?</p>

<p>Or something close enough to be used in the same way in certain scenarios?</p>

<p><hr>
UPDATE:
<br>no if statements<br>no case statements<br>no isnull<br>no coalesce<hr><br></p>

<pre><code>select nvl (purge_date,""SODIUFOSDIUFSDOIFUDSF"") from id_rec where id=36581;


(expression)

SODIUFOSDIUFSDOIFUDSF

1 row(s) retrieved.

select isnull (purge_date,""SODIUFOSDIUFSDOIFUDSF"") from id_rec where id=36581;

  674: Routine (isnull) can not be resolved.
Error in line 1
Near character position 8

select coalesce (purge_date,""SODIUFOSDIUFSDOIFUDSF"") from id_rec where id=36581;

  674: Routine (coalesce) can not be resolved.
Error in line 1
Near character position 8

select decode(purge_date, NULL, ""01/01/2009"", purge_date) from id_rec where id=74115;

  800: Corresponding types must be compatible in CASE expression.
Error in line 1
Near character position 57
</code></pre>
","<p>The problem with your DECODE statement that is generating the 800 error is simple. <code>'01/01/2009'</code> is being treated as a string, and it's actually the 4th argument that generates the error.</p>

<p>Appreciate that the input and output of a DECODE statement can be different data-types, so the engine requires you to be more explicit in this case. (Do you want <code>purge_date</code> cast as a string or the string <code>'01/01/2009'</code>, or the string argument parsed as a date or the original date? There's no way for the engine to know.</p>

<p>Try this:</p>

<pre><code>SELECT DECODE(purge_date, NULL, '01/01/2009'::DATE, purge_date)
</code></pre>

<p>You could also write that 3rd argument as:</p>

<pre><code>    DATE('01/01/2009')
    MDY(1,1,2009)
</code></pre>

<p>depending on version and personal preference.</p>
"
991,452230,0,1,sql,Trying to build an SQL statement for complex search scenario,"<p>I am trying to build an SQL Statement for the following search scenario:</p>

<p>I have trying to return all of the columns for an individual record for Table A based on the value of the status column in Table B.  Each record in table A can have multiple rows in table B, making it a one to many relationship.  The status column is nullable with a data type of integer.</p>

<p>Here are the possible values for status in table B:</p>

<ul>
<li>NULL = Pending,</li>
<li>1 = Approved,</li>
<li>2 = Denied,</li>
<li>6 = Forced Approval,</li>
<li>7 = Forced Denial</li>
</ul>

<p>The end user can search on the following scenarios:</p>

<ul>
<li>Approved - All table B records must have a value of 1 or 6 for status.</li>
<li>Denied - One table B record must have a value of 2 or 5.  Any other records can have 1,6, or null.</li>
<li>Pending - All table B records can have a value of 1,6 or null.  One record must be null because it is not considered completed.</li>
</ul>

<p><b>UPDATE</b><br />
I consulted with one of our DBAs and he developed the following solution:</p>

<p>Approved:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status in (1,6) and b.status IS NOT NULL) AND
b.id NOT IN (SELECT id from TableB  WHERE status IS NULL)
AND b.id NOT IN (SELECT id from TableB WHERE status in (2,7))
</code></pre>

<p>Denied:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status in (2,7))
</code></pre>

<p>Pending:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status IN (1,6) OR b.status IS NULL)
AND b.id NOT IN (SELECT b.id FROM TableA a INNER JOIN TableB b ON b.id = a.id WHERE (b.status IN (1,6) AND b.status IS NOT NULL) AND b.id NOT IN (SELECT id from TableB WHERE status IS NULL))
AND b.id NOT IN (SELECT id FROM TableB WHERE status IN (2,7))
</code></pre>

<p><b>UPDATE 2:</b><br />
@Micth Wheat - How would I refactor the following solution using the EXIST/NOT EXIST t-sql keyword?</p>
","<p>Looks like you would want to use some <strong>exists</strong> statements. </p>

<p>For the ones where all values must be something then you would add a <strong>not</strong> exists against the other possible values.</p>

<p>--Approved</p>

<pre><code>exists(select 1 from B where A.id = B.id and status in (1,6))
and not exists(select 1 from B where A.id = B.id and (status is null or status not in (1,6)))
</code></pre>
"
1181,529870,1,1,sql,SQL Images -> byte arrays,"<p>So I am importing some images stored in SQL image columns, and I need to change them to Byte arrays since I store my images as varbinary(max) and recreate them. I would LOVE it if there was a program to do this, or a really easy way since I don't have a ton of time. </p>

<p>Any ideas out there?</p>
","<p>The image data type in Sql Server is a varbinary field that is being discontinued in future versions.</p>

<p>I would bet that a tool like <a href=""http://msdn.microsoft.com/en-us/library/ms162802.aspx"" rel=""nofollow"">bcp</a> handles the ""conversion"" automatically. I use quotes because its a type conversion and not a format conversion.</p>
"
1068,489420,0,1,sql,How would you write this query?,"<p>I'm looking to refactor the below query to something more readable and modifiable.  The first half is identical to the second, with the exception of the database queried from (table names are the same though.)</p>

<pre><code>  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database1.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database1.dbo.Table2

UNION

  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database2.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database2.dbo.Table2
</code></pre>

<p>This query is the definition of DRY and is calling to me to be re-written, but I have no idea how!</p>

<p><strong>EDIT</strong>: We can't use linq and we desire distinct results; I'm looking to make the query smaller in physical file size, not in results returned.</p>

<p><strong>EDIT</strong>: The database I'm querying off is a proprietary ERP database.  Restructuring it is not an option.</p>
","<p>On the Dynamic SQL theme - here is a sample - not sure if it is any better. The benefit is you only have to write the SELECT list once. </p>

<pre><code>DECLARE @Select1 varchar(1000)
DECLARE @Select2 varchar(1000)

DECLARE @SQL varchar(4000)


SET @Select1 = 'SELECT
    Column 1 AS c1,
    ...
    Column N AS cN'


SET @Select2 = 'SELECT
    ''Some String'' as c1,
    ...
    NULL as cN'


SET @SQL = @Select1 + ' FROM database1.dbo.Table1 '

SET @SQL = @SQL + ' UNION ' + @Select2 + ' FROM database1.dbo.Table2 '

SET @SQL = @SQL + ' UNION ' + @Select1 + ' FROM database2.dbo.Table1 '

SET @SQL = @SQL + ' UNION ' + @Select2 + ' FROM database2.dbo.Table2 '


EXEC @SQL
</code></pre>
"
994,452230,1,1,sql,Trying to build an SQL statement for complex search scenario,"<p>I am trying to build an SQL Statement for the following search scenario:</p>

<p>I have trying to return all of the columns for an individual record for Table A based on the value of the status column in Table B.  Each record in table A can have multiple rows in table B, making it a one to many relationship.  The status column is nullable with a data type of integer.</p>

<p>Here are the possible values for status in table B:</p>

<ul>
<li>NULL = Pending,</li>
<li>1 = Approved,</li>
<li>2 = Denied,</li>
<li>6 = Forced Approval,</li>
<li>7 = Forced Denial</li>
</ul>

<p>The end user can search on the following scenarios:</p>

<ul>
<li>Approved - All table B records must have a value of 1 or 6 for status.</li>
<li>Denied - One table B record must have a value of 2 or 5.  Any other records can have 1,6, or null.</li>
<li>Pending - All table B records can have a value of 1,6 or null.  One record must be null because it is not considered completed.</li>
</ul>

<p><b>UPDATE</b><br />
I consulted with one of our DBAs and he developed the following solution:</p>

<p>Approved:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status in (1,6) and b.status IS NOT NULL) AND
b.id NOT IN (SELECT id from TableB  WHERE status IS NULL)
AND b.id NOT IN (SELECT id from TableB WHERE status in (2,7))
</code></pre>

<p>Denied:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status in (2,7))
</code></pre>

<p>Pending:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status IN (1,6) OR b.status IS NULL)
AND b.id NOT IN (SELECT b.id FROM TableA a INNER JOIN TableB b ON b.id = a.id WHERE (b.status IN (1,6) AND b.status IS NOT NULL) AND b.id NOT IN (SELECT id from TableB WHERE status IS NULL))
AND b.id NOT IN (SELECT id FROM TableB WHERE status IN (2,7))
</code></pre>

<p><b>UPDATE 2:</b><br />
@Micth Wheat - How would I refactor the following solution using the EXIST/NOT EXIST t-sql keyword?</p>
","<p>From what I read Chris Teixeira and hova use basically the same logic, but;<br />
- Hova parses the tables only once<br />
- Chris Teixeira parses the tables multiple times<br />
=>Hova's technique is preferred (in my opinion)  </p>

<p>However, Hova did it very slightly wrong...</p>

<p>The logic should be:</p>

<pre><code>- If Any 2 or 7 records   =&gt; DENIED
- ElseIf Any NULL records =&gt; PENDING
- Else                    =&gt; ACCEPTED
</code></pre>

<p>This gives the following code...</p>

<pre><code>SELECT
    [main].id,
    CASE WHEN MAX(CASE WHEN [status].value IN (2,7) THEN 1 ELSE 0 END) = 1 THEN 'DENIED'
         WHEN MAX(CASE WHEN [status].value IS NULL  THEN 1 ELSE 0 END) = 1 THEN 'PENDING'
         ELSE 'ACCEPTED' END
FROM
    [main]
INNER JOIN
    [status]
        ON [main].id = [status].main_id
GROUP BY
    [main].id
</code></pre>

<p>Also, the use of MAX rather than SUM (which Hova used) means that the query engine only has to find one match, not several.  Also, it is easier for an optimiser to use appropriate indexes on the [status] table.  (In the case, the index would be (main_id, value) in that order on the [status] table.</p>

<p>Dems.</p>

<p>EDIT:</p>

<p>Something similar could be as follows.  I have no SQL Instance to test on here, so i can't tell you if it's faster, but I image it could be...</p>

<pre><code>SELECT
    [main].id,
    MIN(CASE WHEN [status].value IN (2,7) THEN -1        -- Denied
             WHEN [status].value IS NULL  THEN  0        -- Pending
             ELSE                               1  END)  -- Accepted
FROM
    [main]
INNER JOIN
    [status]
        ON [main].id = [status].main_id
GROUP BY
    [main].id
</code></pre>

<p>EDIT:</p>

<p>Another option is just to join on a mapping table instead of using the CASE statements.</p>

<pre><code>DECLARE @map TABLE (
   status_value   INT,
   status_result  INT
   )

INSERT INTO @map VALUES (1,    1)
INSERT INTO @map VALUES (2,   -1)
INSERT INTO @map VALUES (6,    1)
INSERT INTO @map VALUES (7,   -1)
INSERT INTO @map VALUES (NULL, 0)

SELECT
    [main].id,
    MIN([map].status_result)
FROM
    [main]
INNER JOIN
    [status]
        ON [main].id = [status].main_id
INNER JOIN
    @map AS [map]
        ON [status].value = [map].status_value
        OR ([status].value IS NULL AND [map].status_value IS NULL)
        -- # This has been faster than using ISNULLs in my experience...
GROUP BY
    [main].id
</code></pre>
"
1069,489420,0,1,sql,How would you write this query?,"<p>I'm looking to refactor the below query to something more readable and modifiable.  The first half is identical to the second, with the exception of the database queried from (table names are the same though.)</p>

<pre><code>  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database1.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database1.dbo.Table2

UNION

  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database2.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database2.dbo.Table2
</code></pre>

<p>This query is the definition of DRY and is calling to me to be re-written, but I have no idea how!</p>

<p><strong>EDIT</strong>: We can't use linq and we desire distinct results; I'm looking to make the query smaller in physical file size, not in results returned.</p>

<p><strong>EDIT</strong>: The database I'm querying off is a proprietary ERP database.  Restructuring it is not an option.</p>
","<p>If all your procs look like this - you've probably got an architectural problem.</p>

<p>Are all your calls to table2 just have one useful field? (and because of UNION, end up having just one row?)</p>

<p>I totally second the idea of going with parameterized dynamic SQL and/or code-generation for this job, even going so far as to generate the column list dynamically using <code>INFORMATION_SCHEMA</code>.  This isn't exactly what you need but it's a start (you might generate off a table of databases and tables):</p>

<pre><code>DECLARE @template AS varchar(MAX)
SET @template = 'SELECT {@column_list} FROM {@database_name}.dbo.{@table_name}'
DECLARE @column_list AS varchar(MAX)

SELECT @column_list = COALESCE(@column_list + ',', '') + COLUMN_NAME
FROM database1.dbo.INFORMATION_SCHEMA.COLUMNS
WHERE TABLE_NAME = @table_name
ORDER BY ORDINAL_POSITION

DECLARE @sql AS varchar(MAX)
SET @sql = @template
SET @sql = REPLACE(@sql, '{@column_list}', @column_list)
SET @sql = REPLACE(@sql, '{@database_name}', @database_name)
SET @sql = REPLACE(@sql, '{@table_name}', @table_name)
</code></pre>
"
1026,478410,3,1,sql,"Efficient join with a ""correlated"" subquery","<p>Given three tables Dates(date aDate, doUse boolean), Days(rangeId int, day int, qty int) and Range(rangeId int, startDate date) in Oracle</p>

<p>I want to join these so that Range is joined with Dates from aDate = startDate where doUse = 1 whith each day in Days.</p>

<p>Given a single range it might be done something like this</p>

<pre><code>SELECT rangeId, aDate, CASE WHEN doUse = 1 THEN qty ELSE 0 END AS qty
FROM (
    SELECT aDate, doUse, SUM(doUse) OVER (ORDER BY aDate) day
    FROM Dates 
    WHERE aDate &gt;= :startDAte
) INNER JOIN (
    SELECT rangeId, day,qty
    FROM Days
    WHERE rangeId = :rangeId
) USING (day)
ORDER BY day ASC
</code></pre>

<p>What I want to do is make query for all ranges in Range, not just one.</p>

<p>The problem is that the join value ""day"" is dependent on the range startDate to be calculated, wich gives me some trouble in formulating a query.</p>

<p>Keep in mind that the Dates table is pretty huge so I would like to avoid calculating the day value from the first date in the table, while each Range Days shouldn't be more than a 100 days or so.</p>

<p>Edit: Sample data</p>

<pre><code>Dates                            Days
aDate        doUse               rangeId     day     qty
2008-01-01   1                   1           1       1
2008-01-02   1                   1           2       10
2008-01-03   0                   1           3       8
2008-01-04   1                   2           1       2
2008-01-05   1                   2           2       5

Ranges
rangeId      startDate
1            2008-01-02
2            2008-01-03


Result
rangeId      aDate        qty
1            2008-01-02   1
1            2008-01-03   0
1            2008-01-04   10
1            2008-01-05   8
2            2008-01-03   0
2            2008-01-04   2
2            2008-01-05   5
</code></pre>
","<p>Try this:</p>

<pre><code>SELECT  rt.rangeId, aDate, CASE WHEN doUse = 1 THEN qty ELSE 0 END AS qty
FROM    (
    SELECT	*
    FROM	(
    	SELECT	r.*, t.*, SUM(doUse) OVER (PARTITION BY rangeId ORDER BY aDate) AS span
    	FROM	(
    		SELECT	r.rangeId, startDate, MAX(day) AS dm
    		FROM	Range r, Days d
    		WHERE	d.rangeid = r.rangeid
    		GROUP BY
    			r.rangeId, startDate
    		) r, Dates t
    	WHERE	t.adate &gt;= startDate
    	ORDER BY
    		rangeId, t.adate
    	)
    WHERE
    	span &lt;= dm
    ) rt, Days d
WHERE   d.rangeId = rt.rangeID
    AND d.day = GREATEST(rt.span, 1)
</code></pre>

<p>P. S. It seems to me that the only point to keep all these <code>Dates</code> in the database is to get a continuous calendar with holidays marked.</p>

<p>You may generate a calendar of arbitrary length in Oracle using following construction:</p>

<pre><code>SELECT :startDate + ROWNUM
FROM   dual
CONNECT BY
       1 = 1
WHERE  rownum &lt; :length
</code></pre>

<p>and keep only holidays in <code>Dates</code>. A simple join will show you which <code>Dates</code> are holidays and which are not.</p>
"
1102,504110,1,1,sql,SQL 2005 Transactional Replication: Behavior during snapshot processing?,"<p>So, I've got SQL (2005) Transactional Replication generally working well with a single publisher and single (read-only) subscriber.  Data changes and updates flow perfectly, with about 5 second latency, which is just fine.  </p>

<p>My one nagging problem, that I've spent a couple days trying to solve (and Googling everywhere for answers) is that <em>new</em> sprocs/tables/etc. do not get propagated to the read-only subscriber, even though I've added them as ""articles"" to the ""publication"".  The publication has ""transmit schema changes"" set to ON, and stored procedures are set to transfer their definitions.  But, for some reason, they don't.</p>

<p>My ""snapshot agent"" process is set to NOT SCHEDULED.  (In other words, it only happens once, when I initiate it manually.)  Should I be putting this on a schedule to enable the transfer of new or modified tables and sprocs?  </p>

<p>I thought the mere act of adding the object as an article to the publication would do it, but it's still not sending it unless I do a snapshot.  The WAN connecting these is totally fast and reliable, so that's not the issue, and table-data-updates transfer relatively fast and flawlessly.</p>

<p>While I could put my snapshot agent on a schedule, does this have any real-time production impacts for users of the main publication database or the read-only copy?  (My site currently gets 4+ million unique-users a month, so I'd like to have minimal disruption...)  Thanks!</p>
","<p>Transactional replication only distributes (and then subsequently publishes) the DML (Data Manipulation Language) statements from the transaction log of the source (publication) database.</p>

<p>New tables and stored procedures are not replicated to the subscriber. Schema changes in this particular context, although I have to admit it is a little unclear in some of the Books Online documentation, refer to the existing schema, i.e. if you were to a add column to an existing database this change would be propagated to the subscribers.</p>

<p>For clarification here is a Microsoft article that details the schema changes that you can make.</p>

<p>[<a href=""http://msdn.microsoft.com/en-us/library/ms151870"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms151870</a>(SQL.90).aspx][1]</p>

<p>I hope this helps. Replication is a big subject area so please let me know if I can be of further assistance.</p>

<p>Oh yes, you are correct, if you add new articles to your publication you will need to create an updated snapshot.</p>

<p>Cheers,</p>
"
1096,503680,3,1,sql,MS SQL 2005 compare field containing square parenthesis,"<p>I am using MS SQL Server 2005 (9.0.4035) and trying to find rows that contain the same data in a nvarchar(4000) field.  The field contains xml that has both opening and closing square parentheses.<br><br>
Here is sample data:<br>
    DataID   Data<br>
    1        1<br>
    2        1<br>
    3        2]<br>
    4        2]<br>
    5        3[<br>
    6        3[<br></p>

<p>Using the 'like' operator I expected to get 3 matching pairs, but my problem is that row 5 and 6 do not match each other, I only get back that rows 1 &amp; 2 match, and 3 &amp; 4 match.</p>

<p>I know MS SQL 2005 added regular expression support in queries but I did not expect them to evaluate field data as a regular expression, which I think it is doing.  Is there a mode that I need to enable to get the proper results?</p>

<p>Any help appreciated,<br>
Ryan</p>

<p><b>Edit:</b> Added sql statement used:<br></p>

<p>Select t1.DataID, t2.DataID From TestTable t1, TestTable t2<br>
Where t1.DataID &lt;> t2.DataID<br>
and t1.Data like t2.Data</p>

<p><b>Edit:</b> Answer<br>
Using '=' operator works, but escaping the '[' does not.</p>
","<p>Change your query to use = instead of LIKE and you'll get the results that you expect.  SQL 2005 T-SQL won't do regex - you'd need to use CLR functions for that - but the LIKE statment does do pattern matching.  '[' and ']' are reserved for the pattern matching in a like statment, and you'd have to escape them out if you intended for them to be equality matches.  </p>

<p>See <a href=""http://msdn.microsoft.com/en-us/library/ms179859.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms179859.aspx</a> for info on the LIKE statement.</p>

<p>Either of the 2 queries below solved the problem in my tests...</p>

<pre><code>--using equals operator...
Select t1.DataID, t2.DataID From TestTable t1, TestTable t2
Where t1.DataID &lt;&gt; t2.DataID
and t1.Data = t2.Data

--using replace to add an escape character.
Select t1.DataID, t2.DataID From TestTable t1, TestTable t2
Where t1.DataID &lt;&gt; t2.DataID
and t1.Data like REPLACE(t2.Data, '[', '\[') escape '\'
</code></pre>
"
1074,491990,1,1,sql,Hibernate and IDs,"<p>Is it possible in hibernate to have an entity where some IDs are assigned and some are generated?</p>

<p>For instance:</p>

<p>Some objects have an ID between 1-10000 that are generated outside of the database; while some entities come in with no ID and need an ID generated by the database.</p>
","<p>Use any generator you like, make sure it can start at an offset (when you use a sequence, you can initialize it accordingly).</p>

<p>For all other entities, call setId() before you insert them. Hibernate will only generate an id if the id property is 0. Note that you should first insert objects with ids into the db and then work with them. There is a lot of code in Hibernate which expects the object to be in the DB when id != 0.</p>

<p>Another solution is to use negative ids for entities which come with an id. This will also make sure that there are no collisions when you insert an new object.</p>
"
1073,491990,1,1,sql,Hibernate and IDs,"<p>Is it possible in hibernate to have an entity where some IDs are assigned and some are generated?</p>

<p>For instance:</p>

<p>Some objects have an ID between 1-10000 that are generated outside of the database; while some entities come in with no ID and need an ID generated by the database.</p>
","<p>You could use 'assigned' as the Id generation strategy, but you would have to give the entity its id before you saved it to the database. Alternately you could build your own implementation of org.hibernate.id.IdentifierGenerator to provide the Id in the manner you've suggested.</p>

<p>I have to agree w/ Cade Roux though, and doing so seems like it be much more difficult than using built in increment, uuid, or other form of id generation.</p>
"
1072,491990,1,1,sql,Hibernate and IDs,"<p>Is it possible in hibernate to have an entity where some IDs are assigned and some are generated?</p>

<p>For instance:</p>

<p>Some objects have an ID between 1-10000 that are generated outside of the database; while some entities come in with no ID and need an ID generated by the database.</p>
","<p>I would avoid this and simply have an auxiliary column for the information about the source of the object and a column for the external identifier (assuming the external identifier was an important value you wanted to keep track of).</p>

<p>It's generally a bad idea to use columns for mixed purposes - in this case to infer from the nature of a surrogate key the source of an object.</p>
"
1071,489420,0,1,sql,How would you write this query?,"<p>I'm looking to refactor the below query to something more readable and modifiable.  The first half is identical to the second, with the exception of the database queried from (table names are the same though.)</p>

<pre><code>  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database1.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database1.dbo.Table2

UNION

  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database2.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database2.dbo.Table2
</code></pre>

<p>This query is the definition of DRY and is calling to me to be re-written, but I have no idea how!</p>

<p><strong>EDIT</strong>: We can't use linq and we desire distinct results; I'm looking to make the query smaller in physical file size, not in results returned.</p>

<p><strong>EDIT</strong>: The database I'm querying off is a proprietary ERP database.  Restructuring it is not an option.</p>
","<p>Depending on the number of rows returned, you may be best using UNION ALL on the selects with a select distinct query around it.
I've seen a similar problem before and had different execution plans for the two different styles </p>

<pre>
SELECT DISTINCT subquery.c1, subquery.cN
FROM
(
SELECT Column 1 AS c1, Column N AS cN FROM database1.dbo.Table1
UNION ALL
SELECT 'Some String' as c1, NULL as cN FROM database1.dbo.Table2
UNION ALL
SELECT Column 1 AS c1, Column N AS cN FROM database2.dbo.Table1
UNION ALL
SELECT 'Some String' as c1, NULL as cN FROM database2.dbo.Table2
) subquery
</pre>
"
1070,489420,2,1,sql,How would you write this query?,"<p>I'm looking to refactor the below query to something more readable and modifiable.  The first half is identical to the second, with the exception of the database queried from (table names are the same though.)</p>

<pre><code>  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database1.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database1.dbo.Table2

UNION

  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database2.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database2.dbo.Table2
</code></pre>

<p>This query is the definition of DRY and is calling to me to be re-written, but I have no idea how!</p>

<p><strong>EDIT</strong>: We can't use linq and we desire distinct results; I'm looking to make the query smaller in physical file size, not in results returned.</p>

<p><strong>EDIT</strong>: The database I'm querying off is a proprietary ERP database.  Restructuring it is not an option.</p>
","<p>This is a pretty standard SQL pattern. Sometimes it's easy to inadvisedly transfer OOP/Procedural code principles like DRY to SQL, but they aren't necessarily transferable concepts. </p>

<p>Note how easily you can grok the entire logical design of the query, vs. hunting through submodules. If one of the subexpressions had an extra column, or columns reversed, it would stick out. This is basically a pretty simple SQL statement to grok as an execution unit, where disaggregating it would muddle it.</p>

<p>And when you're debugging, it's handy to be able to use the editor's text highlighting option to selectively exercise parts of the statement - a technique that doesn't exist in procedural code. OTOH, it can get messy trying to trace down all the pieces if they are scattered into views etc. Even CTEs can make this inconvenient.</p>
"
1051,487770,2,1,sql,SQL CASE Statement Versus Conditional Statements In Programming Language,"<p>I'm going through some old stored procedures at work and constantly come across</p>

<pre><code>CASE MyColumn WHEN 'Y' THEN 'Yes' WHEN 'N' THEN 'No' ELSE 'Unknown' END
</code></pre>

<p>It gets even worse when this is tied not to a word, but instead a colour.</p>

<pre><code>CASE MyColumn WHEN 'Y' THEN 'style=""background-color:pink""' ELSE '' END
</code></pre>

<p>The reason this was done was for older ASP 1 pages where everything had to be done inline, but as it's such a large system it's impossible to keep up with updating all the pages.</p>

<p>Can anyone give any valid evidence that using a SQL query for conditional statements surpasses that in other languages such as C# or Java?  Is this good practice for speed?  Should the plain value be returned and the presentation layer decide what should be done?</p>
","<p>I would be concerned putting this kind of logic in SQL statements. What happens if your database engine changes? Will you have to update every SQL statement to Oracle SQL? What if the repository itself changes, when you move to a message bus, XML files, or web service call... </p>

<p>It looks like you're storing display information. In which case, it's part of the data model. Let the controller (in a typical <a href=""http://www.asp.net/mvc/"" rel=""nofollow"">MVC pattern</a>) perform the conditional logic. The presentation layer doesn't need to know what happened and the repository can be happy just holding data.</p>
"
995,452230,0,1,sql,Trying to build an SQL statement for complex search scenario,"<p>I am trying to build an SQL Statement for the following search scenario:</p>

<p>I have trying to return all of the columns for an individual record for Table A based on the value of the status column in Table B.  Each record in table A can have multiple rows in table B, making it a one to many relationship.  The status column is nullable with a data type of integer.</p>

<p>Here are the possible values for status in table B:</p>

<ul>
<li>NULL = Pending,</li>
<li>1 = Approved,</li>
<li>2 = Denied,</li>
<li>6 = Forced Approval,</li>
<li>7 = Forced Denial</li>
</ul>

<p>The end user can search on the following scenarios:</p>

<ul>
<li>Approved - All table B records must have a value of 1 or 6 for status.</li>
<li>Denied - One table B record must have a value of 2 or 5.  Any other records can have 1,6, or null.</li>
<li>Pending - All table B records can have a value of 1,6 or null.  One record must be null because it is not considered completed.</li>
</ul>

<p><b>UPDATE</b><br />
I consulted with one of our DBAs and he developed the following solution:</p>

<p>Approved:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status in (1,6) and b.status IS NOT NULL) AND
b.id NOT IN (SELECT id from TableB  WHERE status IS NULL)
AND b.id NOT IN (SELECT id from TableB WHERE status in (2,7))
</code></pre>

<p>Denied:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status in (2,7))
</code></pre>

<p>Pending:</p>

<pre><code>SELECT a.* FROM TableA a INNER JOIN TableB ON b.id = a.id
WHERE
(b.status IN (1,6) OR b.status IS NULL)
AND b.id NOT IN (SELECT b.id FROM TableA a INNER JOIN TableB b ON b.id = a.id WHERE (b.status IN (1,6) AND b.status IS NOT NULL) AND b.id NOT IN (SELECT id from TableB WHERE status IS NULL))
AND b.id NOT IN (SELECT id FROM TableB WHERE status IN (2,7))
</code></pre>

<p><b>UPDATE 2:</b><br />
@Micth Wheat - How would I refactor the following solution using the EXIST/NOT EXIST t-sql keyword?</p>
","<p>You also asked how to make use of EXISTS to solve the query.  I still don't have anything to test this on, but I'd try something like the following...</p>

<p>Approved:</p>

<pre><code>SELECT
    a.*
FROM
    TableA a
WHERE
    NOT EXISTS (SELECT * FROM TableB b WHERE b.id = a.id AND b.status IN (NULL,1,6))
</code></pre>

<p>Denied:</p>

<pre><code>SELECT
    a.*
FROM
    TableA a
WHERE
    EXISTS (SELECT * FROM TableB b WHERE b.id = a.id AND b.status IN (1,6))
</code></pre>

<p>Pending:</p>

<pre><code>SELECT
    a.*
FROM
    TableA a
WHERE
    EXISTS (SELECT * FROM TableB b WHERE b.id = a.id AND b.status IS NULL)
    AND NOT EXISTS (SELECT * FROM TableB b WHERE b.id = a.id AND b.status IN (1,6))
</code></pre>
"
1052,487770,3,1,sql,SQL CASE Statement Versus Conditional Statements In Programming Language,"<p>I'm going through some old stored procedures at work and constantly come across</p>

<pre><code>CASE MyColumn WHEN 'Y' THEN 'Yes' WHEN 'N' THEN 'No' ELSE 'Unknown' END
</code></pre>

<p>It gets even worse when this is tied not to a word, but instead a colour.</p>

<pre><code>CASE MyColumn WHEN 'Y' THEN 'style=""background-color:pink""' ELSE '' END
</code></pre>

<p>The reason this was done was for older ASP 1 pages where everything had to be done inline, but as it's such a large system it's impossible to keep up with updating all the pages.</p>

<p>Can anyone give any valid evidence that using a SQL query for conditional statements surpasses that in other languages such as C# or Java?  Is this good practice for speed?  Should the plain value be returned and the presentation layer decide what should be done?</p>
","<p>When speed is of the essence, the SQL case statements might even be the fastest (I'll run a test) but for maintainability, returning the plain values to the presentation layer (or some business layer thingy) is the best option. </p>

<p>[update] ran some quick and dirty tests (code below) and found the C# code variant slightly faster than the SQL case variant. Conclusion: returning the 'raw' data and manipulating it in the presentation layer is both quicker and more maintainable.</p>

<p>-Edoode</p>

<p>I retrieved 196288 rows with queries below.</p>

<pre><code>StringBuilder result = new StringBuilder();
using (SqlConnection conn = new SqlConnection(Settings.Default.Conn))
{                
    conn.Open();
    string cmd = ""select [state], case [state] when 'ca' then 'california' else [state] end from member"";
    SqlCommand command = new SqlCommand(cmd, conn);
    using (SqlDataReader reader = command.ExecuteReader(CommandBehavior.CloseConnection))
    {
        while (reader.Read())
        {                        
            result.AppendLine(reader.GetString(1));
        }
    }
}
</code></pre>

<p>C# variant:</p>

<pre><code>StringBuilder result = new StringBuilder();
using (SqlConnection conn = new SqlConnection(Settings.Default.Conn))
{

    conn.Open();
    string cmd = ""select [state] from member"";
    SqlCommand command = new SqlCommand(cmd, conn);
    using (SqlDataReader reader = command.ExecuteReader(CommandBehavior.CloseConnection))
    {
        while (reader.Read())
        {
            result.AppendLine(reader.GetString(0) == ""ca"" ? ""california"" : reader.GetString(0));
        }
    }
</code></pre>

<p>}</p>
"
1053,487770,0,1,sql,SQL CASE Statement Versus Conditional Statements In Programming Language,"<p>I'm going through some old stored procedures at work and constantly come across</p>

<pre><code>CASE MyColumn WHEN 'Y' THEN 'Yes' WHEN 'N' THEN 'No' ELSE 'Unknown' END
</code></pre>

<p>It gets even worse when this is tied not to a word, but instead a colour.</p>

<pre><code>CASE MyColumn WHEN 'Y' THEN 'style=""background-color:pink""' ELSE '' END
</code></pre>

<p>The reason this was done was for older ASP 1 pages where everything had to be done inline, but as it's such a large system it's impossible to keep up with updating all the pages.</p>

<p>Can anyone give any valid evidence that using a SQL query for conditional statements surpasses that in other languages such as C# or Java?  Is this good practice for speed?  Should the plain value be returned and the presentation layer decide what should be done?</p>
","<blockquote>
  <p>Can anyone give any valid evidence that using a SQL query for conditional statements surpasses that in other languages such as C# or Java? Is this good practice for speed? Should the plain value be returned and the presentation layer decide what should be done?</p>
</blockquote>

<p>Sometimes (sometimes) it just helps to avoid extra coding in the presentation layer.</p>

<p>As a rule, if both database and presentation are developed by one person, it doesn't matter. Problems begin when the work becames shared. In this case you, obviously, need a well stated contract on what the database emits and what ASP accepts.</p>

<p>Sure, CSS belongs to presentation layer's domain and it should be parsed by ASP rather than hardcoded in SQL.</p>
"
1054,487770,0,1,sql,SQL CASE Statement Versus Conditional Statements In Programming Language,"<p>I'm going through some old stored procedures at work and constantly come across</p>

<pre><code>CASE MyColumn WHEN 'Y' THEN 'Yes' WHEN 'N' THEN 'No' ELSE 'Unknown' END
</code></pre>

<p>It gets even worse when this is tied not to a word, but instead a colour.</p>

<pre><code>CASE MyColumn WHEN 'Y' THEN 'style=""background-color:pink""' ELSE '' END
</code></pre>

<p>The reason this was done was for older ASP 1 pages where everything had to be done inline, but as it's such a large system it's impossible to keep up with updating all the pages.</p>

<p>Can anyone give any valid evidence that using a SQL query for conditional statements surpasses that in other languages such as C# or Java?  Is this good practice for speed?  Should the plain value be returned and the presentation layer decide what should be done?</p>
","<p>That is old style code, I don't believe people code like this anymore (we use CSS now)<br />
Your are probably looking at some soon to be legacy stuff which will be rewritten or abandoned</p>
"
1055,487770,0,1,sql,SQL CASE Statement Versus Conditional Statements In Programming Language,"<p>I'm going through some old stored procedures at work and constantly come across</p>

<pre><code>CASE MyColumn WHEN 'Y' THEN 'Yes' WHEN 'N' THEN 'No' ELSE 'Unknown' END
</code></pre>

<p>It gets even worse when this is tied not to a word, but instead a colour.</p>

<pre><code>CASE MyColumn WHEN 'Y' THEN 'style=""background-color:pink""' ELSE '' END
</code></pre>

<p>The reason this was done was for older ASP 1 pages where everything had to be done inline, but as it's such a large system it's impossible to keep up with updating all the pages.</p>

<p>Can anyone give any valid evidence that using a SQL query for conditional statements surpasses that in other languages such as C# or Java?  Is this good practice for speed?  Should the plain value be returned and the presentation layer decide what should be done?</p>
","<p>In terms of SQL Performance, if you are only returning a few rows (or one by the looks of it), this has minimal impact as the WHERE part of the statement is evaluated before the case (The case is only performed on rows which match the where).</p>

<p>From a best practises point of view, display information should not really be determined in SQL.  Perhaps returning a theme type, but certainly not discreet style information.</p>
"
1056,487770,0,1,sql,SQL CASE Statement Versus Conditional Statements In Programming Language,"<p>I'm going through some old stored procedures at work and constantly come across</p>

<pre><code>CASE MyColumn WHEN 'Y' THEN 'Yes' WHEN 'N' THEN 'No' ELSE 'Unknown' END
</code></pre>

<p>It gets even worse when this is tied not to a word, but instead a colour.</p>

<pre><code>CASE MyColumn WHEN 'Y' THEN 'style=""background-color:pink""' ELSE '' END
</code></pre>

<p>The reason this was done was for older ASP 1 pages where everything had to be done inline, but as it's such a large system it's impossible to keep up with updating all the pages.</p>

<p>Can anyone give any valid evidence that using a SQL query for conditional statements surpasses that in other languages such as C# or Java?  Is this good practice for speed?  Should the plain value be returned and the presentation layer decide what should be done?</p>
","<p>Agree 100% on refactoring to put display decisions up to the presentation layer (or as near as possible).</p>

<p><code>CASE ... END</code> in SQL still can have its uses, though, for example, say I want to calculate the percentage of the total value of all orders that is for domestic customers. I think I'd be happy with </p>

<pre><code>SELECT
  SUM(CASE domestic WHEN 'Y' THEN order_value ELSE 0 END) / SUM(order_value) AS pctg
FROM orders
</code></pre>

<p>as a query. Unless someone knows better, of course.</p>
"
1064,489420,2,1,sql,How would you write this query?,"<p>I'm looking to refactor the below query to something more readable and modifiable.  The first half is identical to the second, with the exception of the database queried from (table names are the same though.)</p>

<pre><code>  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database1.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database1.dbo.Table2

UNION

  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database2.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database2.dbo.Table2
</code></pre>

<p>This query is the definition of DRY and is calling to me to be re-written, but I have no idea how!</p>

<p><strong>EDIT</strong>: We can't use linq and we desire distinct results; I'm looking to make the query smaller in physical file size, not in results returned.</p>

<p><strong>EDIT</strong>: The database I'm querying off is a proprietary ERP database.  Restructuring it is not an option.</p>
","<p>One performance tip that I see off the bat is using <code>UNION ALL</code> instead of <code>UNION</code> unless you intentionally want distinct records. A simple <code>UNION</code> will eliminate duplicates which takes time. <code>UNION ALL</code> doesn't do that.</p>

<p>You could rewrite it with dynamic SQL and a loop but I think the result would be worse. If there is enough duplicate code to justify the dynamic sql approach, then I guess it could be justified.</p>

<p>Alternatively, have you considered moving the logic out of the stored procedure into something like LINQ? For many, this isn't an option so I'm just asking.</p>

<p>A final note: resist the urge to fix what's not broken just to make it look cleaner. If cleanup will aide in maintenance, verification, etc., then go for it.</p>
"
1065,489420,3,1,sql,How would you write this query?,"<p>I'm looking to refactor the below query to something more readable and modifiable.  The first half is identical to the second, with the exception of the database queried from (table names are the same though.)</p>

<pre><code>  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database1.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database1.dbo.Table2

UNION

  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database2.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database2.dbo.Table2
</code></pre>

<p>This query is the definition of DRY and is calling to me to be re-written, but I have no idea how!</p>

<p><strong>EDIT</strong>: We can't use linq and we desire distinct results; I'm looking to make the query smaller in physical file size, not in results returned.</p>

<p><strong>EDIT</strong>: The database I'm querying off is a proprietary ERP database.  Restructuring it is not an option.</p>
","<p>I'm going to go out on a limb here, and say, based on the information you've given us; </p>

<p><strong>That's as good as it's going to get</strong> </p>
"
1066,489420,1,1,sql,How would you write this query?,"<p>I'm looking to refactor the below query to something more readable and modifiable.  The first half is identical to the second, with the exception of the database queried from (table names are the same though.)</p>

<pre><code>  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database1.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database1.dbo.Table2

UNION

  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database2.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database2.dbo.Table2
</code></pre>

<p>This query is the definition of DRY and is calling to me to be re-written, but I have no idea how!</p>

<p><strong>EDIT</strong>: We can't use linq and we desire distinct results; I'm looking to make the query smaller in physical file size, not in results returned.</p>

<p><strong>EDIT</strong>: The database I'm querying off is a proprietary ERP database.  Restructuring it is not an option.</p>
","<p>What's the problem? Too long? Too repetitive?</p>

<p>Sometimes you get ugly SQL - not much you can do about it. </p>

<p>I don't see any way to clean it up unless you want to use separate views and then union them together.</p>
"
1025,478410,1,1,sql,"Efficient join with a ""correlated"" subquery","<p>Given three tables Dates(date aDate, doUse boolean), Days(rangeId int, day int, qty int) and Range(rangeId int, startDate date) in Oracle</p>

<p>I want to join these so that Range is joined with Dates from aDate = startDate where doUse = 1 whith each day in Days.</p>

<p>Given a single range it might be done something like this</p>

<pre><code>SELECT rangeId, aDate, CASE WHEN doUse = 1 THEN qty ELSE 0 END AS qty
FROM (
    SELECT aDate, doUse, SUM(doUse) OVER (ORDER BY aDate) day
    FROM Dates 
    WHERE aDate &gt;= :startDAte
) INNER JOIN (
    SELECT rangeId, day,qty
    FROM Days
    WHERE rangeId = :rangeId
) USING (day)
ORDER BY day ASC
</code></pre>

<p>What I want to do is make query for all ranges in Range, not just one.</p>

<p>The problem is that the join value ""day"" is dependent on the range startDate to be calculated, wich gives me some trouble in formulating a query.</p>

<p>Keep in mind that the Dates table is pretty huge so I would like to avoid calculating the day value from the first date in the table, while each Range Days shouldn't be more than a 100 days or so.</p>

<p>Edit: Sample data</p>

<pre><code>Dates                            Days
aDate        doUse               rangeId     day     qty
2008-01-01   1                   1           1       1
2008-01-02   1                   1           2       10
2008-01-03   0                   1           3       8
2008-01-04   1                   2           1       2
2008-01-05   1                   2           2       5

Ranges
rangeId      startDate
1            2008-01-02
2            2008-01-03


Result
rangeId      aDate        qty
1            2008-01-02   1
1            2008-01-03   0
1            2008-01-04   10
1            2008-01-05   8
2            2008-01-03   0
2            2008-01-04   2
2            2008-01-05   5
</code></pre>
","<p>Ok, so maybe I've found a way. Someting like this:</p>

<pre><code>SELECT irangeId, aDate + sum(case when doUse = 1 then 0 else 1) over (partionBy rangeId order by aDate) as aDate, qty
FROM Days INNER JOIN (
    select irangeId, startDate + day - 1 as aDate, qty
    from Range inner join Days using (irangeid)
) USING (aDate)
</code></pre>

<p>Now I just need a way to fill in the missing dates...</p>

<p>Edit: Nah, this way means that I'll miss the doUse vaue of the last dates...</p>
"
1024,476810,1,1,sql,Problems with big query and subquery,"<p>I thought that I'll be clever and use subquery to get my <a href=""http://stackoverflow.com/questions/470992/how-to-count-number-of-different-items-in-sql#471152"">report</a> in one go. But after running into problems and reading documentation I saw that my approach does not work in MySQL. My inner query returns ~100 records and outer query scans 20000 records.
When I restricted outer query to 20 records then it run 20 sec - really slow.</p>

<p>I wonder is it possible to restructure it somehow so that inner query wouldn't be run EVERY time for every record in the outer query?</p>

<pre><code>select p1.surname ,p1.name,p1.id,r1.start_date,r1.end_date,c1.short_name
FROM ejl_players p1
left JOIN ejl_registration r1 ON ( r1.player_id = p1.id )
left JOIN ejl_teams t1 ON ( r1.team_id = t1.id )
left JOIN ejl_clubs c1 ON ( t1.club_id = c1.id )
where  r1.season=2008
and p1.id in
 (
SELECT p.id
FROM ejl_players p 
left JOIN ejl_registration r ON (r.player_id = p.id) 
left JOIN ejl_teams t ON (r.team_id = t.id) 
left JOIN ejl_clubs c ON (t.club_id = c.id)
WHERE r.season = 2008
GROUP BY p.id
HAVING COUNT(DISTINCT c.id)  &gt; 1
)
</code></pre>

<p>Explain (I restricted outer query to maximum 20 records:</p>

<pre><code>id  select_type  table  type  possible_keys  key  key_len  ref  rows  Extra  
1 PRIMARY p1 range PRIMARY PRIMARY 4 NULL 19 Using where 
1 PRIMARY r1 ref team_id,season season 10 const,d17528sd14898.p1.id 1 Using where 
1 PRIMARY t1 eq_ref PRIMARY PRIMARY 4 d17528sd14898.r1.team_id 1   
1 PRIMARY c1 eq_ref PRIMARY PRIMARY 4 d17528sd14898.t1.club_id 1   
2 DEPENDENT SUBQUERY p index PRIMARY PRIMARY 5 NULL 23395 Using index 
2 DEPENDENT SUBQUERY r ref team_id,season season 10 const,d17528sd14898.p.id 1 Using where; Using index 
2 DEPENDENT SUBQUERY t eq_ref PRIMARY PRIMARY 4 d17528sd14898.r.team_id 1   
2 DEPENDENT SUBQUERY c eq_ref PRIMARY PRIMARY 4 d17528sd14898.t.club_id 1 Using index
</code></pre>
","<p>Like I commented on your <a href=""http://stackoverflow.com/questions/470992/how-to-count-number-of-different-items-in-sql"">question</a> the other day, you don't need to use a LEFT JOIN in this example.  Outer joins often perform slower than inner joins, so you can get some better performance by using a simple inner join.  </p>

<p>You would need to use an outer join only if you need to show all players, even those who <em>don't</em> have any registration.</p>

<p>It seems that your query is looking for players who have been on teams in more than one club this year (like your earlier question), and then outputting some details of their registration and club name.  Here's how I would solve this query:</p>

<pre><code>SELECT p.surname, p.name, p.id, r.start_date, r.end_date, c1.short_name
FROM ejl_players p
 INNER JOIN ejl_registration r1 ON (r.player_id = p.id)
 INNER JOIN ejl_teams t1 ON (r.team_id = t1.id)
 INNER JOIN ejl_clubs c1 ON (t1.club_id = c1.id)
 INNER JOIN ejl_teams t2 ON (r.team_id = t2.id)
 INNER JOIN ejl_clubs c2 ON (t2.club_id = c2.id)
WHERE r.season = 2008
GROUP BY r.player_id, r.team_id
HAVING COUNT(DISTINCT c2.id) &gt; 1;
</code></pre>

<p>This works in MySQL because MySQL is permissive about the Single-Value Rule.  That is, the columns in your GROUP BY clause don't have to be the same as the non-aggregated columns named in your select-list.  In other brands of RDBMS, this query would generate an error.</p>
"
1023,476810,5,1,sql,Problems with big query and subquery,"<p>I thought that I'll be clever and use subquery to get my <a href=""http://stackoverflow.com/questions/470992/how-to-count-number-of-different-items-in-sql#471152"">report</a> in one go. But after running into problems and reading documentation I saw that my approach does not work in MySQL. My inner query returns ~100 records and outer query scans 20000 records.
When I restricted outer query to 20 records then it run 20 sec - really slow.</p>

<p>I wonder is it possible to restructure it somehow so that inner query wouldn't be run EVERY time for every record in the outer query?</p>

<pre><code>select p1.surname ,p1.name,p1.id,r1.start_date,r1.end_date,c1.short_name
FROM ejl_players p1
left JOIN ejl_registration r1 ON ( r1.player_id = p1.id )
left JOIN ejl_teams t1 ON ( r1.team_id = t1.id )
left JOIN ejl_clubs c1 ON ( t1.club_id = c1.id )
where  r1.season=2008
and p1.id in
 (
SELECT p.id
FROM ejl_players p 
left JOIN ejl_registration r ON (r.player_id = p.id) 
left JOIN ejl_teams t ON (r.team_id = t.id) 
left JOIN ejl_clubs c ON (t.club_id = c.id)
WHERE r.season = 2008
GROUP BY p.id
HAVING COUNT(DISTINCT c.id)  &gt; 1
)
</code></pre>

<p>Explain (I restricted outer query to maximum 20 records:</p>

<pre><code>id  select_type  table  type  possible_keys  key  key_len  ref  rows  Extra  
1 PRIMARY p1 range PRIMARY PRIMARY 4 NULL 19 Using where 
1 PRIMARY r1 ref team_id,season season 10 const,d17528sd14898.p1.id 1 Using where 
1 PRIMARY t1 eq_ref PRIMARY PRIMARY 4 d17528sd14898.r1.team_id 1   
1 PRIMARY c1 eq_ref PRIMARY PRIMARY 4 d17528sd14898.t1.club_id 1   
2 DEPENDENT SUBQUERY p index PRIMARY PRIMARY 5 NULL 23395 Using index 
2 DEPENDENT SUBQUERY r ref team_id,season season 10 const,d17528sd14898.p.id 1 Using where; Using index 
2 DEPENDENT SUBQUERY t eq_ref PRIMARY PRIMARY 4 d17528sd14898.r.team_id 1   
2 DEPENDENT SUBQUERY c eq_ref PRIMARY PRIMARY 4 d17528sd14898.t.club_id 1 Using index
</code></pre>
","<p>Try using an INNER JOIN (something like this):</p>

<pre><code>SELECT p1.surname ,p1.name,p1.id,r1.start_date,r1.end_date,c1.short_name
FROM ejl_players p1
INNER JOIN (
    SELECT p.id
    FROM ejl_players p 
    LEFT JOIN ejl_registration r ON (r.player_id = p.id) 
    LEFT JOIN ejl_teams t ON (r.team_id = t.id) 
    LEFT JOIN ejl_clubs c ON (t.club_id = c.id)
    WHERE r.season = 2008
    GROUP BY p.id
    HAVING COUNT(DISTINCT c.id)  &gt; 1
) p2 ON p1.id = p2.id
LEFT JOIN ejl_registration r1 ON ( r1.player_id = p1.id )
LEFT JOIN ejl_teams t1 ON ( r1.team_id = t1.id )
LEFT JOIN ejl_clubs c1 ON ( t1.club_id = c1.id )
WHERE  r1.season=2008
</code></pre>

<p>Using the subquery in this manner should be more efficient but isn't always. However, it does bypass the issue of having the subquery executed for every record returned in the main query. Instead the subquery is constructed as a virtual table in memory and then used for comparison with the main query.</p>

<p><b>Edit:</b> I should point out that you'll want to use EXPLAIN in MySQL to verify that this query is indeed performing more efficiently.</p>
"
1131,521270,0,1,sql,Best way to implement a stored procedure with full text search,"<p>I would like to run a search with MSSQL Full text engine where given the following user input:
""Hollywood square""</p>

<p>I want the results to have both Hollywood and square[s] in them.</p>

<p>I can create a method on the web server (C#, ASP.NET) to dynamically produce a sql statement like this:</p>

<pre><code>SELECT TITLE
FROM MOVIES
WHERE CONTAINS(TITLE,'""hollywood*""')
AND CONTAINS(TITLE, '""square*""')
</code></pre>

<p>Easy enough.  HOWEVER, I would like this in a stored procedure for added speed benefit and security for adding parameters.</p>

<p>Can I have my cake and eat it too?</p>
","<p>The last time I had to do this (with MSSQL Server 2005) I ended up moving the whole search functionality over to Lucene (the Java version, though Lucene.Net now exists I believe). I had high hopes of the full text search but this specific problem annoyed me so much I gave up.</p>
"
1004,460920,1,1,sql,SQL exception when trying make an prepared statement,"<p>I'm trying to pass the following <code>String</code> to a <code>PreparedStatement</code>:</p>

<pre><code>private static final String QUICK_SEARCH = ""select * from c where NAME like '% ? %'"";
</code></pre>

<p>However, I get an SQL exception that the bind variable is missing.</p>

<p>Any suggestions?</p>
","<p>You can't put binding variables inside a string like that.</p>

<p>You need to use:</p>

<pre><code>SELECT * FROM c WHERE name LIKE CONCAT('%', ?, '%')
</code></pre>

<p>or similar, depending on what functions are supported by your version of SQL.</p>
"
1005,460920,1,1,sql,SQL exception when trying make an prepared statement,"<p>I'm trying to pass the following <code>String</code> to a <code>PreparedStatement</code>:</p>

<pre><code>private static final String QUICK_SEARCH = ""select * from c where NAME like '% ? %'"";
</code></pre>

<p>However, I get an SQL exception that the bind variable is missing.</p>

<p>Any suggestions?</p>
","<p>Can't u make use of parameters inside of using string concatenation ?</p>
"
1006,460920,1,1,sql,SQL exception when trying make an prepared statement,"<p>I'm trying to pass the following <code>String</code> to a <code>PreparedStatement</code>:</p>

<pre><code>private static final String QUICK_SEARCH = ""select * from c where NAME like '% ? %'"";
</code></pre>

<p>However, I get an SQL exception that the bind variable is missing.</p>

<p>Any suggestions?</p>
","<p>cool,</p>

<p>i just set the % signs when setting preparedstatement;</p>

<pre><code>pstmt.setString(1, ""%"" + name + ""%"");
</code></pre>
"
1168,528590,0,1,sql,Dynamic Query in SQL Server,"<p>I have a table with 10 columns as col_1,col_2,.... col_10. I want to write a select statement that will select a value of one of the row and from one of these 10 columns. I have a variable that will decide which column to select from. Can such query be written where the column name is dynamically decided from a variable.</p>
","<p>This isn't something you should ever need to do if your database is correctly designed. I'd revisit the design of that element of the schema to remove the need to do this.</p>
"
1167,528590,3,1,sql,Dynamic Query in SQL Server,"<p>I have a table with 10 columns as col_1,col_2,.... col_10. I want to write a select statement that will select a value of one of the row and from one of these 10 columns. I have a variable that will decide which column to select from. Can such query be written where the column name is dynamically decided from a variable.</p>
","<p>Good article for people looking to do dynamic sql:</p>

<p><a href=""http://www.sommarskog.se/dynamic_sql.html"" rel=""nofollow"">The Curse and Blessings of Dynamic SQL</a></p>
"
1166,528590,0,1,sql,Dynamic Query in SQL Server,"<p>I have a table with 10 columns as col_1,col_2,.... col_10. I want to write a select statement that will select a value of one of the row and from one of these 10 columns. I have a variable that will decide which column to select from. Can such query be written where the column name is dynamically decided from a variable.</p>
","<p>I have no idea what platform you are using but you can use <a href=""http://weblogs.asp.net/scottgu/archive/2008/01/07/dynamic-linq-part-1-using-the-linq-dynamic-query-library.aspx"" rel=""nofollow"">Dynamic LINQ</a> pretty easily to do this.</p>

<pre><code>var query = context.Table
                   .Where( t =&gt; t.Id == row_id )
                   .Select( ""Col_"" + column_id );

IEnumerator enumerator = query.GetEnumerator();
enumerator.MoveNext();
object columnValue = enumerator.Current;
</code></pre>

<p>Presumably, you'll know which actual type to cast this to depending on the column.  The nice thing about this is you get the parameterized query for free, protecting you against SQL injection attacks.</p>
"
1165,528590,0,1,sql,Dynamic Query in SQL Server,"<p>I have a table with 10 columns as col_1,col_2,.... col_10. I want to write a select statement that will select a value of one of the row and from one of these 10 columns. I have a variable that will decide which column to select from. Can such query be written where the column name is dynamically decided from a variable.</p>
","<p>IMHO, <a href=""http://stackoverflow.com/questions/528590/dynamic-query-in-ms-sql/528613#528613"">Joel Coehoorn's case statement</a> is probably the best idea </p>

<p>... but if you really have to use dynamic SQL, you can do it with <a href=""http://msdn.microsoft.com/en-us/library/ms188001.aspx"" rel=""nofollow"">sp_executeSQL()</a></p>
"
1164,528590,0,1,sql,Dynamic Query in SQL Server,"<p>I have a table with 10 columns as col_1,col_2,.... col_10. I want to write a select statement that will select a value of one of the row and from one of these 10 columns. I have a variable that will decide which column to select from. Can such query be written where the column name is dynamically decided from a variable.</p>
","<p>You can do it with a T-SQl CASE statement:</p>

<pre><code>SELECT 'The result' =
   CASE 
     WHEN choice = 1 THEN col1
     WHEN choice = 2 THEN col2
     ...
   END
FROM sometable
</code></pre>
"
1163,528590,1,1,sql,Dynamic Query in SQL Server,"<p>I have a table with 10 columns as col_1,col_2,.... col_10. I want to write a select statement that will select a value of one of the row and from one of these 10 columns. I have a variable that will decide which column to select from. Can such query be written where the column name is dynamically decided from a variable.</p>
","<p>I assume you are running purely within Transact-SQL. What you'll need to do is dynamically create the SQL statement with your variable as the column name and use the EXECUTE command to run it.  For example:</p>

<pre><code>EXECUTE('select ' + @myColumn + ' from MyTable')
</code></pre>
"
1067,489420,1,1,sql,How would you write this query?,"<p>I'm looking to refactor the below query to something more readable and modifiable.  The first half is identical to the second, with the exception of the database queried from (table names are the same though.)</p>

<pre><code>  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database1.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database1.dbo.Table2

UNION

  SELECT
    Column 1 AS c1,
    ...
    Column N AS cN
  FROM
    database2.dbo.Table1

UNION

  SELECT
    'Some String' as c1,
    ...
    NULL as cN
  FROM
    database2.dbo.Table2
</code></pre>

<p>This query is the definition of DRY and is calling to me to be re-written, but I have no idea how!</p>

<p><strong>EDIT</strong>: We can't use linq and we desire distinct results; I'm looking to make the query smaller in physical file size, not in results returned.</p>

<p><strong>EDIT</strong>: The database I'm querying off is a proprietary ERP database.  Restructuring it is not an option.</p>
","<p>I vote for views, which impose near-enough zero overhead (OK, maybe a small compile-time cost but that ought to be all). Then your procs become something of the form</p>

<pre><code>SELECT * FROM database1.view1
UNION
SELECT * FROM database1.view2
UNION
SELECT * FROM database2.view1
UNION
SELECT * FROM database2.view2
</code></pre>

<p>I'm not sure if I'd want to condense it any further, although I expect most platforms would tolerate it.</p>
"
1162,528590,3,1,sql,Dynamic Query in SQL Server,"<p>I have a table with 10 columns as col_1,col_2,.... col_10. I want to write a select statement that will select a value of one of the row and from one of these 10 columns. I have a variable that will decide which column to select from. Can such query be written where the column name is dynamically decided from a variable.</p>
","<p>Sounds like a bad, denormalized design to me.  </p>

<p>I think a better one would have the table as parent, with rows that contain a foreign key to a separate child table that contains ten rows, one for each of those columns you have now.  Let the parent table set the foreign key according to that magic value when the row is inserted or updated in the parent table.</p>

<p>If the child table is fairly static, this will work.</p>
"
1161,528590,11,1,sql,Dynamic Query in SQL Server,"<p>I have a table with 10 columns as col_1,col_2,.... col_10. I want to write a select statement that will select a value of one of the row and from one of these 10 columns. I have a variable that will decide which column to select from. Can such query be written where the column name is dynamically decided from a variable.</p>
","<p>Yes, using a CASE statement:</p>

<pre><code>SELECT CASE @MyVariable
       WHEN 1 THEN [Col_1]
       WHEN 2 THEN [Col_2]
       ...
       WHEN 10 THEN [Col_10]
       END
</code></pre>

<p>Whether this is a good idea is another question entirely.  You should use better names than Col_1, Col_2, etc.</p>

<p>You could also use a string substitution method, as suggested by others.  However, that is an option of last resort because it can open up your code to sql injection attacks.</p>
"
1160,528590,1,1,sql,Dynamic Query in SQL Server,"<p>I have a table with 10 columns as col_1,col_2,.... col_10. I want to write a select statement that will select a value of one of the row and from one of these 10 columns. I have a variable that will decide which column to select from. Can such query be written where the column name is dynamically decided from a variable.</p>
","<p>Since I don't have enough details, I can't give code. Instead, I'll explain.</p>

<p>Declare a string variable, something like:</p>

<pre><code>declare @sql varchar(5000)
</code></pre>

<p>Set that variable to be the completed SQL string you want (as a string, and not actually querying... so you embed the row-name you want using string concatenation).</p>

<p>Then call: <code>exec(@sql)</code></p>

<p>All set.</p>
"
1195,534530,0,1,sql,Multiple Parameter Search in SQL Server 2000,"<p>I have a search screen in a Visual Basic .Net App that has text boxes for:</p>

<ol>
<li>First Name Varchar(50)</li>
<li>Last Name  Varchar(50)</li>
<li>Middle Name Varchar(50)</li>
<li>DOB DateTime</li>
<li>Home Phone Varchar(10)</li>
<li>Work Phone Varchar(10)</li>
</ol>

<p>How would I create a stored procedure in SQL Server 2000 that would allow me to be able to search on all/some/one of the fields. If user only enters data on say first name and home phone number what would I need to do for the rest of the parameters where data was not entered. I tried the select statement below but it doesn't work properly.</p>

<pre><code>    Select Last_Name, First_Name, Mid_Name, DOB, Home_Phone, Work_Phone from dbo.tblClient
Where Last_Name Like '%@LastName' and
    First_Name Like '%@FirstName' and
    Mid_Name Like '%@MiddleName' and
    DOB Like '%DOB' and
    Home_Phone Like '%@HomePhone' and
    Work_Phone Like '%@WorkPhone'
</code></pre>
","<p>A quick an dirty solution.  </p>

<pre><code>Select Last_Name, First_Name, Mid_Name, DOB, Home_Phone, Work_Phone from dbo.tblClient
Where (Last_Name Like '%' + @LastName OR @LastName Is Null) and
(First_Name Like '%' + @FirstName OR @FirstName Is Null) and
(Mid_Name Like '%' + @MiddleName OR @MiddleName Is Null) and
(DOB Like '%' + @DOB OR @DOB Is Null) and
(Home_Phone Like '%' + @HomePhone OR @HomePhone Is Null and
(Work_Phone Like '%' + @WorkPhone OR @WorkPhone Is Null)
</code></pre>

<p>Note I've correct the parameter usage.  Wouldn't you also want a wildcard on the other side of the parameter as well?  Also would you really use a Like to a Date of Birth field?</p>

<p>This isn't going to perform very well on a large table.  A far more performant solution would be to construct the SQL with only the required fields in the Where clause.</p>
"
1137,523760,0,1,sql,Update trigger behavior in SQL 2005,"<p>I used an Update statement inside a procedure to update a table which has an update trigger. Does the update statement complete after the trigger completes or what?</p>
","<p>triggers are attached to the statement(s) that trigger them and are implicitly the part of transaction that fired them.</p>

<p>For ex :</p>

<p>if triggers are fired because of update , then it helps to understand that database would implicitly insert a <em>begin tran</em> and <em>end tran</em> surrounding that update.   </p>
"
1136,523760,2,1,sql,Update trigger behavior in SQL 2005,"<p>I used an Update statement inside a procedure to update a table which has an update trigger. Does the update statement complete after the trigger completes or what?</p>
","<p>There are two types of triggers in SQL Servers.  INSTEAD OF triggers, and AFTER triggers.  By default, a trigger is an AFTER trigger, meaning this is what happens.  Consider TableA, with an UPDATE AFTER TRIGGER which updates TableB.</p>

<ul>
<li>Issue statement: UPDATE TableA set XXX = 5;</li>
<li>TableA gets updated</li>
<li>The trigger fires, and TableB gets updated.</li>
</ul>
"
1135,523760,2,1,sql,Update trigger behavior in SQL 2005,"<p>I used an Update statement inside a procedure to update a table which has an update trigger. Does the update statement complete after the trigger completes or what?</p>
","<p>the trigger runs as part of the UPDATE statement (after the data in the table has been updated); the proc resumes after this. There are also ""instead of"" triggers that <em>replace</em> the UPDATE statement.</p>

<p>See <a href=""http://msdn.microsoft.com/en-us/magazine/cc164047.aspx"" rel=""nofollow"">here</a> for more.</p>
"
1194,534530,0,1,sql,Multiple Parameter Search in SQL Server 2000,"<p>I have a search screen in a Visual Basic .Net App that has text boxes for:</p>

<ol>
<li>First Name Varchar(50)</li>
<li>Last Name  Varchar(50)</li>
<li>Middle Name Varchar(50)</li>
<li>DOB DateTime</li>
<li>Home Phone Varchar(10)</li>
<li>Work Phone Varchar(10)</li>
</ol>

<p>How would I create a stored procedure in SQL Server 2000 that would allow me to be able to search on all/some/one of the fields. If user only enters data on say first name and home phone number what would I need to do for the rest of the parameters where data was not entered. I tried the select statement below but it doesn't work properly.</p>

<pre><code>    Select Last_Name, First_Name, Mid_Name, DOB, Home_Phone, Work_Phone from dbo.tblClient
Where Last_Name Like '%@LastName' and
    First_Name Like '%@FirstName' and
    Mid_Name Like '%@MiddleName' and
    DOB Like '%DOB' and
    Home_Phone Like '%@HomePhone' and
    Work_Phone Like '%@WorkPhone'
</code></pre>
","<p>In your stored procedure or in your VB, you're going to have to decide how you want to handle no input.  For example I use:</p>

<pre><code>IF ltrim(rtrim(@FirstName)) = ''
SET @FirstName = null
</code></pre>

<p>...in my stored procedure.  You may have to experiment with ORs instead of ANDs.  You're basically telling your query that you have to meet all of those conditions by using AND, regardless of there not being any input to go by.</p>
"
614,272190,1,1,sql,SQL: Complex Deletion,"<p>I basically created some tables to play around with:  I have Two main tables, and a Many-Many join table.  Here is the DDL:  (I am using HSQLDB)</p>

<pre><code>CREATE TABLE PERSON
(
    PERSON_ID INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, 
    NAME VARCHAR(50), MAIN_PERSON_ID INTEGER
)

CREATE TABLE JOB
(
    JOB_ID INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, 
    NAME VARCHAR(50)
)
CREATE TABLE JOB_PERSON
(
    PERSON_ID INTEGER, 
    JOB_ID INTEGER
)
ALTER TABLE JOB_PERSON ADD 
    CONSTRAINT FK_PERSON_JOB FOREIGN KEY(PERSON_ID) 
    REFERENCES PERSON ON DELETE CASCADE ON UPDATE CASCADE 

ALTER TABLE JOB_PERSON ADD
    CONSTRAINT FK_JOB_PERSON FOREIGN KEY(JOB_ID) 
    REFERENCES JOB ON DELETE CASCADE ON UPDATE CASCADE

ALTER TABLE PERSON ADD
    CONSTRAINT FK_PERSON_PERSON FOREIGN KEY(MAIN_PERSON_ID) 
    REFERENCES PERSON ON DELETE CASCADE ON UPDATE CASCADE

insert into person values(null,'Arthur', null);
insert into person values(null,'James',0);
insert into job values(null, 'Programmer')
insert into job values(null, 'Manager')
insert into job_person values(0,0);
insert into job_person values(0,1);
insert into job_person values(1,1);
</code></pre>

<p>I want to create a delete statement that deletes orphans from JOB (if there exists only one entry in the join table for a specific job) based on the PERSON.PERSON_ID.  </p>

<p>In pseudo language:  </p>

<pre><code>delete from job where job_person.job_id=job.job_id 
AND count(job_person.job_id)=1 AND job_person.person_id=X
</code></pre>

<p>Where X is some person_id.  I have tried a lot of different ways; I think it is the ""COUNT"" part that is causing problems.  I am an SQL rookie, so any help would be much appreciated.</p>
","<p>This will delete from your table JOB entries which have no entry in the table JOB_PERSON (Orpheans).</p>

<pre><code>DELETE FROM JOB
WHERE JOB_ID NOT IN (
    SELECT JOB_ID
    FROM JOB_PERSON
)
</code></pre>

<p>You can't delete rows which are linked by a foreign on an other table...</p>
"
832,364230,0,1,sql,Problem with table JOIN in MySQL and aggregation,"<p>I have three tables. This query will write down the right answer (x-lines for btv.id_user with appropriate btv.cas and race.id_zavod</p>

<pre><code>SELECT `btv.id_user`, `btv.id_zavod`,`btv.cas`
FROM `btv`
JOIN `btu` ON `btv.id_user` = `btu.id_user`
JOIN `race` ON 'btv.id_zavod' = `race.id_zavod`
WHERE `race.type` = '8' AND `btv.id_user` = '607'
</code></pre>

<p>Result:</p>

<pre><code>| 607 |  512 | 03:15:58 |  
| 607 |  730 | 03:01:18 |  
| 607 |  164 | 03:07:26 |  
| 607 |  767 | 02:58:31 |  
| 607 | 1147 | 03:06:47 |  
| 607 | 1149 | 03:09:41 |  
| 607 | 1178 | 03:24:20 |
</code></pre>

<p>But when I try to aggregate it to one row by the id_user it return correct min btv.cas but wrong join wrong race.id_zavod</p>

<pre><code>SELECT `btv.id_user`, `btv.id_zavod`, MIN( `btv.cas` )
FROM `btv`
JOIN `btu` ON `btv.id_user` = `btu.id_user`
JOIN `race` ON 'btv.id_zavod' = `race.id_zavod`
WHERE `race.type` = '8' AND `btv.id_user` = '607'
GROUP BY `btv.id_user`
</code></pre>

<p>Result:</p>

<pre><code>| 607 | 512 | 02:58:31 |
</code></pre>
","<p>Try:</p>

<pre><code>SELECT `btv.id_user`, `btv.id_zavod`, MIN( `btv.cas` )
FROM `btv`
Inner JOIN `btu` ON `btv.id_user` = `btu.id_user`
Inner JOIN `race` ON 'btv.id_zavod' = `race.id_zavod`
WHERE `btv.id_user` = '607'
GROUP BY `btv.id_user` having `race.type` = '8'
</code></pre>
"
482,205340,1,1,sql,MySQL LEFT JOIN SELECT not selecting all the left side records?,"<p>I'm getting odd results from a <code>MySQL SELECT</code> query involving a <code>LEFT JOIN</code>, and I can't understand whether my understanding of <code>LEFT JOIN</code> is wrong or whether I'm seeing a genuinely odd behavior.</p>

<p>I have a two tables with a many-to-one relationship: For every record in <code>table 1</code> there are 0 or more records in <code>table 2</code>. I want to select all the records in table 1 with a column that counts the number of related records in table 2. As I understand it, <code>LEFT JOIN</code> should always return all records on the <code>LEFT</code> side of the statement.</p>

<p>Here's a test database that exhibits the problem:</p>

<pre><code>CREATE DATABASE Test;
USE Test;

CREATE TABLE Dates (
   dateID INT UNSIGNED NOT NULL AUTO_INCREMENT,
   date DATE NOT NULL,
   UNIQUE KEY (dateID)
) TYPE=MyISAM;


CREATE TABLE Slots (
   slotID INT UNSIGNED NOT NULL AUTO_INCREMENT,
   dateID INT UNSIGNED NOT NULL,
   UNIQUE KEY (slotID)
) TYPE=MyISAM;

INSERT INTO Dates (date) VALUES ('2008-10-12'),('2008-10-13'),('2008-10-14');
INSERT INTO Slots (dateID) VALUES (3);
</code></pre>

<p>The Dates table has three records, and the Slots 1 - and that record points to the third record in Dates.</p>

<p>If I do the following query..</p>

<pre><code>SELECT d.date, count(s.slotID) FROM Dates AS d LEFT JOIN Slots AS s ON s.dateID=d.dateID GROUP BY s.dateID;
</code></pre>

<p>..I expect to see a table with 3 rows in - two with a count of 0, and one with a count of 1. But what I actually see is this:</p>

<pre><code>+------------+-----------------+
| date       | count(s.slotID) |
+------------+-----------------+
| 2008-10-12 |               0 |
| 2008-10-14 |               1 |
+------------+-----------------+
</code></pre>

<p>The first record with a zero count appears, but the later record with a zero count is ignored. </p>

<p>Am I doing something wrong, or do I just not understand what LEFT JOIN is supposed to do?</p>
","<p>I don't know if this is valid in MySQL but you could probably void this mistake in the future by using the following syntax instead</p>

<pre><code>SELECT date, count(slotID) as slotCount
FROM Dates LEFT OUTER JOIN Slots USING (dateID)
GROUP BY (date)
</code></pre>

<p>By using the USING clause you don't get two dateID's to keep track of.</p>
"
776,350780,1,1,sql,SQL query to calculate visit duration from log table,"<p>I have a MySQL table LOGIN_LOG with fields ID, PLAYER, TIMESTAMP and ACTION. ACTION can be either 'login' or 'logout'. Only around 20% of the logins have an accompanying logout row. For those that do, I want to calculate the average duration.</p>

<p>I'm thinking of something like</p>

<pre><code>select avg(LL2.TIMESTAMP - LL1.TIMESTAMP)
from LOGIN_LOG LL1
inner join LOGIN_LOG LL2 on LL1.PLAYER = LL2.PLAYER and LL2.TIMESTAMP &gt; LL1.TIMESTAMP
left join LOGIN_LOG LL3 on LL3.PLAYER = LL1.PLAYER
  and LL3.TIMESTAMP between LL1.TIMESTAMP + 1 and LL2.TIMESTAMP - 1
  and LL3.ACTION = 'login'
where LL1.ACTION = 'login' and LL2.ACTION = 'logout' and isnull(LL3.ID)
</code></pre>

<p>is this the best way to do it, or is there one more efficient?</p>
","<p>Given the data you have, there probably isn't anything much faster you can do because you have to look at a LOGIN and a LOGOUT record, and ensure there is no other LOGIN (or LOGOUT?) record for the same user between the two.</p>

<p>Alternatively, find a way to ensure that a disconnect records a logout, so that the data is complete (instead of 20% complete).  However, the query probably still has to ensure that the criteria are all met, so it won't help the query all that much.</p>

<p>If you can get the data into a format where the LOGIN and corresponding LOGOUT times are both in the same record, then you can simplify the query immensely.  I'm not clear if the SessionManager does that for you.</p>
"
777,350780,0,1,sql,SQL query to calculate visit duration from log table,"<p>I have a MySQL table LOGIN_LOG with fields ID, PLAYER, TIMESTAMP and ACTION. ACTION can be either 'login' or 'logout'. Only around 20% of the logins have an accompanying logout row. For those that do, I want to calculate the average duration.</p>

<p>I'm thinking of something like</p>

<pre><code>select avg(LL2.TIMESTAMP - LL1.TIMESTAMP)
from LOGIN_LOG LL1
inner join LOGIN_LOG LL2 on LL1.PLAYER = LL2.PLAYER and LL2.TIMESTAMP &gt; LL1.TIMESTAMP
left join LOGIN_LOG LL3 on LL3.PLAYER = LL1.PLAYER
  and LL3.TIMESTAMP between LL1.TIMESTAMP + 1 and LL2.TIMESTAMP - 1
  and LL3.ACTION = 'login'
where LL1.ACTION = 'login' and LL2.ACTION = 'logout' and isnull(LL3.ID)
</code></pre>

<p>is this the best way to do it, or is there one more efficient?</p>
","<p>If only 20% of your users actually log out, this search will not give you a very accurate time of each session. A better way to gauge how long an average user session is would be to take the average time between actions, or avg. time per page. This, then, can multiplied by the average number of pages/actions per visit to give a more accurate time.</p>

<p>Additionally, you can determine avg. time for each page, and then get your session end time = session time to that point + avg time spent on their last page. This will give you a much more fine-grained(and accurate) measure of time spent per session.</p>

<p>Regarding the given SQL, it seems to be more complicated than you really need. This sort of statistical operation can often be better handled/more maintainable in code external to the database where you can have the full power of whichever language you choose, and not just the rather convoluted abilities of SQL for statistical calculations</p>
"
797,353040,2,1,sql,SQL query (order by),"<p>I want to list (a sorted list) all my entries from an attribute called streetNames in my table/relation Customers.
eg. I want to achieve the following order: </p>

<p>Street_1A<br />
Street_1B<br />
Street_2A<br />
Street_2B<br />
Street_12A<br />
Street_12B  </p>

<p>A simple order by streetNames will do a lexical comparision and then Street_12A and B will come before Street_2A/B, and that is not correct. Is it possible to solve this by pure SQL?</p>
","<p>Select street_name from tablex
order by udf_getStreetNumber(street_name)</p>

<p>in your udf_getStreetNumber - write your business rule for stripping out the number</p>

<p>EDIT</p>

<p>I think you can use regex functionality in SQL Server now.  I'd just strip out all non-number characters from the input.</p>
"
798,353040,-1,1,sql,SQL query (order by),"<p>I want to list (a sorted list) all my entries from an attribute called streetNames in my table/relation Customers.
eg. I want to achieve the following order: </p>

<p>Street_1A<br />
Street_1B<br />
Street_2A<br />
Street_2B<br />
Street_12A<br />
Street_12B  </p>

<p>A simple order by streetNames will do a lexical comparision and then Street_12A and B will come before Street_2A/B, and that is not correct. Is it possible to solve this by pure SQL?</p>
","<p>Yes it's possible! But definitely of no interest! If you find somebody here ready to spend a few hours writing down and testing the SP that will split your streetNames into a streetName + streetNumber combination, give me his name: I will submit him a few problems where I thought I had to pay to get the work done.</p>

<p>By the way, can't you split your data into 2 fields, one 'streetName' with only the name of the street, and a new 'buildingNumber' field? (Avoid to name this one 'streetNumber', as, in some countries/cities, streets are given numbers).</p>
"
799,353040,1,1,sql,SQL query (order by),"<p>I want to list (a sorted list) all my entries from an attribute called streetNames in my table/relation Customers.
eg. I want to achieve the following order: </p>

<p>Street_1A<br />
Street_1B<br />
Street_2A<br />
Street_2B<br />
Street_12A<br />
Street_12B  </p>

<p>A simple order by streetNames will do a lexical comparision and then Street_12A and B will come before Street_2A/B, and that is not correct. Is it possible to solve this by pure SQL?</p>
","<p>I'm sure you could by splitting up the streetName field into it's different pieces with something like substr(streetName, 1, find("" "",streetName)) just for the street and so on. But that's going to be pretty messy and it will have to deal with all kinds of special cases (no house number, house number without an addition) or international issues (in the US, adresses are typically like 1 Street).</p>

<p>But if you want to the sorting as you described and that is an important requirement, it would be better to model you streetName in three parts, i.e. street (e.g. ""Street""), house_number (e.g. 1, 2, 12), house_num_addition (e.g. ""A"", ""B""). Then the sort becomes trivial in SQL.</p>
"
800,353040,1,1,sql,SQL query (order by),"<p>I want to list (a sorted list) all my entries from an attribute called streetNames in my table/relation Customers.
eg. I want to achieve the following order: </p>

<p>Street_1A<br />
Street_1B<br />
Street_2A<br />
Street_2B<br />
Street_12A<br />
Street_12B  </p>

<p>A simple order by streetNames will do a lexical comparision and then Street_12A and B will come before Street_2A/B, and that is not correct. Is it possible to solve this by pure SQL?</p>
","<p>If you have write-access to the database I would really recommend converting it all to use 3 separate fields and then using them appropriately. This way you could even do it in PHP (yes, it will take some time, but it will happen only once).
This could be some pain if you have a large code-base, having to check for all of the queries with this table, but it will eventually pay-off later. For example, it will make the search by address much easier.</p>
"
801,353040,-2,1,sql,SQL query (order by),"<p>I want to list (a sorted list) all my entries from an attribute called streetNames in my table/relation Customers.
eg. I want to achieve the following order: </p>

<p>Street_1A<br />
Street_1B<br />
Street_2A<br />
Street_2B<br />
Street_12A<br />
Street_12B  </p>

<p>A simple order by streetNames will do a lexical comparision and then Street_12A and B will come before Street_2A/B, and that is not correct. Is it possible to solve this by pure SQL?</p>
","<p>The reliable way to do it (reliable in terms of ""to sort your data correctly"", not ""to solve your general problem"") is to split the data into street name and house number and sort both of them on their own. But this requires knowing where the house number starts. And this is the tricky part - making the assumption best fits your data.</p>

<p>You should use something like the following to refactor your data and from now on store the house number in a separate field. All this string-juggling won't perform too well when it comes to sorting large data sets.</p>

<p>Assuming it is the last thing in the street name, and it contains a number:</p>

<pre><code>DECLARE @test TABLE
(
  street VARCHAR(100)
)

INSERT INTO @test (street) VALUES('Street')
INSERT INTO @test (street) VALUES('Street 1A')
INSERT INTO @test (street) VALUES('Street1 12B')
INSERT INTO @test (street) VALUES('Street 22A')
INSERT INTO @test (street) VALUES('Street1 200B-8a')
INSERT INTO @test (street) VALUES('')
INSERT INTO @test (street) VALUES(NULL)

SELECT
  street,
  CASE 
    WHEN LEN(street) &gt; 0 AND CHARINDEX(' ', REVERSE(street)) &gt; 0
    THEN CASE
      WHEN RIGHT(street, CHARINDEX(' ', REVERSE(street)) - 1) LIKE '%[0-9]%'
      THEN LEFT(street, LEN(street) - CHARINDEX(' ', REVERSE(street)))
    END
  END street_part,
  CASE 
    WHEN LEN(street) &gt; 0 AND CHARINDEX(' ', REVERSE(street)) &gt; 0
    THEN CASE 
      WHEN RIGHT(street, CHARINDEX(' ', REVERSE(street)) - 1) LIKE '%[0-9]%'
      THEN RIGHT(street, CHARINDEX(' ', REVERSE(street)) - 1)
    END
  END house_part,
  CASE 
    WHEN LEN(street) &gt; 0 AND CHARINDEX(' ', REVERSE(street)) &gt; 0
    THEN CASE 
      WHEN RIGHT(street, CHARINDEX(' ', REVERSE(street)) - 1) LIKE '%[0-9]%'
      THEN CASE
        WHEN PATINDEX('%[a-z]%', LOWER(RIGHT(street, CHARINDEX(' ', REVERSE(street)) - 1))) &gt; 0
        THEN CONVERT(INT, LEFT(RIGHT(street, CHARINDEX(' ', REVERSE(street)) - 1), PATINDEX('%[^0-9]%', LOWER(RIGHT(street, CHARINDEX(' ', REVERSE(street)) - 1))) - 1))
      END
    END
  END house_part_num
FROM
  @test 
ORDER BY
  street_part,
  house_part_num,
  house_part
</code></pre>

<p>This assumes these conditions:</p>

<ul>
<li>a street address <em>can</em> have a house number</li>
<li>a house number <em>must</em> be the last thing in a street address (no ""525 Monroe Av."")</li>
<li>a house number <em>should</em> start with a digit to be sorted correctly</li>
<li>a house number <em>can</em> be a range (""200-205""), this would be sorted below 200</li>
<li>a house number <em>must not</em> contain spaces or recognition fails (When you look at your data, you could apply something like <code>REPLACE(street, ' - ', '-')</code> to sanitize common patterns beforehand.)</li>
<li>the whole thing is still an approximation that certainly deviates from what it would look like in a telephone book, for example</li>
</ul>
"
534,239910,1,1,sql,"SQL CE 3.5 deployment problem, concerning interop between C# and C++","<p>We have a situation where a C# application is working with SQL CE 3.5 . To allow for a legacy program to use some of its features we have produced a C++ dll which uses interop to extract the info that it needs from the C# program. For this to work, the C#-program needs to access the database. Its not a very complex scenario.</p>

<p>When trying to deploy with a private install some problems occur though.
<strong>There is no problem with the C# program, it can access the database and work with it without any problems.</strong></p>

<p><strong>But when trying to access functions in the C#-program through the C++ interop which forces the C#-program to access the database, we get a crash with the exception saying that ""...the Provider: System.Data.SqlServerCe.3.5 is not installed"".</strong></p>

<p>This is obviously because we cannot add a App.config file to the executing program.</p>

<p>How can we get around this? Is there another way to fix this? Any other forms of SQL CE 3.5 install methods are out of the question. So we must get this to work.</p>

<p>Regards,</p>

<p>P</p>

<p><strong>Edit:</strong></p>

<p>I'm not working against SQL CE directly, but through Linq2SQL. I have tried to add config files to all my dll's, it does not help. It seems to only matter if the executable file have got a app.config.</p>

<p>The exception thrown says - The provider System.Data.SqlServerCe.3.5 is not installed.</p>

<p>And the latest function to be called according to the stack trace is
System.Data.Linq.SqlClient.SqlProvider.System.Data.Linq.Provider.IProvider.Initialize(...).</p>

<p><strong>Edit 2</strong></p>

<p>I have added all the files necessery for the deployment to work. As I wrote above, it works if I use the program dll (which uses Linq 2 Sql) through a .net executable with a app.config file that specifies where to look for the SQL CE 3.5 dll. Deployment will <em>not</em> work with only the files, an app.config file is necessary.</p>

<p>The problem is that we have to use the dll file through a C++ executable which have no means of telling .net where to look for the Sql Ce 3.5 dll.</p>
","<p>add the following files to your application folder:</p>

<ul>
<li>sqlceca35.dll</li>
<li>sqlcecompact35.dll</li>
<li>sqlceer35E.dll</li>
<li>sqlceme35.dll</li>
<li>sqlceoledb35.dll</li>
<li>sqlceqp35.dll</li>
<li>sqlcese35.dll</li>
<li>System.Data.SqlServerCe.dll</li>
</ul>

<p>then it will work.</p>

<p>that is necessary if you have not explicitely installed sql server ce 3.5 on the target machine (which is case for most deployments i think).</p>
"
533,239910,0,1,sql,"SQL CE 3.5 deployment problem, concerning interop between C# and C++","<p>We have a situation where a C# application is working with SQL CE 3.5 . To allow for a legacy program to use some of its features we have produced a C++ dll which uses interop to extract the info that it needs from the C# program. For this to work, the C#-program needs to access the database. Its not a very complex scenario.</p>

<p>When trying to deploy with a private install some problems occur though.
<strong>There is no problem with the C# program, it can access the database and work with it without any problems.</strong></p>

<p><strong>But when trying to access functions in the C#-program through the C++ interop which forces the C#-program to access the database, we get a crash with the exception saying that ""...the Provider: System.Data.SqlServerCe.3.5 is not installed"".</strong></p>

<p>This is obviously because we cannot add a App.config file to the executing program.</p>

<p>How can we get around this? Is there another way to fix this? Any other forms of SQL CE 3.5 install methods are out of the question. So we must get this to work.</p>

<p>Regards,</p>

<p>P</p>

<p><strong>Edit:</strong></p>

<p>I'm not working against SQL CE directly, but through Linq2SQL. I have tried to add config files to all my dll's, it does not help. It seems to only matter if the executable file have got a app.config.</p>

<p>The exception thrown says - The provider System.Data.SqlServerCe.3.5 is not installed.</p>

<p>And the latest function to be called according to the stack trace is
System.Data.Linq.SqlClient.SqlProvider.System.Data.Linq.Provider.IProvider.Initialize(...).</p>

<p><strong>Edit 2</strong></p>

<p>I have added all the files necessery for the deployment to work. As I wrote above, it works if I use the program dll (which uses Linq 2 Sql) through a .net executable with a app.config file that specifies where to look for the SQL CE 3.5 dll. Deployment will <em>not</em> work with only the files, an app.config file is necessary.</p>

<p>The problem is that we have to use the dll file through a C++ executable which have no means of telling .net where to look for the Sql Ce 3.5 dll.</p>
","<p>You can add a foo.dll.config file and make sure it lives alongside the DLL. You just need to make sure that you have code in your DLL to determine where it lives on disk, and read the configuration from the same location.</p>

<p>Good luck!</p>
"
802,353040,-1,1,sql,SQL query (order by),"<p>I want to list (a sorted list) all my entries from an attribute called streetNames in my table/relation Customers.
eg. I want to achieve the following order: </p>

<p>Street_1A<br />
Street_1B<br />
Street_2A<br />
Street_2B<br />
Street_12A<br />
Street_12B  </p>

<p>A simple order by streetNames will do a lexical comparision and then Street_12A and B will come before Street_2A/B, and that is not correct. Is it possible to solve this by pure SQL?</p>
","<p>If it is the case that all values in the streetNames column follow the pattern 
StreetName- space - StreetNumber</p>

<p>where StreetName can contain other spaces, but StreetNumber CANNOT, then this will work:</p>

<pre><code>Declare @T Table (streetName VarChar(50))
Insert @T(streetName) Values('Street 1A')
Insert @T(streetName) Values('Street 2A')
Insert @T(streetName) Values('Street 2B')
Insert @T(streetName) Values('Street 12A')
Insert @T(streetName) Values('Another Street 1A')
Insert @T(streetName) Values('Another Street 4A')
Insert @T(streetName) Values('a third Street 12B')
Insert @T(streetName) Values('a third Street 1C')

Select * From @T 
Order By Substring(StreetName, 0, 1 + len(StreetName) - charIndex(' ', reverse(StreetName))),
       Cast(Substring(StreetName, 2 + len(StreetName) - charIndex(' ', reverse(StreetName)),  
    	Case When IsNumeric(Substring(StreetName, 2 + len(StreetName) - charIndex(' ', reverse(StreetName)), 5)) = 1  Then 5
    		 When IsNumeric(Substring(StreetName, 2 + len(StreetName) - charIndex(' ', reverse(StreetName)), 4)) = 1  Then 4
    		 When IsNumeric(Substring(StreetName, 2 + len(StreetName) - charIndex(' ', reverse(StreetName)), 3)) = 1  Then 3
    		 When IsNumeric(Substring(StreetName, 2 + len(StreetName) - charIndex(' ', reverse(StreetName)), 2)) = 1  Then 2
    		 When IsNumeric(Substring(StreetName, 2 + len(StreetName) - charIndex(' ', reverse(StreetName)), 1)) = 1  Then 1
    			End) as Integer),
        Substring(StreetName, len(StreetName) - charIndex(' ', reverse(StreetName)) +
    		Case When IsNumeric(Substring(StreetName, 2 + len(StreetName) - charIndex(' ', reverse(StreetName)), 5)) = 1  Then 5
    		 When IsNumeric(Substring(StreetName, 2 + len(StreetName) - charIndex(' ', reverse(StreetName)), 4)) = 1  Then 6
    		 When IsNumeric(Substring(StreetName, 2 + len(StreetName) - charIndex(' ', reverse(StreetName)), 3)) = 1  Then 5
    		 When IsNumeric(Substring(StreetName, 2 + len(StreetName) - charIndex(' ', reverse(StreetName)), 2)) = 1  Then 4
    		 When IsNumeric(Substring(StreetName, 2 + len(StreetName) - charIndex(' ', reverse(StreetName)), 1)) = 1  Then 3
    			End, Len(StreetName))
</code></pre>
"
803,353040,2,1,sql,SQL query (order by),"<p>I want to list (a sorted list) all my entries from an attribute called streetNames in my table/relation Customers.
eg. I want to achieve the following order: </p>

<p>Street_1A<br />
Street_1B<br />
Street_2A<br />
Street_2B<br />
Street_12A<br />
Street_12B  </p>

<p>A simple order by streetNames will do a lexical comparision and then Street_12A and B will come before Street_2A/B, and that is not correct. Is it possible to solve this by pure SQL?</p>
","<p>For the record: it is called <strong>Natural Sort Order</strong>, and there is a <a href=""http://www.codinghorror.com/blog/archives/001018.html"" rel=""nofollow"">Coding horror article</a>
in the subject.</p>

<p>I guess you can do it in SQL using some of the code showed here, but it will by always in a case by case scenario.</p>
"
515,218100,3,1,sql,ORM support for compound primary keys,"<p>I've read that compound primary keys will <a href=""http://stackoverflow.com/questions/107404/what-are-the-down-sides-of-using-a-compositecompound-primary-key#108337"">confuse the hell out of typical ORM code generators</a>. Which ORMs work best with compound PKs and which to avoid? (I've a particular interest in .NET)</p>
","<p>I'm using NHibernate successfully with compound keys.</p>

<pre><code>&lt;class name=""UserProfileField"" table=""UserProfileFields""&gt;
    &lt;composite-id&gt;
        &lt;key-many-to-one name=""Parent"" column=""UserId"" lazy=""false""/&gt;
        &lt;key-property name=""FieldName""/&gt;
    &lt;/composite-id&gt;
...
</code></pre>
"
484,205950,5,1,sql,Dynamically look up column names for a table while in an sql query,"<p>I'm writing SQL (for Oracle) like:</p>

<pre>
INSERT INTO Schema1.tableA SELECT * FROM Schema2.tableA;
</pre>

<p>where Schema1.tableA and Schema2.tableA have the same columns. However, it seems like this is unsafe, since the order of the columns coming back in the SELECT is undefined. What I should be doing is:</p>

<pre>
INSERT INTO Schema1.tableA (col1, col2, ... colN) 
SELECT (col1, col2, ... colN) FROM Schema2.tableA;
</pre>

<p>I'm doing this for lots of tables using some scripts, so what I'd like to do is write something like:</p>

<pre>
INSERT INTO Schema1.tableA (foo(Schema1.tableA)) 
SELECT (foo(Schema1.tableA)) FROM Schema2.tableA;
</pre>

<p>Where foo is some nifty magic that extracts the column names from table one and packages them in the appropriate syntax. Thoughts?</p>
","<p>This PL/SQL should do it:</p>

<pre><code>declare
    l_cols long;
    l_sql  long;
begin
    for r in (select column_name from all_tab_columns
              where  table_name = 'TABLEA'
              and    owner = 'SCHEMA1'
             )
    loop
       l_cols := l_cols || ',' || r.column_name;
    end loop;

    -- Remove leading comma
    l_cols := substr(l_cols, 2);

    l_sql := 'insert into schema1.tableA (' || l_cols || ') select ' 
             || l_cols || ' from schema2.tableA';

    execute immediate l_sql;

end;
/
</code></pre>
"
483,205950,1,1,sql,Dynamically look up column names for a table while in an sql query,"<p>I'm writing SQL (for Oracle) like:</p>

<pre>
INSERT INTO Schema1.tableA SELECT * FROM Schema2.tableA;
</pre>

<p>where Schema1.tableA and Schema2.tableA have the same columns. However, it seems like this is unsafe, since the order of the columns coming back in the SELECT is undefined. What I should be doing is:</p>

<pre>
INSERT INTO Schema1.tableA (col1, col2, ... colN) 
SELECT (col1, col2, ... colN) FROM Schema2.tableA;
</pre>

<p>I'm doing this for lots of tables using some scripts, so what I'd like to do is write something like:</p>

<pre>
INSERT INTO Schema1.tableA (foo(Schema1.tableA)) 
SELECT (foo(Schema1.tableA)) FROM Schema2.tableA;
</pre>

<p>Where foo is some nifty magic that extracts the column names from table one and packages them in the appropriate syntax. Thoughts?</p>
","<p>You may need to construct the insert statements dynamically using <a href=""http://download.oracle.com/docs/cd/B28359_01/server.111/b28320/statviews_5429.htm#REFRN26277"" rel=""nofollow"">USER_TAB_COLUMNS</a> and execute them using <a href=""http://download.oracle.com/docs/cd/B28359_01/appdev.111/b28370/executeimmediate_statement.htm#LNPLS01317"" rel=""nofollow"">EXECUTE IMMEDIATE</a>.</p>
"
831,364230,1,1,sql,Problem with table JOIN in MySQL and aggregation,"<p>I have three tables. This query will write down the right answer (x-lines for btv.id_user with appropriate btv.cas and race.id_zavod</p>

<pre><code>SELECT `btv.id_user`, `btv.id_zavod`,`btv.cas`
FROM `btv`
JOIN `btu` ON `btv.id_user` = `btu.id_user`
JOIN `race` ON 'btv.id_zavod' = `race.id_zavod`
WHERE `race.type` = '8' AND `btv.id_user` = '607'
</code></pre>

<p>Result:</p>

<pre><code>| 607 |  512 | 03:15:58 |  
| 607 |  730 | 03:01:18 |  
| 607 |  164 | 03:07:26 |  
| 607 |  767 | 02:58:31 |  
| 607 | 1147 | 03:06:47 |  
| 607 | 1149 | 03:09:41 |  
| 607 | 1178 | 03:24:20 |
</code></pre>

<p>But when I try to aggregate it to one row by the id_user it return correct min btv.cas but wrong join wrong race.id_zavod</p>

<pre><code>SELECT `btv.id_user`, `btv.id_zavod`, MIN( `btv.cas` )
FROM `btv`
JOIN `btu` ON `btv.id_user` = `btu.id_user`
JOIN `race` ON 'btv.id_zavod' = `race.id_zavod`
WHERE `race.type` = '8' AND `btv.id_user` = '607'
GROUP BY `btv.id_user`
</code></pre>

<p>Result:</p>

<pre><code>| 607 | 512 | 02:58:31 |
</code></pre>
","<p>The query you have written:</p>

<pre><code>SELECT `btv.id_user`, `btv.id_zavod`, MIN( `btv.cas` )
FROM `btv`
JOIN `btu` ON `btv.id_user` = `btu.id_user`
JOIN `race` ON 'btv.id_zavod' = `race.id_zavod`
WHERE `race.type` = '8' AND `btv.id_user` = '607'
GROUP BY `btv.id_user`</code></pre>

<p>won't run.  You need a group by id_zavod or something.  Can you tell us what query you are really running?  And what result set you expect?</p>
"
402,182130,1,1,sql,SQL - state machine - reporting on historical data based on changeset,"<p>I want to record user states and then be able to report historically based on the record of changes we've kept. I'm trying to do this in SQL (using PostgreSQL) and I have a proposed structure for recording user changes like the following.</p>

<pre><code>CREATE TABLE users (
  userid SERIAL NOT NULL PRIMARY KEY, 
  name VARCHAR(40), 
  status CHAR NOT NULL
);

CREATE TABLE status_log (
  logid SERIAL, 
  userid INTEGER NOT NULL REFERENCES users(userid), 
  status CHAR NOT NULL, 
  logcreated TIMESTAMP
);
</code></pre>

<p>That's my proposed table structure, based on the data.</p>

<p>For the status field 'a' represents an active user and 's' represents a suspended user,</p>

<pre><code>INSERT INTO status_log (userid, status, logcreated) VALUES (1, 's', '2008-01-01'); 
INSERT INTO status_log (userid, status, logcreated) VALUES (1, 'a', '2008-02-01');
</code></pre>

<p>So this user was suspended on 1st Jan and active again on 1st of February.</p>

<p>If I wanted to get a suspended list of customers on 15th January 2008, then userid 1 should show up. If I get a suspended list of customers on 15th February 2008, then userid 1 should not show up.</p>

<p>1) Is this the best way to structure this data for this kind of query?</p>

<p>2) How do I query the data in either this structure or in your proposed modified structure so that I can simply have a date (say 15th January) and find a list of customers that had an active status on that date in SQL only? Is this a job for SQL?</p>
","<p>Does Postgres support analytic queries? This would give the active users on 2008-02-15</p>

<pre><code>select userid
from
(
select logid, 
       userid, 
       status, 
       logcreated,
       max(logcreated) over (partition by userid) max_logcreated_by_user
from   status_log
where  logcreated &lt;= date '2008-02-15'
)
where  logcreated = max_logcreated_by_user
  and  status     = 'a'
/
</code></pre>
"
481,205340,0,1,sql,MySQL LEFT JOIN SELECT not selecting all the left side records?,"<p>I'm getting odd results from a <code>MySQL SELECT</code> query involving a <code>LEFT JOIN</code>, and I can't understand whether my understanding of <code>LEFT JOIN</code> is wrong or whether I'm seeing a genuinely odd behavior.</p>

<p>I have a two tables with a many-to-one relationship: For every record in <code>table 1</code> there are 0 or more records in <code>table 2</code>. I want to select all the records in table 1 with a column that counts the number of related records in table 2. As I understand it, <code>LEFT JOIN</code> should always return all records on the <code>LEFT</code> side of the statement.</p>

<p>Here's a test database that exhibits the problem:</p>

<pre><code>CREATE DATABASE Test;
USE Test;

CREATE TABLE Dates (
   dateID INT UNSIGNED NOT NULL AUTO_INCREMENT,
   date DATE NOT NULL,
   UNIQUE KEY (dateID)
) TYPE=MyISAM;


CREATE TABLE Slots (
   slotID INT UNSIGNED NOT NULL AUTO_INCREMENT,
   dateID INT UNSIGNED NOT NULL,
   UNIQUE KEY (slotID)
) TYPE=MyISAM;

INSERT INTO Dates (date) VALUES ('2008-10-12'),('2008-10-13'),('2008-10-14');
INSERT INTO Slots (dateID) VALUES (3);
</code></pre>

<p>The Dates table has three records, and the Slots 1 - and that record points to the third record in Dates.</p>

<p>If I do the following query..</p>

<pre><code>SELECT d.date, count(s.slotID) FROM Dates AS d LEFT JOIN Slots AS s ON s.dateID=d.dateID GROUP BY s.dateID;
</code></pre>

<p>..I expect to see a table with 3 rows in - two with a count of 0, and one with a count of 1. But what I actually see is this:</p>

<pre><code>+------------+-----------------+
| date       | count(s.slotID) |
+------------+-----------------+
| 2008-10-12 |               0 |
| 2008-10-14 |               1 |
+------------+-----------------+
</code></pre>

<p>The first record with a zero count appears, but the later record with a zero count is ignored. </p>

<p>Am I doing something wrong, or do I just not understand what LEFT JOIN is supposed to do?</p>
","<p>replace GROUP BY s.dateID with d.dateID.</p>
"
480,205340,1,1,sql,MySQL LEFT JOIN SELECT not selecting all the left side records?,"<p>I'm getting odd results from a <code>MySQL SELECT</code> query involving a <code>LEFT JOIN</code>, and I can't understand whether my understanding of <code>LEFT JOIN</code> is wrong or whether I'm seeing a genuinely odd behavior.</p>

<p>I have a two tables with a many-to-one relationship: For every record in <code>table 1</code> there are 0 or more records in <code>table 2</code>. I want to select all the records in table 1 with a column that counts the number of related records in table 2. As I understand it, <code>LEFT JOIN</code> should always return all records on the <code>LEFT</code> side of the statement.</p>

<p>Here's a test database that exhibits the problem:</p>

<pre><code>CREATE DATABASE Test;
USE Test;

CREATE TABLE Dates (
   dateID INT UNSIGNED NOT NULL AUTO_INCREMENT,
   date DATE NOT NULL,
   UNIQUE KEY (dateID)
) TYPE=MyISAM;


CREATE TABLE Slots (
   slotID INT UNSIGNED NOT NULL AUTO_INCREMENT,
   dateID INT UNSIGNED NOT NULL,
   UNIQUE KEY (slotID)
) TYPE=MyISAM;

INSERT INTO Dates (date) VALUES ('2008-10-12'),('2008-10-13'),('2008-10-14');
INSERT INTO Slots (dateID) VALUES (3);
</code></pre>

<p>The Dates table has three records, and the Slots 1 - and that record points to the third record in Dates.</p>

<p>If I do the following query..</p>

<pre><code>SELECT d.date, count(s.slotID) FROM Dates AS d LEFT JOIN Slots AS s ON s.dateID=d.dateID GROUP BY s.dateID;
</code></pre>

<p>..I expect to see a table with 3 rows in - two with a count of 0, and one with a count of 1. But what I actually see is this:</p>

<pre><code>+------------+-----------------+
| date       | count(s.slotID) |
+------------+-----------------+
| 2008-10-12 |               0 |
| 2008-10-14 |               1 |
+------------+-----------------+
</code></pre>

<p>The first record with a zero count appears, but the later record with a zero count is ignored. </p>

<p>Am I doing something wrong, or do I just not understand what LEFT JOIN is supposed to do?</p>
","<p>The dateid for 10-12 and 10-13 are groupd together by you. Since they are 2 null values the count is evaluated to 0</p>
"
479,205340,6,1,sql,MySQL LEFT JOIN SELECT not selecting all the left side records?,"<p>I'm getting odd results from a <code>MySQL SELECT</code> query involving a <code>LEFT JOIN</code>, and I can't understand whether my understanding of <code>LEFT JOIN</code> is wrong or whether I'm seeing a genuinely odd behavior.</p>

<p>I have a two tables with a many-to-one relationship: For every record in <code>table 1</code> there are 0 or more records in <code>table 2</code>. I want to select all the records in table 1 with a column that counts the number of related records in table 2. As I understand it, <code>LEFT JOIN</code> should always return all records on the <code>LEFT</code> side of the statement.</p>

<p>Here's a test database that exhibits the problem:</p>

<pre><code>CREATE DATABASE Test;
USE Test;

CREATE TABLE Dates (
   dateID INT UNSIGNED NOT NULL AUTO_INCREMENT,
   date DATE NOT NULL,
   UNIQUE KEY (dateID)
) TYPE=MyISAM;


CREATE TABLE Slots (
   slotID INT UNSIGNED NOT NULL AUTO_INCREMENT,
   dateID INT UNSIGNED NOT NULL,
   UNIQUE KEY (slotID)
) TYPE=MyISAM;

INSERT INTO Dates (date) VALUES ('2008-10-12'),('2008-10-13'),('2008-10-14');
INSERT INTO Slots (dateID) VALUES (3);
</code></pre>

<p>The Dates table has three records, and the Slots 1 - and that record points to the third record in Dates.</p>

<p>If I do the following query..</p>

<pre><code>SELECT d.date, count(s.slotID) FROM Dates AS d LEFT JOIN Slots AS s ON s.dateID=d.dateID GROUP BY s.dateID;
</code></pre>

<p>..I expect to see a table with 3 rows in - two with a count of 0, and one with a count of 1. But what I actually see is this:</p>

<pre><code>+------------+-----------------+
| date       | count(s.slotID) |
+------------+-----------------+
| 2008-10-12 |               0 |
| 2008-10-14 |               1 |
+------------+-----------------+
</code></pre>

<p>The first record with a zero count appears, but the later record with a zero count is ignored. </p>

<p>Am I doing something wrong, or do I just not understand what LEFT JOIN is supposed to do?</p>
","<p>You need to <code>GROUP BY d.dateID</code>.  In two of your cases, <code>s.DateID</code> is <code>NULL</code> (<code>LEFT JOIN</code>) and these are combined together.</p>

<p>I think you will also find that this is invalid (ANSI) SQL, because d.date is not part of a <code>GROUP BY</code> or the result of an aggregate operation, and should not be able to be <code>SELECT</code>ed.</p>
"
478,205340,1,1,sql,MySQL LEFT JOIN SELECT not selecting all the left side records?,"<p>I'm getting odd results from a <code>MySQL SELECT</code> query involving a <code>LEFT JOIN</code>, and I can't understand whether my understanding of <code>LEFT JOIN</code> is wrong or whether I'm seeing a genuinely odd behavior.</p>

<p>I have a two tables with a many-to-one relationship: For every record in <code>table 1</code> there are 0 or more records in <code>table 2</code>. I want to select all the records in table 1 with a column that counts the number of related records in table 2. As I understand it, <code>LEFT JOIN</code> should always return all records on the <code>LEFT</code> side of the statement.</p>

<p>Here's a test database that exhibits the problem:</p>

<pre><code>CREATE DATABASE Test;
USE Test;

CREATE TABLE Dates (
   dateID INT UNSIGNED NOT NULL AUTO_INCREMENT,
   date DATE NOT NULL,
   UNIQUE KEY (dateID)
) TYPE=MyISAM;


CREATE TABLE Slots (
   slotID INT UNSIGNED NOT NULL AUTO_INCREMENT,
   dateID INT UNSIGNED NOT NULL,
   UNIQUE KEY (slotID)
) TYPE=MyISAM;

INSERT INTO Dates (date) VALUES ('2008-10-12'),('2008-10-13'),('2008-10-14');
INSERT INTO Slots (dateID) VALUES (3);
</code></pre>

<p>The Dates table has three records, and the Slots 1 - and that record points to the third record in Dates.</p>

<p>If I do the following query..</p>

<pre><code>SELECT d.date, count(s.slotID) FROM Dates AS d LEFT JOIN Slots AS s ON s.dateID=d.dateID GROUP BY s.dateID;
</code></pre>

<p>..I expect to see a table with 3 rows in - two with a count of 0, and one with a count of 1. But what I actually see is this:</p>

<pre><code>+------------+-----------------+
| date       | count(s.slotID) |
+------------+-----------------+
| 2008-10-12 |               0 |
| 2008-10-14 |               1 |
+------------+-----------------+
</code></pre>

<p>The first record with a zero count appears, but the later record with a zero count is ignored. </p>

<p>Am I doing something wrong, or do I just not understand what LEFT JOIN is supposed to do?</p>
","<p>Try removing the GROUP BY s.dateID</p>
"
477,205340,2,1,sql,MySQL LEFT JOIN SELECT not selecting all the left side records?,"<p>I'm getting odd results from a <code>MySQL SELECT</code> query involving a <code>LEFT JOIN</code>, and I can't understand whether my understanding of <code>LEFT JOIN</code> is wrong or whether I'm seeing a genuinely odd behavior.</p>

<p>I have a two tables with a many-to-one relationship: For every record in <code>table 1</code> there are 0 or more records in <code>table 2</code>. I want to select all the records in table 1 with a column that counts the number of related records in table 2. As I understand it, <code>LEFT JOIN</code> should always return all records on the <code>LEFT</code> side of the statement.</p>

<p>Here's a test database that exhibits the problem:</p>

<pre><code>CREATE DATABASE Test;
USE Test;

CREATE TABLE Dates (
   dateID INT UNSIGNED NOT NULL AUTO_INCREMENT,
   date DATE NOT NULL,
   UNIQUE KEY (dateID)
) TYPE=MyISAM;


CREATE TABLE Slots (
   slotID INT UNSIGNED NOT NULL AUTO_INCREMENT,
   dateID INT UNSIGNED NOT NULL,
   UNIQUE KEY (slotID)
) TYPE=MyISAM;

INSERT INTO Dates (date) VALUES ('2008-10-12'),('2008-10-13'),('2008-10-14');
INSERT INTO Slots (dateID) VALUES (3);
</code></pre>

<p>The Dates table has three records, and the Slots 1 - and that record points to the third record in Dates.</p>

<p>If I do the following query..</p>

<pre><code>SELECT d.date, count(s.slotID) FROM Dates AS d LEFT JOIN Slots AS s ON s.dateID=d.dateID GROUP BY s.dateID;
</code></pre>

<p>..I expect to see a table with 3 rows in - two with a count of 0, and one with a count of 1. But what I actually see is this:</p>

<pre><code>+------------+-----------------+
| date       | count(s.slotID) |
+------------+-----------------+
| 2008-10-12 |               0 |
| 2008-10-14 |               1 |
+------------+-----------------+
</code></pre>

<p>The first record with a zero count appears, but the later record with a zero count is ignored. </p>

<p>Am I doing something wrong, or do I just not understand what LEFT JOIN is supposed to do?</p>
","<p>I think you mean to group by d.dateId.</p>
"
449,196480,1,1,sql,Identify full vs half yearly datasets in SQL,"<p>I have a table with two fields of interest for this particular exercise: a CHAR(3) ID and a DATETIME.  The ID identifies the submitter of the data - several thousand rows.  The DATETIME is not necessarily unique, either.  (The primary keys are other fields of the table.)</p>

<p>Data for this table is submitted every six months.  In December, we receive July-December data from each submitter, and in June we receive July-June data.  My task is to write a script that identifies people who have only submitted half their data, or only submitted January-June data in June.</p>

<p>...Does anyone have a solution?</p>
","<p>For interest, this is what I wound up using.  It was based off Stephen's answer, but with a few adaptations.  I don't yet have the reputation to upvote him.  :).</p>

<p>It's part of a larger script that's run every six months, but we're only checking this every twelve months - hence the ""If FullYear = 1"".  I'm sure there's a more stylish way to identify the boundary dates, but this seems to work.</p>

<pre><code>IF @FullYear = 1 
    BEGIN
        DECLARE @FirstDate AS DATETIME
        DECLARE @LastDayFirstYear AS DATETIME
        DECLARE @SecondYear AS INT
        DECLARE @NewYearsDay AS DATETIME
        DECLARE @LastDate AS DATETIME

        SELECT @FirstDate = MIN(dscdate), @LastDate = MAX(dscdate)
        FROM    TheTable

        SELECT  @SecondYear = DATEPART(yyyy, @FirstDate) + 1
        SELECT  @NewYearsDay = CAST(CAST(@SecondYear AS VARCHAR) 
            + '-01-01' AS DATETIME)

        INSERT  INTO @AuditResults
                SELECT DISTINCT
                    'Submitter missing Jan-Jun data', t.id
                FROM    TheTable t
                WHERE   
                    EXISTS ( 
                        SELECT 1
                        FROM   TheTable t1
                        WHERE  t.id = t1.id 
                            AND t1.date &gt;= @FirstDate
                            AND t1.date &lt; @NewYearsDay )
                    AND NOT EXISTS ( 
                        SELECT 1
                        FROM   TheTable t2
                        WHERE  t2.date &gt;= @NewYearsDay
                        AND t2.date &lt;= @LastDate
                        AND t2.id = t.id
                        GROUP BY t2.id )
                GROUP BY t.id
    END
</code></pre>
"
833,364230,0,1,sql,Problem with table JOIN in MySQL and aggregation,"<p>I have three tables. This query will write down the right answer (x-lines for btv.id_user with appropriate btv.cas and race.id_zavod</p>

<pre><code>SELECT `btv.id_user`, `btv.id_zavod`,`btv.cas`
FROM `btv`
JOIN `btu` ON `btv.id_user` = `btu.id_user`
JOIN `race` ON 'btv.id_zavod' = `race.id_zavod`
WHERE `race.type` = '8' AND `btv.id_user` = '607'
</code></pre>

<p>Result:</p>

<pre><code>| 607 |  512 | 03:15:58 |  
| 607 |  730 | 03:01:18 |  
| 607 |  164 | 03:07:26 |  
| 607 |  767 | 02:58:31 |  
| 607 | 1147 | 03:06:47 |  
| 607 | 1149 | 03:09:41 |  
| 607 | 1178 | 03:24:20 |
</code></pre>

<p>But when I try to aggregate it to one row by the id_user it return correct min btv.cas but wrong join wrong race.id_zavod</p>

<pre><code>SELECT `btv.id_user`, `btv.id_zavod`, MIN( `btv.cas` )
FROM `btv`
JOIN `btu` ON `btv.id_user` = `btu.id_user`
JOIN `race` ON 'btv.id_zavod' = `race.id_zavod`
WHERE `race.type` = '8' AND `btv.id_user` = '607'
GROUP BY `btv.id_user`
</code></pre>

<p>Result:</p>

<pre><code>| 607 | 512 | 02:58:31 |
</code></pre>
","<p>When you use GROUP BY, the columns in the select-list must satisfy one of the following:</p>

<ul>
<li>Column is named in the GROUP BY (e.g. <code>btv.id_user</code> in your example)</li>
<li>Column is inside an aggregate function (e.g. <code>MIN( btv.cas )</code> )</li>
<li>Column is a <em>functional dependency</em> of the column(s) you named in the GROUP BY.</li>
</ul>

<p>This is the error in your query:  <code>btv.id_zavod</code> has many values for each value of <code>btv.id_user</code>.  This does not satisfy functional dependency.  There must be only one value in <code>id_zavod</code> for each value of <code>id_user</code> for it to be a functional dependency.</p>

<p>In some database brands, this query would actually give you an error. MySQL is more flexible, trusting you to name only columns in the select-list that are functional dependencies of the column(s) you named in the GROUP BY.</p>

<p>Here's a query that returns what you want, the MIN value of <code>btv.cas</code> per <code>id_user</code>, with the corresponding value of <code>btv.id_zavod</code>:</p>

<pre><code>SELECT b1.id_user, b1.id_zavod, b1.cas
FROM btv AS b1
 JOIN btu ON (b1.id_user = btu.id_user)
 JOIN race ON (b1.id_zavod = race.id_zavod)
 LEFT OUTER JOIN btv AS b2 ON (b1.id_user = bt2.id_user AND 
   (b1.cas &gt; b2.cas OR (b1.cas = b2.cas AND b1.primarykey &gt; b2.primarykey))
WHERE race.type = '8' AND b1.id_user = '607'
 AND b2.id_user IS NULL;
</code></pre>

<p>In other words, you need to do your join as before, but then join that to <code>btv</code> again, to see if there's another row with the same <code>id_user</code> value and a smaller value in <code>cas</code>.  Use an OUTER JOIN, because you're looking for the case where there is no match.  You can test for that with <code>b2.id_user IS NULL</code>, because OUTER JOIN makes all columns NULL when there is no match.</p>

<p>Note that there could be ties, so we add the extra term using the primary key as the tiebreaker.</p>

<p>You don't need to use GROUP BY in this query.  That's taken care of implicitly, because there will be only one row that satisfies the OUTER JOIN condition.</p>
"
448,196480,1,1,sql,Identify full vs half yearly datasets in SQL,"<p>I have a table with two fields of interest for this particular exercise: a CHAR(3) ID and a DATETIME.  The ID identifies the submitter of the data - several thousand rows.  The DATETIME is not necessarily unique, either.  (The primary keys are other fields of the table.)</p>

<p>Data for this table is submitted every six months.  In December, we receive July-December data from each submitter, and in June we receive July-June data.  My task is to write a script that identifies people who have only submitted half their data, or only submitted January-June data in June.</p>

<p>...Does anyone have a solution?</p>
","<p>from your description, i wouldn't worry about the efficiency of the query since apparently it only needs to run twice a year!</p>

<p>there are a few ways to do this, which one is 'best' depends on the data that you have. the datediff (on max/min date values) you suggested should work, another option is to just count records for each submitted within each date range, e.g.</p>

<pre><code>select * from (
    select T.submitterId,
        (select count(*) 
        from TABLE T1
        where T1.datefield between [july] and [december]
        and T1.submitterId = T.submitterId
        group by T1.submitterId) as JDCount,
        (select count(*)
        from TABLE T2
        where T2.datefield between [december] and [june]
        and T2.submitterId = T.submitterId
        group by T2.submitterId) as DJCount
    from TABLE T) X
where X.JDCount &lt;= 0 OR X.DJCount &lt;= 0
</code></pre>

<p>caveat: untested query off the top of my head; your mileage may vary</p>
"
834,364230,0,1,sql,Problem with table JOIN in MySQL and aggregation,"<p>I have three tables. This query will write down the right answer (x-lines for btv.id_user with appropriate btv.cas and race.id_zavod</p>

<pre><code>SELECT `btv.id_user`, `btv.id_zavod`,`btv.cas`
FROM `btv`
JOIN `btu` ON `btv.id_user` = `btu.id_user`
JOIN `race` ON 'btv.id_zavod' = `race.id_zavod`
WHERE `race.type` = '8' AND `btv.id_user` = '607'
</code></pre>

<p>Result:</p>

<pre><code>| 607 |  512 | 03:15:58 |  
| 607 |  730 | 03:01:18 |  
| 607 |  164 | 03:07:26 |  
| 607 |  767 | 02:58:31 |  
| 607 | 1147 | 03:06:47 |  
| 607 | 1149 | 03:09:41 |  
| 607 | 1178 | 03:24:20 |
</code></pre>

<p>But when I try to aggregate it to one row by the id_user it return correct min btv.cas but wrong join wrong race.id_zavod</p>

<pre><code>SELECT `btv.id_user`, `btv.id_zavod`, MIN( `btv.cas` )
FROM `btv`
JOIN `btu` ON `btv.id_user` = `btu.id_user`
JOIN `race` ON 'btv.id_zavod' = `race.id_zavod`
WHERE `race.type` = '8' AND `btv.id_user` = '607'
GROUP BY `btv.id_user`
</code></pre>

<p>Result:</p>

<pre><code>| 607 | 512 | 02:58:31 |
</code></pre>
","<p>I'm not sure what you are trying to accomplish, but are you maybe looking for the <a href=""http://dev.mysql.com/doc/refman/5.0/en/group-by-functions.html#function_group-concat"" rel=""nofollow"" title=""group by functions @ mysql.com"">GROUP_CONCAT function?</a>?</p>
"
835,364230,0,1,sql,Problem with table JOIN in MySQL and aggregation,"<p>I have three tables. This query will write down the right answer (x-lines for btv.id_user with appropriate btv.cas and race.id_zavod</p>

<pre><code>SELECT `btv.id_user`, `btv.id_zavod`,`btv.cas`
FROM `btv`
JOIN `btu` ON `btv.id_user` = `btu.id_user`
JOIN `race` ON 'btv.id_zavod' = `race.id_zavod`
WHERE `race.type` = '8' AND `btv.id_user` = '607'
</code></pre>

<p>Result:</p>

<pre><code>| 607 |  512 | 03:15:58 |  
| 607 |  730 | 03:01:18 |  
| 607 |  164 | 03:07:26 |  
| 607 |  767 | 02:58:31 |  
| 607 | 1147 | 03:06:47 |  
| 607 | 1149 | 03:09:41 |  
| 607 | 1178 | 03:24:20 |
</code></pre>

<p>But when I try to aggregate it to one row by the id_user it return correct min btv.cas but wrong join wrong race.id_zavod</p>

<pre><code>SELECT `btv.id_user`, `btv.id_zavod`, MIN( `btv.cas` )
FROM `btv`
JOIN `btu` ON `btv.id_user` = `btu.id_user`
JOIN `race` ON 'btv.id_zavod' = `race.id_zavod`
WHERE `race.type` = '8' AND `btv.id_user` = '607'
GROUP BY `btv.id_user`
</code></pre>

<p>Result:</p>

<pre><code>| 607 | 512 | 02:58:31 |
</code></pre>
","<p>Are you simply trying to fetch the lowest btv.cas value and its other corresponding columns? If so, you could just order by btv.cas and limit to 1 hit:</p>

<pre><code>SELECT `btv.id_user`, `btv.id_zavod`,`btv.cas`
FROM `btv`
JOIN `btu` ON `btv.id_user` = `btu.id_user`
JOIN `race` ON 'btv.id_zavod' = `race.id_zavod`
WHERE `race.type` = '8' AND `btv.id_user` = '607'
ORDER BY `btv.cas` LIMIT 1</code></pre>
"
839,371490,2,1,sql,Oracle SQL - Parsing a name string and converting it to first initial & last name,"<p>Does anyone know how to turn this string: ""Smith, John R""<br>
Into this string: ""jsmith"" ?</p>

<p>I need to lowercase everything with lower()<br>
Find where the comma is and track it's integer location value<br>
Get the first character after that comma and put it in front of the string<br>
Then get the entire last name and stick it after the first initial.<br><br>
Sidenote - instr() function is not compatible with my version<br><br>
Thanks for any help!</p>
","<p>Start by writing your own INSTR function - call it my_instr for example.  It will start at char 1 and loop until it finds a ','.</p>

<p>Then use as you would INSTR.</p>
"
840,371490,1,1,sql,Oracle SQL - Parsing a name string and converting it to first initial & last name,"<p>Does anyone know how to turn this string: ""Smith, John R""<br>
Into this string: ""jsmith"" ?</p>

<p>I need to lowercase everything with lower()<br>
Find where the comma is and track it's integer location value<br>
Get the first character after that comma and put it in front of the string<br>
Then get the entire last name and stick it after the first initial.<br><br>
Sidenote - instr() function is not compatible with my version<br><br>
Thanks for any help!</p>
","<p>instr() is not compatible with your version of what? Oracle? Are you using version 4 or something?</p>
"
841,371490,1,1,sql,Oracle SQL - Parsing a name string and converting it to first initial & last name,"<p>Does anyone know how to turn this string: ""Smith, John R""<br>
Into this string: ""jsmith"" ?</p>

<p>I need to lowercase everything with lower()<br>
Find where the comma is and track it's integer location value<br>
Get the first character after that comma and put it in front of the string<br>
Then get the entire last name and stick it after the first initial.<br><br>
Sidenote - instr() function is not compatible with my version<br><br>
Thanks for any help!</p>
","<p>I have a hard time believing you dont have access to a proper instr() but if thats the case, implement your own version.</p>

<p>Assuming you have that straightened out:</p>

<pre>
select 
  substr( 
      lower( 'Smith, John R' )
    , instr( 'Smith, John R', ',' ) + 2
    , 1 
  ) || -- first_initial
  substr( 
      lower( 'Smith, John R' )
    , 1
    , instr( 'Smith, John R', ',' ) - 1 
  ) -- last_name
from dual;
</pre>

<p>Also, be careful about your assumption that all names will be in that format. Watch out for something other than a single space after the comma, last names having data like Parisi, Jr., etc.</p>
"
842,371490,1,1,sql,Oracle SQL - Parsing a name string and converting it to first initial & last name,"<p>Does anyone know how to turn this string: ""Smith, John R""<br>
Into this string: ""jsmith"" ?</p>

<p>I need to lowercase everything with lower()<br>
Find where the comma is and track it's integer location value<br>
Get the first character after that comma and put it in front of the string<br>
Then get the entire last name and stick it after the first initial.<br><br>
Sidenote - instr() function is not compatible with my version<br><br>
Thanks for any help!</p>
","<p>There is no need to create your own function, and quite frankly, it seems a waste of time when this can be done fairly easily with sql functions that already exist.  Care must be taken to account for sloppy data entry.</p>

<p>Here is another way to accomplish your stated goal:</p>

<pre><code>with name_list as
  (select '   Parisi, Kenneth R' name from dual)
select name
      -- There may be a space after the comma.  This will strip an arbitrary
      -- amount of whitespace from the first name, so we can easily extract
      -- the first initial.
     , substr(trim(substr(name, instr(name, ',') + 1)), 1, 1) AS first_init
      -- a simple substring function, from the first character until the
      -- last character before the comma.
     , substr(trim(name), 1, instr(trim(name), ',') - 1) AS last_name
      -- put together what we have done above to create the output field      
     , lower(substr(trim(substr(name, instr(name, ',') + 1)), 1, 1)) ||
       lower(substr(trim(name), 1, instr(trim(name), ',') - 1)) AS init_plus_last
  from name_list;
</code></pre>

<p>HTH,
Gabe</p>
"
775,350780,0,1,sql,SQL query to calculate visit duration from log table,"<p>I have a MySQL table LOGIN_LOG with fields ID, PLAYER, TIMESTAMP and ACTION. ACTION can be either 'login' or 'logout'. Only around 20% of the logins have an accompanying logout row. For those that do, I want to calculate the average duration.</p>

<p>I'm thinking of something like</p>

<pre><code>select avg(LL2.TIMESTAMP - LL1.TIMESTAMP)
from LOGIN_LOG LL1
inner join LOGIN_LOG LL2 on LL1.PLAYER = LL2.PLAYER and LL2.TIMESTAMP &gt; LL1.TIMESTAMP
left join LOGIN_LOG LL3 on LL3.PLAYER = LL1.PLAYER
  and LL3.TIMESTAMP between LL1.TIMESTAMP + 1 and LL2.TIMESTAMP - 1
  and LL3.ACTION = 'login'
where LL1.ACTION = 'login' and LL2.ACTION = 'logout' and isnull(LL3.ID)
</code></pre>

<p>is this the best way to do it, or is there one more efficient?</p>
","<p>I agree with JeeBee, but another advantage to a SessionManager type object is that you can handle the sessionEnd event and write a logout row with the active time in it. This way you would likely go from 20% accompanying logout rows to 100% accompanying logout rows. Querying for the activity time would then be trivial and consistent for all sessions.</p>
"
774,350780,0,1,sql,SQL query to calculate visit duration from log table,"<p>I have a MySQL table LOGIN_LOG with fields ID, PLAYER, TIMESTAMP and ACTION. ACTION can be either 'login' or 'logout'. Only around 20% of the logins have an accompanying logout row. For those that do, I want to calculate the average duration.</p>

<p>I'm thinking of something like</p>

<pre><code>select avg(LL2.TIMESTAMP - LL1.TIMESTAMP)
from LOGIN_LOG LL1
inner join LOGIN_LOG LL2 on LL1.PLAYER = LL2.PLAYER and LL2.TIMESTAMP &gt; LL1.TIMESTAMP
left join LOGIN_LOG LL3 on LL3.PLAYER = LL1.PLAYER
  and LL3.TIMESTAMP between LL1.TIMESTAMP + 1 and LL2.TIMESTAMP - 1
  and LL3.ACTION = 'login'
where LL1.ACTION = 'login' and LL2.ACTION = 'logout' and isnull(LL3.ID)
</code></pre>

<p>is this the best way to do it, or is there one more efficient?</p>
","<p>Do you have a SessionManager type object that can timeout sessions? Because a timeout could be logged there, and you could get the last activity time from that and the timeout period.</p>

<p>Or you log all activity on the website/service, and thus you can query website/service visit duration directly, and see what activities they performed. For a website, Apache log analysers can probably generate the required stats.</p>
"
742,345380,2,1,sql,SQL Server 2005 deadlock on key,"<p>I have a table with a clustered primary key index on a uniqueidentifier column. I have a procedure that runs the following psuedo functions:</p>

<pre><code>begin transaction
read from table 1
insert into table 2
update table 1 with pointer to table 2 record
commit transaction
</code></pre>

<p>This all works fine until the same procedure is executed concurrently from elsewhere. Once this happens, one of the executions gets deadlocked and terminated every single time on the primary key.</p>

<p>Any idea what I can do to prevent this, short of simply saying ""don't run it concurrently""? The transactions are currently running in READ COMMITTED isolation level.</p>
","<ol>
<li><p>increase the transaction isolation level as eulerfx.myopenid.com is hinting.</p></li>
<li><p>use sql ""mutexes"" to simply wait for a procedure to finish before alowing another to run. <a href=""http://weblogs.sqlteam.com/mladenp/archive/2008/01/08/Application-Locks-or-Mutexes-in-SQL-Server-2005.aspx"" rel=""nofollow"">http://weblogs.sqlteam.com/mladenp/archive/2008/01/08/Application-Locks-or-Mutexes-in-SQL-Server-2005.aspx</a></p></li>
<li><p>use snapshot isolation level. dependin on what your app does this can work. however this brings other problems to the table. <a href=""http://msdn.microsoft.com/en-us/library/ms189050.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms189050.aspx</a></p></li>
</ol>

<p>number 2 requires more code change than 1 though. but sometimes you can't just increase the isolation level.</p>
"
741,345380,1,1,sql,SQL Server 2005 deadlock on key,"<p>I have a table with a clustered primary key index on a uniqueidentifier column. I have a procedure that runs the following psuedo functions:</p>

<pre><code>begin transaction
read from table 1
insert into table 2
update table 1 with pointer to table 2 record
commit transaction
</code></pre>

<p>This all works fine until the same procedure is executed concurrently from elsewhere. Once this happens, one of the executions gets deadlocked and terminated every single time on the primary key.</p>

<p>Any idea what I can do to prevent this, short of simply saying ""don't run it concurrently""? The transactions are currently running in READ COMMITTED isolation level.</p>
","<p>Look here:</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/aa213026"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/aa213026</a>(SQL.80).aspx</p>

<p>and here:</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/aa213039"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/aa213039</a>(SQL.80).aspx</p>
"
671,297010,1,1,sql,Partial Keyword Searching (MS SQL 2005),"<p>Current, I've got a stored procedure that has a main goal of doing a full text search through a database table of films and tv shows.  In order to get it to do partial-keyword searching, I added some code in SQL to split up the search query by spaces, and output a statement like the following:</p>

<p>' ""batman*"" ~ ""be*"" '</p>

<p>The original string, ""batman be"", for instance, could be generated from a textbox on the page as the user is typing and on each javascript keyup event, I send whatever is in that textbox to the stored proc for results to get results as I type (like autocomplete).  In this case, the user may have been looking for ""Batman Begins"", or ""The Batman: Batgirl Begins"" (a TV show episode) and they both should show up as a result.</p>

<p>Below is a sample of my query. @partialKeywordString is, in the example above, ' ""batman*"" ~ ""be*"" '.</p>

<pre><code>SELECT f.title
FROM Films f INNER JOIN
    CONTAINSTABLE(Films, Title, @partialKeywordString) f_key ON f.filmid = f_key.[key]
ORDER BY f_key.Rank DESC
</code></pre>

<p>The problem I have with the query is that the ranking doesn't seem to be exactly what I'd expect.  If I were to just search for ""batman"", one would believe that all movie titles, beginning with, or only containing the word ""batman"" would appear first. But they don't.
A sample result of what happens when one searches for just ""batman"" is below:</p>

<p>""Batman: The animated series - Episode 114""
""Adventures of Batman and Robin - Episode 218""
""Batman and Robin - Episode 101""
""The Batman - Episode 101""
""Batman and Robin - Episode 204""</p>

<p>Much further down the list is the movie I was searching for--""Batman Begins"" or even just ""Batman"".</p>

<p>I'm looking for advice on how to tweak this query--I'm definitely not a SQL expert, and I feel like I just man-handled the above code to get it to work.  I have a feeling there's a more elegant or powerful solution, and I just haven't found it yet.</p>

<p>Thank you in advance</p>
","<p>After some more researching, I'm going to try and use Lucene.Net for my movie-title search engine, and not rely on Full-Text Searching in SQL Server 2005.  Early testing shows that the results have been better and more relevant with Lucene. A search for ""batman"" returns the following partial result-set:</p>

<ul>
<li>Batman </li>
<li>Batman Begins</li>
<li>Batman Returns</li>
<li>Batman and Robin: Batman Takes Over</li>
<li>Batman Beyond: A Touch of Curar</li>
<li>Batman Beyond: Babel</li>
<li>The Batman: Season 02</li>
<li>The Batman: Topsy Turvy</li>
<li>Batman and Robin: Tunnel of Terror</li>
<li>Batman Beyond [Animated TV Series]</li>
<li>The New Adventures of Batman: Curses! Oiled Again!</li>
<li>The New Adventures of Batman: This Looks Like a Job for Bat-Mite!</li>
</ul>
"
672,297010,0,1,sql,Partial Keyword Searching (MS SQL 2005),"<p>Current, I've got a stored procedure that has a main goal of doing a full text search through a database table of films and tv shows.  In order to get it to do partial-keyword searching, I added some code in SQL to split up the search query by spaces, and output a statement like the following:</p>

<p>' ""batman*"" ~ ""be*"" '</p>

<p>The original string, ""batman be"", for instance, could be generated from a textbox on the page as the user is typing and on each javascript keyup event, I send whatever is in that textbox to the stored proc for results to get results as I type (like autocomplete).  In this case, the user may have been looking for ""Batman Begins"", or ""The Batman: Batgirl Begins"" (a TV show episode) and they both should show up as a result.</p>

<p>Below is a sample of my query. @partialKeywordString is, in the example above, ' ""batman*"" ~ ""be*"" '.</p>

<pre><code>SELECT f.title
FROM Films f INNER JOIN
    CONTAINSTABLE(Films, Title, @partialKeywordString) f_key ON f.filmid = f_key.[key]
ORDER BY f_key.Rank DESC
</code></pre>

<p>The problem I have with the query is that the ranking doesn't seem to be exactly what I'd expect.  If I were to just search for ""batman"", one would believe that all movie titles, beginning with, or only containing the word ""batman"" would appear first. But they don't.
A sample result of what happens when one searches for just ""batman"" is below:</p>

<p>""Batman: The animated series - Episode 114""
""Adventures of Batman and Robin - Episode 218""
""Batman and Robin - Episode 101""
""The Batman - Episode 101""
""Batman and Robin - Episode 204""</p>

<p>Much further down the list is the movie I was searching for--""Batman Begins"" or even just ""Batman"".</p>

<p>I'm looking for advice on how to tweak this query--I'm definitely not a SQL expert, and I feel like I just man-handled the above code to get it to work.  I have a feeling there's a more elegant or powerful solution, and I just haven't found it yet.</p>

<p>Thank you in advance</p>
","<p>I think you find SQL Server Full Text works just as good but you have to understand how to build the keywords. It is not the same as Lucene, especially in terms of indexing. I think you will find that SQL Server would be better , in terms of scalability and features - especially SQL 2008 now it is part of the engine.</p>
"
661,289220,2,1,sql,Updating an associative table in MySQL,"<p>Below is my (simplified) schema (in MySQL ver. 5.0.51b) and my strategy for updating it. There has got to be a better way. Inserting a new item requires 4 trips to the database and editing/updating an item takes up to <strong>7</strong>!</p>

<p><strong>items</strong>: itemId, itemName
<br /><strong>categories</strong>: catId, catName
<br /><strong>map</strong>: mapId*, itemId, catId
<br />* mapId (varchar) is concat of itemId + | + catId</p>

<p>1) If inserting: insert item. Get itemId via MySQL API.
<br />Else updating: just update the item table. We already have the itemId.</p>

<p>2) Conditionally batch insert into <code>categories</code>.</p>

<pre><code>INSERT IGNORE INTO categories (catName)
VALUES ('each'), ('category'), ('name');
</code></pre>

<p>3) Select IDs from <code>categories</code>.</p>

<pre><code>SELECT catId FROM categories
WHERE catName = 'each' OR catName = 'category' OR catName = 'name';
</code></pre>

<p>4) Conditionally batch insert into <code>map</code>.</p>

<pre><code>INSERT IGNORE INTO map (mapId, itemId, catId)
VALUES ('1|1', 1, 1), ('1|2', 1, 2), ('1|3', 1, 3);
</code></pre>

<p>If inserting: we're done. Else updating: continue.</p>

<p>5) It's possible that we no longer associate a category with this item that we did prior to the update. Delete old categories for this itemId.</p>

<pre><code>DELETE FROM MAP WHERE itemId = 2
AND catID &lt;&gt; 2 AND catID &lt;&gt; 3 AND catID &lt;&gt; 5;
</code></pre>

<p>6) If we have disassociated ourselves from a category, it's possible that we left it orphaned. We do not want categories with no items. Therefore, if <code>affected rows &gt; 0</code>, kill orphaned categories. I haven't found a way to combine these in MySQL, so this is #6 &amp; #7.</p>

<pre><code>SELECT categories.catId
FROM categories
LEFT JOIN map USING (catId)
GROUP BY categories.catId
HAVING COUNT(map.catId) &lt; 1;
</code></pre>

<p>7) Delete IDs found in step 6.</p>

<pre><code>DELETE FROM categories
WHERE catId = 9
  AND catId = 10;
</code></pre>

<p>Please tell me there's a better way that I'm not seeing.</p>
","<p>There are a number of things you can do to make a bit easier:</p>

<ul>
<li><p>Read about [<code>INSERT...ON DUPLICATE KEY UPDATE</code>][1]</p></li>
<li><p>Delete old categories before you insert new categories. This may benefit from an index better.</p>

<p><code>DELETE FROM map WHERE itemId=2</code>;</p></li>
<li><p>You probably don't need <code>map.mapID</code>.  Instead, declare a compound primary key over <code>(itemID, catID)</code>.</p></li>
<li><p>As Peter says in his answer, use MySQL's multi-table delete:</p>

<pre><code>DELETE categories.* FROM categories LEFT JOIN map USING (catId) 
WHERE map.catID IS NULL
</code></pre>

<p><a href=""http://dev.mysql.com/doc/refman/5.0/en/insert-on-duplicate.html"" rel=""nofollow"">http://dev.mysql.com/doc/refman/5.0/en/insert-on-duplicate.html</a></p></li>
</ul>
"
660,289220,1,1,sql,Updating an associative table in MySQL,"<p>Below is my (simplified) schema (in MySQL ver. 5.0.51b) and my strategy for updating it. There has got to be a better way. Inserting a new item requires 4 trips to the database and editing/updating an item takes up to <strong>7</strong>!</p>

<p><strong>items</strong>: itemId, itemName
<br /><strong>categories</strong>: catId, catName
<br /><strong>map</strong>: mapId*, itemId, catId
<br />* mapId (varchar) is concat of itemId + | + catId</p>

<p>1) If inserting: insert item. Get itemId via MySQL API.
<br />Else updating: just update the item table. We already have the itemId.</p>

<p>2) Conditionally batch insert into <code>categories</code>.</p>

<pre><code>INSERT IGNORE INTO categories (catName)
VALUES ('each'), ('category'), ('name');
</code></pre>

<p>3) Select IDs from <code>categories</code>.</p>

<pre><code>SELECT catId FROM categories
WHERE catName = 'each' OR catName = 'category' OR catName = 'name';
</code></pre>

<p>4) Conditionally batch insert into <code>map</code>.</p>

<pre><code>INSERT IGNORE INTO map (mapId, itemId, catId)
VALUES ('1|1', 1, 1), ('1|2', 1, 2), ('1|3', 1, 3);
</code></pre>

<p>If inserting: we're done. Else updating: continue.</p>

<p>5) It's possible that we no longer associate a category with this item that we did prior to the update. Delete old categories for this itemId.</p>

<pre><code>DELETE FROM MAP WHERE itemId = 2
AND catID &lt;&gt; 2 AND catID &lt;&gt; 3 AND catID &lt;&gt; 5;
</code></pre>

<p>6) If we have disassociated ourselves from a category, it's possible that we left it orphaned. We do not want categories with no items. Therefore, if <code>affected rows &gt; 0</code>, kill orphaned categories. I haven't found a way to combine these in MySQL, so this is #6 &amp; #7.</p>

<pre><code>SELECT categories.catId
FROM categories
LEFT JOIN map USING (catId)
GROUP BY categories.catId
HAVING COUNT(map.catId) &lt; 1;
</code></pre>

<p>7) Delete IDs found in step 6.</p>

<pre><code>DELETE FROM categories
WHERE catId = 9
  AND catId = 10;
</code></pre>

<p>Please tell me there's a better way that I'm not seeing.</p>
","<p>Steps 6 &amp; 7 can be combined easily enough:</p>

<pre><code>DELETE categories.*
FROM categories
LEFT JOIN map USING (catId)
WHERE map.catID IS NULL;
</code></pre>

<p>Steps 3 &amp; 4 can also be combined:</p>

<pre><code>INSERT IGNORE INTO map (mapId, itemId, catId)
    SELECT CONCAT('1|', c.catId), 1, c.catID
    FROM categories AS c
    WHERE c.catName IN('each','category','name');
</code></pre>

<p>Otherwise, your solution is pretty standard, unless you want to use triggers to maintain the map table.</p>
"
655,287630,0,1,sql,query join question,"<p>I have a right outer join, that almost does what I want...</p>

<pre><code>SELECT
users_usr.firstname_usr,
users_usr.lastname_usr,
credit_acc.given_credit_acc,
users_usr.created_usr,
users_usr.sitenum_usr,
users_usr.original_aff_usr,
users_usr.id_usr
FROM
credit_acc
right Outer Join users_usr ON credit_acc.uid_usr = users_usr.id_usr
</code></pre>

<p>The problem is, I want to add a </p>

<pre><code>where credit_acc.type_acc = 'init'
</code></pre>

<p>But this gets rid of all users who don't have a row in credit_acc... which is WHY I need a right outer join.</p>

<p>Is there a way to get this without having to do two queries and a union?</p>
","<p>Just add another predicate to the Join Condition.</p>

<pre><code>SELECT  U.firstname_usr, U.lastname_usr, C.given_credit_acc, 
        U.created_usr, U.sitenum_usr, U.original_aff_usr, U.id_usr
From credit_acc C Right Join users_usr U
   On C.uid_usr = U.id_usr
      And C.type_acc = 'init'
</code></pre>

<p>This works because Join conditions are applied BEFORE the non-matching records from ""other"" side of an ""Outer"" join are added to the result set, whereas Where Conditions are applied after the two tables are joined... </p>

<p>This syntax more clearly represents your intent as well... </p>
"
654,287630,0,1,sql,query join question,"<p>I have a right outer join, that almost does what I want...</p>

<pre><code>SELECT
users_usr.firstname_usr,
users_usr.lastname_usr,
credit_acc.given_credit_acc,
users_usr.created_usr,
users_usr.sitenum_usr,
users_usr.original_aff_usr,
users_usr.id_usr
FROM
credit_acc
right Outer Join users_usr ON credit_acc.uid_usr = users_usr.id_usr
</code></pre>

<p>The problem is, I want to add a </p>

<pre><code>where credit_acc.type_acc = 'init'
</code></pre>

<p>But this gets rid of all users who don't have a row in credit_acc... which is WHY I need a right outer join.</p>

<p>Is there a way to get this without having to do two queries and a union?</p>
","<p>I would make the predicate:</p>

<pre><code>WHERE credit_acc.uid_usr IS NULL OR credit_acc.type_acc = 'init'
</code></pre>

<p>This would give you rows where there is no match on UID_USR, and rows where there is a match and the account type is 'init'.</p>

<p>The other solution proposed (checking type_acc for NULL) would also give you rows where there is a match on UID_USR and the actual value for account type is NULL.</p>

<p>If credit_acc.type_acc can't be NULL, there's no difference between the two.  If it can, you need to decide whether you want to include those rows in your result set.</p>
"
653,287630,0,1,sql,query join question,"<p>I have a right outer join, that almost does what I want...</p>

<pre><code>SELECT
users_usr.firstname_usr,
users_usr.lastname_usr,
credit_acc.given_credit_acc,
users_usr.created_usr,
users_usr.sitenum_usr,
users_usr.original_aff_usr,
users_usr.id_usr
FROM
credit_acc
right Outer Join users_usr ON credit_acc.uid_usr = users_usr.id_usr
</code></pre>

<p>The problem is, I want to add a </p>

<pre><code>where credit_acc.type_acc = 'init'
</code></pre>

<p>But this gets rid of all users who don't have a row in credit_acc... which is WHY I need a right outer join.</p>

<p>Is there a way to get this without having to do two queries and a union?</p>
","<p>You want all records from the two tables, joined on user-id, WHERE credit_acc is 'init' OR where there isn't a credit_acc row to be joined? How about</p>

<pre><code>where credit_acc.type_acc is null  OR credit_acc.type_acc = 'init'
</code></pre>
"
652,287630,2,1,sql,query join question,"<p>I have a right outer join, that almost does what I want...</p>

<pre><code>SELECT
users_usr.firstname_usr,
users_usr.lastname_usr,
credit_acc.given_credit_acc,
users_usr.created_usr,
users_usr.sitenum_usr,
users_usr.original_aff_usr,
users_usr.id_usr
FROM
credit_acc
right Outer Join users_usr ON credit_acc.uid_usr = users_usr.id_usr
</code></pre>

<p>The problem is, I want to add a </p>

<pre><code>where credit_acc.type_acc = 'init'
</code></pre>

<p>But this gets rid of all users who don't have a row in credit_acc... which is WHY I need a right outer join.</p>

<p>Is there a way to get this without having to do two queries and a union?</p>
","<p>If the row doesn't exist, *credit_acc.type_acc* should be null.  You could try something like this:  </p>

<pre><code>WHERE credit_acc.type_acc = 'init' OR credit_acc.type_acc IS NULL;
</code></pre>

<p>That will only work if there are no null fields in *credit_acc.type_acc*.  </p>
"
651,287630,1,1,sql,query join question,"<p>I have a right outer join, that almost does what I want...</p>

<pre><code>SELECT
users_usr.firstname_usr,
users_usr.lastname_usr,
credit_acc.given_credit_acc,
users_usr.created_usr,
users_usr.sitenum_usr,
users_usr.original_aff_usr,
users_usr.id_usr
FROM
credit_acc
right Outer Join users_usr ON credit_acc.uid_usr = users_usr.id_usr
</code></pre>

<p>The problem is, I want to add a </p>

<pre><code>where credit_acc.type_acc = 'init'
</code></pre>

<p>But this gets rid of all users who don't have a row in credit_acc... which is WHY I need a right outer join.</p>

<p>Is there a way to get this without having to do two queries and a union?</p>
","<p>Have you tried the following?</p>

<pre><code>SELECT
users_usr.firstname_usr,
users_usr.lastname_usr,
credit_acc.given_credit_acc,
users_usr.created_usr,
users_usr.sitenum_usr,
users_usr.original_aff_usr,
users_usr.id_usr
FROM
credit_acc
right Outer Join users_usr ON credit_acc.uid_usr = users_usr.id_usr and credit_acc.type_acc = 'init'
</code></pre>
"
650,287630,4,1,sql,query join question,"<p>I have a right outer join, that almost does what I want...</p>

<pre><code>SELECT
users_usr.firstname_usr,
users_usr.lastname_usr,
credit_acc.given_credit_acc,
users_usr.created_usr,
users_usr.sitenum_usr,
users_usr.original_aff_usr,
users_usr.id_usr
FROM
credit_acc
right Outer Join users_usr ON credit_acc.uid_usr = users_usr.id_usr
</code></pre>

<p>The problem is, I want to add a </p>

<pre><code>where credit_acc.type_acc = 'init'
</code></pre>

<p>But this gets rid of all users who don't have a row in credit_acc... which is WHY I need a right outer join.</p>

<p>Is there a way to get this without having to do two queries and a union?</p>
","<pre><code>SELECT
users_usr.firstname_usr,
users_usr.lastname_usr,
credit_acc.given_credit_acc,
users_usr.created_usr,
users_usr.sitenum_usr,
users_usr.original_aff_usr,
users_usr.id_usr
FROM
credit_acc
right Outer Join users_usr ON credit_acc.uid_usr = users_usr.id_usr
WHERE credit_acc.type_acc = 'init' OR credit_acc.type_acc is NULL
</code></pre>

<p>Or, as @Tomalak pointed out:</p>

<pre><code>WHERE COALESCE(credit_acc.type_acc, 'init') = 'init'
</code></pre>

<p>which <em>may</em> be faster (see comments).</p>
"
637,278980,1,1,sql,question on how to use sql server integrated service,"<p>I have a table called book with, the attrbutes are booked_id, yearmon, and day_01....day_31. Now i need to unpivot the table and transform day_01...day_31 into rows, I have successed in doing that, but the problem is that my yearmon is a format of 200805 and i need to append a day to it based on day_01 or day_02 etc, so that i can create a new column with date information for example, if it is day_01, it looks like 20080501. Instead of writing huge query, does anyone how to use ssis to tranform it</p>
","<p>You should be able to use the Unpivot component and the Derived Column component to do what you need. Look into those and post back if they don't seem to do what you need.</p>
"
613,272190,2,1,sql,SQL: Complex Deletion,"<p>I basically created some tables to play around with:  I have Two main tables, and a Many-Many join table.  Here is the DDL:  (I am using HSQLDB)</p>

<pre><code>CREATE TABLE PERSON
(
    PERSON_ID INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, 
    NAME VARCHAR(50), MAIN_PERSON_ID INTEGER
)

CREATE TABLE JOB
(
    JOB_ID INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, 
    NAME VARCHAR(50)
)
CREATE TABLE JOB_PERSON
(
    PERSON_ID INTEGER, 
    JOB_ID INTEGER
)
ALTER TABLE JOB_PERSON ADD 
    CONSTRAINT FK_PERSON_JOB FOREIGN KEY(PERSON_ID) 
    REFERENCES PERSON ON DELETE CASCADE ON UPDATE CASCADE 

ALTER TABLE JOB_PERSON ADD
    CONSTRAINT FK_JOB_PERSON FOREIGN KEY(JOB_ID) 
    REFERENCES JOB ON DELETE CASCADE ON UPDATE CASCADE

ALTER TABLE PERSON ADD
    CONSTRAINT FK_PERSON_PERSON FOREIGN KEY(MAIN_PERSON_ID) 
    REFERENCES PERSON ON DELETE CASCADE ON UPDATE CASCADE

insert into person values(null,'Arthur', null);
insert into person values(null,'James',0);
insert into job values(null, 'Programmer')
insert into job values(null, 'Manager')
insert into job_person values(0,0);
insert into job_person values(0,1);
insert into job_person values(1,1);
</code></pre>

<p>I want to create a delete statement that deletes orphans from JOB (if there exists only one entry in the join table for a specific job) based on the PERSON.PERSON_ID.  </p>

<p>In pseudo language:  </p>

<pre><code>delete from job where job_person.job_id=job.job_id 
AND count(job_person.job_id)=1 AND job_person.person_id=X
</code></pre>

<p>Where X is some person_id.  I have tried a lot of different ways; I think it is the ""COUNT"" part that is causing problems.  I am an SQL rookie, so any help would be much appreciated.</p>
","<p>I'm not following.</p>

<p>You cannot delete <code>JOB</code> rows which have <code>JOB_PERSON</code> rows (even one) because of your FK contraints.  Thus there is no way to delete <code>JOB</code> rows based on <code>PERSON</code> rows.</p>

<p><code>JOB_PERSON</code> rows have to be deleted before either a <code>JOB</code> or <code>PERSON</code> can be deleted.</p>

<p>If you want to delete all <code>JOB</code> rows with no <code>JOB_PERSON</code>, then one way is:</p>

<pre><code>DELETE FROM JOB
WHERE JOB_ID NOT IN (
    SELECT JOB_ID
    FROM JOB_PERSON
)
</code></pre>

<p>If you want to delete all <code>JOB_PERSON</code> rows for a particular person and then all orphans, do it in two steps:</p>

<pre><code>DELETE FROM JOB_PERSON
WHERE PERSON_ID = X

DELETE FROM JOB
WHERE JOB_ID NOT IN (
    SELECT JOB_ID
    FROM JOB_PERSON
)
</code></pre>

<p>If you want to delete only the orphan <code>JOB</code>s previously linked to X, you will need to hold those in a temporary table before the first delete.</p>

<pre><code>INSERT INTO TEMP_TABLE
SELECT JOB.JOB_ID
FROM JOB
INNER JOIN JOB_PERSON
    ON JOB_PERSON.JOB_ID = JOB.JOB_ID
WHERE JOB_PERSON.PERSON_ID = X

DELETE FROM PERSON
WHERE PERSON_ID = X

-- YOUR CASCADING DELETE DOES THIS:
/*
DELETE FROM JOB_PERSON
WHERE PERSON_ID = X
*/

-- Now clean up (only) new orphans on the other side
DELETE FROM JOB
WHERE JOB_ID NOT IN (
    SELECT JOB_ID
    FROM JOB_PERSON
)
AND JOB_ID IN (
    SELECT JOB_ID
    FROM TEMP_TABLE
)
</code></pre>
"
608,270440,4,1,sql,SQL Deletion Cascading Help (Specific Question),"<p>I have two tables (renamed/refactored for illustrative purposes) with a Many-To-Many relationship in an HSQL database.  I want everything to be wiped out when I delete from one side of a Many-to-Many relationship (without querying the table; this is performance critical)</p>

<p>Here are my main tables:</p>

<pre><code>CREATE TABLE PERSON
(
    PERSON_ID INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, 
    NAME VARCHAR(50)
)

CREATE TABLE JOB
(
    JOB_ID INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, 
    NAME VARCHAR(50)
)
</code></pre>

<p>Here is my join table:</p>

<pre><code>CREATE TABLE JOB_PERSON
(
    PERSON_ID INTEGER, 
    JOB_ID INTEGER
)
</code></pre>

<p>Here are my constraints:</p>

<pre><code>ALTER TABLE JOB_PERSON ADD 
    CONSTRAINT FK_PERSON_JOB FOREIGN KEY(PERSON_ID) 
    REFERENCES PERSON ON DELETE CASCADE ON UPDATE CASCADE 

ALTER TABLE JOB_PERSON ADD
    CONSTRAINT FK_JOB_PERSON FOREIGN KEY(JOB_ID) 
    REFERENCES JOB ON DELETE CASCADE ON UPDATE CASCADE
</code></pre>

<p>I basically want to do this:  ""delete from person where person_id=0"" and have it delete everything from PERSON, JOB_PERSON and JOB if the JOB entity will be orphaned (no longer referenced in the many to many table)</p>

<p>Is this possible without querying the database?  When I delete, it only deletes from PERSON and JOB_PERSON.  As you can probably tell, my sql skills are lacking.</p>

<p>Here is the dummy data I have been playing around with:</p>

<pre><code>insert into person values(null,'Arthur');
insert into person values(null,'James');
insert into job values(null, 'Programmer')
insert into job values(null, 'Manager')
insert into job_person values(0,0);
insert into job_person values(0,1);
insert into job_person values(1,1);
</code></pre>

<p>So if I enter both of these statements:  </p>

<pre><code>delete from person where person_id=0
delete from person where person_id=1
</code></pre>

<p>I would like to have everything in all 3 tables deleted.  Possible?</p>
","<p>Create a Store Procedure where you pass the ID, then simply DELETE the proper row in the order you need to.</p>

<p>This way your app isn't tied to the exact order, which might change in the future with DB redesigns.  You also gain the added bonus that Stored Procs are faster then sending a bunch of queries.</p>

<p>Although if you absolutely wanted a way to delete the dependent tables when you try to delete that entry, you have to use triggers, but the rule for triggers are, avoid them whenever possible, if another solution exists, use it.  So ultimately, using a Stored Proc is the best solution.</p>
"
702,316340,0,1,sql,Can SQL Server Express be used to effectively administrate a SQL Server Standard/Enterprise installation?,"<p>We have a number of MS SQL Server 2005 installations (both Standard and Enterprise editions) on our webservers. From time to time I need to administrate them from home. Right now I'm using Remote Desktop to connect to my work machine, but I'd prefer to install SQL Server Management Studio on my home machine so that I can work more efficiently. I don't have a spare license, so I was wondering... if I installed MS SQL Server 2005 Express on my home machine, could I use it to effectively administrate the higher-end installations on our servers?</p>
","<p>I'm not sure if you can create backup schedules and maintenance plans in Management Studio Express.</p>
"
703,316340,4,1,sql,Can SQL Server Express be used to effectively administrate a SQL Server Standard/Enterprise installation?,"<p>We have a number of MS SQL Server 2005 installations (both Standard and Enterprise editions) on our webservers. From time to time I need to administrate them from home. Right now I'm using Remote Desktop to connect to my work machine, but I'd prefer to install SQL Server Management Studio on my home machine so that I can work more efficiently. I don't have a spare license, so I was wondering... if I installed MS SQL Server 2005 Express on my home machine, could I use it to effectively administrate the higher-end installations on our servers?</p>
","<p>See this question:<br />
<a href=""http://stackoverflow.com/questions/117347/whats-the-difference-between-sql-server-management-studio-and-the-express-versi"">http://stackoverflow.com/questions/117347/whats-the-difference-between-sql-server-management-studio-and-the-express-versi</a></p>

<p>Also, if you have any trouble doing anything from Managment Studio Express, there are third-party tools out there that have no trouble connecting to SQL Server.</p>

<p>Personally, I've noticed a few things missing out of the box:</p>

<ul>
<li>Import/Export</li>
<li>Activity Monitor</li>
<li>Job monitor</li>
</ul>

<p>However, the question I linked to indicated you may be able to restore most of that for use when you connect to a full sql server edition.</p>
"
704,316340,2,1,sql,Can SQL Server Express be used to effectively administrate a SQL Server Standard/Enterprise installation?,"<p>We have a number of MS SQL Server 2005 installations (both Standard and Enterprise editions) on our webservers. From time to time I need to administrate them from home. Right now I'm using Remote Desktop to connect to my work machine, but I'd prefer to install SQL Server Management Studio on my home machine so that I can work more efficiently. I don't have a spare license, so I was wondering... if I installed MS SQL Server 2005 Express on my home machine, could I use it to effectively administrate the higher-end installations on our servers?</p>
","<p>If you do a client tools only install of the standard edition (ie. just SSMS) and don't install the database, agent, etc. then I'm pretty sure you don't need another license and won't be violating the EULA. If you want a full install the SQL Server developer edition is only $49 and comes with everything.   </p>

<p><a href=""http://www.microsoft.com/sqlserver/2005/en/us/developer.aspx"" rel=""nofollow"">http://www.microsoft.com/sqlserver/2005/en/us/developer.aspx</a></p>
"
707,320250,3,1,sql,sql - Using aggregate functions (min/max) as part of select statement,"<p>I am trying to return the minimum and maximum prices for a villa booking system. I have a look up table that stores the price for each week for each villa. </p>

<p>I am using the min and max functions to do this within the select but I'm having lots of problems. Can anyone explain where i'm going wrong? Heres the sp</p>

<pre><code>ALTER PROCEDURE spVillaGet 
-- Add the parameters for the stored procedure here
@accomodationTypeFK int = null,
@regionFK int = null,
@arrivalDate datetime = null,
@numberOfNights int = null,
@sleeps int = null,
@priceFloor money = null,
@priceCeil money = null
</code></pre>

<p>AS
BEGIN
    -- SET NOCOUNT ON added to prevent extra result sets from
    -- interfering with SELECT statements.
    SET NOCOUNT ON;</p>

<pre><code>-- Insert statements for procedure here
SELECT tblVillas.name, 
	   tblVillas.introduction,
	   tblVillas.italian_introduction,
	   tblVillas.uk_content,
	   tblVillas.italian_content,
	   tblVillas.sleeps,
	   tblVillas.postcode,
	   tblLkUpRegions.regionName,
	   tblLkUpAccomodationTypes.accomodationType,
	   MIN(price) As MinPrice,
	   MAX(price) As MaxPrice

FROM tblVillas

LEFT JOIN tblLkUpRegions on tblVillas.regionFK = tblLkUpRegions.regionID
LEFT JOIN tblLkUpAccomodationTypes on tblVillas.accomodationTypeFK = tblLkUpAccomodationTypes.accomodationId    
LEFT JOIN tblWeeklyPrices on tblWeeklyPrices.villaFK = tblVillas.villaId

WHERE

	((@accomodationTypeFK is null OR accomodationTypeFK = @accomodationTypeFK)
	 AND (@regionFK is null OR regionFK = @regionFK)
	 AND (@sleeps is null OR sleeps = @sleeps) 
	 AND tblVillas.deleted = 0)

GROUP BY tblVillas.name
</code></pre>
","<p>You don't elaborate on <em>what</em> problems you are getting, but this is probably one: you need to specify <strong>all</strong> the non-aggregate columns in the GROUP BY clause i.e.:</p>

<pre><code>GROUP BY tblVillas.name, 
       tblVillas.introduction,
       tblVillas.italian_introduction,
       tblVillas.uk_content,
       tblVillas.italian_content,
       tblVillas.sleeps,
       tblVillas.postcode,
       tblLkUpRegions.regionName,
       tblLkUpAccomodationTypes.accomodationType
</code></pre>

<p>From your follow-up comment is appears that some of your columns are of a data type that can't be used in a GROUP BY clause.  Try this instead:</p>

<pre><code>SELECT tblVillas.name, 
           tblVillas.introduction,
           tblVillas.italian_introduction,
           tblVillas.uk_content,
           tblVillas.italian_content,
           tblVillas.sleeps,
           tblVillas.postcode,
           tblLkUpRegions.regionName,
           tblLkUpAccomodationTypes.accomodationType,
           (SELECT MIN(price) FROM tblWeeklyPrices where tblWeeklyPrices.villaFK = tblVillas.villaId) As MinPrice,
           (SELECT MAX(price) FROM tblWeeklyPrices where tblWeeklyPrices.villaFK = tblVillas.villaId) As MaxPrice
FROM tblVillas
LEFT JOIN tblLkUpRegions on tblVillas.regionFK = tblLkUpRegions.regionID
LEFT JOIN tblLkUpAccomodationTypes on tblVillas.accomodationTypeFK = tblLkUpAccomodationTypes.accomodationId    
WHERE
        ((@accomodationTypeFK is null OR accomodationTypeFK = @accomodationTypeFK)
         AND (@regionFK is null OR regionFK = @regionFK)
         AND (@sleeps is null OR sleeps = @sleeps) 
         AND tblVillas.deleted = 0)
</code></pre>
"
708,320250,0,1,sql,sql - Using aggregate functions (min/max) as part of select statement,"<p>I am trying to return the minimum and maximum prices for a villa booking system. I have a look up table that stores the price for each week for each villa. </p>

<p>I am using the min and max functions to do this within the select but I'm having lots of problems. Can anyone explain where i'm going wrong? Heres the sp</p>

<pre><code>ALTER PROCEDURE spVillaGet 
-- Add the parameters for the stored procedure here
@accomodationTypeFK int = null,
@regionFK int = null,
@arrivalDate datetime = null,
@numberOfNights int = null,
@sleeps int = null,
@priceFloor money = null,
@priceCeil money = null
</code></pre>

<p>AS
BEGIN
    -- SET NOCOUNT ON added to prevent extra result sets from
    -- interfering with SELECT statements.
    SET NOCOUNT ON;</p>

<pre><code>-- Insert statements for procedure here
SELECT tblVillas.name, 
	   tblVillas.introduction,
	   tblVillas.italian_introduction,
	   tblVillas.uk_content,
	   tblVillas.italian_content,
	   tblVillas.sleeps,
	   tblVillas.postcode,
	   tblLkUpRegions.regionName,
	   tblLkUpAccomodationTypes.accomodationType,
	   MIN(price) As MinPrice,
	   MAX(price) As MaxPrice

FROM tblVillas

LEFT JOIN tblLkUpRegions on tblVillas.regionFK = tblLkUpRegions.regionID
LEFT JOIN tblLkUpAccomodationTypes on tblVillas.accomodationTypeFK = tblLkUpAccomodationTypes.accomodationId    
LEFT JOIN tblWeeklyPrices on tblWeeklyPrices.villaFK = tblVillas.villaId

WHERE

	((@accomodationTypeFK is null OR accomodationTypeFK = @accomodationTypeFK)
	 AND (@regionFK is null OR regionFK = @regionFK)
	 AND (@sleeps is null OR sleeps = @sleeps) 
	 AND tblVillas.deleted = 0)

GROUP BY tblVillas.name
</code></pre>
","<p>Thanks for your help</p>

<p>When I Group By and include all the columns from the select except the two functions I get the following error</p>

<pre><code>Msg 306, Level 16, State 2, Procedure spVillaGet, Line 22
</code></pre>

<p>The text, ntext, and image data types cannot be compared or sorted, except when using IS NULL or LIKE operator.
Msg 306, Level 16, State 2, Procedure spVillaGet, Line 22
The text, ntext, and image data types cannot be compared or sorted, except when using IS NULL or LIKE operator.</p>
"
952,441760,3,1,sql,Django custom SQL to return QuerySet where each object has additional properties,"<p>Let's say I have the following objects: </p>

<pre><code>squirrel_table 
  - name
  - country_of_origin
  - id

nut_table
  - id
  - squirrel_who_owns_me[fk to squirrel]
</code></pre>

<p>I want to retrieve a list of all squirrels in a particular country. The returned squirrel objects can be in a QuerySet, but do not need to be. A list will suffice. Each squirrel will have an additional property call nut_count. The SQL for this would be something like what follows (please note I use the subquery in order to not enumerate all of squirrel's columns, since in reality there will be many) (I use PostgreSQL):</p>

<pre><code>select sq.*,
       nut_counts.nut_count
  from squirrel_table sq,
      (select sq2.id as squirrel_id,
              count(nuts) as nut_count
         from squirrel_table sq2,
              nut_table nuts
        where nuts.squirrel_who_owns_me = sq2.id
          and sq.country_of_origin = 'USA'
        group by sq2.id) as nut_counts
 where sq.id = nut_counts.squirrel_id
</code></pre>

<p>Is there a way to execute the SQL, take the cursor it generates, and turn it into a list of squirrel objects, and add the nut_count to each squirrel?</p>
","<p>You probably want to read through <a href=""http://docs.djangoproject.com/en/dev/ref/models/querysets/#extra-select-none-where-none-params-none-tables-none-order-by-none-select-params-none"" rel=""nofollow"">the documentation for the ""extra()"" method</a>, which includes an example of a similar ""select something else and append it onto each object"" situation.</p>
"
582,260320,2,1,sql,How to get partition ranges in SQL 2005,"<p>I have a partitioned table in SQL Enterprise 2005. I need to query the PARTITION FUNCTION to find it's partition ranges. What SQL query will give me those values?</p>
","<p>Got this from the SQL profiler watching the management studio generate the script for creating the function</p>

<p>SELECT
sprv.value AS [Value],
sprv.boundary_id AS [ID]
FROM
sys.partition_functions AS spf
INNER JOIN sys.partition_range_values sprv ON sprv.function_id=spf.function_id
WHERE
(spf.name=N'fnPartitionLast30Days')
ORDER BY
[ID] ASC</p>
"
536,239910,0,1,sql,"SQL CE 3.5 deployment problem, concerning interop between C# and C++","<p>We have a situation where a C# application is working with SQL CE 3.5 . To allow for a legacy program to use some of its features we have produced a C++ dll which uses interop to extract the info that it needs from the C# program. For this to work, the C#-program needs to access the database. Its not a very complex scenario.</p>

<p>When trying to deploy with a private install some problems occur though.
<strong>There is no problem with the C# program, it can access the database and work with it without any problems.</strong></p>

<p><strong>But when trying to access functions in the C#-program through the C++ interop which forces the C#-program to access the database, we get a crash with the exception saying that ""...the Provider: System.Data.SqlServerCe.3.5 is not installed"".</strong></p>

<p>This is obviously because we cannot add a App.config file to the executing program.</p>

<p>How can we get around this? Is there another way to fix this? Any other forms of SQL CE 3.5 install methods are out of the question. So we must get this to work.</p>

<p>Regards,</p>

<p>P</p>

<p><strong>Edit:</strong></p>

<p>I'm not working against SQL CE directly, but through Linq2SQL. I have tried to add config files to all my dll's, it does not help. It seems to only matter if the executable file have got a app.config.</p>

<p>The exception thrown says - The provider System.Data.SqlServerCe.3.5 is not installed.</p>

<p>And the latest function to be called according to the stack trace is
System.Data.Linq.SqlClient.SqlProvider.System.Data.Linq.Provider.IProvider.Initialize(...).</p>

<p><strong>Edit 2</strong></p>

<p>I have added all the files necessery for the deployment to work. As I wrote above, it works if I use the program dll (which uses Linq 2 Sql) through a .net executable with a app.config file that specifies where to look for the SQL CE 3.5 dll. Deployment will <em>not</em> work with only the files, an app.config file is necessary.</p>

<p>The problem is that we have to use the dll file through a C++ executable which have no means of telling .net where to look for the Sql Ce 3.5 dll.</p>
","<p>I have also seen an instance where the System.Data.SqlServerCe.dll in the GAC was the wrong file version and I had replace the dll in the GAC from a cmd command prompt.</p>

<p>The point about the files having to be in the folder is true - unless the GAC gets itself confused by have multiple versions</p>
"
535,239910,0,1,sql,"SQL CE 3.5 deployment problem, concerning interop between C# and C++","<p>We have a situation where a C# application is working with SQL CE 3.5 . To allow for a legacy program to use some of its features we have produced a C++ dll which uses interop to extract the info that it needs from the C# program. For this to work, the C#-program needs to access the database. Its not a very complex scenario.</p>

<p>When trying to deploy with a private install some problems occur though.
<strong>There is no problem with the C# program, it can access the database and work with it without any problems.</strong></p>

<p><strong>But when trying to access functions in the C#-program through the C++ interop which forces the C#-program to access the database, we get a crash with the exception saying that ""...the Provider: System.Data.SqlServerCe.3.5 is not installed"".</strong></p>

<p>This is obviously because we cannot add a App.config file to the executing program.</p>

<p>How can we get around this? Is there another way to fix this? Any other forms of SQL CE 3.5 install methods are out of the question. So we must get this to work.</p>

<p>Regards,</p>

<p>P</p>

<p><strong>Edit:</strong></p>

<p>I'm not working against SQL CE directly, but through Linq2SQL. I have tried to add config files to all my dll's, it does not help. It seems to only matter if the executable file have got a app.config.</p>

<p>The exception thrown says - The provider System.Data.SqlServerCe.3.5 is not installed.</p>

<p>And the latest function to be called according to the stack trace is
System.Data.Linq.SqlClient.SqlProvider.System.Data.Linq.Provider.IProvider.Initialize(...).</p>

<p><strong>Edit 2</strong></p>

<p>I have added all the files necessery for the deployment to work. As I wrote above, it works if I use the program dll (which uses Linq 2 Sql) through a .net executable with a app.config file that specifies where to look for the SQL CE 3.5 dll. Deployment will <em>not</em> work with only the files, an app.config file is necessary.</p>

<p>The problem is that we have to use the dll file through a C++ executable which have no means of telling .net where to look for the Sql Ce 3.5 dll.</p>
","<blockquote>
  <p>This is obviously because we cannot add a App.config file to the executing program.</p>
</blockquote>

<p>Why not? Okay, so Visual Studio won't automatically build the config file and rename it and move it to the output directory, but have you tried a <code>.exe.config</code> file alongside your C++ application?</p>
"
729,339560,2,1,sql,T-SQL Query Optimization,"<p>I'm working on some upgrades to an internal web analytics system we provide for our clients (in the absence of a preferred vendor or Google Analytics), and I'm working on the following query:</p>

<pre><code>select 
    path as EntryPage, 
    count(Path) as [Count] 
from 
    (
    	/* Sub-query 1 */
    	select 
    		pv2.path
    	from 
    		pageviews pv2 
    			inner join
    				(
    					/* Sub-query 2 */
    					select
    						pv1.sessionid,
    						min(pv1.created) as created
    					from
    						pageviews pv1 
    							inner join Sessions s1 on pv1.SessionID = s1.SessionID
    							inner join Visitors v1 on s1.VisitorID = v1.VisitorID
    					where
    						pv1.Domain = isnull(@Domain, pv1.Domain) and
    						v1.Campaign = @Campaign
    					group by
    						pv1.sessionid
    				) t1 on pv2.sessionid = t1.sessionid and pv2.created = t1.created
    ) t2
group by 
    Path;
</code></pre>

<p>I've tested this query with 2 million rows in the PageViews table and it takes about 20 seconds to run. I'm noticing a clustered index scan twice in the execution plan, both times it hits the PageViews table. There is a clustered index on the Created column in that table.</p>

<p>The problem is that in both cases it appears to iterate over all 2 million rows, which I believe is the performance bottleneck. Is there anything I can do to prevent this, or am I pretty much maxed out as far as optimization goes?</p>

<p>For reference, the purpose of the query is to find the first page view for each session.</p>

<p><strong>EDIT:</strong> After much frustration, despite the help received here, I could not make this query work. Therefore, I decided to simply store a reference to the entry page (and now exit page) in the sessions table, which allows me to do the following:</p>

<pre><code>select
    pv.Path,
    count(*)
from
    PageViews pv
    	inner join Sessions s on pv.SessionID = s.SessionID
    		and pv.PageViewID = s.ExitPage
    	inner join Visitors v on s.VisitorID = v.VisitorID
where
    (
        @Domain is null or 
        pv.Domain = @Domain
    ) and
    v.Campaign = @Campaign
group by pv.Path;
</code></pre>

<p>This query runs in 3 seconds or less. Now I either have to update the entry/exit page in real time as the page views are recorded (the optimal solution) or run a batch update at some interval. Either way, it solves the problem, but not like I'd intended. </p>

<p>Edit Edit: Adding a missing index (after cleaning up from last night) reduced the query to mere milliseconds). Woo hoo!</p>
","<p>For starters,</p>

<pre><code>    where pv1.Domain = isnull(@Domain, pv1.Domain)
</code></pre>

<p>won't SARG. You can't optimize a match on a function, as I remember.</p>
"
730,339560,1,1,sql,T-SQL Query Optimization,"<p>I'm working on some upgrades to an internal web analytics system we provide for our clients (in the absence of a preferred vendor or Google Analytics), and I'm working on the following query:</p>

<pre><code>select 
    path as EntryPage, 
    count(Path) as [Count] 
from 
    (
    	/* Sub-query 1 */
    	select 
    		pv2.path
    	from 
    		pageviews pv2 
    			inner join
    				(
    					/* Sub-query 2 */
    					select
    						pv1.sessionid,
    						min(pv1.created) as created
    					from
    						pageviews pv1 
    							inner join Sessions s1 on pv1.SessionID = s1.SessionID
    							inner join Visitors v1 on s1.VisitorID = v1.VisitorID
    					where
    						pv1.Domain = isnull(@Domain, pv1.Domain) and
    						v1.Campaign = @Campaign
    					group by
    						pv1.sessionid
    				) t1 on pv2.sessionid = t1.sessionid and pv2.created = t1.created
    ) t2
group by 
    Path;
</code></pre>

<p>I've tested this query with 2 million rows in the PageViews table and it takes about 20 seconds to run. I'm noticing a clustered index scan twice in the execution plan, both times it hits the PageViews table. There is a clustered index on the Created column in that table.</p>

<p>The problem is that in both cases it appears to iterate over all 2 million rows, which I believe is the performance bottleneck. Is there anything I can do to prevent this, or am I pretty much maxed out as far as optimization goes?</p>

<p>For reference, the purpose of the query is to find the first page view for each session.</p>

<p><strong>EDIT:</strong> After much frustration, despite the help received here, I could not make this query work. Therefore, I decided to simply store a reference to the entry page (and now exit page) in the sessions table, which allows me to do the following:</p>

<pre><code>select
    pv.Path,
    count(*)
from
    PageViews pv
    	inner join Sessions s on pv.SessionID = s.SessionID
    		and pv.PageViewID = s.ExitPage
    	inner join Visitors v on s.VisitorID = v.VisitorID
where
    (
        @Domain is null or 
        pv.Domain = @Domain
    ) and
    v.Campaign = @Campaign
group by pv.Path;
</code></pre>

<p>This query runs in 3 seconds or less. Now I either have to update the entry/exit page in real time as the page views are recorded (the optimal solution) or run a batch update at some interval. Either way, it solves the problem, but not like I'd intended. </p>

<p>Edit Edit: Adding a missing index (after cleaning up from last night) reduced the query to mere milliseconds). Woo hoo!</p>
","<p>To continue from doofledorf. </p>

<p>Try this:</p>

<pre><code>where
   (@Domain is null or pv1.Domain = @Domain) and
   v1.Campaign = @Campaign
</code></pre>

<p>Ok, I have a couple of suggestions</p>

<ol>
<li><p>Create this covered index: </p>

<pre><code> create index idx2 on [PageViews]([SessionID], Domain, Created, Path)
</code></pre></li>
<li><p>If you can amend the Sessions table so that it stores the entry page, eg. EntryPageViewID you will be able to heavily optimise this. </p></li>
</ol>
"
731,339560,1,1,sql,T-SQL Query Optimization,"<p>I'm working on some upgrades to an internal web analytics system we provide for our clients (in the absence of a preferred vendor or Google Analytics), and I'm working on the following query:</p>

<pre><code>select 
    path as EntryPage, 
    count(Path) as [Count] 
from 
    (
    	/* Sub-query 1 */
    	select 
    		pv2.path
    	from 
    		pageviews pv2 
    			inner join
    				(
    					/* Sub-query 2 */
    					select
    						pv1.sessionid,
    						min(pv1.created) as created
    					from
    						pageviews pv1 
    							inner join Sessions s1 on pv1.SessionID = s1.SessionID
    							inner join Visitors v1 on s1.VisitorID = v1.VisitorID
    					where
    						pv1.Domain = isnull(@Domain, pv1.Domain) and
    						v1.Campaign = @Campaign
    					group by
    						pv1.sessionid
    				) t1 on pv2.sessionid = t1.sessionid and pv2.created = t1.created
    ) t2
group by 
    Path;
</code></pre>

<p>I've tested this query with 2 million rows in the PageViews table and it takes about 20 seconds to run. I'm noticing a clustered index scan twice in the execution plan, both times it hits the PageViews table. There is a clustered index on the Created column in that table.</p>

<p>The problem is that in both cases it appears to iterate over all 2 million rows, which I believe is the performance bottleneck. Is there anything I can do to prevent this, or am I pretty much maxed out as far as optimization goes?</p>

<p>For reference, the purpose of the query is to find the first page view for each session.</p>

<p><strong>EDIT:</strong> After much frustration, despite the help received here, I could not make this query work. Therefore, I decided to simply store a reference to the entry page (and now exit page) in the sessions table, which allows me to do the following:</p>

<pre><code>select
    pv.Path,
    count(*)
from
    PageViews pv
    	inner join Sessions s on pv.SessionID = s.SessionID
    		and pv.PageViewID = s.ExitPage
    	inner join Visitors v on s.VisitorID = v.VisitorID
where
    (
        @Domain is null or 
        pv.Domain = @Domain
    ) and
    v.Campaign = @Campaign
group by pv.Path;
</code></pre>

<p>This query runs in 3 seconds or less. Now I either have to update the entry/exit page in real time as the page views are recorded (the optimal solution) or run a batch update at some interval. Either way, it solves the problem, but not like I'd intended. </p>

<p>Edit Edit: Adding a missing index (after cleaning up from last night) reduced the query to mere milliseconds). Woo hoo!</p>
","<p>Your inner query (pv1) will require a nonclustered index on (Domain).</p>

<p>The second query (pv2) can already find the rows it needs due to the clustered index on Created, but pv1 might be returning so many rows that SQL Server decides that a table scan is quicker than all the locks it would need to take.  As pv1 groups on SessionID (and hence has to order by SessionID), a nonclustered index on SessionID, Created, and including path should permit a MERGE join to occur.  If not, you can force a merge join with ""SELECT .. FROM pageviews pv2 INNER MERGE JOIN ...""</p>

<p>The two indexes listed above will be:</p>

<p>CREATE NONCLUSTERED INDEX ncixcampaigndomain ON PageViews (Domain)</p>

<p>CREATE NONCLUSTERED INDEX ncixsessionidcreated ON PageViews(SessionID, Created) INCLUDE (path)</p>
"
732,339560,1,1,sql,T-SQL Query Optimization,"<p>I'm working on some upgrades to an internal web analytics system we provide for our clients (in the absence of a preferred vendor or Google Analytics), and I'm working on the following query:</p>

<pre><code>select 
    path as EntryPage, 
    count(Path) as [Count] 
from 
    (
    	/* Sub-query 1 */
    	select 
    		pv2.path
    	from 
    		pageviews pv2 
    			inner join
    				(
    					/* Sub-query 2 */
    					select
    						pv1.sessionid,
    						min(pv1.created) as created
    					from
    						pageviews pv1 
    							inner join Sessions s1 on pv1.SessionID = s1.SessionID
    							inner join Visitors v1 on s1.VisitorID = v1.VisitorID
    					where
    						pv1.Domain = isnull(@Domain, pv1.Domain) and
    						v1.Campaign = @Campaign
    					group by
    						pv1.sessionid
    				) t1 on pv2.sessionid = t1.sessionid and pv2.created = t1.created
    ) t2
group by 
    Path;
</code></pre>

<p>I've tested this query with 2 million rows in the PageViews table and it takes about 20 seconds to run. I'm noticing a clustered index scan twice in the execution plan, both times it hits the PageViews table. There is a clustered index on the Created column in that table.</p>

<p>The problem is that in both cases it appears to iterate over all 2 million rows, which I believe is the performance bottleneck. Is there anything I can do to prevent this, or am I pretty much maxed out as far as optimization goes?</p>

<p>For reference, the purpose of the query is to find the first page view for each session.</p>

<p><strong>EDIT:</strong> After much frustration, despite the help received here, I could not make this query work. Therefore, I decided to simply store a reference to the entry page (and now exit page) in the sessions table, which allows me to do the following:</p>

<pre><code>select
    pv.Path,
    count(*)
from
    PageViews pv
    	inner join Sessions s on pv.SessionID = s.SessionID
    		and pv.PageViewID = s.ExitPage
    	inner join Visitors v on s.VisitorID = v.VisitorID
where
    (
        @Domain is null or 
        pv.Domain = @Domain
    ) and
    v.Campaign = @Campaign
group by pv.Path;
</code></pre>

<p>This query runs in 3 seconds or less. Now I either have to update the entry/exit page in real time as the page views are recorded (the optimal solution) or run a batch update at some interval. Either way, it solves the problem, but not like I'd intended. </p>

<p>Edit Edit: Adding a missing index (after cleaning up from last night) reduced the query to mere milliseconds). Woo hoo!</p>
","<p>I'm back. To answer your first question, you could probably just do a union on the two conditions, since they are obviously disjoint.</p>

<p>Actually, you're trying to cover both the case where you provide a domain, and where you don't. You want two queries. They may optimize entirely differently.</p>
"
733,339560,1,1,sql,T-SQL Query Optimization,"<p>I'm working on some upgrades to an internal web analytics system we provide for our clients (in the absence of a preferred vendor or Google Analytics), and I'm working on the following query:</p>

<pre><code>select 
    path as EntryPage, 
    count(Path) as [Count] 
from 
    (
    	/* Sub-query 1 */
    	select 
    		pv2.path
    	from 
    		pageviews pv2 
    			inner join
    				(
    					/* Sub-query 2 */
    					select
    						pv1.sessionid,
    						min(pv1.created) as created
    					from
    						pageviews pv1 
    							inner join Sessions s1 on pv1.SessionID = s1.SessionID
    							inner join Visitors v1 on s1.VisitorID = v1.VisitorID
    					where
    						pv1.Domain = isnull(@Domain, pv1.Domain) and
    						v1.Campaign = @Campaign
    					group by
    						pv1.sessionid
    				) t1 on pv2.sessionid = t1.sessionid and pv2.created = t1.created
    ) t2
group by 
    Path;
</code></pre>

<p>I've tested this query with 2 million rows in the PageViews table and it takes about 20 seconds to run. I'm noticing a clustered index scan twice in the execution plan, both times it hits the PageViews table. There is a clustered index on the Created column in that table.</p>

<p>The problem is that in both cases it appears to iterate over all 2 million rows, which I believe is the performance bottleneck. Is there anything I can do to prevent this, or am I pretty much maxed out as far as optimization goes?</p>

<p>For reference, the purpose of the query is to find the first page view for each session.</p>

<p><strong>EDIT:</strong> After much frustration, despite the help received here, I could not make this query work. Therefore, I decided to simply store a reference to the entry page (and now exit page) in the sessions table, which allows me to do the following:</p>

<pre><code>select
    pv.Path,
    count(*)
from
    PageViews pv
    	inner join Sessions s on pv.SessionID = s.SessionID
    		and pv.PageViewID = s.ExitPage
    	inner join Visitors v on s.VisitorID = v.VisitorID
where
    (
        @Domain is null or 
        pv.Domain = @Domain
    ) and
    v.Campaign = @Campaign
group by pv.Path;
</code></pre>

<p>This query runs in 3 seconds or less. Now I either have to update the entry/exit page in real time as the page views are recorded (the optimal solution) or run a batch update at some interval. Either way, it solves the problem, but not like I'd intended. </p>

<p>Edit Edit: Adding a missing index (after cleaning up from last night) reduced the query to mere milliseconds). Woo hoo!</p>
","<p>What's the nature of the data in these tables?  Do you find most of the data is inserted/deleted regularly?  </p>

<p>Is that the full schema for the tables?  The query plan shows different indexing..
Edit: Sorry, just read the last line of text.  I'd suggest if the tables are routinely cleared/insertsed, you could think about ditching the clustered index and using the tables as heap tables.. just a thought</p>

<p>Definately should put non-clustered index(es) on Campaign, Domain as John suggested</p>
"
734,339560,1,1,sql,T-SQL Query Optimization,"<p>I'm working on some upgrades to an internal web analytics system we provide for our clients (in the absence of a preferred vendor or Google Analytics), and I'm working on the following query:</p>

<pre><code>select 
    path as EntryPage, 
    count(Path) as [Count] 
from 
    (
    	/* Sub-query 1 */
    	select 
    		pv2.path
    	from 
    		pageviews pv2 
    			inner join
    				(
    					/* Sub-query 2 */
    					select
    						pv1.sessionid,
    						min(pv1.created) as created
    					from
    						pageviews pv1 
    							inner join Sessions s1 on pv1.SessionID = s1.SessionID
    							inner join Visitors v1 on s1.VisitorID = v1.VisitorID
    					where
    						pv1.Domain = isnull(@Domain, pv1.Domain) and
    						v1.Campaign = @Campaign
    					group by
    						pv1.sessionid
    				) t1 on pv2.sessionid = t1.sessionid and pv2.created = t1.created
    ) t2
group by 
    Path;
</code></pre>

<p>I've tested this query with 2 million rows in the PageViews table and it takes about 20 seconds to run. I'm noticing a clustered index scan twice in the execution plan, both times it hits the PageViews table. There is a clustered index on the Created column in that table.</p>

<p>The problem is that in both cases it appears to iterate over all 2 million rows, which I believe is the performance bottleneck. Is there anything I can do to prevent this, or am I pretty much maxed out as far as optimization goes?</p>

<p>For reference, the purpose of the query is to find the first page view for each session.</p>

<p><strong>EDIT:</strong> After much frustration, despite the help received here, I could not make this query work. Therefore, I decided to simply store a reference to the entry page (and now exit page) in the sessions table, which allows me to do the following:</p>

<pre><code>select
    pv.Path,
    count(*)
from
    PageViews pv
    	inner join Sessions s on pv.SessionID = s.SessionID
    		and pv.PageViewID = s.ExitPage
    	inner join Visitors v on s.VisitorID = v.VisitorID
where
    (
        @Domain is null or 
        pv.Domain = @Domain
    ) and
    v.Campaign = @Campaign
group by pv.Path;
</code></pre>

<p>This query runs in 3 seconds or less. Now I either have to update the entry/exit page in real time as the page views are recorded (the optimal solution) or run a batch update at some interval. Either way, it solves the problem, but not like I'd intended. </p>

<p>Edit Edit: Adding a missing index (after cleaning up from last night) reduced the query to mere milliseconds). Woo hoo!</p>
","<pre><code>SELECT  
    sessionid,  
    MIN(created) AS created  
FROM  
    pageviews pv  
JOIN  
    visitors v ON pv.visitorid = v.visitorid  
WHERE  
    v.campaign = @Campaign  
GROUP BY  
    sessionid
</code></pre>

<p>so that gives you the sessions for a campaign. Now let's see what you're doing with that.</p>

<p>OK, this gets rid of your grouping:</p>

<pre><code>SELECT  
    campaignid,  
    sessionid,   
    pv.path  
FROM  
    pageviews pv  
JOIN  
    visitors v ON pv.visitorid = v.visitorid  
WHERE  
    v.campaign = @Campaign  
    AND NOT EXISTS (  
        SELECT 1 FROM pageviews  
        WHERE sessionid = pv.sessionid  
        AND created &lt; pv.created  
    )
</code></pre>
"
735,342290,1,1,sql,tool for detecting non-parametrized sql in java jdbc code,"<p>I'm looking to inspect SQL statements in Java/jdbc code to ensure that the SQL to be executed is of acceptable quality. Neither PMD not Findbugs appears to have JDBC or sql rules. I could use p6spy to log the SQL and look at  that way, but this is manual. </p>

<p>I'm wondering if the strategy of of using PMD/Findbugs/etc to create a rule that any string passed to PreparedStatement where there is an ""="" or ""in"" has only parametrized vars on the compare side.</p>

<p>Has anyone done this? Or done this by other means?</p>
","<p>This is a tricky problem.  Comparison operators like <code>=</code> and <code>IN()</code> are some cases, but there's also:  <code>!= &lt;&gt; &lt; &lt;= &gt; &gt;= LIKE</code>.</p>

<p>How do you spot cases of interpolating application variables as literals in expressions?</p>

<pre><code>String sql = ""SELECT *, "" + someJavaVar + "" AS constant_column FROM mytable"";
</code></pre>

<p>You could search for SQL containing string delimiters, but SQL injection doesn't come only from interpolating string literals.</p>

<p>How would you spot cases of interpolating application variables as things other than data values?</p>

<pre><code>String sql = ""SELECT * FROM mytable ORDER BY "" + columnname;
</code></pre>

<p>I don't know any automatic way to detect SQL injection flaws.  Code review is a more effective way to spot them.  In every SQL statement that contains interpolated application variables, you have to confirm that the application variables are ""safe"" and that your app has explicitly validated them or transformed them so they don't contain dangerous payload.</p>
"
843,371490,2,1,sql,Oracle SQL - Parsing a name string and converting it to first initial & last name,"<p>Does anyone know how to turn this string: ""Smith, John R""<br>
Into this string: ""jsmith"" ?</p>

<p>I need to lowercase everything with lower()<br>
Find where the comma is and track it's integer location value<br>
Get the first character after that comma and put it in front of the string<br>
Then get the entire last name and stick it after the first initial.<br><br>
Sidenote - instr() function is not compatible with my version<br><br>
Thanks for any help!</p>
","<p>The best way to do this is using Oracle Regular Expressions feature, like this:</p>

<pre><code>SELECT LOWER(regexp_replace('Smith, John R', 
             '(.+)(, )([A-Z])(.+)', 
             '\3\1', 1, 1)) 
  FROM DUAL;
</code></pre>

<p>That says, 1) when you find the pattern of any set of characters, followed by "", "", followed by an uppercase character, followed by any remaining characters, take the third element (initial of first name) and append the last name.  Then make everything lowercase.</p>

<p>Your side note: ""instr() function is not compatible with my version"" doesn't make sense to me, as that function's been around for ages.  Check your version, because Regular Expressions was only added to Oracle in version 9i.</p>

<p>Thanks for the points.</p>

<p>-- Stew</p>
"
662,289220,2,1,sql,Updating an associative table in MySQL,"<p>Below is my (simplified) schema (in MySQL ver. 5.0.51b) and my strategy for updating it. There has got to be a better way. Inserting a new item requires 4 trips to the database and editing/updating an item takes up to <strong>7</strong>!</p>

<p><strong>items</strong>: itemId, itemName
<br /><strong>categories</strong>: catId, catName
<br /><strong>map</strong>: mapId*, itemId, catId
<br />* mapId (varchar) is concat of itemId + | + catId</p>

<p>1) If inserting: insert item. Get itemId via MySQL API.
<br />Else updating: just update the item table. We already have the itemId.</p>

<p>2) Conditionally batch insert into <code>categories</code>.</p>

<pre><code>INSERT IGNORE INTO categories (catName)
VALUES ('each'), ('category'), ('name');
</code></pre>

<p>3) Select IDs from <code>categories</code>.</p>

<pre><code>SELECT catId FROM categories
WHERE catName = 'each' OR catName = 'category' OR catName = 'name';
</code></pre>

<p>4) Conditionally batch insert into <code>map</code>.</p>

<pre><code>INSERT IGNORE INTO map (mapId, itemId, catId)
VALUES ('1|1', 1, 1), ('1|2', 1, 2), ('1|3', 1, 3);
</code></pre>

<p>If inserting: we're done. Else updating: continue.</p>

<p>5) It's possible that we no longer associate a category with this item that we did prior to the update. Delete old categories for this itemId.</p>

<pre><code>DELETE FROM MAP WHERE itemId = 2
AND catID &lt;&gt; 2 AND catID &lt;&gt; 3 AND catID &lt;&gt; 5;
</code></pre>

<p>6) If we have disassociated ourselves from a category, it's possible that we left it orphaned. We do not want categories with no items. Therefore, if <code>affected rows &gt; 0</code>, kill orphaned categories. I haven't found a way to combine these in MySQL, so this is #6 &amp; #7.</p>

<pre><code>SELECT categories.catId
FROM categories
LEFT JOIN map USING (catId)
GROUP BY categories.catId
HAVING COUNT(map.catId) &lt; 1;
</code></pre>

<p>7) Delete IDs found in step 6.</p>

<pre><code>DELETE FROM categories
WHERE catId = 9
  AND catId = 10;
</code></pre>

<p>Please tell me there's a better way that I'm not seeing.</p>
","<p>Also, if you are worried about trips to the db, make steps into a stored procedure.  Then you have one trip.</p>
"
925,431080,-1,1,sql,Better way of returning the values of a column in Active Record?,"<p>Quick one, but thought I'd ask.</p>

<p>Is there a better way of getting the column values from a model's column than something like this?</p>

<pre><code>Item.count(:all, :group =&gt; 'status').reject! { |i, e| i.blank? }.collect { |i,e| i}
</code></pre>
","<p>Is it the same thing as the following code?</p>

<pre><code>Item.count(:all, :group =&gt; ""status"", :conditions =&gt; ""status != ''""}
</code></pre>

<p>.. maybe not ..</p>

<p>but then could you please specify more criteria you want? i.e. status is blank? count is blank?</p>
"
252,106400,0,1,sql,"Fetch top X users, plus a specific user (if they're not in the top X)","<p>I have a list of ranked users, and would like to select the top 50. I also want to make sure one particular user is in this result set, even if they aren't in the top 50. Is there a sensible way to do this in a single mysql query? Or should I just check the results for the particular user and fetch him separately, if necessary?</p>

<p>Thanks!</p>
","<pre><code>declare @topUsers table(
    userId int primary key,
    username varchar(25)
)
insert into @topUsers
select top 50 
    userId, 
    userName
from Users
order by rank desc

insert into @topUsers
select
    userID,
    userName
from Users
where userID = 1234 --userID of special user

select * from @topUsers
</code></pre>
"
71,29040,5,1,sql,Linq To SQL: Can I eager load only one field in a joined table?,"<p>I have one table ""orders"" with a foreing key ""ProductID"".</p>

<p>I want to show the orders in a grid with the <strong>product name</strong>, without <strong>LazyLoad</strong> for better performance, but I if use <strong>DataLoadOptions</strong> it retrieves <strong>all</strong> Product fields, which seams like a <strong>overkill</strong>.</p>

<p>Is there a way to retrieve <strong>only</strong> the Product name in the first query?
Can I set some attribute in the DBML?</p>

<p>In this <a href=""http://visualstudiomagazine.com/listings/list.aspx?id=566"" rel=""nofollow"">table</a> says that ""Foreign-key values"" are ""Visible"" in Linq To SQL, but don't know what this means.</p>

<p><strong>Edit</strong>: Changed the title, because I'm not really sure the there is no solution.<br />
Can't believe no one has the same problem, it is a very common scenario.</p>
","<p>What you are asking for is a level of optimisation the linq-to-sql does not provide. I think your best bet is to create a query that returns exactly the data you want, possibly as an anonymous type:</p>

<pre><code>from order in DB.GetTable&lt;Orders&gt;()
join product in DB.GetTable&lt;Products&gt;()
on order.ProductID = product.ID
select new { ID = order.ID, Name = order.Name, ProductName = product.Name };
</code></pre>
"
96,35320,2,1,sql,How do you get the last record generated in a recursive CTE?,"<p>In the code below I am using a recursive CTE(Common Table Expression) in SQL Server 2005 to try and find the top level parent of a basic hierarchical structure. The rule of this hierarchy is that every CustID has a ParentID and if the CustID has no parent then the ParentID = CustID and it is the highest level.</p>

<pre><code>DECLARE @LookupID int

--Our test value
SET @LookupID = 1

WITH cteLevelOne (ParentID, CustID) AS
(
    	SELECT   a.ParentID, a.CustID
    	FROM     tblCustomer AS a
    	WHERE    a.CustID = @LookupID
    UNION ALL
    	SELECT   a.ParentID, a.CustID
    	FROM     tblCustomer AS a
    	INNER JOIN cteLevelOne AS c ON a.CustID = c.ParentID
    	WHERE c.CustID &lt;&gt; a.CustomerID
)
</code></pre>

<p>So if tblCustomer looks like this:  </p>

<pre><code>ParentID    CustID
5            5
1            8
5            4
4            1
</code></pre>

<p>The result I get from the code above is:  </p>

<pre><code>ParentID    CustID
4            1
5            4
5            5
</code></pre>

<p>What I want is just the last row of that result:  </p>

<pre><code>ParentID    CustID
5            5
</code></pre>

<p>How do I just return the last record generated in the CTE (which would be highest level CustID)?</p>

<p>Also note that there are multiple unrelated CustID hierarchies in this table so I can't just do a SELECT * FROM tblCustomer WHERE ParentID = CustID. I can't order by ParentID or CustID because the ID number is not related to where it is in the hierarchy.</p>
","<p>If you just want want the highest recursion depth couldn't you do something like this?Then, when you actually query the CTE just look for the row with max(Depth)?  Like so:</p>

<pre><code>DECLARE @LookupID int

--Our test value
SET @LookupID = 1;

WITH cteLevelOne (ParentID, CustID, Depth) AS
(
        SELECT   a.ParentID, a.CustID, 1
        FROM     tblCustomer AS a
        WHERE    a.CustID = @LookupID
    UNION ALL
        SELECT   a.ParentID, a.CustID, c.Depth + 1
        FROM     tblCustomer AS a
        INNER JOIN cteLevelOne AS c ON a.CustID = c.ParentID 
        WHERE c.CustID &lt;&gt; a.CustID
)
select * from CTELevelone where Depth = (select max(Depth) from CTELevelone)
</code></pre>

<p>or, adapting what trevor suggests, this could be used with the same CTE:  </p>

<pre><code>select top 1 * from CTELevelone order by Depth desc
</code></pre>

<p>I don't think CustomerID was necessarily what you wanted to order by in the case you described, but I wasn't perfectly clear on the question either.</p>
"
217,104230,1,1,sql,how do I query multiple SQL tables for a specific key-value pair?,"<p>Situation: A PHP application with multiple installable modules creates a new table in database for each, in the style of mod_A, mod_B, mod_C etc. Each has the column section_id.</p>

<p>Now, I am looking for all entries for a specific section_id, and I'm hoping there's another way besides ""Select * from mod_a, mod_b, mod_c ... mod_xyzzy where section_id=value""... or even worse, using a separate query for each module.</p>
","<p>What about?</p>

<pre><code>SELECT * FROM mod_a WHERE section_id=value
UNION ALL
SELECT * FROM mod_b WHERE section_id=value
UNION ALL
SELECT * FROM mod_c WHERE section_id=value
</code></pre>
"
945,439670,0,1,sql,How can I mix COUNT() and non-COUNT() columns without losing information in the query?,"<p>I started with a query:</p>

<pre><code>SELECT strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
</code></pre>

<p>Which yielded me some results:</p>

<pre><code>strip                 | character
'Calvin &amp; Hobbes'     | 'Calvin'
'Calvin &amp; Hobbes'     | 'Hobbes'
'Pearls Before Swine' | 'Pig'
'Pearls Before Swine' | 'Rat'
'Pearls Before Swine' | 'Hobbes'  # a guest appearance
'Pearls Before Swine' | 'Calvin'  # a guest appearance
</code></pre>

<p>Then I wanted to also get the <code>COUNT</code> of the number of times a character is used (in any strip) within the result set.  So I tried:</p>

<pre><code>SELECT count(character.id), strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
</code></pre>

<p>But that gave me</p>

<pre><code>[ERROR 11:20:17] Mixing of GROUP columns (MIN(),MAX(),COUNT(),...) with no GROUP columns is illegal if there is no GROUP BY clause
</code></pre>

<p>So I tried:</p>

<pre><code>SELECT count(character.id), strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
 group by character.id
</code></pre>

<p>Which gave me</p>

<pre><code>count | strip                 | character
4     | 'Calvin &amp; Hobbes'     | 'Calvin'
4     | 'Calvin &amp; Hobbes'     | 'Hobbes'
2     | 'Pearls Before Swine' | 'Pig'
2     | 'Pearls Before Swine' | 'Rat'
</code></pre>

<p>That is, I lose all the extra information about exactly which characters appear in which strips.</p>

<p>What I'd like to get is this:</p>

<pre><code>count | strip                 | character
4     | 'Calvin &amp; Hobbes'     | 'Calvin'
4     | 'Calvin &amp; Hobbes'     | 'Hobbes'
2     | 'Pearls Before Swine' | 'Pig'
2     | 'Pearls Before Swine' | 'Rat'
4     | 'Pearls Before Swine' | 'Calvin'
4     | 'Pearls Before Swine' | 'Hobbes'
</code></pre>

<p>But I can't seem to figure it out.  I'm on MySQL if it matters.  Perhaps it'll just take two queries.</p>
","<p>Subselect:</p>

<pre><code>SELECT foo.bar
    ,baz.yoo
    ,(SELECT COUNT(*) FROM baz AS baz2 WHERE baz2.yoo = baz.yoo etc.) AS yoo_count
FROM foo, baz
WHERE foo.baz_id = baz.id
    AND baz.id in (...)
</code></pre>

<p>You can also take the subselect and nest it and join.</p>
"
254,116630,1,1,sql,Hiding Subreports in SQL Report (RDL),"<p>I have a bunch a reports that are printed out and mailed to clients. At the top of the report is the return address, left aligned. I was asked to add an optional logo to the report. This logo should be left of the return address. (The logo and all other info is stored in the database). So if the logo exists, you SHOULD see:</p>

<p>&lt;someimage&gt; &lt;Return Address&gt;</p>

<p>And if no logo exists, you SHOULD see:</p>

<p>&lt;Return Address&gt;</p>

<p>There are many different logos possible placed in many different reports, so to make life easier, the logo was implemented as a subreport. The subreport just grabs the correct logo image, and then it automatically displays in the report.</p>

<p>The problem I'm having is this. If the log DOES NOT exist, then we want the return address left aligned, as shown above. But what is happening is that while the subreport shows nothing, it still takes up the space where the logo WOULD be, and the return address is floating a few inches to the right of the left side of the page.</p>

<pre><code>           &lt;Return Address&gt;
</code></pre>

<p>SO... is there a setting I can use/set to get the subreport to either not show, or not take up any space, if there is no logo to be displayed?</p>

<p>Sorry, hope I made this clear enough. I'm totally new to RDL's.</p>
","<p>You should be able to set an expression on the subreport's visibility so that it does not show if there isn't a logo.</p>

<p>Here is the XML from an RDL I had handy:</p>

<pre><code>&lt;Subreport Name=""SubReport""&gt;
  &lt;ReportName&gt;SubReport&lt;/ReportName&gt;
  &lt;Visibility&gt;
    &lt;Hidden&gt;=Not Parameters!ShowLogo.Value&lt;/Hidden&gt;
  &lt;/Visibility&gt;
&lt;/Subreport&gt;
</code></pre>

<p>This tests against a boolean parameter called ShowLogo, but you could just as easily test the value of another parameter (perhaps the length of a URL?).</p>

<p>To be clear, when specifying the expression for the ""Hidden"" property, you want it to evaluate to False when you want the element to display.  If your expression evaluates to True, that means that the element will be hidden.</p>
"
944,439670,0,1,sql,How can I mix COUNT() and non-COUNT() columns without losing information in the query?,"<p>I started with a query:</p>

<pre><code>SELECT strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
</code></pre>

<p>Which yielded me some results:</p>

<pre><code>strip                 | character
'Calvin &amp; Hobbes'     | 'Calvin'
'Calvin &amp; Hobbes'     | 'Hobbes'
'Pearls Before Swine' | 'Pig'
'Pearls Before Swine' | 'Rat'
'Pearls Before Swine' | 'Hobbes'  # a guest appearance
'Pearls Before Swine' | 'Calvin'  # a guest appearance
</code></pre>

<p>Then I wanted to also get the <code>COUNT</code> of the number of times a character is used (in any strip) within the result set.  So I tried:</p>

<pre><code>SELECT count(character.id), strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
</code></pre>

<p>But that gave me</p>

<pre><code>[ERROR 11:20:17] Mixing of GROUP columns (MIN(),MAX(),COUNT(),...) with no GROUP columns is illegal if there is no GROUP BY clause
</code></pre>

<p>So I tried:</p>

<pre><code>SELECT count(character.id), strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
 group by character.id
</code></pre>

<p>Which gave me</p>

<pre><code>count | strip                 | character
4     | 'Calvin &amp; Hobbes'     | 'Calvin'
4     | 'Calvin &amp; Hobbes'     | 'Hobbes'
2     | 'Pearls Before Swine' | 'Pig'
2     | 'Pearls Before Swine' | 'Rat'
</code></pre>

<p>That is, I lose all the extra information about exactly which characters appear in which strips.</p>

<p>What I'd like to get is this:</p>

<pre><code>count | strip                 | character
4     | 'Calvin &amp; Hobbes'     | 'Calvin'
4     | 'Calvin &amp; Hobbes'     | 'Hobbes'
2     | 'Pearls Before Swine' | 'Pig'
2     | 'Pearls Before Swine' | 'Rat'
4     | 'Pearls Before Swine' | 'Calvin'
4     | 'Pearls Before Swine' | 'Hobbes'
</code></pre>

<p>But I can't seem to figure it out.  I'm on MySQL if it matters.  Perhaps it'll just take two queries.</p>
","<p>If MySQL supports Analytics/Window Functions, then:</p>

<pre><code>select bar, yoo,
    count(yoo) over (partition by yoo) c 
from t
/
</code></pre>

<p>otherwise you'll need to use a correlated subquery:</p>

<pre><code>select bar, yoo,
    (select count(yoo) from t t2 where t2.yoo=t.yoo) c 
from t
/
</code></pre>

<p>on oracle, the test data looks like:</p>

<pre><code>create table t(bar number, yoo varchar2(16));

insert into t(bar, yoo) values (1, 'hello');

insert into t(bar, yoo) values (2, 'goodbye');

insert into t(bar, yoo) values (3, 'goodbye');

insert into t(bar, yoo) values (4, 'goodbye');

insert into t(bar, yoo) values (2, 'calvin');

insert into t(bar, yoo) values (5, 'Hobbes');

insert into t(bar, yoo) values (6, 'Hobbes');

commit;
</code></pre>
"
943,439670,0,1,sql,How can I mix COUNT() and non-COUNT() columns without losing information in the query?,"<p>I started with a query:</p>

<pre><code>SELECT strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
</code></pre>

<p>Which yielded me some results:</p>

<pre><code>strip                 | character
'Calvin &amp; Hobbes'     | 'Calvin'
'Calvin &amp; Hobbes'     | 'Hobbes'
'Pearls Before Swine' | 'Pig'
'Pearls Before Swine' | 'Rat'
'Pearls Before Swine' | 'Hobbes'  # a guest appearance
'Pearls Before Swine' | 'Calvin'  # a guest appearance
</code></pre>

<p>Then I wanted to also get the <code>COUNT</code> of the number of times a character is used (in any strip) within the result set.  So I tried:</p>

<pre><code>SELECT count(character.id), strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
</code></pre>

<p>But that gave me</p>

<pre><code>[ERROR 11:20:17] Mixing of GROUP columns (MIN(),MAX(),COUNT(),...) with no GROUP columns is illegal if there is no GROUP BY clause
</code></pre>

<p>So I tried:</p>

<pre><code>SELECT count(character.id), strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
 group by character.id
</code></pre>

<p>Which gave me</p>

<pre><code>count | strip                 | character
4     | 'Calvin &amp; Hobbes'     | 'Calvin'
4     | 'Calvin &amp; Hobbes'     | 'Hobbes'
2     | 'Pearls Before Swine' | 'Pig'
2     | 'Pearls Before Swine' | 'Rat'
</code></pre>

<p>That is, I lose all the extra information about exactly which characters appear in which strips.</p>

<p>What I'd like to get is this:</p>

<pre><code>count | strip                 | character
4     | 'Calvin &amp; Hobbes'     | 'Calvin'
4     | 'Calvin &amp; Hobbes'     | 'Hobbes'
2     | 'Pearls Before Swine' | 'Pig'
2     | 'Pearls Before Swine' | 'Rat'
4     | 'Pearls Before Swine' | 'Calvin'
4     | 'Pearls Before Swine' | 'Hobbes'
</code></pre>

<p>But I can't seem to figure it out.  I'm on MySQL if it matters.  Perhaps it'll just take two queries.</p>
","<p>On an RDBMS system, I'd select the count query into a temporary table, then rejoin the temp table to the main table. This will give you the best of both worlds.</p>

<p>I don't know if mySQL supports temp tables, though.</p>
"
72,29040,0,1,sql,Linq To SQL: Can I eager load only one field in a joined table?,"<p>I have one table ""orders"" with a foreing key ""ProductID"".</p>

<p>I want to show the orders in a grid with the <strong>product name</strong>, without <strong>LazyLoad</strong> for better performance, but I if use <strong>DataLoadOptions</strong> it retrieves <strong>all</strong> Product fields, which seams like a <strong>overkill</strong>.</p>

<p>Is there a way to retrieve <strong>only</strong> the Product name in the first query?
Can I set some attribute in the DBML?</p>

<p>In this <a href=""http://visualstudiomagazine.com/listings/list.aspx?id=566"" rel=""nofollow"">table</a> says that ""Foreign-key values"" are ""Visible"" in Linq To SQL, but don't know what this means.</p>

<p><strong>Edit</strong>: Changed the title, because I'm not really sure the there is no solution.<br />
Can't believe no one has the same problem, it is a very common scenario.</p>
","<p>I get the solution in this other question <a href=""http://stackoverflow.com/questions/381049/which-net-orm-can-deal-with-this-scenario#381084"">http://stackoverflow.com/questions/381049/which-net-orm-can-deal-with-this-scenario#381084</a>, that is related to the <strong>liammclennan</strong> answer but more clear (maybe the question was more clear too)</p>
"
218,104230,0,1,sql,how do I query multiple SQL tables for a specific key-value pair?,"<p>Situation: A PHP application with multiple installable modules creates a new table in database for each, in the style of mod_A, mod_B, mod_C etc. Each has the column section_id.</p>

<p>Now, I am looking for all entries for a specific section_id, and I'm hoping there's another way besides ""Select * from mod_a, mod_b, mod_c ... mod_xyzzy where section_id=value""... or even worse, using a separate query for each module.</p>
","<p>I was going to suggest the same think as borjab.  The only problem with that is that you will have to update all of these queries if you add another table.  The only other option I see is a stored procedure.</p>

<p>I did think of another option here, or at least an easier way to present this.  You can also use a view to these multiple tables to make them appear as one, and then your query would look cleaner, be easier to understand and you wouldn't have to rewrite a long union query when you wanted to do other queries on these multiple tables.</p>
"
219,104230,0,1,sql,how do I query multiple SQL tables for a specific key-value pair?,"<p>Situation: A PHP application with multiple installable modules creates a new table in database for each, in the style of mod_A, mod_B, mod_C etc. Each has the column section_id.</p>

<p>Now, I am looking for all entries for a specific section_id, and I'm hoping there's another way besides ""Select * from mod_a, mod_b, mod_c ... mod_xyzzy where section_id=value""... or even worse, using a separate query for each module.</p>
","<p>Perhaps some additional info would help, but it sounds like you have the solution already.  You will have to select from all the tables with a section_id.  You could use joins instead of a table list, joining on section_id.  For example</p>

<pre><code>select a.some_field, b.some_field.... 
from mod_a a
inner join mod_b b on a.section_id = b.section_id
...
where a.section_id = &lt;parameter&gt;
</code></pre>

<p>You could also package this up as a view.
Also notice the field list instead of *, which I would recommend if you were intending to actually use *.</p>
"
253,106400,0,1,sql,"Fetch top X users, plus a specific user (if they're not in the top X)","<p>I have a list of ranked users, and would like to select the top 50. I also want to make sure one particular user is in this result set, even if they aren't in the top 50. Is there a sensible way to do this in a single mysql query? Or should I just check the results for the particular user and fetch him separately, if necessary?</p>

<p>Thanks!</p>
","<p>The simplest solution depends on your requirements, and what your database supports.</p>

<p>If you don't mind the possibility of having duplicate results, then a simple union (as Mariano Conti demonstrated) is fine.</p>

<p>Otherwise, you could do something like </p>

<p>select distinct 
from
(select * from users order by max(rank) desc limit 0, 49 
union 
select * from users where user = x)</p>

<p>if you database supports it.</p>
"
251,106400,1,1,sql,"Fetch top X users, plus a specific user (if they're not in the top X)","<p>I have a list of ranked users, and would like to select the top 50. I also want to make sure one particular user is in this result set, even if they aren't in the top 50. Is there a sensible way to do this in a single mysql query? Or should I just check the results for the particular user and fetch him separately, if necessary?</p>

<p>Thanks!</p>
","<p>Regardless if a single, fancy SQL query could be made, the most maintainable code would probably be two queries:</p>

<pre><code>select user from users where id = ""fred""; 
select user from users where id != ""fred"" order by rank limit 49;
</code></pre>

<p>Of course ""fred"" (or whomever) would usually be replaced by a placeholder but the specifics depend on the environment. </p>
"
220,104230,0,1,sql,how do I query multiple SQL tables for a specific key-value pair?,"<p>Situation: A PHP application with multiple installable modules creates a new table in database for each, in the style of mod_A, mod_B, mod_C etc. Each has the column section_id.</p>

<p>Now, I am looking for all entries for a specific section_id, and I'm hoping there's another way besides ""Select * from mod_a, mod_b, mod_c ... mod_xyzzy where section_id=value""... or even worse, using a separate query for each module.</p>
","<p>Well, there are only so many ways to aggregate information from multiple tables.  You can join, like you mentioned in your example, or you can run multiple queries and union them together as in borjab's answer.  I don't know if some idea of creating a table that intersects all the module tables would be useful to you, but if section_id was on a table like that you'd be able to get everything from a single query.  Otherwise, I applaud your laziness, but am afraid to say, I don't see any way to make that job eaiser :)</p>
"
916,425020,1,1,sql,SQL Distinct by ID and Latest By Date,"<p>I have the following SQL Statement. I need to select the latest record for each System.Id using the System.RevisedDate</p>

<pre><code>SELECT     [System.Id],[System.RevisedDate], [System.Title], [System.State], [System.Reason], [System.CreatedDate], [System.WorkItemType], [System.TeamProject], 
                      [Microsoft.VSTS.Scheduling.RemainingWork], [Microsoft.VSTS.Scheduling.CompletedWork], [Microsoft.VSTS.CMMI.Estimate]
FROM         WorkItems
WHERE     ([System.WorkItemType] = 'Change Request') AND ([System.CreatedDate] &gt;= '09/30/2008') AND ([System.TeamProject] NOT LIKE '%Deleted%') AND 
                      ([System.TeamProject] NOT LIKE '%Sandbox%')
</code></pre>

<p>Can you please help?</p>
","<p>In general it should go some thing like</p>

<pre><code>SELECT ID,DATE_FIELD,FIELD1,FIELD2
FROM TBL1 AS A WHERE DATE_FIELD &gt;= ALL (
   SELECT DATE_FIELD FROM TBL1 AS B
   WHERE A.ID = B.ID 
)
</code></pre>
"
917,425020,1,1,sql,SQL Distinct by ID and Latest By Date,"<p>I have the following SQL Statement. I need to select the latest record for each System.Id using the System.RevisedDate</p>

<pre><code>SELECT     [System.Id],[System.RevisedDate], [System.Title], [System.State], [System.Reason], [System.CreatedDate], [System.WorkItemType], [System.TeamProject], 
                      [Microsoft.VSTS.Scheduling.RemainingWork], [Microsoft.VSTS.Scheduling.CompletedWork], [Microsoft.VSTS.CMMI.Estimate]
FROM         WorkItems
WHERE     ([System.WorkItemType] = 'Change Request') AND ([System.CreatedDate] &gt;= '09/30/2008') AND ([System.TeamProject] NOT LIKE '%Deleted%') AND 
                      ([System.TeamProject] NOT LIKE '%Sandbox%')
</code></pre>

<p>Can you please help?</p>
","<p>or, (using subquery)</p>

<pre><code>SELECT ID,DATE_FIELD,FIELD1,FIELD2
FROM TBL1 T
Where DATE_FIELD = 
    (Select Max(Date_Field) From Tbl1 
     Where Id = T.Id)
</code></pre>

<p>but I couldn't decipher your example query... Is ""System"" a table?  Why are there no references to WorkItem in the Select clause? it doesn't seem to jibe together... </p>
"
918,425020,3,1,sql,SQL Distinct by ID and Latest By Date,"<p>I have the following SQL Statement. I need to select the latest record for each System.Id using the System.RevisedDate</p>

<pre><code>SELECT     [System.Id],[System.RevisedDate], [System.Title], [System.State], [System.Reason], [System.CreatedDate], [System.WorkItemType], [System.TeamProject], 
                      [Microsoft.VSTS.Scheduling.RemainingWork], [Microsoft.VSTS.Scheduling.CompletedWork], [Microsoft.VSTS.CMMI.Estimate]
FROM         WorkItems
WHERE     ([System.WorkItemType] = 'Change Request') AND ([System.CreatedDate] &gt;= '09/30/2008') AND ([System.TeamProject] NOT LIKE '%Deleted%') AND 
                      ([System.TeamProject] NOT LIKE '%Sandbox%')
</code></pre>

<p>Can you please help?</p>
","<p>Try this:</p>

<pre><code>SELECT * FROM WorkItems w
JOIN (
SELECT     [System.Id],MAX([System.RevisedDate])
FROM WorkItems
WHERE ([System.WorkItemType] = 'Change Request') 
AND ([System.CreatedDate] &gt;= '09/30/2008') 
AND ([System.TeamProject] NOT LIKE '%Deleted%') 
AND ([System.TeamProject] NOT LIKE '%Sandbox%')
GROUP BY {System.Id]
) x ON w.[System.Id] = x.[System.Id] AND w.[System.DateRevised] = x.[System.DateRevised]
</code></pre>
"
919,425020,0,1,sql,SQL Distinct by ID and Latest By Date,"<p>I have the following SQL Statement. I need to select the latest record for each System.Id using the System.RevisedDate</p>

<pre><code>SELECT     [System.Id],[System.RevisedDate], [System.Title], [System.State], [System.Reason], [System.CreatedDate], [System.WorkItemType], [System.TeamProject], 
                      [Microsoft.VSTS.Scheduling.RemainingWork], [Microsoft.VSTS.Scheduling.CompletedWork], [Microsoft.VSTS.CMMI.Estimate]
FROM         WorkItems
WHERE     ([System.WorkItemType] = 'Change Request') AND ([System.CreatedDate] &gt;= '09/30/2008') AND ([System.TeamProject] NOT LIKE '%Deleted%') AND 
                      ([System.TeamProject] NOT LIKE '%Sandbox%')
</code></pre>

<p>Can you please help?</p>
","<p>Try </p>

<pre><code>SELECT [System.Id],[System.RevisedDate], [System.Title], [System.State], [System.Reason], [System.CreatedDate], [System.WorkItemType], [System.TeamProject], 
[Microsoft.VSTS.Scheduling.RemainingWork], [Microsoft.VSTS.Scheduling.CompletedWork], [Microsoft.VSTS.CMMI.Estimate]
FROM         WorkItems
Left JOIN (Select [System.Id],Max([System.RevisedDate]) group by [System.Id]) LatestItems
    on Workitems.[System.Id] = LatestItems.[System.Id] and 
    Workitems.[System.RevisedDate] = LatestItems.[System.RevisedDate]
    WHERE     
([System.WorkItemType] = 'Change Request') AND ([System.CreatedDate] &gt;= '09/30/2008') AND ([System.TeamProject] NOT LIKE '%Deleted%') AND 
                          ([System.TeamProject] NOT LIKE '%Sandbox%')
</code></pre>
"
920,425020,0,1,sql,SQL Distinct by ID and Latest By Date,"<p>I have the following SQL Statement. I need to select the latest record for each System.Id using the System.RevisedDate</p>

<pre><code>SELECT     [System.Id],[System.RevisedDate], [System.Title], [System.State], [System.Reason], [System.CreatedDate], [System.WorkItemType], [System.TeamProject], 
                      [Microsoft.VSTS.Scheduling.RemainingWork], [Microsoft.VSTS.Scheduling.CompletedWork], [Microsoft.VSTS.CMMI.Estimate]
FROM         WorkItems
WHERE     ([System.WorkItemType] = 'Change Request') AND ([System.CreatedDate] &gt;= '09/30/2008') AND ([System.TeamProject] NOT LIKE '%Deleted%') AND 
                      ([System.TeamProject] NOT LIKE '%Sandbox%')
</code></pre>

<p>Can you please help?</p>
","<p>I like Alex's answer, but thought I'd throw in another possibility.  Sorry, didn't get a chance to test it. :-)</p>

<pre><code>SELECT     WorkItems.[System.Id], WorkItems.[System.RevisedDate], [System.Title], [System.State],     [System.Reason], [System.CreatedDate], [System.WorkItemType], [System.TeamProject], 
                  [Microsoft.VSTS.Scheduling.RemainingWork], [Microsoft.VSTS.Scheduling.CompletedWork], [Microsoft.VSTS.CMMI.Estimate]
FROM         WorkItems join (SELECT     [System.Id],max([System.RevisedDate]) [MaxDate]
						 FROM         WorkItems
						 WHERE     ([System.WorkItemType] = 'Change Request') AND ([System.CreatedDate] &gt;= '09/30/2008') AND ([System.TeamProject] NOT LIKE '%Deleted%') AND 
                         ([System.TeamProject] NOT LIKE '%Sandbox%')
						 group by [System.Id]) MaxDates
on  WorkItems.[System.Id] = MaxDates.[System.Id]
and WorkItems.[System.RevisedDate] = MaxDates.[MaxDate]
</code></pre>
"
95,35320,1,1,sql,How do you get the last record generated in a recursive CTE?,"<p>In the code below I am using a recursive CTE(Common Table Expression) in SQL Server 2005 to try and find the top level parent of a basic hierarchical structure. The rule of this hierarchy is that every CustID has a ParentID and if the CustID has no parent then the ParentID = CustID and it is the highest level.</p>

<pre><code>DECLARE @LookupID int

--Our test value
SET @LookupID = 1

WITH cteLevelOne (ParentID, CustID) AS
(
    	SELECT   a.ParentID, a.CustID
    	FROM     tblCustomer AS a
    	WHERE    a.CustID = @LookupID
    UNION ALL
    	SELECT   a.ParentID, a.CustID
    	FROM     tblCustomer AS a
    	INNER JOIN cteLevelOne AS c ON a.CustID = c.ParentID
    	WHERE c.CustID &lt;&gt; a.CustomerID
)
</code></pre>

<p>So if tblCustomer looks like this:  </p>

<pre><code>ParentID    CustID
5            5
1            8
5            4
4            1
</code></pre>

<p>The result I get from the code above is:  </p>

<pre><code>ParentID    CustID
4            1
5            4
5            5
</code></pre>

<p>What I want is just the last row of that result:  </p>

<pre><code>ParentID    CustID
5            5
</code></pre>

<p>How do I just return the last record generated in the CTE (which would be highest level CustID)?</p>

<p>Also note that there are multiple unrelated CustID hierarchies in this table so I can't just do a SELECT * FROM tblCustomer WHERE ParentID = CustID. I can't order by ParentID or CustID because the ID number is not related to where it is in the hierarchy.</p>
","<p>I'm not certain I fully understand the problem, but just to hack &amp; slash at it you could try:</p>

<pre><code>SELECT TOP 1 FROM cteLevelOne ORDER BY CustID DESC
</code></pre>

<p>That assumes that the CustID is also in order as in the example, and not something like a GUID.</p>
"
926,431080,2,1,sql,Better way of returning the values of a column in Active Record?,"<p>Quick one, but thought I'd ask.</p>

<p>Is there a better way of getting the column values from a model's column than something like this?</p>

<pre><code>Item.count(:all, :group =&gt; 'status').reject! { |i, e| i.blank? }.collect { |i,e| i}
</code></pre>
","<pre><code>Item.find(:all, :select=&gt;:status, :group =&gt; 'status', :conditions =&gt; ""status != ''"").collect{|r| r.status}
</code></pre>
"
250,106400,4,1,sql,"Fetch top X users, plus a specific user (if they're not in the top X)","<p>I have a list of ranked users, and would like to select the top 50. I also want to make sure one particular user is in this result set, even if they aren't in the top 50. Is there a sensible way to do this in a single mysql query? Or should I just check the results for the particular user and fetch him separately, if necessary?</p>

<p>Thanks!</p>
","<p>If I understand correctly, you could do:</p>

<pre><code>select * from users order by max(rank) desc limit 0, 49  
union  
select * from users where user = x
</code></pre>

<p>This way you get 49 top users plus your particular user.</p>
"
224,104230,0,1,sql,how do I query multiple SQL tables for a specific key-value pair?,"<p>Situation: A PHP application with multiple installable modules creates a new table in database for each, in the style of mod_A, mod_B, mod_C etc. Each has the column section_id.</p>

<p>Now, I am looking for all entries for a specific section_id, and I'm hoping there's another way besides ""Select * from mod_a, mod_b, mod_c ... mod_xyzzy where section_id=value""... or even worse, using a separate query for each module.</p>
","<p>An option from the database side would be to create a view of the UNION ALL of the various tables.  When you add a table, you would need to add it to the view, but otherwise it would look like a single table.</p>

<pre><code>CREATE VIEW modules AS (
    SELECT * FROM mod_A
    UNION ALL 
    SELECT * FROM mod_B
    UNION ALL 
    SELECT * FROM mod_C
);

select * from modules where section_id=value;
</code></pre>
"
223,104230,0,1,sql,how do I query multiple SQL tables for a specific key-value pair?,"<p>Situation: A PHP application with multiple installable modules creates a new table in database for each, in the style of mod_A, mod_B, mod_C etc. Each has the column section_id.</p>

<p>Now, I am looking for all entries for a specific section_id, and I'm hoping there's another way besides ""Select * from mod_a, mod_b, mod_c ... mod_xyzzy where section_id=value""... or even worse, using a separate query for each module.</p>
","<pre><code>SELECT * FROM (
	SELECT * FROM table1
	UNION ALL
	SELECT * FROM table2
	UNION ALL
	SELECT * FROM table3
) subQry
WHERE field=value
</code></pre>
"
222,104230,1,1,sql,how do I query multiple SQL tables for a specific key-value pair?,"<p>Situation: A PHP application with multiple installable modules creates a new table in database for each, in the style of mod_A, mod_B, mod_C etc. Each has the column section_id.</p>

<p>Now, I am looking for all entries for a specific section_id, and I'm hoping there's another way besides ""Select * from mod_a, mod_b, mod_c ... mod_xyzzy where section_id=value""... or even worse, using a separate query for each module.</p>
","<p>I have two suggestions.</p>

<ol>
<li><p>Perhaps you need to consolidate all your tables. If they all contain the same structure, then why not have one ""master"" module table, that just adds one new column identifying the module (""A"", ""B"", ""C"", ....)</p>

<p>If your module tables are mostly the same, but you have a few columns that are different, you might still be able to consolidate all the common information into one table, and keep smaller module-specific tables with those differences. Then you would just need to do a join on them.</p>

<p>This suggestion assumes that your query on the column section_id you mention is super-critical to look up quickly. With one query you get all the common information, and with a second you would get any specific information if you needed it. (And you might not -- for instance if you were trying to validate the existense of the section, then finding it in the common table would be enough)</p></li>
<li><p>Alternatively you can add another table that maps section_id's to the modules that they are in.</p>

<pre>
section_id | module
-----------+-------
      1    |  A
      2    |  B
      3    |  A
     ...   | ...
</pre>

<p>This does mean though that you have to run two queries, one against this mapping table, and another against the module table to pull out any useful data.</p>

<p>You can extend this table with other columns and indices on those columns if you need to look up other columns that are common to all modules.</p>

<p>This method has the definite disadvanage that the data is duplicated.</p></li>
</ol>
"
70,29040,0,1,sql,Linq To SQL: Can I eager load only one field in a joined table?,"<p>I have one table ""orders"" with a foreing key ""ProductID"".</p>

<p>I want to show the orders in a grid with the <strong>product name</strong>, without <strong>LazyLoad</strong> for better performance, but I if use <strong>DataLoadOptions</strong> it retrieves <strong>all</strong> Product fields, which seams like a <strong>overkill</strong>.</p>

<p>Is there a way to retrieve <strong>only</strong> the Product name in the first query?
Can I set some attribute in the DBML?</p>

<p>In this <a href=""http://visualstudiomagazine.com/listings/list.aspx?id=566"" rel=""nofollow"">table</a> says that ""Foreign-key values"" are ""Visible"" in Linq To SQL, but don't know what this means.</p>

<p><strong>Edit</strong>: Changed the title, because I'm not really sure the there is no solution.<br />
Can't believe no one has the same problem, it is a very common scenario.</p>
","<p>If you select only the columns you want in the linq query, and then call .ToList() on the query, it will be immedietly executed, and will only bring back the columns you are interested in. For example if you do this:</p>

<pre><code>var q = from p in dataContext.products select p.ProductName;
var results = q.ToList();
</code></pre>

<p>You will get back a list of product names stored in results, and when the query executes on the server it will only bring back the ProductName column.</p>
"
264,121700,2,1,sql,What Exception should be thrown when an ADO.NET query cannot retrieve the requested data?,"<p>In an attempt to add some parameter validation and correct usage semantics to our application, we are trying to add correct exception handling to our .NET applications.</p>

<p>My question is this: When throwing exceptions in ADO.NET if a particular query returns no data or the data could not be found, what type of exception should I use?</p>

<p>Psuedocode:
(read, don't scrutinize the semantics of the code, I know it won't compile)</p>

<pre><code>public DataSet GetData(int identifier)
{
    dataAdapter.Command.Text = ""Select * from table1 Where ident = "" + identifier.toString();
    DataSet ds = dataAdapter.Fill(ds);
    if (ds.table1.Rows.Count == 0)
        throw new Exception(""Data not found"");

    return ds;
}
</code></pre>
","<p>As far as ADO.net is concerned, a query that returns zero rows is not an error. If your application wishes to treat such a query as an error, you should create your own exception class by inheriting from Exception.</p>

<pre><code>public class myException : Exception
{
   public myException(string s) : base() 
   {
      this.MyReasonMessage = s;
   }
}

public void GetData(int identifier)
{
    dataAdapter.Command.Text = ""Select * from table1 Where ident = "" + identifier.toString();
    DataSet ds = dataAdapter.Fill(ds);
    if (ds.table1.Rows.Count == 0)
        throw new myException(""Data not found"");
}
</code></pre>
"
902,413940,2,1,sql,How can I prevent/detect an underflow in a Postgresql calculation that uses EXP(),"<p>I am receiving a value out of range: underflow error from pgsql, in a query that uses the EXP(x) function.  What values of x trigger this?  How do I prevent or detect it?</p>
","<p>The function exp is called the exponential function, and its inverse is the natural logarithm, or logarithm to base e. The number e is also commonly defined as the base of the natural logarithm</p>

<p>In other words, exp(x) and e^x are the same function.  However, since e is a transcendental number, and therefore irrational, its value cannot be given exactly.</p>

<p>The Numerical value of e truncated to 10 decimal places is 2.718281828</p>

<p>So, the function exp(x) is technically valid for all values of x, but practically speaking, you can limit them.  For example, if you limit them to +/- 700 you should cover all cases covering the range </p>

<pre><code>exp(700) = 1.01423205  10^304
exp(-700) = 9.85967654  10^-305
</code></pre>

<p>More than that depends on your application</p>
"
400,182130,0,1,sql,SQL - state machine - reporting on historical data based on changeset,"<p>I want to record user states and then be able to report historically based on the record of changes we've kept. I'm trying to do this in SQL (using PostgreSQL) and I have a proposed structure for recording user changes like the following.</p>

<pre><code>CREATE TABLE users (
  userid SERIAL NOT NULL PRIMARY KEY, 
  name VARCHAR(40), 
  status CHAR NOT NULL
);

CREATE TABLE status_log (
  logid SERIAL, 
  userid INTEGER NOT NULL REFERENCES users(userid), 
  status CHAR NOT NULL, 
  logcreated TIMESTAMP
);
</code></pre>

<p>That's my proposed table structure, based on the data.</p>

<p>For the status field 'a' represents an active user and 's' represents a suspended user,</p>

<pre><code>INSERT INTO status_log (userid, status, logcreated) VALUES (1, 's', '2008-01-01'); 
INSERT INTO status_log (userid, status, logcreated) VALUES (1, 'a', '2008-02-01');
</code></pre>

<p>So this user was suspended on 1st Jan and active again on 1st of February.</p>

<p>If I wanted to get a suspended list of customers on 15th January 2008, then userid 1 should show up. If I get a suspended list of customers on 15th February 2008, then userid 1 should not show up.</p>

<p>1) Is this the best way to structure this data for this kind of query?</p>

<p>2) How do I query the data in either this structure or in your proposed modified structure so that I can simply have a date (say 15th January) and find a list of customers that had an active status on that date in SQL only? Is this a job for SQL?</p>
","<p>@Tony the ""end"" date isn't necessarily applicable.</p>

<p>A user might get moved from active, to suspended, to cancelled, to active again. This is a simplified version, in reality, there are even more states and people can be moved directly from one state to another.</p>

<p>Additionally, there would be no ""end date"" for the current status either, so I think this slightly breaks your query?</p>
"
948,439670,0,1,sql,How can I mix COUNT() and non-COUNT() columns without losing information in the query?,"<p>I started with a query:</p>

<pre><code>SELECT strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
</code></pre>

<p>Which yielded me some results:</p>

<pre><code>strip                 | character
'Calvin &amp; Hobbes'     | 'Calvin'
'Calvin &amp; Hobbes'     | 'Hobbes'
'Pearls Before Swine' | 'Pig'
'Pearls Before Swine' | 'Rat'
'Pearls Before Swine' | 'Hobbes'  # a guest appearance
'Pearls Before Swine' | 'Calvin'  # a guest appearance
</code></pre>

<p>Then I wanted to also get the <code>COUNT</code> of the number of times a character is used (in any strip) within the result set.  So I tried:</p>

<pre><code>SELECT count(character.id), strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
</code></pre>

<p>But that gave me</p>

<pre><code>[ERROR 11:20:17] Mixing of GROUP columns (MIN(),MAX(),COUNT(),...) with no GROUP columns is illegal if there is no GROUP BY clause
</code></pre>

<p>So I tried:</p>

<pre><code>SELECT count(character.id), strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
 group by character.id
</code></pre>

<p>Which gave me</p>

<pre><code>count | strip                 | character
4     | 'Calvin &amp; Hobbes'     | 'Calvin'
4     | 'Calvin &amp; Hobbes'     | 'Hobbes'
2     | 'Pearls Before Swine' | 'Pig'
2     | 'Pearls Before Swine' | 'Rat'
</code></pre>

<p>That is, I lose all the extra information about exactly which characters appear in which strips.</p>

<p>What I'd like to get is this:</p>

<pre><code>count | strip                 | character
4     | 'Calvin &amp; Hobbes'     | 'Calvin'
4     | 'Calvin &amp; Hobbes'     | 'Hobbes'
2     | 'Pearls Before Swine' | 'Pig'
2     | 'Pearls Before Swine' | 'Rat'
4     | 'Pearls Before Swine' | 'Calvin'
4     | 'Pearls Before Swine' | 'Hobbes'
</code></pre>

<p>But I can't seem to figure it out.  I'm on MySQL if it matters.  Perhaps it'll just take two queries.</p>
","<p>If I'm going to be requiring a count field like this reasonably often then I create a user defined function to return the value and just use that inside a normal select.</p>
"
870,383760,4,1,sql,"Django objects.filter, how ""expensive"" would this be?","<p>I am trying to make a search view in Django. It is a search form with freetext input + some options to select, so that you can filter on years and so on. This is some of the code I have in the view so far, the part that does the filtering. And I would like some input on how expensive this would be on the database server.</p>

<p><code>
    soknad_list = Soknad.objects.all()</p>

<pre><code>if var1:
    soknad_list = soknad_list.filter(pub_date__year=var1)

if var2:
    soknad_list = soknad_list.filter(muncipality__name__exact=var2)

if var3:
    soknad_list = soknad_list.filter(genre__name__exact=var3)

# TEXT SEARCH
stop_word_list = re.compile(STOP_WORDS, re.IGNORECASE)
search_term = '%s' % request.GET['q']
cleaned_search_term = stop_word_list.sub('', search_term)
cleaned_search_term = cleaned_search_term.strip()
if len(cleaned_search_term) != 0:
    soknad_list = soknad_list.filter(Q(dream__icontains=cleaned_search_term) | Q(tags__icontains=cleaned_search_term) | Q(name__icontains=cleaned_search_term) | Q(school__name__icontains=cleaned_search_term))
</code></pre>

<p></code></p>

<p>So what I do is, first make a list of all objects, then I check which variables exists (I fetch these with GET on an earlier point) and then I filter the results if they exists. But this doesn't seem too elegant, it probably does a lot of queries to achieve the result, so is there a better way to this?</p>

<p>It does exactly what I want, but I guess there is a better/smarter way to do this. Any ideas?</p>
","<p>filter itself doesn't execute a query, no query is executed until you explicitly fetch items from query (e.g. get), and list( query ) also executes it.</p>
"
871,383760,2,1,sql,"Django objects.filter, how ""expensive"" would this be?","<p>I am trying to make a search view in Django. It is a search form with freetext input + some options to select, so that you can filter on years and so on. This is some of the code I have in the view so far, the part that does the filtering. And I would like some input on how expensive this would be on the database server.</p>

<p><code>
    soknad_list = Soknad.objects.all()</p>

<pre><code>if var1:
    soknad_list = soknad_list.filter(pub_date__year=var1)

if var2:
    soknad_list = soknad_list.filter(muncipality__name__exact=var2)

if var3:
    soknad_list = soknad_list.filter(genre__name__exact=var3)

# TEXT SEARCH
stop_word_list = re.compile(STOP_WORDS, re.IGNORECASE)
search_term = '%s' % request.GET['q']
cleaned_search_term = stop_word_list.sub('', search_term)
cleaned_search_term = cleaned_search_term.strip()
if len(cleaned_search_term) != 0:
    soknad_list = soknad_list.filter(Q(dream__icontains=cleaned_search_term) | Q(tags__icontains=cleaned_search_term) | Q(name__icontains=cleaned_search_term) | Q(school__name__icontains=cleaned_search_term))
</code></pre>

<p></code></p>

<p>So what I do is, first make a list of all objects, then I check which variables exists (I fetch these with GET on an earlier point) and then I filter the results if they exists. But this doesn't seem too elegant, it probably does a lot of queries to achieve the result, so is there a better way to this?</p>

<p>It does exactly what I want, but I guess there is a better/smarter way to do this. Any ideas?</p>
","<p>You can see the query that will be generated by using:</p>

<pre><code>soknad_list.query.as_sql()[0]
</code></pre>

<p>You can then put that into your database shell to see how long the query takes, or use EXPLAIN (if your database backend supports it) to see how expensive it is.</p>
"
872,383760,-1,1,sql,"Django objects.filter, how ""expensive"" would this be?","<p>I am trying to make a search view in Django. It is a search form with freetext input + some options to select, so that you can filter on years and so on. This is some of the code I have in the view so far, the part that does the filtering. And I would like some input on how expensive this would be on the database server.</p>

<p><code>
    soknad_list = Soknad.objects.all()</p>

<pre><code>if var1:
    soknad_list = soknad_list.filter(pub_date__year=var1)

if var2:
    soknad_list = soknad_list.filter(muncipality__name__exact=var2)

if var3:
    soknad_list = soknad_list.filter(genre__name__exact=var3)

# TEXT SEARCH
stop_word_list = re.compile(STOP_WORDS, re.IGNORECASE)
search_term = '%s' % request.GET['q']
cleaned_search_term = stop_word_list.sub('', search_term)
cleaned_search_term = cleaned_search_term.strip()
if len(cleaned_search_term) != 0:
    soknad_list = soknad_list.filter(Q(dream__icontains=cleaned_search_term) | Q(tags__icontains=cleaned_search_term) | Q(name__icontains=cleaned_search_term) | Q(school__name__icontains=cleaned_search_term))
</code></pre>

<p></code></p>

<p>So what I do is, first make a list of all objects, then I check which variables exists (I fetch these with GET on an earlier point) and then I filter the results if they exists. But this doesn't seem too elegant, it probably does a lot of queries to achieve the result, so is there a better way to this?</p>

<p>It does exactly what I want, but I guess there is a better/smarter way to do this. Any ideas?</p>
","<p>As Aaron mentioned, you should get a hold of the query text that is going to be run against the database and use an EXPLAIN (or other some method) to view the query execution plan. Once you have a hold of the execution plan for the query you can see what is going on in the database itself. There are a lot of operations that see very expensive to run through procedural code that are very trivial for any database to run, especially if you provide indexes that the database can use for speeding up your query.</p>

<p>If I read your question correctly, you're retrieving a result set of all rows in the Soknad table. Once you have these results back you use the filter() method to trim down your results meet your criteria. From looking at the Django documentation, it looks like this will do an in-memory filter rather than re-query the database (of course, this really depends on which data access layer you're using and not on Django itself).</p>

<p>The most optimal solution would be to use a full-text search engine (Lucene, ferret, etc) to handle this for you. If that is not available or practical the next best option would be to to construct a query predicate (WHERE clause) before issuing your query to the database and let the database perform the filtering. </p>

<p><strong>However,</strong> as with all things that involve the database, the real answer is 'it depends.' The best suggestion is to try out several different approaches using data that is close to production and benchmark them over at least 3 iterations before settling on a final solution to the problem. It may be just as fast, or even faster, to filter in memory rather than filter in the database.</p>
"
878,392750,5,1,sql,How to do it in mysql: If id=idold THEN UPDATE status=1,"<p>I would like to compare two tables and then update if some logic is true,
<BR>
In pseudo code:</p>

<p>SELECT * FROM users, usersold IF users.id=usersold.id THEN UPDATE users.status=1;</p>

<p>Is there a way to do it in mysql?</p>
","<pre><code>UPDATE users u
SET status = 1
WHERE EXISTS (SELECT id FROM usersold WHERE id = u.id)
</code></pre>

<p>Alternate version:</p>

<pre><code>UPDATE users
SET status = 1
WHERE id IN (SELECT id FROM usersold)
</code></pre>

<p>You should test and, depending on your database, you may find one performs better than the other although I expect any decent database will optimize then to be much the same anyway.</p>
"
888,404450,0,1,sql,LINQ to SQL,"<p>I am finishing off a C# ASP.NET program that allows the user to build their own computer by selecting hardware components such as memory, cpu, etc from a drop down lists. The SQL datatable has 3 columns; ComputerID, Attribute and Value. The computerID is an ID that corresponds to a certain computer in my main datatable of products, the Attribtute is the name of the hardware component; memory,cpu, hard drive etc.. and the value is the value assigned to that attribute, such as 1GB or 2.8GHz 320GB. This means that a computer will have multiple attributes. </p>

<p>What I am trying to do it narrow down the results by first selecting all computers that meet the first attribute requirements and then getting from that list, all computers that meet the next requirement.. and so on for about 10+ attributes.</p>

<p>I thought it might be a good idea to show you an example of my LINQ to SQL query so that you have a btter idea of what I am trying to do. This basically selects the ComputerID where the the computers memory is larger than 1GB.</p>

<pre><code>var resultsList = from results in db.ComputerAttributes
                  where computer.Value == ""MEMORY"" &amp;&amp; computer.Value &gt;= ""1""
                  select results.ComputerID;
</code></pre>

<p>Next I want to select from the resultsList where the CPU is say, faster than 2.8Ghz and so on. </p>

<p>I hope I have given you enough information.
If anyone could please give me some advice as to how I might go about finishing this project that would be great.</p>

<p>Thanks</p>
","<p>I'm assuming you're asking:</p>

<blockquote>
  <p>How do I refine the content of a search I've done using LINQ to SQL?</p>
</blockquote>

<p>Or something similar right?</p>

<p>To my understanding, you have two options:</p>

<ol>
<li>Filter your results in memory (if you have them cached).</li>
<li>Extend your SQL query and hit the DB again.</li>
</ol>

<p>I'm not sure that LINQ to SQL allows you to requery an existing result set. I'm pretty sure it doesn't.</p>
"
889,404450,0,1,sql,LINQ to SQL,"<p>I am finishing off a C# ASP.NET program that allows the user to build their own computer by selecting hardware components such as memory, cpu, etc from a drop down lists. The SQL datatable has 3 columns; ComputerID, Attribute and Value. The computerID is an ID that corresponds to a certain computer in my main datatable of products, the Attribtute is the name of the hardware component; memory,cpu, hard drive etc.. and the value is the value assigned to that attribute, such as 1GB or 2.8GHz 320GB. This means that a computer will have multiple attributes. </p>

<p>What I am trying to do it narrow down the results by first selecting all computers that meet the first attribute requirements and then getting from that list, all computers that meet the next requirement.. and so on for about 10+ attributes.</p>

<p>I thought it might be a good idea to show you an example of my LINQ to SQL query so that you have a btter idea of what I am trying to do. This basically selects the ComputerID where the the computers memory is larger than 1GB.</p>

<pre><code>var resultsList = from results in db.ComputerAttributes
                  where computer.Value == ""MEMORY"" &amp;&amp; computer.Value &gt;= ""1""
                  select results.ComputerID;
</code></pre>

<p>Next I want to select from the resultsList where the CPU is say, faster than 2.8Ghz and so on. </p>

<p>I hope I have given you enough information.
If anyone could please give me some advice as to how I might go about finishing this project that would be great.</p>

<p>Thanks</p>
","<p>You might want to switch to use extension methods.  It may make it a little easier to chain these together.  Also, you won't be able to do less-than/greater-than comparisons on strings since SQL doesn't support these types of string comparisons.  If you stored ids that had the same ordering as the string descriptions, however, you could compare these.</p>

<p>Using extension methods you can do things like:</p>

<pre><code>Dictionary&lt;string,int&gt;  attributeMap = new Dictionary&lt;string,int&gt;();
attributeMap.Add(""MEMORY"",1000);
attributeMap.Add(""SPEED"",2800);

var results = db.ComputerAttributes;
foreach (var attribute in attributeMap)
{
    results = results.Where( c =&gt; c.Attribute == attribute.Key
                             &amp;&amp; c.Value &gt;= attribute.Value );
}

var ids = results.Select( c =&gt; c.ComputerID );

foreach (int id in ids)
{
    ...
}
</code></pre>

<p>In the above example 1000 is equivalent to 1GB and 2800 is equivalent to 2.8GHz.</p>
"
401,182130,0,1,sql,SQL - state machine - reporting on historical data based on changeset,"<p>I want to record user states and then be able to report historically based on the record of changes we've kept. I'm trying to do this in SQL (using PostgreSQL) and I have a proposed structure for recording user changes like the following.</p>

<pre><code>CREATE TABLE users (
  userid SERIAL NOT NULL PRIMARY KEY, 
  name VARCHAR(40), 
  status CHAR NOT NULL
);

CREATE TABLE status_log (
  logid SERIAL, 
  userid INTEGER NOT NULL REFERENCES users(userid), 
  status CHAR NOT NULL, 
  logcreated TIMESTAMP
);
</code></pre>

<p>That's my proposed table structure, based on the data.</p>

<p>For the status field 'a' represents an active user and 's' represents a suspended user,</p>

<pre><code>INSERT INTO status_log (userid, status, logcreated) VALUES (1, 's', '2008-01-01'); 
INSERT INTO status_log (userid, status, logcreated) VALUES (1, 'a', '2008-02-01');
</code></pre>

<p>So this user was suspended on 1st Jan and active again on 1st of February.</p>

<p>If I wanted to get a suspended list of customers on 15th January 2008, then userid 1 should show up. If I get a suspended list of customers on 15th February 2008, then userid 1 should not show up.</p>

<p>1) Is this the best way to structure this data for this kind of query?</p>

<p>2) How do I query the data in either this structure or in your proposed modified structure so that I can simply have a date (say 15th January) and find a list of customers that had an active status on that date in SQL only? Is this a job for SQL?</p>
","<p>@Phil</p>

<p>I like Tony's solution. It seems to most approriately model the situation described. Any particular user has a status for a given period of time (a minute, an hour, a day, etc.), but it is for a duration, not an instant in time. Since you want to know who was active during a certain period of time, modeling the information as a duration seems like the best approach.</p>

<p>I am not sure that additional statuses are a problem. If someone is active, then suspended, then cancelled, then active again, each of those statuses would be applicable for a given duration, would they not? It may be a vey short duration, such as a few seconds or a minute, but they would still be for a length of time.</p>

<p>Are you concerned that a person's status can change multiple times in a given day, but you want to know who was active for a given day? If so, then you just need to more specifically define what it means to be active on a given day. If it is enough that they were active for any part of that day, then Tony's answer works well as is. If they would have to be active for a certain amount of time in a given day, then Tony's solution could be modified to simply determine the length of time (in hours, or minutes, or days), and adding further restrictions in the WHERE clause to retrieve for the proper date, status, and length of time in that status.</p>

<p>As for there being no ""end date"" for the current status, that is no problem either as long as the end date were nullable. Simply use something like this ""WHERE enddate &lt;= '2008-08-15' or enddate is null"".</p>
"
947,439670,3,1,sql,How can I mix COUNT() and non-COUNT() columns without losing information in the query?,"<p>I started with a query:</p>

<pre><code>SELECT strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
</code></pre>

<p>Which yielded me some results:</p>

<pre><code>strip                 | character
'Calvin &amp; Hobbes'     | 'Calvin'
'Calvin &amp; Hobbes'     | 'Hobbes'
'Pearls Before Swine' | 'Pig'
'Pearls Before Swine' | 'Rat'
'Pearls Before Swine' | 'Hobbes'  # a guest appearance
'Pearls Before Swine' | 'Calvin'  # a guest appearance
</code></pre>

<p>Then I wanted to also get the <code>COUNT</code> of the number of times a character is used (in any strip) within the result set.  So I tried:</p>

<pre><code>SELECT count(character.id), strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
</code></pre>

<p>But that gave me</p>

<pre><code>[ERROR 11:20:17] Mixing of GROUP columns (MIN(),MAX(),COUNT(),...) with no GROUP columns is illegal if there is no GROUP BY clause
</code></pre>

<p>So I tried:</p>

<pre><code>SELECT count(character.id), strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
 group by character.id
</code></pre>

<p>Which gave me</p>

<pre><code>count | strip                 | character
4     | 'Calvin &amp; Hobbes'     | 'Calvin'
4     | 'Calvin &amp; Hobbes'     | 'Hobbes'
2     | 'Pearls Before Swine' | 'Pig'
2     | 'Pearls Before Swine' | 'Rat'
</code></pre>

<p>That is, I lose all the extra information about exactly which characters appear in which strips.</p>

<p>What I'd like to get is this:</p>

<pre><code>count | strip                 | character
4     | 'Calvin &amp; Hobbes'     | 'Calvin'
4     | 'Calvin &amp; Hobbes'     | 'Hobbes'
2     | 'Pearls Before Swine' | 'Pig'
2     | 'Pearls Before Swine' | 'Rat'
4     | 'Pearls Before Swine' | 'Calvin'
4     | 'Pearls Before Swine' | 'Hobbes'
</code></pre>

<p>But I can't seem to figure it out.  I'm on MySQL if it matters.  Perhaps it'll just take two queries.</p>
","<p>Does mySQL support analytic functions?  Like:</p>

<pre><code>SELECT foo.bar, baz.yoo, count(baz.yoo) over (partition by foo.bar) as yoo_count 
from foo, bar
where foo.baz_id = baz.id and baz.id in (...)
</code></pre>

<p>Alternatively:</p>

<pre><code>SELECT foo.bar, baz.yoo, v.yoo_count 
from foo, bar, 
( select foo.baz_id, count(*) as yoo_count
  from foo
  group by foo.baz_id
) as v
where foo.baz_id = baz.id and baz.id in (...)
and v.baz_id = foo.baz_id;
</code></pre>
"
946,439670,1,1,sql,How can I mix COUNT() and non-COUNT() columns without losing information in the query?,"<p>I started with a query:</p>

<pre><code>SELECT strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
</code></pre>

<p>Which yielded me some results:</p>

<pre><code>strip                 | character
'Calvin &amp; Hobbes'     | 'Calvin'
'Calvin &amp; Hobbes'     | 'Hobbes'
'Pearls Before Swine' | 'Pig'
'Pearls Before Swine' | 'Rat'
'Pearls Before Swine' | 'Hobbes'  # a guest appearance
'Pearls Before Swine' | 'Calvin'  # a guest appearance
</code></pre>

<p>Then I wanted to also get the <code>COUNT</code> of the number of times a character is used (in any strip) within the result set.  So I tried:</p>

<pre><code>SELECT count(character.id), strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
</code></pre>

<p>But that gave me</p>

<pre><code>[ERROR 11:20:17] Mixing of GROUP columns (MIN(),MAX(),COUNT(),...) with no GROUP columns is illegal if there is no GROUP BY clause
</code></pre>

<p>So I tried:</p>

<pre><code>SELECT count(character.id), strip.name as strip, character.name as character
  from strips, characters, appearances
 where strips.id = appearances.strip_id
   and characters.id = appearances.character.id
   and appearances.date in (...)
 group by character.id
</code></pre>

<p>Which gave me</p>

<pre><code>count | strip                 | character
4     | 'Calvin &amp; Hobbes'     | 'Calvin'
4     | 'Calvin &amp; Hobbes'     | 'Hobbes'
2     | 'Pearls Before Swine' | 'Pig'
2     | 'Pearls Before Swine' | 'Rat'
</code></pre>

<p>That is, I lose all the extra information about exactly which characters appear in which strips.</p>

<p>What I'd like to get is this:</p>

<pre><code>count | strip                 | character
4     | 'Calvin &amp; Hobbes'     | 'Calvin'
4     | 'Calvin &amp; Hobbes'     | 'Hobbes'
2     | 'Pearls Before Swine' | 'Pig'
2     | 'Pearls Before Swine' | 'Rat'
4     | 'Pearls Before Swine' | 'Calvin'
4     | 'Pearls Before Swine' | 'Hobbes'
</code></pre>

<p>But I can't seem to figure it out.  I'm on MySQL if it matters.  Perhaps it'll just take two queries.</p>
","<p>What about grouping by foo.bar?</p>

<pre><code>SELECT count(baz.id) as count, foo.bar, baz.yoo where foo.baz_id = baz.id and baz.id in (...) group by foo.bar
</code></pre>
"
67,28280,2,1,sql,Can I maintain state between calls to a SQL Server UDF?,"<p>I have a SQL script that inserts data (via INSERT statements currently numbering in the thousands) One of the columns contains a unique identifier (though not an IDENTITY type, just a plain ol' int) that's actually unique across a few different tables. </p>

<p>I'd like to add a scalar function to my script that gets the next available ID (i.e. last used ID + 1) but I'm not sure this is possible because there doesn't seem to be a way to use a global or static variable from within a UDF, I can't use a temp table, and I can't update a permanent table from within a function. </p>

<p>Currently my script looks like this: </p>

<pre>
   declare @v_baseID int 
   exec dbo.getNextID @v_baseID out  --sproc to get the next available id
   --Lots of these - where n is a hardcoded value
   insert into tableOfStuff (someStuff, uniqueID) values ('stuff', @v_baseID + n ) 
   exec dbo.UpdateNextID @v_baseID + lastUsedn  --sproc to update the last used id
</pre>

<p>But I would like it to look like this: </p>

<pre>
   --Lots of these
   insert into tableOfStuff (someStuff, uniqueID) values ('stuff', getNextID() ) 
</pre>

<p>Hardcoding the offset is a pain in the arse, and is error prone.  Packaging it up into a simple scalar function is very appealing, but I'm starting to think it can't be done that way since there doesn't seem to be a way to maintain the offset counter between calls.  Is that right, or is there something I'm missing.  </p>

<p>We're using SQL Server 2005 at the moment. </p>

<p><em>edits for clarification:</em></p>

<p>Two users hitting it won't happen.  This is an upgrade script that will be run only once, and never concurrently. </p>

<p>The actual sproc isn't prefixed with sp_, fixed the example code. </p>

<p>In normal usage, we do use an id table and a sproc to get IDs as needed, I was just looking for a cleaner way to do it in this script, which essentially just dumps a bunch of data into the db. </p>
","<p>If you have 2 users hitting it at the same time they will get the same id. Why didn't you use an id table with an identity instead, insert into that and use that as the unique (which is guaranteed) id, this will also perform much faster</p>

<blockquote>
  <blockquote>
    <p>sp_getNextID </p>
  </blockquote>
</blockquote>

<p>never ever prefix procs with sp_, this has performance implication because the optimizer first checks the master DB to see if that proc exists there and then th local DB, also if MS decide to create a sp_getNextID in a service pack yours will never get executed</p>
"
399,182130,2,1,sql,SQL - state machine - reporting on historical data based on changeset,"<p>I want to record user states and then be able to report historically based on the record of changes we've kept. I'm trying to do this in SQL (using PostgreSQL) and I have a proposed structure for recording user changes like the following.</p>

<pre><code>CREATE TABLE users (
  userid SERIAL NOT NULL PRIMARY KEY, 
  name VARCHAR(40), 
  status CHAR NOT NULL
);

CREATE TABLE status_log (
  logid SERIAL, 
  userid INTEGER NOT NULL REFERENCES users(userid), 
  status CHAR NOT NULL, 
  logcreated TIMESTAMP
);
</code></pre>

<p>That's my proposed table structure, based on the data.</p>

<p>For the status field 'a' represents an active user and 's' represents a suspended user,</p>

<pre><code>INSERT INTO status_log (userid, status, logcreated) VALUES (1, 's', '2008-01-01'); 
INSERT INTO status_log (userid, status, logcreated) VALUES (1, 'a', '2008-02-01');
</code></pre>

<p>So this user was suspended on 1st Jan and active again on 1st of February.</p>

<p>If I wanted to get a suspended list of customers on 15th January 2008, then userid 1 should show up. If I get a suspended list of customers on 15th February 2008, then userid 1 should not show up.</p>

<p>1) Is this the best way to structure this data for this kind of query?</p>

<p>2) How do I query the data in either this structure or in your proposed modified structure so that I can simply have a date (say 15th January) and find a list of customers that had an active status on that date in SQL only? Is this a job for SQL?</p>
","<p>This can be done, but would be a lot more efficient if you stored the end date of each log.  With your model you have to do something like:</p>

<pre><code>select l1.userid
from status_log l1
where l1.status='s'
and l1.logcreated = (select max(l2.logcreated)
                     from status_log l2
                     where l2.userid = l1.userid
                     and   l2.logcreated &lt;= date '2008-02-15'
                    );
</code></pre>

<p>With the additional column it woud be more like:</p>

<pre><code>select userid
from status_log
where status='s'
and logcreated &lt;= date '2008-02-15'
and logsuperseded &gt;= date '2008-02-15';
</code></pre>

<p>(Apologies for any syntax errors, I don't know Postgresql.)</p>

<p>To address some further issues raised by Phil:</p>

<blockquote>
  <p>A user might get moved from active, to suspended, to cancelled, to active again. This is a simplified version, in reality, there are even more states and people can be moved directly from one state to another.</p>
</blockquote>

<p>This would appear in the table like this:</p>

<pre><code>userid  from       to         status
FRED    2008-01-01 2008-01-31 s
FRED    2008-02-01 2008-02-07 c
FRED    2008-02-08            a
</code></pre>

<p>I used a null for the ""to"" date of the current record.  I could have used a future date like 2999-12-31 but null is preferable in some ways.</p>

<blockquote>
  <p>Additionally, there would be no ""end date"" for the current status either, so I think this slightly breaks your query?</p>
</blockquote>

<p>Yes, my query would have to be re-written as</p>

<pre><code>select userid
from status_log
where status='s'
and logcreated &lt;= date '2008-02-15'
and (logsuperseded is null or logsuperseded &gt;= date '2008-02-15');
</code></pre>

<p>A downside of this design is that whenever the user's status changes you have to end date their current status_log as well as create a new one.  However, that isn't difficult, and I think the query advantage probably outweighs this.</p>
"
68,28280,0,1,sql,Can I maintain state between calls to a SQL Server UDF?,"<p>I have a SQL script that inserts data (via INSERT statements currently numbering in the thousands) One of the columns contains a unique identifier (though not an IDENTITY type, just a plain ol' int) that's actually unique across a few different tables. </p>

<p>I'd like to add a scalar function to my script that gets the next available ID (i.e. last used ID + 1) but I'm not sure this is possible because there doesn't seem to be a way to use a global or static variable from within a UDF, I can't use a temp table, and I can't update a permanent table from within a function. </p>

<p>Currently my script looks like this: </p>

<pre>
   declare @v_baseID int 
   exec dbo.getNextID @v_baseID out  --sproc to get the next available id
   --Lots of these - where n is a hardcoded value
   insert into tableOfStuff (someStuff, uniqueID) values ('stuff', @v_baseID + n ) 
   exec dbo.UpdateNextID @v_baseID + lastUsedn  --sproc to update the last used id
</pre>

<p>But I would like it to look like this: </p>

<pre>
   --Lots of these
   insert into tableOfStuff (someStuff, uniqueID) values ('stuff', getNextID() ) 
</pre>

<p>Hardcoding the offset is a pain in the arse, and is error prone.  Packaging it up into a simple scalar function is very appealing, but I'm starting to think it can't be done that way since there doesn't seem to be a way to maintain the offset counter between calls.  Is that right, or is there something I'm missing.  </p>

<p>We're using SQL Server 2005 at the moment. </p>

<p><em>edits for clarification:</em></p>

<p>Two users hitting it won't happen.  This is an upgrade script that will be run only once, and never concurrently. </p>

<p>The actual sproc isn't prefixed with sp_, fixed the example code. </p>

<p>In normal usage, we do use an id table and a sproc to get IDs as needed, I was just looking for a cleaner way to do it in this script, which essentially just dumps a bunch of data into the db. </p>
","<p>It would probably be more work than it's worth, but you can use static C#/VB variables in a SQL CLR UDF, so I think you'd be able to do what you want to do by simply incrementing this variable every time the UDF is called.  The static variable would be lost whenever the appdomain unloaded, of course.  So if you need continuity of your ID from one day to the next, you'd need a way, on first access of NextId, to poll all of tables that use this ID, to find the highest value.</p>
"
890,404450,1,1,sql,LINQ to SQL,"<p>I am finishing off a C# ASP.NET program that allows the user to build their own computer by selecting hardware components such as memory, cpu, etc from a drop down lists. The SQL datatable has 3 columns; ComputerID, Attribute and Value. The computerID is an ID that corresponds to a certain computer in my main datatable of products, the Attribtute is the name of the hardware component; memory,cpu, hard drive etc.. and the value is the value assigned to that attribute, such as 1GB or 2.8GHz 320GB. This means that a computer will have multiple attributes. </p>

<p>What I am trying to do it narrow down the results by first selecting all computers that meet the first attribute requirements and then getting from that list, all computers that meet the next requirement.. and so on for about 10+ attributes.</p>

<p>I thought it might be a good idea to show you an example of my LINQ to SQL query so that you have a btter idea of what I am trying to do. This basically selects the ComputerID where the the computers memory is larger than 1GB.</p>

<pre><code>var resultsList = from results in db.ComputerAttributes
                  where computer.Value == ""MEMORY"" &amp;&amp; computer.Value &gt;= ""1""
                  select results.ComputerID;
</code></pre>

<p>Next I want to select from the resultsList where the CPU is say, faster than 2.8Ghz and so on. </p>

<p>I hope I have given you enough information.
If anyone could please give me some advice as to how I might go about finishing this project that would be great.</p>

<p>Thanks</p>
","<p>You need to use Concat as a ""Union All"".</p>

<pre><code>IQueryable&lt;ComputerAttribute&gt; results = null;
foreach(ComputerRequirement z in requirements)
{
  //must assign to a locally scoped variable to avoid using
  //  the same reference in all of the where methods.
  ComputerRequirement cr = z;
  if (results == null)
  {
    results = db.ComputerAttributes
      .Where(c =&gt; c.Attribute == cr.Attribute &amp;&amp; c.Value &gt;= cr.Value);
  }
  else
  {
    results = results
      .Concat(db.ComputerAttributes
         .Where(c =&gt; c.Attribute == cr.Attribute &amp;&amp; c.Value &gt;= cr.Value)
      );
  }
}

int requirementCount = requirements.Count();

//Get the id's of computers that matched all requirements.
IQueryable&lt;int&gt; ids = results
  .GroupBy(x =&gt; x.ComputerId)
  .Where(g =&gt; g.Count == requirementsCount)
  .Select(g =&gt; g.Key);


//Get all attributes for those id's
List&lt;ComputerAttributes&gt; data = db
  .ComputerAttributes.Where(c =&gt; ids.Contains(c.ComputerId))
  .ToList();
</code></pre>
"
69,28280,2,1,sql,Can I maintain state between calls to a SQL Server UDF?,"<p>I have a SQL script that inserts data (via INSERT statements currently numbering in the thousands) One of the columns contains a unique identifier (though not an IDENTITY type, just a plain ol' int) that's actually unique across a few different tables. </p>

<p>I'd like to add a scalar function to my script that gets the next available ID (i.e. last used ID + 1) but I'm not sure this is possible because there doesn't seem to be a way to use a global or static variable from within a UDF, I can't use a temp table, and I can't update a permanent table from within a function. </p>

<p>Currently my script looks like this: </p>

<pre>
   declare @v_baseID int 
   exec dbo.getNextID @v_baseID out  --sproc to get the next available id
   --Lots of these - where n is a hardcoded value
   insert into tableOfStuff (someStuff, uniqueID) values ('stuff', @v_baseID + n ) 
   exec dbo.UpdateNextID @v_baseID + lastUsedn  --sproc to update the last used id
</pre>

<p>But I would like it to look like this: </p>

<pre>
   --Lots of these
   insert into tableOfStuff (someStuff, uniqueID) values ('stuff', getNextID() ) 
</pre>

<p>Hardcoding the offset is a pain in the arse, and is error prone.  Packaging it up into a simple scalar function is very appealing, but I'm starting to think it can't be done that way since there doesn't seem to be a way to maintain the offset counter between calls.  Is that right, or is there something I'm missing.  </p>

<p>We're using SQL Server 2005 at the moment. </p>

<p><em>edits for clarification:</em></p>

<p>Two users hitting it won't happen.  This is an upgrade script that will be run only once, and never concurrently. </p>

<p>The actual sproc isn't prefixed with sp_, fixed the example code. </p>

<p>In normal usage, we do use an id table and a sproc to get IDs as needed, I was just looking for a cleaner way to do it in this script, which essentially just dumps a bunch of data into the db. </p>
","<blockquote>
  <p>I'm starting to think it can't be done that way since there doesn't seem to be a way to maintain the offset counter between calls. Is that right, or is there something I'm missing.</p>
</blockquote>

<p>You aren't missing anything; SQL Server does not support global variables, and it doesn't support data modification within UDFs.  And even if you wanted to do something as kludgy as using CONTEXT_INFO (see <a href=""http://weblogs.sqlteam.com/mladenp/archive/2007/04/23/60185.aspx"" rel=""nofollow"">http://weblogs.sqlteam.com/mladenp/archive/2007/04/23/60185.aspx</a>), you can't set that from within a UDF anyway.</p>

<p>Is there a way you can get around the ""hardcoding"" of the offset by making that a variable and looping over the iteration of it, doing the inserts within that loop?</p>
"
891,404450,0,1,sql,LINQ to SQL,"<p>I am finishing off a C# ASP.NET program that allows the user to build their own computer by selecting hardware components such as memory, cpu, etc from a drop down lists. The SQL datatable has 3 columns; ComputerID, Attribute and Value. The computerID is an ID that corresponds to a certain computer in my main datatable of products, the Attribtute is the name of the hardware component; memory,cpu, hard drive etc.. and the value is the value assigned to that attribute, such as 1GB or 2.8GHz 320GB. This means that a computer will have multiple attributes. </p>

<p>What I am trying to do it narrow down the results by first selecting all computers that meet the first attribute requirements and then getting from that list, all computers that meet the next requirement.. and so on for about 10+ attributes.</p>

<p>I thought it might be a good idea to show you an example of my LINQ to SQL query so that you have a btter idea of what I am trying to do. This basically selects the ComputerID where the the computers memory is larger than 1GB.</p>

<pre><code>var resultsList = from results in db.ComputerAttributes
                  where computer.Value == ""MEMORY"" &amp;&amp; computer.Value &gt;= ""1""
                  select results.ComputerID;
</code></pre>

<p>Next I want to select from the resultsList where the CPU is say, faster than 2.8Ghz and so on. </p>

<p>I hope I have given you enough information.
If anyone could please give me some advice as to how I might go about finishing this project that would be great.</p>

<p>Thanks</p>
","<p>Wow, thank you everyone for your  advice it has been extremely useful. I'l try your methods and tell you how things go. The last solution by David B was very similar to what I had done before(counting occurrences of ComputerID)  however my code was extremely inefficient. :)</p>

<pre><code>        string[] FinalResults = new string[100];
        int Counter2 = 0;
        foreach (string Result in Results)
        {
            string test = Result;
            var Counter1 = 0;
            foreach (string Result2 in Results)
            {
                if (test == Result2)
                {
                    Counter1++;
                }
                else
                {
                    continue;
                }
            }
            if (Counter1 &gt;= 3 &amp;&amp; Result != null)
            {
                FinalResults.SetValue(Result,Convert.ToInt32(Counter2));
            }
            else
            {
                continue;
            }
            Counter2++;
        }
        foreach (string FinalResult in FinalResults)
        {
            if (FinalResult != null)
            {
                Response.Write(""Laptop: "" + FinalResult + ""&lt;br /&gt;"");
            }
            else
            {
                continue;
            }
        }
    }
</code></pre>

<p>Will choose the best answer after I have tried each one out. Thanks again everyone for your help, it has been a life saver .</p>
"
379,170130,2,1,sql,Benefits of using a Case statement over an If statement in a stored procedure?,"<p>Hi are there any pros / cons relating to the speed that a stored procedure executes when using an IF statement or choosing to use a CASE statement instead?</p>
","<p>Don't concern yourself with any speed difference between a case and an IF statement. Because you're dealing with a database, the amount of time it takes to write or read from disk is going to dwarf the time it takes the CPU to branch via an IF or Case. You should focus instead on which makes your code more readable and maintainable.</p>
"
378,170130,2,1,sql,Benefits of using a Case statement over an If statement in a stored procedure?,"<p>Hi are there any pros / cons relating to the speed that a stored procedure executes when using an IF statement or choosing to use a CASE statement instead?</p>
","<p>I try not to use <code>IF</code>s if I can avoid it, because they are non transactional, i.e. you have generally no guarantee that the condition of the <code>IF</code> will still be valid inside the <code>BEGIN... END</code> block of the <code>IF</code>.</p>

<p>I assume that you mean using <code>CASE</code> statements inside a SQL <code>SELECT</code>, for example. If the usage is meant to avoid an <code>IF</code> then, by all means, do it.</p>

<p>The golden rule of SQL is: <em>let the server figure out HOW to do things, tell the server what you WANT</em>.</p>
"
359,154920,6,1,sql,How do I fix connection manager error that causes the package to fail in production?,"<p>I have created an SSIS package and it works great on my dev machine. But, when I try to run it on the production server, it errors out on me.</p>

<p>Here is the error:</p>

<pre><code>Error: The AcquireConection method call to the connection manager 
""DestinationConnectionOLEDB"" failed with error code 0xC0202009.
</code></pre>

<p>I have figured out the cause, but am not sure how to get it fixed. The password isn't in the connection string. But I have set the password in the SSIS project. For some reason though, when I deploy and run this on the production server, it won't run since the password isn't part of the connection string.</p>

<p>Is there some setting in the SSIS project that I need to change in order to get this to work right?</p>

<p>Thanks.</p>
","<p>Disable the password by setting the ProtectionLevel in the package properties to DontSaveSensitive.</p>

<p>I also recommend moving the connection string to a package variable and make an expression on the connection.  Enable package configurations.</p>

<p>Then you are free to change the connection and to use integrated security or not without changing the package.  You can either put the connection string in the configuration or then provide it on the command line.</p>
"
266,121700,7,1,sql,What Exception should be thrown when an ADO.NET query cannot retrieve the requested data?,"<p>In an attempt to add some parameter validation and correct usage semantics to our application, we are trying to add correct exception handling to our .NET applications.</p>

<p>My question is this: When throwing exceptions in ADO.NET if a particular query returns no data or the data could not be found, what type of exception should I use?</p>

<p>Psuedocode:
(read, don't scrutinize the semantics of the code, I know it won't compile)</p>

<pre><code>public DataSet GetData(int identifier)
{
    dataAdapter.Command.Text = ""Select * from table1 Where ident = "" + identifier.toString();
    DataSet ds = dataAdapter.Fill(ds);
    if (ds.table1.Rows.Count == 0)
        throw new Exception(""Data not found"");

    return ds;
}
</code></pre>
","<p>The <a href=""http://msdn.microsoft.com/en-us/library/ms229021(VS.80).aspx"" rel=""nofollow"">MSDN guidelines</a> state:</p>

<ul>
<li><p>Consider throwing existing exceptions residing in the System namespaces instead of creating custom exception types.</p></li>
<li><p>Do create and throw custom exceptions if you have an error condition that can be programmatically handled in a different way than any other existing exceptions. Otherwise, throw one of the existing exceptions.</p></li>
<li><p>Do not create and throw new exceptions just to have your team's exception.</p></li>
</ul>

<p>There is no hard and fast rule: but if you have a scenario for treating this exception differently, consider creating a custom exception type, such as DataNotFoundException <a href=""http://stackoverflow.com/questions/121700/what-exception-should-be-thrown-when-an-adonet-query-cannot-retrieve-the-reques#121809"">as suggested by Johan Buret</a>.</p>

<p>Otherwise you might consider throwing one of the existing exception types, such as System.Data.DataException or possibly even System.Collections.Generic.KeyNotFoundException.</p>
"
265,121700,2,1,sql,What Exception should be thrown when an ADO.NET query cannot retrieve the requested data?,"<p>In an attempt to add some parameter validation and correct usage semantics to our application, we are trying to add correct exception handling to our .NET applications.</p>

<p>My question is this: When throwing exceptions in ADO.NET if a particular query returns no data or the data could not be found, what type of exception should I use?</p>

<p>Psuedocode:
(read, don't scrutinize the semantics of the code, I know it won't compile)</p>

<pre><code>public DataSet GetData(int identifier)
{
    dataAdapter.Command.Text = ""Select * from table1 Where ident = "" + identifier.toString();
    DataSet ds = dataAdapter.Fill(ds);
    if (ds.table1.Rows.Count == 0)
        throw new Exception(""Data not found"");

    return ds;
}
</code></pre>
","<p>You really should define your own exception : DataNotFoundException.</p>

<p>You should not use the basic class Exception, since when you will catch it in calling code, you will write something like</p>

<pre><code>try
{
     int i;
     GetData(i);

}
catch(Exception e) //will catch many many exceptions
{
    //Handle gracefully the ""Data not Found"" case;
    //Whatever else happens will get caught and ignored
}
</code></pre>

<p>Where as catching only your DataNotFoundEXception will get only the case you really want to handle.</p>

<pre><code>try
{
     int i;
     GetData(i);

}
catch(DataNotFoundException e) 
{
    //Handle gracefully the ""Data not Found"" case;
} //Any other exception will bubble up
</code></pre>

<p>There is a class aptly named SqlException, when there are troubles with the SQL engine but it's better not overload it with your business logic </p>
"
221,104230,1,1,sql,how do I query multiple SQL tables for a specific key-value pair?,"<p>Situation: A PHP application with multiple installable modules creates a new table in database for each, in the style of mod_A, mod_B, mod_C etc. Each has the column section_id.</p>

<p>Now, I am looking for all entries for a specific section_id, and I'm hoping there's another way besides ""Select * from mod_a, mod_b, mod_c ... mod_xyzzy where section_id=value""... or even worse, using a separate query for each module.</p>
","<p>If the tables are changing over time, you can inline code gen your solution in an SP (pseudo code - you'll have to fill in):</p>

<pre><code>SET @sql = ''

DECLARE CURSOR FOR
SELECT t.[name] AS TABLE_NAME
FROM sys.tables t
WHERE t.[name] LIKE 'SOME_PATTERN_TO_IDENTIFY_THE_TABLES'
</code></pre>

<p>-- or this</p>

<pre><code>DECLARE CURSOR FOR
SELECT t.[name] AS TABLE_NAME
FROM TABLE_OF_TABLES_TO_SEACRH t

START LOOP

IF @sql &lt;&gt; '' SET @sql = @sql + 'UNION ALL '
SET @sql = 'SELECT * FROM [' + @TABLE_NAME + '] WHERE section_id=value '

END LOOP

EXEC(@sql)
</code></pre>

<p>I've used this technique occasionally, when there just isn't any obvious way to make it future-proof without dynamic SQL.</p>

<p>Note: In your loop, you can use the COALESCE/NULL propagation trick and leave the string as NULL before the loop, but it's not as clear if you are unfamiliar with the idiom:</p>

<pre><code>SET @sql = COALESCE(@sql + ' UNION ALL ', '')
    + 'SELECT * FROM [' + @TABLE_NAME + '] WHERE section_id=value '
</code></pre>
"
601,267530,1,0,sql,query: cross product instead of join,"<p>I have two tables that I would like to join but I am getting an error from MySQL</p>

<pre><code>Table: books
bookTagNum ShelfTagNum
book1      1
book2      2
book3      2

Table: shelf
shelfNum   shelfTagNum
1          shelf1
2          shelf2
</code></pre>

<p>I want my results to be:</p>

<pre><code>bookTagNum ShelfTagNum shelfNum
book1      shelf1           1
book2      shelf2           2
book3      shelf2           2
</code></pre>

<p>but instead I am also getting an extra result:</p>

<pre><code>book1      shelf2           2
</code></pre>

<p>I think my query is doing a cross product instead of a join:</p>

<pre><code>SELECT `books`.`bookTagNum` , `books`.`shelfNum` , `shelf`.`shelfTagNum` , `books`.`title`
FROM books, shelf
where `books`.`shelfNum`=`books`.`shelfNum`
ORDER BY `shelf`.`shelfTagNum` ASC
LIMIT 0 , 30
</code></pre>

<p>What am I doing wrong?</p>
","<p>Check your SQL. Your where clause cannot possibly be <code>books</code>.<code>shelfNum</code>=<code>books</code>.<code>shelfNum</code></p>

<p>And what are all those single quotes for?</p>
"
180,76680,1,0,sql,"Fetch unread messages, by user","<p>I want to maintain a list of global messages that will be displayed to all users of a web app. I want each user to be able to mark these messages as read individually. I've created 2 tables; <code>messages (id, body)</code> and <code>messages_read (user_id, message_id)</code>.</p>

<p>Can you provide an sql statement that selects the unread messages for a single user? Or do you have any suggestions for a better way to handle this?</p>

<p>Thanks!</p>
","<p>If the table definitions you mentioned are complete, you might want to include a date for each message, so you can order them by date.</p>

<p>Also, this might be a slightly more efficient way to do the select:</p>

<pre><code>SELECT id, message
FROM messages
LEFT JOIN messages_read
    ON messages_read.message_id = messages.id
    AND messages_read.[user_id] = @user_id
WHERE
    messages_read.message_id IS NULL
</code></pre>
"
179,76680,0,0,sql,"Fetch unread messages, by user","<p>I want to maintain a list of global messages that will be displayed to all users of a web app. I want each user to be able to mark these messages as read individually. I've created 2 tables; <code>messages (id, body)</code> and <code>messages_read (user_id, message_id)</code>.</p>

<p>Can you provide an sql statement that selects the unread messages for a single user? Or do you have any suggestions for a better way to handle this?</p>

<p>Thanks!</p>
","<p>Something like:</p>

<pre><code>SELECT id, body FROM messages LEFT JOIN
  (SELECT message_id FROM messages_read WHERE user_id = ?)
  ON id=message_id WHERE message_id IS NULL
</code></pre>

<p>Slightly tricky and I'm not sure how the performance will scale up, but it should work.</p>
"
178,76680,5,0,sql,"Fetch unread messages, by user","<p>I want to maintain a list of global messages that will be displayed to all users of a web app. I want each user to be able to mark these messages as read individually. I've created 2 tables; <code>messages (id, body)</code> and <code>messages_read (user_id, message_id)</code>.</p>

<p>Can you provide an sql statement that selects the unread messages for a single user? Or do you have any suggestions for a better way to handle this?</p>

<p>Thanks!</p>
","<p>Well, you could use</p>

<pre><code>SELECT id FROM messages m WHERE m.id NOT IN(
    SELECT message_id FROM messages_read WHERE user_id = ?)
</code></pre>

<p>Where ? is passed in by your app.</p>
"
151,59180,1,0,sql,How do I disable validation in Web Data Administrator?,"<p>I'm trying to run some queries to get rid of XSS in our database using Web Data Administrator but I keep running into this Potentially Dangerous Request crap.</p>

<p>How do I disable validation of the query in Web Data Administrator?</p>
","<p>Go into the install directory of web data admin, usually:</p>

<p><code>C:\Program Files\Microsoft SQL Server Tools\Microsoft SQL Web Data Administrator</code></p>

<p>Then in the ""Web"" folder open the file ""QueryDatabase.aspx"" and edit the following line:</p>

<p><code>&lt;%@ Page language=""c#"" Codebehind=""QueryDatabase.aspx.cs"" AutoEventWireup=""false"" Inherits=""SqlWebAdmin.query"" %></code></p>

<p>Add <code>ValidateRequest=""false""</code> to the end of it like so:</p>

<p><code>&lt;%@ Page language=""c#"" Codebehind=""QueryDatabase.aspx.cs"" AutoEventWireup=""false"" Inherits=""SqlWebAdmin.query"" ValidateRequest=""false"" %></code></p>

<p><strong>NOTE</strong>: THIS IS POTENTIALLY DANGEROUS!! Be Careful!</p>
"
1134,523710,1,0,sql,Union or Use Flow Control Logic to Determine which table to report on,"<p>I'm working with a 3rd pary app where I can't alter the tables. We built custom matching ""Monthly"" tables with an additional datetime column ""AsOfDate"" where we dump the data at the end of the month and flag those data with the date of last day of the month.</p>

<p>I want to be able to create a single Stored Procedure (Application is designed to require a view or stored proc as the source of all reports.) and use a parameter which will either use the current data table (Parameter may be NULL or = Today's Date) or use the month end table and filter by the End of the month date. This way, I have one report where the user can either use current or data from a particular month end period. </p>

<p>Which would you prefer (And why) Sorry, this is not fully coded</p>

<p><strong>Solution #1 Union Query</strong></p>

<pre><code>Create Proc Balance_Report (@AsOfDate)
AS

Select Column1
From
    (Select GetDate() as AsOfDate
       , Column1 
     From Current.Balance
    Union 
    Select AsOfDate
       , Column1 From MonthEnd.Balance
    ) AS All_Balances
Where All_Balances.AsOfDate = @AsOfDate
</code></pre>

<p><strong>Solution #2 Use If Statement to select table</strong></p>

<pre><code>Create Proc Balance_Report (@AsOfDate)
AS

If @AsOfDate IS NULL or @AsOfDate = GetDate()
   Select GetDate() as AsOfDate
       , Column1 
     From Current.Balance
Else
    Select AsOfDate
       , Column1 From MonthEnd.Balance
    Where AsOfDate = @AsOfDate
</code></pre>

<p>Again, this is not fully coded and is sort of db agnostic (But it is SQL Server 2005).</p>

<p><strong>Edit: Variation to Solution #2 using separate stored procedures</strong></p>

<pre><code>Create Proc Balance_Report (@AsOfDate)
AS

If @AsOfDate IS NULL or @AsOfDate = GetDate()
   Exec Current_Balance_Date -- no param necessary
Else
    exec MonthEnd_Balance_Date @AsOfDate
</code></pre>
","<p>How you have things set up, the second method will probably be faster. If you were to use a partitioned view then you could set up constraints in such a way that the optimized would know to ignore one or more of the tables in the select and you would get the same performance. This would also let you keep all of your logic in one statement rather than having to keep two statements in sync. That may or may not be an issue for you based on how complex the SELECT statement is.</p>

<p>One thing to remember though, is that if you use the second method, be sure to mark your stored procedure as WITH (RECOMPILE) (I can't remember if the parentheses are require or not - check the syntax). That way the optimizer will create a new query plan based on which branch of the IF statement needs to be executed.</p>
"
602,267530,5,0,sql,query: cross product instead of join,"<p>I have two tables that I would like to join but I am getting an error from MySQL</p>

<pre><code>Table: books
bookTagNum ShelfTagNum
book1      1
book2      2
book3      2

Table: shelf
shelfNum   shelfTagNum
1          shelf1
2          shelf2
</code></pre>

<p>I want my results to be:</p>

<pre><code>bookTagNum ShelfTagNum shelfNum
book1      shelf1           1
book2      shelf2           2
book3      shelf2           2
</code></pre>

<p>but instead I am also getting an extra result:</p>

<pre><code>book1      shelf2           2
</code></pre>

<p>I think my query is doing a cross product instead of a join:</p>

<pre><code>SELECT `books`.`bookTagNum` , `books`.`shelfNum` , `shelf`.`shelfTagNum` , `books`.`title`
FROM books, shelf
where `books`.`shelfNum`=`books`.`shelfNum`
ORDER BY `shelf`.`shelfTagNum` ASC
LIMIT 0 , 30
</code></pre>

<p>What am I doing wrong?</p>
","<p>if you want to be sure you're doing a join instead of a cross product, you should state it explicitly in the SQL, thus:</p>

<pre><code>SELECT books.bookTagNum,books.shelfNum, shelf.shelfTagNum, books.title
FROM books INNER JOIN shelf ON books.shelfNum = shelf.shelfTagNum
ORDER BY shelf.shelfTagNum
</code></pre>

<p>(which will return only those rows which exist in both tables), or:</p>

<pre><code>SELECT books.bookTagNum,books.shelfNum, shelf.shelfTagNum, books.title
FROM books LEFT OUTER JOIN shelf ON books.shelfNum = shelf.shelfTagNum
ORDER BY shelf.shelfTagNum
</code></pre>

<p>(which will return all rows from books), or:</p>

<pre><code>SELECT books.bookTagNum,books.shelfNum, shelf.shelfTagNum, books.title
FROM books RIGHT OUTER JOIN shelf ON books.shelfNum = shelf.shelfTagNum
ORDER BY shelf.shelfTagNum
</code></pre>

<p>(which will return all rows from shelf)</p>
"
603,267530,4,0,sql,query: cross product instead of join,"<p>I have two tables that I would like to join but I am getting an error from MySQL</p>

<pre><code>Table: books
bookTagNum ShelfTagNum
book1      1
book2      2
book3      2

Table: shelf
shelfNum   shelfTagNum
1          shelf1
2          shelf2
</code></pre>

<p>I want my results to be:</p>

<pre><code>bookTagNum ShelfTagNum shelfNum
book1      shelf1           1
book2      shelf2           2
book3      shelf2           2
</code></pre>

<p>but instead I am also getting an extra result:</p>

<pre><code>book1      shelf2           2
</code></pre>

<p>I think my query is doing a cross product instead of a join:</p>

<pre><code>SELECT `books`.`bookTagNum` , `books`.`shelfNum` , `shelf`.`shelfTagNum` , `books`.`title`
FROM books, shelf
where `books`.`shelfNum`=`books`.`shelfNum`
ORDER BY `shelf`.`shelfTagNum` ASC
LIMIT 0 , 30
</code></pre>

<p>What am I doing wrong?</p>
","<p>FYI: If you rewrite your names to be consistent, things get a lot easier to read.</p>

<pre><code>Table 1: Book
BookID     ShelfID  BookName
1          1        book1
2          2        book2
3          2        book3

Table 2: Shelf
ShelfID    ShelfName
1          shelf1
2          shelf2
</code></pre>

<p>now, a query to extract books to shelves is</p>

<pre><code>SELECT 
 b.BookName,
 s.ShelfName
FROM
 Book b
JOIN Shelf s ON s.ShelfID = b.ShelfID
</code></pre>

<p><hr /></p>

<p>To answer the original question:</p>

<pre><code>&gt; where `books`.`shelfNum`=`books`.`shelfNum`
&gt;        ^^^^^--------------^^^^^------------- books repeated - this is an error
</code></pre>

<p>the <code>WHERE</code> clause, as written, does nothing, and because your where clause isn't limiting any rows, you are indeed getting the cross product.</p>
"
599,267530,7,0,sql,query: cross product instead of join,"<p>I have two tables that I would like to join but I am getting an error from MySQL</p>

<pre><code>Table: books
bookTagNum ShelfTagNum
book1      1
book2      2
book3      2

Table: shelf
shelfNum   shelfTagNum
1          shelf1
2          shelf2
</code></pre>

<p>I want my results to be:</p>

<pre><code>bookTagNum ShelfTagNum shelfNum
book1      shelf1           1
book2      shelf2           2
book3      shelf2           2
</code></pre>

<p>but instead I am also getting an extra result:</p>

<pre><code>book1      shelf2           2
</code></pre>

<p>I think my query is doing a cross product instead of a join:</p>

<pre><code>SELECT `books`.`bookTagNum` , `books`.`shelfNum` , `shelf`.`shelfTagNum` , `books`.`title`
FROM books, shelf
where `books`.`shelfNum`=`books`.`shelfNum`
ORDER BY `shelf`.`shelfTagNum` ASC
LIMIT 0 , 30
</code></pre>

<p>What am I doing wrong?</p>
","<p>I think you want</p>

<pre><code>where `books`.`shelfTagNum`=`shelf`.`shelfNum`
</code></pre>

<p>In order to match rows from the <code>books</code> and <code>shelf</code> tables, you need to have terms from each in your <code>where</code> clause - otherwise, you're just performing a no-operation check on the rows of <code>books</code>, since every row's <code>shelfNum</code> will be equal to its <code>shelfNum</code>.</p>

<p>As @<a href=""#267544"" rel=""nofollow"">fixme.myopenid.com</a> suggests, you could also go the explicit <code>JOIN</code> route, but it's not necessary.</p>
"
1133,523710,1,0,sql,Union or Use Flow Control Logic to Determine which table to report on,"<p>I'm working with a 3rd pary app where I can't alter the tables. We built custom matching ""Monthly"" tables with an additional datetime column ""AsOfDate"" where we dump the data at the end of the month and flag those data with the date of last day of the month.</p>

<p>I want to be able to create a single Stored Procedure (Application is designed to require a view or stored proc as the source of all reports.) and use a parameter which will either use the current data table (Parameter may be NULL or = Today's Date) or use the month end table and filter by the End of the month date. This way, I have one report where the user can either use current or data from a particular month end period. </p>

<p>Which would you prefer (And why) Sorry, this is not fully coded</p>

<p><strong>Solution #1 Union Query</strong></p>

<pre><code>Create Proc Balance_Report (@AsOfDate)
AS

Select Column1
From
    (Select GetDate() as AsOfDate
       , Column1 
     From Current.Balance
    Union 
    Select AsOfDate
       , Column1 From MonthEnd.Balance
    ) AS All_Balances
Where All_Balances.AsOfDate = @AsOfDate
</code></pre>

<p><strong>Solution #2 Use If Statement to select table</strong></p>

<pre><code>Create Proc Balance_Report (@AsOfDate)
AS

If @AsOfDate IS NULL or @AsOfDate = GetDate()
   Select GetDate() as AsOfDate
       , Column1 
     From Current.Balance
Else
    Select AsOfDate
       , Column1 From MonthEnd.Balance
    Where AsOfDate = @AsOfDate
</code></pre>

<p>Again, this is not fully coded and is sort of db agnostic (But it is SQL Server 2005).</p>

<p><strong>Edit: Variation to Solution #2 using separate stored procedures</strong></p>

<pre><code>Create Proc Balance_Report (@AsOfDate)
AS

If @AsOfDate IS NULL or @AsOfDate = GetDate()
   Exec Current_Balance_Date -- no param necessary
Else
    exec MonthEnd_Balance_Date @AsOfDate
</code></pre>
","<p>I prefer the non-union solution.  Selecting from a single table will always be faster than doing a union and selecting a single table's data from the union.</p>
"
1130,519300,1,0,sql,MSSQL Paging is returning random rows when not supposed too,"<p>I'm trying to do some basic paging in MSSQL. The problem I'm having is that I'm sorting the paging on a row that (potentially) has similar values, and the ORDER BY clause is returning ""random"" results, which doesn't work well.</p>

<p>So for example.</p>

<p>If I have three rows, and I'm sorting them by a ""rating"", and all of the ratings are = '5' - the rows will seemingly ""randomly"" order themselves. How do I make it so the rows are showing up in the same order everytime?</p>

<p>I tried ordering it by a datetime that the field was last edited, but the ""rating"" is sorted in reverse, and again, does not work how i expect it to work.</p>

<p>Here is the SQL I'm using thus far. I know it's sort of confusing without the data so.. any help would be greatful.</p>

<pre><code>SELECT * FROM 
(
  SELECT 
    CAST(grg.defaultthumbid AS VARCHAR) + '_' + 
    CAST(grg.garageid AS VARCHAR) AS imagename,
    (
      SELECT COUNT(imageid) 
      FROM dbo.images im (nolock) 
      WHERE im.garageid = grg.garageid
    ) AS piccount, 
    (
      SELECT COUNT(commentid) 
      FROM dbo.comments cmt (nolock) 
      WHERE cmt.garageid = grg.garageid
    ) AS commentcount,
    grg.GarageID, mk.make, mdl.model, grg.year, 
    typ.type, usr.username, grg.content, 
    grg.rating, grg.DateEdit as DateEdit,
    ROW_NUMBER() OVER (ORDER BY Rating DESC) As RowIndex 
  FROM 
    dbo.garage grg (nolock)
    LEFT JOIN dbo.users (nolock) AS usr ON (grg.userid = usr.userid)
    LEFT JOIN dbo.make (nolock) AS mk ON (grg.makeid = mk.makeid)
    LEFT JOIN dbo.type (nolock) AS typ ON (typ.typeid = mk.typeid)
    LEFT JOIN dbo.model (nolock) AS mdl ON (grg.modelid = mdl.modelid)
  WHERE 
    typ.type = 'Automobile' AND
    grg.defaultthumbid != 0 AND
    usr.username IS NOT NULL
) As QueryResults 
WHERE 
  RowIndex BETWEEN (2 - 1) * 25 + 2 AND 2 * 25
ORDER BY 
  DateEdit DESC
</code></pre>
","<p>The query first numbers the rows by [Rating], and then re-sorts the results by [DateEdit]. Possibly not what you intended. Ordering by [RowIndex] ASC should sort it out.</p>

<pre><code>ROW_NUMBER() OVER (ORDER BY [Rating] DESC) As [RowIndex]
...
ORDER BY [RowIndex]
</code></pre>
"
1129,519300,3,0,sql,MSSQL Paging is returning random rows when not supposed too,"<p>I'm trying to do some basic paging in MSSQL. The problem I'm having is that I'm sorting the paging on a row that (potentially) has similar values, and the ORDER BY clause is returning ""random"" results, which doesn't work well.</p>

<p>So for example.</p>

<p>If I have three rows, and I'm sorting them by a ""rating"", and all of the ratings are = '5' - the rows will seemingly ""randomly"" order themselves. How do I make it so the rows are showing up in the same order everytime?</p>

<p>I tried ordering it by a datetime that the field was last edited, but the ""rating"" is sorted in reverse, and again, does not work how i expect it to work.</p>

<p>Here is the SQL I'm using thus far. I know it's sort of confusing without the data so.. any help would be greatful.</p>

<pre><code>SELECT * FROM 
(
  SELECT 
    CAST(grg.defaultthumbid AS VARCHAR) + '_' + 
    CAST(grg.garageid AS VARCHAR) AS imagename,
    (
      SELECT COUNT(imageid) 
      FROM dbo.images im (nolock) 
      WHERE im.garageid = grg.garageid
    ) AS piccount, 
    (
      SELECT COUNT(commentid) 
      FROM dbo.comments cmt (nolock) 
      WHERE cmt.garageid = grg.garageid
    ) AS commentcount,
    grg.GarageID, mk.make, mdl.model, grg.year, 
    typ.type, usr.username, grg.content, 
    grg.rating, grg.DateEdit as DateEdit,
    ROW_NUMBER() OVER (ORDER BY Rating DESC) As RowIndex 
  FROM 
    dbo.garage grg (nolock)
    LEFT JOIN dbo.users (nolock) AS usr ON (grg.userid = usr.userid)
    LEFT JOIN dbo.make (nolock) AS mk ON (grg.makeid = mk.makeid)
    LEFT JOIN dbo.type (nolock) AS typ ON (typ.typeid = mk.typeid)
    LEFT JOIN dbo.model (nolock) AS mdl ON (grg.modelid = mdl.modelid)
  WHERE 
    typ.type = 'Automobile' AND
    grg.defaultthumbid != 0 AND
    usr.username IS NOT NULL
) As QueryResults 
WHERE 
  RowIndex BETWEEN (2 - 1) * 25 + 2 AND 2 * 25
ORDER BY 
  DateEdit DESC
</code></pre>
","<p>Try ordering by both, e.g.:
ORDER BY Rating DESC, DateEdit ASC</p>
"
1128,519010,1,0,sql,Compare subselect value with value in master select,"<p>In MS Access, I have a query where I want to use a column in the outer query as a condition in the inner query:</p>

<pre><code>SELECT P.FirstName, P.LastName, Count(A.attendance_date) AS CountOfattendance_date,
       First(A.attendance_date) AS FirstOfattendance_date,
       (SELECT COUNT (*) 
          FROM(SELECT DISTINCT attendance_date 
                FROM tblEventAttendance AS B 
                WHERE B.event_id=8 
                  AND B.attendance_date &gt;= FirstOfattendance_date)
       ) AS total
FROM tblPeople AS P INNER JOIN tblEventAttendance AS A ON P.ID = A.people_id
WHERE A.event_id=8
GROUP BY P.FirstName, P.LastName
;
</code></pre>

<p>The key point is <code>FirstOfattendance_date</code> - I want the comparison deep in the subselect to  use the value in each iteration of the master select.  Obviously this doesn't work, it asks me for the value of <code>FirstOfattendance_date</code> when I try to run it.</p>

<p>I'd like to do this without resorting to VB code... any ideas?</p>
","<p>How about:</p>

<pre><code>SELECT 
     p.FirstName,
     p.LastName,
     Count(a.attendance_date) AS CountOfattendance_date,
     First(a.attendance_date) AS FirstOfattendance_date,
     c.total
FROM (
     tblPeople AS p 
INNER JOIN tblEventAttendance AS a ON 
     a.people_id = p.ID) 
INNER JOIN (SELECT people_id, Count (attendance_date) As total
            FROM (
                SELECT DISTINCT people_id,attendance_date
                FROM tblEventAttendance) 
            Group By people_id) AS c ON 
     p.ID = c.people_id
GROUP BY 
     p.ID, c.total;
</code></pre>
"
1127,519010,0,0,sql,Compare subselect value with value in master select,"<p>In MS Access, I have a query where I want to use a column in the outer query as a condition in the inner query:</p>

<pre><code>SELECT P.FirstName, P.LastName, Count(A.attendance_date) AS CountOfattendance_date,
       First(A.attendance_date) AS FirstOfattendance_date,
       (SELECT COUNT (*) 
          FROM(SELECT DISTINCT attendance_date 
                FROM tblEventAttendance AS B 
                WHERE B.event_id=8 
                  AND B.attendance_date &gt;= FirstOfattendance_date)
       ) AS total
FROM tblPeople AS P INNER JOIN tblEventAttendance AS A ON P.ID = A.people_id
WHERE A.event_id=8
GROUP BY P.FirstName, P.LastName
;
</code></pre>

<p>The key point is <code>FirstOfattendance_date</code> - I want the comparison deep in the subselect to  use the value in each iteration of the master select.  Obviously this doesn't work, it asks me for the value of <code>FirstOfattendance_date</code> when I try to run it.</p>

<p>I'd like to do this without resorting to VB code... any ideas?</p>
","<p>Can you change </p>

<p>B.attendance_date >= FirstOfattendance_date </p>

<p>to</p>

<p>B.attendance_date >= First(A.attendance_date)</p>
"
1227,546410,2,0,sql,How to UNPIVOT to split columns into rows?,"<p>I've got a sql query (using MS-SQL 2005) that generates data with these columns:</p>

<pre><code>TimeStamp | SpeedMax | SpeedMin | HeightMax | HeightMin
-------------------------------------------------------
10        | 50       | 10       | 300       | 70
</code></pre>

<p>The form I need it in though is this:</p>

<pre><code>TimeStamp | Speed | Height
---------------------------
10        | 50    | 300          &lt;-- one row for the max values 
10        | 10    | 70           &lt;-- a second row for the min values
</code></pre>

<p>Given the first result set... what query would I need to get the data into the second format? I think it might involve an unpivot, but I'm new to that, and am having trouble working out what to write.</p>

<p>Thank you very much.</p>
","<pre><code>SELECT TimeStamp,
       minmax,
       CASE WHEN minmax = 0 THEN SpeedMax ELSE SpeedMin END AS Speed
       CASE WHEN minmax = 0 THEN HeightMax ELSE HeightMin END AS Height
FROM Table,
(
    SELECT 0 AS minmax
    UNION ALL
    SELECT 1
) mm
</code></pre>

<p>You may add</p>

<pre><code>OPTION (FORCE ORDER)
</code></pre>

<p>to avoid double scan on <code>Table</code></p>
"
600,267530,0,0,sql,query: cross product instead of join,"<p>I have two tables that I would like to join but I am getting an error from MySQL</p>

<pre><code>Table: books
bookTagNum ShelfTagNum
book1      1
book2      2
book3      2

Table: shelf
shelfNum   shelfTagNum
1          shelf1
2          shelf2
</code></pre>

<p>I want my results to be:</p>

<pre><code>bookTagNum ShelfTagNum shelfNum
book1      shelf1           1
book2      shelf2           2
book3      shelf2           2
</code></pre>

<p>but instead I am also getting an extra result:</p>

<pre><code>book1      shelf2           2
</code></pre>

<p>I think my query is doing a cross product instead of a join:</p>

<pre><code>SELECT `books`.`bookTagNum` , `books`.`shelfNum` , `shelf`.`shelfTagNum` , `books`.`title`
FROM books, shelf
where `books`.`shelfNum`=`books`.`shelfNum`
ORDER BY `shelf`.`shelfTagNum` ASC
LIMIT 0 , 30
</code></pre>

<p>What am I doing wrong?</p>
","<p>Try this:</p>

<pre><code>SELECT `books`.`bookTagNum` , `books`.`shelfNum` , `shelf`.`shelfTagNum` , 
   `books`.`title`
FROM books, shelf
where `books`.`shelftagNum`=`shelf`.`shelfNum`
ORDER BY `shelf`.`shelfTagNum` ASC
LIMIT 0 , 30
</code></pre>

<p>Because the implicit JOIN condition was not properly stated the result was a cross product.</p>
"
416,188720,1,0,sql,Any way to transfer value from one cell to another?,"<p>Is there any way in the SQL language or in MySQL (or other DBMA) to transfer a value from one cell to another? For example, say there is a table called user_cars with the following structure:</p>

<pre><code>|id| |user_name| |num_cars|
</code></pre>

<p>Bob has 5 cars, and John has 3 cars. Is there any way to in one query subtract 2 cars from Bob and add 2 to John? I know this can be done with two update queries, but I'd just like to know if there was a more efficient way.</p>
","<p>That's what transactions are for ...</p>
"
181,81560,1,0,sql,override constraint from no action to cascading at runtime,"<p>I feel like I have a verry basic/stupid question, yet I never saw/read/heard anything in this direction.</p>

<p>Say I have a table <em>users(userId, name)</em> and a table <em>preferences(id, userId, language)</em>. The example is trivial, but could be extended to a situation with multi-level relations and way more tables..
When my UI requests to delete a user I first want to show a warning stating that also its preferences will be deleted. If at some point the database gets extended with more tables and relationships, but the software isn't adapted accordingly (client didn't update) a generic message should be shown.</p>

<p>How can I implement this? The UI cannot know about the whole data structure and should not be bothered to walk down all the relations to manually delete all the depending records.<br />
I would think this would be with constraints.
The constraint would be <em>no action</em> at first so the constraint will throw an error that can be caught by the UI. After the UI receives a confirmation, the constraint should become a <em>cascade</em>.</p>

<p>Somehow I'm feeling like I'm getting this all wrong..</p>
","<p>What I would do is this:</p>

<ol>
<li>The constraint is CASCADE</li>
<li>The application checks if preferences exist.</li>
<li>If they do, show the warning.</li>
<li>If no preferences exist, or the warning is accepted, delete the client.</li>
</ol>

<p>Changing database relationships on the fly is not going to be a good idea!!</p>

<p>Cheers,</p>

<p>RB.</p>
"
1159,528000,0,0,sql,Query question related to retrieving the most recent entry from a table?,"<p>Hi I'm not good in framing questions. I will try my best. I'm creating a website and my question is related to the queries related to the site.This is the current query that I have. </p>

<pre><code>SELECT
  GPS_modem.vehicle_no, 
  vehicle_log.longitude, 
  vehicle_log.latitude, 
  vehicle_log.timestamp
FROM
  vehicle_log,
  GPS_modem
WHERE
  GPS_modem.modem_ID = vehicle_log.modem_ID
ORDER BY 
  timestamp desc
</code></pre>

<p>What I want to display is the entry with the most recent timestamp from the <code>vehicle_log</code> table where the <code>modem_ID</code> from the <code>GPS_modem</code> table matches with the <code>modem_ID</code> from <code>vehicle_log</code> table. </p>

<p>I tried using <code>DISTINCT</code> but I didn't work. I was getting errors when I tried using <code>MAX</code> function. Hope you are able to understand my question, if then please help me. Thanking you in advance.</p>
","<p>In Oracle:</p>

<pre><code>SELECT
  GPS_modem.vehicle_no, 
  vehicle_log.longitude, 
  vehicle_log.latitude, 
  vehicle_log.timestamp
FROM
  (
  SELECT v.*, ROW_NUMBER() OVER (PARTITION BY modem_id ORDER BY timespace DESC) AS rn
  ) l, GPS_modem m
WHERE
  l.rn = 1
  AND m.modem_ID = l.modem_ID
</code></pre>

<p>In MySQL:</p>

<pre><code>SELECT *
FROM (
   SELECT DISTINCT g.id AS gid, (
     SELECT l.modem_id
     FROM vehicle_log l
     WHERE l.modem_id = g.modem_id
     ORDER BY timestemp DESC
     LIMIT 1
     ) lid
 ), vehicle_log lo, GPS_modem go
WHERE lo.modem_id = lid
  AND go.modem_id = lo.modem_id
</code></pre>
"
418,188720,4,0,sql,Any way to transfer value from one cell to another?,"<p>Is there any way in the SQL language or in MySQL (or other DBMA) to transfer a value from one cell to another? For example, say there is a table called user_cars with the following structure:</p>

<pre><code>|id| |user_name| |num_cars|
</code></pre>

<p>Bob has 5 cars, and John has 3 cars. Is there any way to in one query subtract 2 cars from Bob and add 2 to John? I know this can be done with two update queries, but I'd just like to know if there was a more efficient way.</p>
","<p>For Oracle you could do this.  Don't know if there is an equivalent in mysql.  Obviously this particular statement is very specific to the example you stated.</p>

<pre><code> UPDATE user_cars
   SET num_cars = num_cars +
                     CASE WHEN user_name='Bob' THEN -2
                          WHEN user_name='John' THEN +2
                     END
   WHERE user_name IN ( 'Bob', 'John' )
</code></pre>
"
419,188720,2,0,sql,Any way to transfer value from one cell to another?,"<p>Is there any way in the SQL language or in MySQL (or other DBMA) to transfer a value from one cell to another? For example, say there is a table called user_cars with the following structure:</p>

<pre><code>|id| |user_name| |num_cars|
</code></pre>

<p>Bob has 5 cars, and John has 3 cars. Is there any way to in one query subtract 2 cars from Bob and add 2 to John? I know this can be done with two update queries, but I'd just like to know if there was a more efficient way.</p>
","<p>This will work, but it is not pleasant:</p>

<pre><code>UPDATE USER_CARS UC
SET
  NUM_CARS = NUM_CARS + CASE WHEN UC.USER_NAME = 'Bob'
                             THEN -2  --take from bob
                             WHEN UC.USER_NAME = 'John'
                             THEN 2  --give to John
                             ELSE 0  --no change for anybody else
                        END
</code></pre>
"
420,188720,0,0,sql,Any way to transfer value from one cell to another?,"<p>Is there any way in the SQL language or in MySQL (or other DBMA) to transfer a value from one cell to another? For example, say there is a table called user_cars with the following structure:</p>

<pre><code>|id| |user_name| |num_cars|
</code></pre>

<p>Bob has 5 cars, and John has 3 cars. Is there any way to in one query subtract 2 cars from Bob and add 2 to John? I know this can be done with two update queries, but I'd just like to know if there was a more efficient way.</p>
","<p>I agree with Jonas Klemming, there isnt a meaningful way of doing that.  This is precisely what transactions were invented to do.</p>
"
421,188720,1,0,sql,Any way to transfer value from one cell to another?,"<p>Is there any way in the SQL language or in MySQL (or other DBMA) to transfer a value from one cell to another? For example, say there is a table called user_cars with the following structure:</p>

<pre><code>|id| |user_name| |num_cars|
</code></pre>

<p>Bob has 5 cars, and John has 3 cars. Is there any way to in one query subtract 2 cars from Bob and add 2 to John? I know this can be done with two update queries, but I'd just like to know if there was a more efficient way.</p>
","<p>As others have explained, you can do it with a CASE statement.<br />
However, doing so is probably unwise, as it makes the intention of the code harder to see.  This will make it harder for a subsequent programmer to understand the purpose of the code.  </p>

<p>Unless you have some specific reason for needing to do it in one statement, the best thing to do is to use 2 update statements, wrapping them in a transaction if required.  </p>

<p>I often recall this quotation (although I had to look up the attribution on <a href=""http://en.wikiquote.org/wiki/Programming"" rel=""nofollow"">wikiquote</a>):  </p>

<p>""Programs must be written for people to read, and only incidentally for machines to execute.""
 - Abelson &amp; Sussman, SICP, preface to the first edition</p>
"
427,189770,1,0,sql,Retrieving the new ID from a SQLDataAdaptor.Update,"<p>How would you go about retrieving the @@IDENTITY value for each row when the SQLDataAdapater.Update is executed on a table?</p>

<p>eg. Is it possible to modify/intercept the InsertCommand, generated by the SQLCommandBuilder, to say add an output parameter, and then retrieve its value in the da.RowUpdated event???</p>
","<p>Bill Vaughn knows a thing or two about this. They key is tweaking your InsertCommand.</p>

<p>See <a href=""http://www.betav.com/Files/Content/Articles/Managing%20and%20Identity%20Crisis.pdf"" rel=""nofollow"">""Managing an @@IDENTITY Crisis""</a>.</p>

<p>Note: the actual solution uses SCOPE_IDENTITY() in order to be trigger-safe.</p>
"
1121,512560,0,0,sql,Is there an equivalent to the iSeries OVRDBF command in SQL?,"<p>I have a requirement in a SQL environment that under specific circumstances, all references to table (or view) A in a procedure actually use table (or view) B.  On the iSeries I would have used the OVRDBF command to override references to table A with table B: OVRDBF FILE(A) TOFILE(B).  What would be the equivalent to this in SQL?  Is there one?  </p>

<p>My goal is to end up with a procedure that is ignorant of the override.  I don't want conditional logic inside the procedure that directs processing at table B when certain conditions are met.  The vision:</p>

<p>Under typical circumstances:  Just invoke the procedure</p>

<p>Under specific alternative circumstances:  Perform the OVRDBF equivalent and then Invoke the procedure</p>
","<p>As Ed mentions if you can modify your procedure:</p>

<p>1) Create an alias for file(A)</p>

<pre><code>CREATE ALIAS XYZ FOR A
</code></pre>

<p>2) Modify the procedure to reference XYZ instead of A.</p>

<p>3) When running the procedure to use file B execute</p>

<pre><code>DROP ALIAS XYZ;
CREATE ALIAS XYZ FOR B;
CALL PROCEDURE;
DROP ALIAS XYZ;
CREATE ALIAS XYZ FOR A;
</code></pre>

<p>If you can't modify the procedure and you're not worried about simultaneous access to table A you could use:</p>

<pre><code>RENAME TABLE A TO C;
CREATE ALIAS A FOR B;
CALL PROCEDURE;
DROP ALIAS A;
RENAME TABLE C TO A;
</code></pre>
"
461,201990,0,0,sql,How can I determine the last time any record changed in a specific Sql Server 2000 database?,"<p>I have a SQL Server 2000 database instance that is rarely updated.  I also have a database table which has no columns holding each row's created date or modified date.  </p>

<p>Is there any way that I can determine the last time an update or insert was performed on the database as a whole, so that I can at least put a bound on when the specific records in the table may have changed?</p>

<p>Note:  I am looking for information about transactions that have already occurred.  Triggers may help we should I require this again in the future, but does not address the problem I'm trying to describe.</p>

<p>If it can be done, how can I do it?</p>
","<p>Depending on the size of the database and the number of tables you could put a trigger in place that would handle updates/or inserts and log that to another table, potentially logging the table name and a timestamp, it isn't elegant but could work.  and Doesn't require any modification to the rest of the db.</p>
"
462,201990,1,0,sql,How can I determine the last time any record changed in a specific Sql Server 2000 database?,"<p>I have a SQL Server 2000 database instance that is rarely updated.  I also have a database table which has no columns holding each row's created date or modified date.  </p>

<p>Is there any way that I can determine the last time an update or insert was performed on the database as a whole, so that I can at least put a bound on when the specific records in the table may have changed?</p>

<p>Note:  I am looking for information about transactions that have already occurred.  Triggers may help we should I require this again in the future, but does not address the problem I'm trying to describe.</p>

<p>If it can be done, how can I do it?</p>
","<p>The database's log file may have some information that is useful to your quest.  AFAIK, the database itself doesn't store a ""last updated"" date.</p>
"
282,128830,1,0,sql,SQL sp_help_operator,"<p>Anyone know what group I need to belong to show up in the sp_help_operator list?</p>
","<p>Judging from the docs for <code>sp_help_operator</code>, it looks like you need to explicitly add/remove operators using <code>sp_add_operator</code> and <code>sp_delete_operator</code>.</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/aa238703(SQL.80).aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/aa238703(SQL.80).aspx</a></p>
"
256,116760,2,0,sql,"Oracle: Is there a simple way to say ""if null keep the current value"" in merge/update statements?","<p>I have a rather weak understanding of any of oracle's more advanced functionality but this should I think be possible.</p>

<p>Say I have a table with the following schema:</p>

<pre><code>MyTable
  Id INTEGER,
  Col1 VARCHAR2(100),
  Col2 VARCHAR2(100)
</code></pre>

<p>I would like to write an sproc with the following </p>

<pre><code>PROCEDURE InsertOrUpdateMyTable(p_id in integer, p_col1 in varcahr2, p_col2 in varchar2)
</code></pre>

<p>Which, in the case of an update will, if the value in p_col1, p_col2 is null will not overwrite Col1, Col2 respectively</p>

<p>So If I have a record:</p>

<pre><code>id=123, Col1='ABC', Col2='DEF'

exec InsertOrUpdateMyTable(123, 'XYZ', '098'); --results in id=123, Col1='XYZ', Col2='098'
exec InsertOrUpdateMyTable(123, NULL, '098');  --results in id=123, Col1='ABC', Col2='098'
exec InsertOrUpdateMyTable(123, NULL, NULL);   --results in id=123, Col1='ABC', Col2='DEF'
</code></pre>

<p>Is there any simple way of doing this without having multiple SQL statements?  </p>

<p>I am thinking there might be a way to do this with the Merge statement though I am only mildly familiar with it.</p>

<p><hr /></p>

<p><strong>EDIT:</strong>
Cade Roux bellow suggests using COALESCE which works great!  <a href=""http://www.java2s.com/Code/Oracle/Conversion-Functions/COALESCEreturnsthefirstnonnullexpressionintheexpressionlist.htm"" rel=""nofollow"">Here are some examples of using the coalesce kewyord.</a>
And here is the solution for my problem:</p>

<pre><code>MERGE INTO MyTable mt
    USING (SELECT 1 FROM   DUAL) a
    ON (mt.ID = p_id)
    WHEN MATCHED THEN
        UPDATE
           SET mt.Col1 = coalesce(p_col1, mt.Col1), mt.Col2 = coalesce(p_col2, mt.Col2)
    WHEN NOT MATCHED THEN
        INSERT (ID, Col1, Col2)
        VALUES (p_id, p_col1, p_col2);
</code></pre>
","<p>Change the call or the update statement to use</p>

<pre><code>nvl(newValue, oldValue)
</code></pre>

<p>for the new field value.</p>
"
528,234110,3,0,sql,"Getting a sqlexception on successful insert, VB.NET","<p>I'm trying to do a very simple INSERT using VB.NET.  For some reason I'm getting a SqlException on every insert though.  The data is inserted, but still get the following: </p>

<p>Violation of PRIMARY KEY constraint 'PK_User'. Cannot insert duplicate key in object 'dbo.Employee'. The statement has been terminated</p>

<p>When I check in SQL Management Studio, the data is succesfully inserted.</p>

<p>Here is the code where the problem is happening</p>

<pre><code>Try
    conn.Open()
    Dim insertSQL As String = ""insert into Employee(uName, firstName, lastName,
        On_Switch, On_Phone) "" + ""values('"" &amp; uName &amp; ""', '"" &amp; firstName &amp; ""', '"" _
        &amp; lastName &amp; ""', '"" &amp; onSwitch &amp; ""', '"" &amp; onPhone &amp; ""')""
        Dim AddCom As SqlCommand = New SqlCommand(insertSQL, conn)

        If (AddCom.ExecuteNonQuery() = 1) Then

            lblError.Text = ""User Added.""
            ' string urlBack = ""../ViewAsset.aspx?DeptID="" + DeptID;
            ' Response.Redirect(urlBack);
        End If

        conn.Close()

    Catch ex As SqlException
        Dim ExMsg As String = ex.Message.ToString()
        lblError.Text = ExMsg
</code></pre>

<p>I went back and tested the same code in C# and there is no Exception thrown.  It seems to be something small I'm doing in VB, but I'm lost as to what it is.</p>
","<p>Two theories. Either your code is being executed twice, or there's a trigger on the Employee table that's attempting an insert following the successful insert. (Edit: @Mitchel Sellers is exactly right, if the same code works in c# it's absolutely not a trigger issue.)</p>

<p>My hunch is that your code is being executed twice. Try running with the debugger attached and a breakpoint set on the ExecuteNonQuery - I think you'll find that some other method calls this method multiple times.</p>

<p>@Mitchel Sellers - GOOD CATCH ON THE SQL INJECTION BUG! Parameters, please! </p>
"
529,234110,7,0,sql,"Getting a sqlexception on successful insert, VB.NET","<p>I'm trying to do a very simple INSERT using VB.NET.  For some reason I'm getting a SqlException on every insert though.  The data is inserted, but still get the following: </p>

<p>Violation of PRIMARY KEY constraint 'PK_User'. Cannot insert duplicate key in object 'dbo.Employee'. The statement has been terminated</p>

<p>When I check in SQL Management Studio, the data is succesfully inserted.</p>

<p>Here is the code where the problem is happening</p>

<pre><code>Try
    conn.Open()
    Dim insertSQL As String = ""insert into Employee(uName, firstName, lastName,
        On_Switch, On_Phone) "" + ""values('"" &amp; uName &amp; ""', '"" &amp; firstName &amp; ""', '"" _
        &amp; lastName &amp; ""', '"" &amp; onSwitch &amp; ""', '"" &amp; onPhone &amp; ""')""
        Dim AddCom As SqlCommand = New SqlCommand(insertSQL, conn)

        If (AddCom.ExecuteNonQuery() = 1) Then

            lblError.Text = ""User Added.""
            ' string urlBack = ""../ViewAsset.aspx?DeptID="" + DeptID;
            ' Response.Redirect(urlBack);
        End If

        conn.Close()

    Catch ex As SqlException
        Dim ExMsg As String = ex.Message.ToString()
        lblError.Text = ExMsg
</code></pre>

<p>I went back and tested the same code in C# and there is no Exception thrown.  It seems to be something small I'm doing in VB, but I'm lost as to what it is.</p>
","<p>As a side note, I STRONGLY recommend changing to parameterized queries to prevent the risk of SQL injection that your current code is not protected from.</p>

<p>For the error issue, I would check to see that your code isn't being called twice in the VB version.</p>
"
530,234110,0,0,sql,"Getting a sqlexception on successful insert, VB.NET","<p>I'm trying to do a very simple INSERT using VB.NET.  For some reason I'm getting a SqlException on every insert though.  The data is inserted, but still get the following: </p>

<p>Violation of PRIMARY KEY constraint 'PK_User'. Cannot insert duplicate key in object 'dbo.Employee'. The statement has been terminated</p>

<p>When I check in SQL Management Studio, the data is succesfully inserted.</p>

<p>Here is the code where the problem is happening</p>

<pre><code>Try
    conn.Open()
    Dim insertSQL As String = ""insert into Employee(uName, firstName, lastName,
        On_Switch, On_Phone) "" + ""values('"" &amp; uName &amp; ""', '"" &amp; firstName &amp; ""', '"" _
        &amp; lastName &amp; ""', '"" &amp; onSwitch &amp; ""', '"" &amp; onPhone &amp; ""')""
        Dim AddCom As SqlCommand = New SqlCommand(insertSQL, conn)

        If (AddCom.ExecuteNonQuery() = 1) Then

            lblError.Text = ""User Added.""
            ' string urlBack = ""../ViewAsset.aspx?DeptID="" + DeptID;
            ' Response.Redirect(urlBack);
        End If

        conn.Close()

    Catch ex As SqlException
        Dim ExMsg As String = ex.Message.ToString()
        lblError.Text = ExMsg
</code></pre>

<p>I went back and tested the same code in C# and there is no Exception thrown.  It seems to be something small I'm doing in VB, but I'm lost as to what it is.</p>
","<p>As another side note, I noticed that your code could potentially leave a sql connection open.  If you're using the .NET 2.0 framework you should use the Using statement.  It ensures that connections are closed and disposed even if an exception is thrown.  Check this article on MSDN for more detail: <a href=""http://msdn.microsoft.com/en-us/library/htd05whh.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/htd05whh.aspx</a>.  The other option would be to add the close statement in a Finally block of your try-catch handler.</p>
"
1158,528000,0,0,sql,Query question related to retrieving the most recent entry from a table?,"<p>Hi I'm not good in framing questions. I will try my best. I'm creating a website and my question is related to the queries related to the site.This is the current query that I have. </p>

<pre><code>SELECT
  GPS_modem.vehicle_no, 
  vehicle_log.longitude, 
  vehicle_log.latitude, 
  vehicle_log.timestamp
FROM
  vehicle_log,
  GPS_modem
WHERE
  GPS_modem.modem_ID = vehicle_log.modem_ID
ORDER BY 
  timestamp desc
</code></pre>

<p>What I want to display is the entry with the most recent timestamp from the <code>vehicle_log</code> table where the <code>modem_ID</code> from the <code>GPS_modem</code> table matches with the <code>modem_ID</code> from <code>vehicle_log</code> table. </p>

<p>I tried using <code>DISTINCT</code> but I didn't work. I was getting errors when I tried using <code>MAX</code> function. Hope you are able to understand my question, if then please help me. Thanking you in advance.</p>
","<p>Here is an example for you using SQL Server. It uses a correlated subquery with the advantage of performing a match using modem_ID rather than an equality match of timestamp.</p>

<pre><code>CREATE TABLE #GPS_modem
(
    ID INT IDENTITY(1,1) PRIMARY KEY,
    vehicle_no VARCHAR(10)
)

CREATE TABLE #vehicle_log
(
    ID INT IDENTITY(1,1) PRIMARY KEY,
    modem_ID	INT,
    longitude	INT,
    latitude	INT,
    [timestamp] DATETIME DEFAULT GETDATE()
)

INSERT INTO #GPS_modem
SELECT 'ABC123' UNION ALL SELECT 'XYZ123'

INSERT INTO #vehicle_log
SELECT 1,234,543,GETDATE()
UNION all
SELECT 2,4342,432234,GETDATE()
UNION all
SELECT 1,4322,432,DATEADD(DAY,-1,GETDATE())
UNION all
SELECT 2,6336,5324,DATEADD(DAY,-1,GETDATE())

SELECT * FROM #GPS_modem
SELECT * FROM #vehicle_log


SELECT
    vehicle_no,
    longitude,
    latitude,
    [timestamp]
FROM 
    #GPS_modem A
    	inner join #vehicle_log B on
    	A.ID = B.modem_ID
WHERE B.ID IN
(
    SELECT TOP 1 ID
    FROM #vehicle_log
    WHERE modem_ID = A.ID
    ORDER BY [timestamp] DESC 
)

DROP TABLE #GPS_modem
DROP TABLE #vehicle_log
</code></pre>

<p>Cheers, John</p>
"
545,244390,3,0,sql,What is the proper syntax for a cross-table SQL query?,"<p>Right now, I have </p>

<pre><code>SELECT gp_id FROM gp.keywords 
WHERE keyword_id = 15 
AND (SELECT practice_link FROM gp.practices 
     WHERE practice_link IS NOT NULL 
     AND id = gp_id)
</code></pre>

<p>This does not provide a syntax error, however for values where it should return row(s), it just returns 0 rows.</p>

<p>What I'm trying to do is get the gp_id from gp.keywords where the the keywords table keyword_id column is a specific value and the practice_link is the practices table corresponds to the gp_id that I have, which is stored in the id column of that table.</p>
","<p>I'm not even sure that is valid SQL, so I'm surprised it is working at all:</p>

<pre><code>SELECT gp_id
FROM gp.keywords
WHERE keyword_id = 15
    AND (SELECT practice_link FROM gp.practices WHERE practice_link IS NOT NULL AND id = gp_id)
</code></pre>

<p>How about this instead:</p>

<pre><code>SELECT kw.gp_id, p.practice_link
FROM gp.keywords AS kw
INNER JOIN gp.practices AS p
    ON p.id = kw.gp_id
WHERE kw.keyword_id = 15
</code></pre>

<p>I would steer clear of implicit joins as in the other examples.  It only leads to tears later.</p>
"
255,116760,1,0,sql,"Oracle: Is there a simple way to say ""if null keep the current value"" in merge/update statements?","<p>I have a rather weak understanding of any of oracle's more advanced functionality but this should I think be possible.</p>

<p>Say I have a table with the following schema:</p>

<pre><code>MyTable
  Id INTEGER,
  Col1 VARCHAR2(100),
  Col2 VARCHAR2(100)
</code></pre>

<p>I would like to write an sproc with the following </p>

<pre><code>PROCEDURE InsertOrUpdateMyTable(p_id in integer, p_col1 in varcahr2, p_col2 in varchar2)
</code></pre>

<p>Which, in the case of an update will, if the value in p_col1, p_col2 is null will not overwrite Col1, Col2 respectively</p>

<p>So If I have a record:</p>

<pre><code>id=123, Col1='ABC', Col2='DEF'

exec InsertOrUpdateMyTable(123, 'XYZ', '098'); --results in id=123, Col1='XYZ', Col2='098'
exec InsertOrUpdateMyTable(123, NULL, '098');  --results in id=123, Col1='ABC', Col2='098'
exec InsertOrUpdateMyTable(123, NULL, NULL);   --results in id=123, Col1='ABC', Col2='DEF'
</code></pre>

<p>Is there any simple way of doing this without having multiple SQL statements?  </p>

<p>I am thinking there might be a way to do this with the Merge statement though I am only mildly familiar with it.</p>

<p><hr /></p>

<p><strong>EDIT:</strong>
Cade Roux bellow suggests using COALESCE which works great!  <a href=""http://www.java2s.com/Code/Oracle/Conversion-Functions/COALESCEreturnsthefirstnonnullexpressionintheexpressionlist.htm"" rel=""nofollow"">Here are some examples of using the coalesce kewyord.</a>
And here is the solution for my problem:</p>

<pre><code>MERGE INTO MyTable mt
    USING (SELECT 1 FROM   DUAL) a
    ON (mt.ID = p_id)
    WHEN MATCHED THEN
        UPDATE
           SET mt.Col1 = coalesce(p_col1, mt.Col1), mt.Col2 = coalesce(p_col2, mt.Col2)
    WHEN NOT MATCHED THEN
        INSERT (ID, Col1, Col2)
        VALUES (p_id, p_col1, p_col2);
</code></pre>
","<p>Using MERGE and COALESCE?  <a href=""http://blogs.oracle.com/cmar/entry/using_merge_to_do_an"" rel=""nofollow"">Try this link for an example</a></p>

<p>with</p>

<pre><code>SET a.Col1 = COALESCE(incoming.Col1, a.Col1)
    ,a.Col2 = COALESCE(incoming.Col2, a.Col2)
</code></pre>
"
1157,528000,4,0,sql,Query question related to retrieving the most recent entry from a table?,"<p>Hi I'm not good in framing questions. I will try my best. I'm creating a website and my question is related to the queries related to the site.This is the current query that I have. </p>

<pre><code>SELECT
  GPS_modem.vehicle_no, 
  vehicle_log.longitude, 
  vehicle_log.latitude, 
  vehicle_log.timestamp
FROM
  vehicle_log,
  GPS_modem
WHERE
  GPS_modem.modem_ID = vehicle_log.modem_ID
ORDER BY 
  timestamp desc
</code></pre>

<p>What I want to display is the entry with the most recent timestamp from the <code>vehicle_log</code> table where the <code>modem_ID</code> from the <code>GPS_modem</code> table matches with the <code>modem_ID</code> from <code>vehicle_log</code> table. </p>

<p>I tried using <code>DISTINCT</code> but I didn't work. I was getting errors when I tried using <code>MAX</code> function. Hope you are able to understand my question, if then please help me. Thanking you in advance.</p>
","<p>You can use correlated sub-query:</p>

<pre><code>SELECT
  m.vehicle_no, 
  l.longitude, 
  l.latitude, 
  l.timestamp
FROM
  vehicle_log AS l,
  GPS_modem   AS m 
WHERE
  m.modem_ID = l.modem_ID
  AND l.timestamp = (
    SELECT MAX(timestamp) FROM vehicle_log WHERE modem_ID = l.modem_ID
  )
</code></pre>

<p><hr /></p>

<p>EDIT: In revision #1 of my answer, I had the query seen above. Then something made me think I should change it to the one below. The one below works but is unnecessary complicated, very probably performing worse. Having slept on it, I recommend against this approach. ;-)</p>

<pre><code>SELECT
  m.vehicle_no,
  latest.longitude, 
  latest.latitude, 
  latest.timestamp
FROM
  GPS_modem AS m,
  (
    SELECT
      modem_ID,
      longitude, 
      latitude, 
      timestamp
    FROM
      vehicle_log AS l
    WHERE
      timestamp = (
        SELECT MAX(timestamp) FROM vehicle_log WHERE modem_ID = l.modem_ID
      )
  ) AS latest
WHERE
  m.modem_ID = latest.modem_ID
</code></pre>
"
1156,528000,0,0,sql,Query question related to retrieving the most recent entry from a table?,"<p>Hi I'm not good in framing questions. I will try my best. I'm creating a website and my question is related to the queries related to the site.This is the current query that I have. </p>

<pre><code>SELECT
  GPS_modem.vehicle_no, 
  vehicle_log.longitude, 
  vehicle_log.latitude, 
  vehicle_log.timestamp
FROM
  vehicle_log,
  GPS_modem
WHERE
  GPS_modem.modem_ID = vehicle_log.modem_ID
ORDER BY 
  timestamp desc
</code></pre>

<p>What I want to display is the entry with the most recent timestamp from the <code>vehicle_log</code> table where the <code>modem_ID</code> from the <code>GPS_modem</code> table matches with the <code>modem_ID</code> from <code>vehicle_log</code> table. </p>

<p>I tried using <code>DISTINCT</code> but I didn't work. I was getting errors when I tried using <code>MAX</code> function. Hope you are able to understand my question, if then please help me. Thanking you in advance.</p>
","<p>This might not be the best way. </p>

<p>But since you order the results, you could use LIMIT.</p>

<p><code>SELECT GPS_modem.vehicle_no, vehicle_log.longitude, vehicle_log.latitude, vehicle_log.timestamp from vehicle_log,GPS_modem where GPS_modem.modem_ID = vehicle_log.modem_ID order by timestamp desc LIMIT 1</code></p>

<p>There are other solutions (probably better ones), but this is one option.</p>
"
1155,528000,0,0,sql,Query question related to retrieving the most recent entry from a table?,"<p>Hi I'm not good in framing questions. I will try my best. I'm creating a website and my question is related to the queries related to the site.This is the current query that I have. </p>

<pre><code>SELECT
  GPS_modem.vehicle_no, 
  vehicle_log.longitude, 
  vehicle_log.latitude, 
  vehicle_log.timestamp
FROM
  vehicle_log,
  GPS_modem
WHERE
  GPS_modem.modem_ID = vehicle_log.modem_ID
ORDER BY 
  timestamp desc
</code></pre>

<p>What I want to display is the entry with the most recent timestamp from the <code>vehicle_log</code> table where the <code>modem_ID</code> from the <code>GPS_modem</code> table matches with the <code>modem_ID</code> from <code>vehicle_log</code> table. </p>

<p>I tried using <code>DISTINCT</code> but I didn't work. I was getting errors when I tried using <code>MAX</code> function. Hope you are able to understand my question, if then please help me. Thanking you in advance.</p>
","<p>In MySQL you can use 'limit 1' at the end of the query.</p>
"
1154,528000,1,0,sql,Query question related to retrieving the most recent entry from a table?,"<p>Hi I'm not good in framing questions. I will try my best. I'm creating a website and my question is related to the queries related to the site.This is the current query that I have. </p>

<pre><code>SELECT
  GPS_modem.vehicle_no, 
  vehicle_log.longitude, 
  vehicle_log.latitude, 
  vehicle_log.timestamp
FROM
  vehicle_log,
  GPS_modem
WHERE
  GPS_modem.modem_ID = vehicle_log.modem_ID
ORDER BY 
  timestamp desc
</code></pre>

<p>What I want to display is the entry with the most recent timestamp from the <code>vehicle_log</code> table where the <code>modem_ID</code> from the <code>GPS_modem</code> table matches with the <code>modem_ID</code> from <code>vehicle_log</code> table. </p>

<p>I tried using <code>DISTINCT</code> but I didn't work. I was getting errors when I tried using <code>MAX</code> function. Hope you are able to understand my question, if then please help me. Thanking you in advance.</p>
","<p>Depending on DB, </p>

<pre><code>SELECT TOP 1 GPS_modem.vehicle_no, vehicle_log.longitude, vehicle_log.latitude,  vehicle_log.timestamp from vehicle_log,GPS_modem where GPS_modem.modem_ID = vehicle_log.modem_ID order by timestamp desc
</code></pre>

<p>Will work on SQL Server.</p>
"
531,234110,0,0,sql,"Getting a sqlexception on successful insert, VB.NET","<p>I'm trying to do a very simple INSERT using VB.NET.  For some reason I'm getting a SqlException on every insert though.  The data is inserted, but still get the following: </p>

<p>Violation of PRIMARY KEY constraint 'PK_User'. Cannot insert duplicate key in object 'dbo.Employee'. The statement has been terminated</p>

<p>When I check in SQL Management Studio, the data is succesfully inserted.</p>

<p>Here is the code where the problem is happening</p>

<pre><code>Try
    conn.Open()
    Dim insertSQL As String = ""insert into Employee(uName, firstName, lastName,
        On_Switch, On_Phone) "" + ""values('"" &amp; uName &amp; ""', '"" &amp; firstName &amp; ""', '"" _
        &amp; lastName &amp; ""', '"" &amp; onSwitch &amp; ""', '"" &amp; onPhone &amp; ""')""
        Dim AddCom As SqlCommand = New SqlCommand(insertSQL, conn)

        If (AddCom.ExecuteNonQuery() = 1) Then

            lblError.Text = ""User Added.""
            ' string urlBack = ""../ViewAsset.aspx?DeptID="" + DeptID;
            ' Response.Redirect(urlBack);
        End If

        conn.Close()

    Catch ex As SqlException
        Dim ExMsg As String = ex.Message.ToString()
        lblError.Text = ExMsg
</code></pre>

<p>I went back and tested the same code in C# and there is no Exception thrown.  It seems to be something small I'm doing in VB, but I'm lost as to what it is.</p>
","<p>If you are executing this code within an event of some sort make sure you have not subscribed to the event multiple times. I have had this problem in asp.net.  Usually I just delete the click event handler in the code behind and the onclick attribute in the aspx file if it exists there as well and then try it again.</p>
"
417,188720,0,0,sql,Any way to transfer value from one cell to another?,"<p>Is there any way in the SQL language or in MySQL (or other DBMA) to transfer a value from one cell to another? For example, say there is a table called user_cars with the following structure:</p>

<pre><code>|id| |user_name| |num_cars|
</code></pre>

<p>Bob has 5 cars, and John has 3 cars. Is there any way to in one query subtract 2 cars from Bob and add 2 to John? I know this can be done with two update queries, but I'd just like to know if there was a more efficient way.</p>
","<p>If you really want to do it in one query, you can do an update on a self join of the table, but it's both less readable and probably less efficient.</p>
"
214,96390,2,0,sql,SQL server 2000 Like Statement Usage,"<p>I have a SQL statement that looks like:</p>

<pre><code>SELECT [Phone]
FROM [Table]
WHERE
(
    [Phone] LIKE '[A-Z][a-z]'
    OR [Phone] = 'N/A'
    OR [Phone] LIKE '[0]'
)
</code></pre>

<p>The part I'm having trouble with is the where statement with the ""LIKEs"". I've seen SQL statements where authors used <code>like</code> statements in the way I'm using them above. At first, I thought this might be a version of Regular Expressions but I've since learned. </p>

<p>Is anyone familiar with using like statements in such a way. Note: the ""N/A"" is working fine. </p>

<p>What I need to match is phone numbers that have characters. Or phone numbers which contain nothing but zero.</p>
","<p>Try using the <code>t-sql</code> <code>ISNUMERIC</code> function.  That will show you which ones are/are not numeric.</p>

<p>You may also need to <code>TRIM</code> or <code>REPLACE</code> spaces to get what you want.</p>

<p>For example, to find valid phone numbers, replace spaces with '', test with <code>ISNUMERIC</code>, and test with <code>LEN</code>.</p>

<p>Although I will warn you, this will be tedious if you have to deal with international phone numbers.</p>

<p>The thing to note with your SQL above, is that SQL Server doesn't understand Regex.</p>
"
213,96390,4,0,sql,SQL server 2000 Like Statement Usage,"<p>I have a SQL statement that looks like:</p>

<pre><code>SELECT [Phone]
FROM [Table]
WHERE
(
    [Phone] LIKE '[A-Z][a-z]'
    OR [Phone] = 'N/A'
    OR [Phone] LIKE '[0]'
)
</code></pre>

<p>The part I'm having trouble with is the where statement with the ""LIKEs"". I've seen SQL statements where authors used <code>like</code> statements in the way I'm using them above. At first, I thought this might be a version of Regular Expressions but I've since learned. </p>

<p>Is anyone familiar with using like statements in such a way. Note: the ""N/A"" is working fine. </p>

<p>What I need to match is phone numbers that have characters. Or phone numbers which contain nothing but zero.</p>
","<p>Check <a href=""http://technet.microsoft.com/en-us/library/aa933232%28v=sql.80%29.aspx"" rel=""nofollow"">here</a>.</p>

<p>[] matches a range of characters.</p>

<p>I think you want something like this:</p>

<pre><code>SELECT [Phone]
FROM [Table]
WHERE
(
    [Phone] LIKE '%[A-Z]%'
    OR [Phone] LIKE '%[a-z]%'
    OR [Phone] = 'N/A'
    OR [Phone] LIKE '0'
)
</code></pre>
"
182,81560,0,0,sql,override constraint from no action to cascading at runtime,"<p>I feel like I have a verry basic/stupid question, yet I never saw/read/heard anything in this direction.</p>

<p>Say I have a table <em>users(userId, name)</em> and a table <em>preferences(id, userId, language)</em>. The example is trivial, but could be extended to a situation with multi-level relations and way more tables..
When my UI requests to delete a user I first want to show a warning stating that also its preferences will be deleted. If at some point the database gets extended with more tables and relationships, but the software isn't adapted accordingly (client didn't update) a generic message should be shown.</p>

<p>How can I implement this? The UI cannot know about the whole data structure and should not be bothered to walk down all the relations to manually delete all the depending records.<br />
I would think this would be with constraints.
The constraint would be <em>no action</em> at first so the constraint will throw an error that can be caught by the UI. After the UI receives a confirmation, the constraint should become a <em>cascade</em>.</p>

<p>Somehow I'm feeling like I'm getting this all wrong..</p>
","<p>If you are worried about the user not realising the full impact of their delete, you might want to consider not actually deleting the data - instead you could simply set a flag on a column called say ""<code>marked_for_deletion</code>"". (the entries could then be deleted a safe time later)<br />
The downside is that you need to remember to filter out the marked rows in other queries. This can be mitigated by creating a view on the table with the marked rows filtered out, and then always using the view in your queries.</p>
"
542,244390,1,0,sql,What is the proper syntax for a cross-table SQL query?,"<p>Right now, I have </p>

<pre><code>SELECT gp_id FROM gp.keywords 
WHERE keyword_id = 15 
AND (SELECT practice_link FROM gp.practices 
     WHERE practice_link IS NOT NULL 
     AND id = gp_id)
</code></pre>

<p>This does not provide a syntax error, however for values where it should return row(s), it just returns 0 rows.</p>

<p>What I'm trying to do is get the gp_id from gp.keywords where the the keywords table keyword_id column is a specific value and the practice_link is the practices table corresponds to the gp_id that I have, which is stored in the id column of that table.</p>
","<p><pre><code>
select k.gp_id 
from gp.keywords as k,
     gp.practices as p
where
keyword_id=15
and practice_link is not null
and p.id=k.gp_id
</pre></code></p>
"
543,244390,0,0,sql,What is the proper syntax for a cross-table SQL query?,"<p>Right now, I have </p>

<pre><code>SELECT gp_id FROM gp.keywords 
WHERE keyword_id = 15 
AND (SELECT practice_link FROM gp.practices 
     WHERE practice_link IS NOT NULL 
     AND id = gp_id)
</code></pre>

<p>This does not provide a syntax error, however for values where it should return row(s), it just returns 0 rows.</p>

<p>What I'm trying to do is get the gp_id from gp.keywords where the the keywords table keyword_id column is a specific value and the practice_link is the practices table corresponds to the gp_id that I have, which is stored in the id column of that table.</p>
","<pre><code>SELECT k.gp_id
FROM gp.keywords k, gp.practices p
WHERE 
   p.id = k.gp_id.AND
   k.keyword_id = 15 AND
   p.practice_link is not null
</code></pre>
"
544,244390,0,0,sql,What is the proper syntax for a cross-table SQL query?,"<p>Right now, I have </p>

<pre><code>SELECT gp_id FROM gp.keywords 
WHERE keyword_id = 15 
AND (SELECT practice_link FROM gp.practices 
     WHERE practice_link IS NOT NULL 
     AND id = gp_id)
</code></pre>

<p>This does not provide a syntax error, however for values where it should return row(s), it just returns 0 rows.</p>

<p>What I'm trying to do is get the gp_id from gp.keywords where the the keywords table keyword_id column is a specific value and the practice_link is the practices table corresponds to the gp_id that I have, which is stored in the id column of that table.</p>
","<pre><code>SELECT g.gp_id, p.practice_link FROM gp.keywords g, gp.practices p 
WHERE
g.keyword_id = 15 AND p.practice_link IS NOT NULL AND p.id = g.gp_id
</code></pre>
"
953,441880,4,0,sql,"Equivalent? No, but why?","<p>T-SQL:</p>

<p>1(ANSI):    <code>convert(varchar(10),@DueDate, 102) &lt; convert(varchar(10),getdate(), 102)</code></p>

<p>2(USA):    <code>convert(varchar(10),@DueDate, 101) &lt; convert(varchar(10),getdate(), 101)</code></p>

<p>Notice that these will return different results when year is considered.</p>

<p>Why?</p>

<p>What's the difference? Why isn't the operator taking year into consideration when using #2?</p>
","<p>What are you trying to do? You're comparing varchars, there. Look at the output from these statements:</p>

<pre><code>print convert(varchar(10), getdate(), 101)
print convert(varchar(10), getdate(), 102)
</code></pre>

<p>That prints this:</p>

<pre><code>01/14/2009
2009.01.14
</code></pre>

<p>Comparing the first form is only really going to be checking to see if the month of one date is less than the month of the current date.</p>

<p>Is there a reason you need to convert the dates to varchar? Why not compare them directly?</p>

<pre><code>@DueDate &lt; getdate()
</code></pre>
"
715,327010,1,0,sql,"using a vector of column names, to generate a sql statement","<p>A problem that we need to solve regularly at my workplace is how to build sql statements based on user supplied table/column names.  The issue I am trying to address is the commas between column names.  </p>

<p>One technique looks something like this.</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    selectSql += "", ""; 
}

selectSql = selectSql(0, selectSql.len() - 2);

selectSql += ""FROM some-table"";
</code></pre>

<p>Another technique looks something like this</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    if (z &lt; columns.size() - 1) 
        selectSql += "", ""; 
}

selectSql += ""FROM some-table"";
</code></pre>

<p>I am not particularly enthralled by either of these implementations.</p>

<p>I am interesting in hearing ideas for other ways to address this issue, with an eye toward making the code easier to read/understand/maintain.</p>

<p>What alternate techniques are available?</p>
","<p>The way I build up statements is usually:</p>

<pre><code>pad = """"
stmt = ""SELECT ""

for (i = 0; i &lt; number; i++)
{
    stmt += pad + item[i]
    pad = "", ""
}
</code></pre>

<p>This is relatively clean - it reassigns to pad each iteration, but that's trivial.  I've used any number of trivial variations on this, but it is the cleanest mechanism I know of.</p>

<p>Of course, there'll be someone else's answer to learn from too...</p>
"
1120,512560,1,0,sql,Is there an equivalent to the iSeries OVRDBF command in SQL?,"<p>I have a requirement in a SQL environment that under specific circumstances, all references to table (or view) A in a procedure actually use table (or view) B.  On the iSeries I would have used the OVRDBF command to override references to table A with table B: OVRDBF FILE(A) TOFILE(B).  What would be the equivalent to this in SQL?  Is there one?  </p>

<p>My goal is to end up with a procedure that is ignorant of the override.  I don't want conditional logic inside the procedure that directs processing at table B when certain conditions are met.  The vision:</p>

<p>Under typical circumstances:  Just invoke the procedure</p>

<p>Under specific alternative circumstances:  Perform the OVRDBF equivalent and then Invoke the procedure</p>
","<p>Not sure which SQL environment support which options:</p>

<p>I believe DB2 has a CREATE ALIAS statement.  Write the SQL over the alias.  </p>

<p>Another possibility:  run your queries over views:  where you would do the OVRDBF, drop the view and rebuild it over the desired table.</p>
"
673,298580,0,0,sql,Subsonic Join issue,"<p>For those of you who are decent with subsonic!</p>

<pre><code>        TblNewsCollection col =
            new Select().From(Tables.TblNews)
                .InnerJoin(Tables.TblContent)
                .Paged(currentPage, pageSize)
                .OrderDesc(TblContent.Columns.PubDate)
                .ExecuteAsCollection&lt;TblNewsCollection&gt;();
</code></pre>

<p>The above works, no problem, but when I try to add a where clause</p>

<pre><code>        TblNewsCollection col =
            new Select().From(Tables.TblNews)
                .InnerJoin(Tables.TblContent)
                .Where(TblContent.Columns.UserFK)
                .IsEqualTo(guidUserFK)
                .Paged(currentPage, pageSize)
                .OrderDesc(TblContent.Columns.PubDate)
                .ExecuteAsCollection&lt;TblNewsCollection&gt;();
</code></pre>

<p>I get this message</p>

<pre><code>System.InvalidCastException: Object must implement IConvertible.
at System.Convert.ChangeType(Object value, Type conversionType, IFormatProvider provider)
at System.Data.SqlClient.SqlParameter.CoerceValue(Object value, MetaType destinationType) 
System.InvalidCastException: Failed to convert parameter value from a Guid to a String.
</code></pre>

<p>I've tried it from other fields, for example a bit field in a database it says it can't convert from bool to bit!</p>

<p>Seems to only be an issue on where statements after joins</p>
","<pre><code>Northwind.CustomerCollection customersByCategory = new Select()
    .From(Northwind.Customer.Schema)
    .InnerJoin(Northwind.Order.Schema)
    .InnerJoin(Northwind.OrderDetail.OrderIDColumn, Northwind.Order.OrderIDColumn)
    .InnerJoin(Northwind.Product.ProductIDColumn, Northwind.OrderDetail.ProductIDColumn)
    .Where(""CategoryID"").IsEqualTo(5)
    .ExecuteAsCollection&lt;Northwind.CustomerCollection&gt;();
</code></pre>

<p>There's an example that supposedly works.  If that helps anyone help me!</p>
"
909,416740,0,0,sql,Problem with SQL Join,"<p>I have two tables, tblEntities and tblScheduling.</p>

<p>tblEntities:</p>

<pre><code>EntityID  ShortName          Active
1         Dirtville          1
2         Goldtown           1
3         Blackston          0
4         Cornfelt           1
5         Vick               1
</code></pre>

<p>tblScheduling:</p>

<pre><code>ScheduleID EntityID SchedulingYearID
1          1        20
2          1        21
3          2        20
4          3        19
5          5        20
</code></pre>

<p>I need a query that will show <strong>ALL ACTIVE</strong> Entities and their schedule information for a particular ScheduleYearID.</p>

<p>Output should look like (the desired SchedulingYearID in this case is 20):</p>

<pre><code>EntityID ScheduleID
1        1
2        3
4        NULL
5        5
</code></pre>

<p>The query that I have written so far is: </p>

<pre><code>SELECT     tblEntities.EntityID, tblEntities.ShortName, tblScheduling.ScheduleID
FROM         tblScheduling RIGHT OUTER JOIN
                      tblEntities ON tblScheduling.EntityID = tblEntities.EntityID
WHERE     (tblScheduling.SchedulingYearID = @SchedulingYearID) 
AND (tblEntities.Active = 1)
ORDER BY tblEntities.EntityID
</code></pre>

<p>My problem is that using this query it will not include active entities without schedule information (such as EntityID 4 in the example above). I can write the query to display all active entities and their schedule status fine, but once I start limiting it via the SchedulingYearID I lose those particular entities. </p>

<p>Are there any solutions that I am obviously missing without having to resort to subqueries, cursors, etc.? If not it's not a big deal, I just feel like I am missing something simple here.</p>
","<p>I think the trouble is that the WHERE clause is filtering out the rows where SchedulingYearID is null.  So don't.</p>

<pre><code>SELECT tblEntities.EntityID, tblEntities.ShortName, tblScheduling.ScheduleID
    FROM tblScheduling RIGHT OUTER JOIN
         tblEntities ON tblScheduling.EntityID = tblEntities.EntityID
    WHERE (tblScheduling.SchedulingYearID = @SchedulingYearID OR
           tblScheduling.SchedulingYearID IS NULL) 
      AND (tblEntities.Active = 1)
    ORDER BY tblEntities.EntityID;
</code></pre>
"
908,416740,0,0,sql,Problem with SQL Join,"<p>I have two tables, tblEntities and tblScheduling.</p>

<p>tblEntities:</p>

<pre><code>EntityID  ShortName          Active
1         Dirtville          1
2         Goldtown           1
3         Blackston          0
4         Cornfelt           1
5         Vick               1
</code></pre>

<p>tblScheduling:</p>

<pre><code>ScheduleID EntityID SchedulingYearID
1          1        20
2          1        21
3          2        20
4          3        19
5          5        20
</code></pre>

<p>I need a query that will show <strong>ALL ACTIVE</strong> Entities and their schedule information for a particular ScheduleYearID.</p>

<p>Output should look like (the desired SchedulingYearID in this case is 20):</p>

<pre><code>EntityID ScheduleID
1        1
2        3
4        NULL
5        5
</code></pre>

<p>The query that I have written so far is: </p>

<pre><code>SELECT     tblEntities.EntityID, tblEntities.ShortName, tblScheduling.ScheduleID
FROM         tblScheduling RIGHT OUTER JOIN
                      tblEntities ON tblScheduling.EntityID = tblEntities.EntityID
WHERE     (tblScheduling.SchedulingYearID = @SchedulingYearID) 
AND (tblEntities.Active = 1)
ORDER BY tblEntities.EntityID
</code></pre>

<p>My problem is that using this query it will not include active entities without schedule information (such as EntityID 4 in the example above). I can write the query to display all active entities and their schedule status fine, but once I start limiting it via the SchedulingYearID I lose those particular entities. </p>

<p>Are there any solutions that I am obviously missing without having to resort to subqueries, cursors, etc.? If not it's not a big deal, I just feel like I am missing something simple here.</p>
","<p>It's your conditions in the where clause:
(tblScheduling.SchedulingYearID = @SchedulingYearID) </p>

<p>when there is no tblScheduling info this wil always fail. Add </p>

<p>(((tblScheduling.SchedulingYearID = @SchedulingYearID) OR (tblScheduling.SchedulingYearID is null) )</p>

<p>or wathever null condition checking your DB uses.</p>
"
907,416740,6,0,sql,Problem with SQL Join,"<p>I have two tables, tblEntities and tblScheduling.</p>

<p>tblEntities:</p>

<pre><code>EntityID  ShortName          Active
1         Dirtville          1
2         Goldtown           1
3         Blackston          0
4         Cornfelt           1
5         Vick               1
</code></pre>

<p>tblScheduling:</p>

<pre><code>ScheduleID EntityID SchedulingYearID
1          1        20
2          1        21
3          2        20
4          3        19
5          5        20
</code></pre>

<p>I need a query that will show <strong>ALL ACTIVE</strong> Entities and their schedule information for a particular ScheduleYearID.</p>

<p>Output should look like (the desired SchedulingYearID in this case is 20):</p>

<pre><code>EntityID ScheduleID
1        1
2        3
4        NULL
5        5
</code></pre>

<p>The query that I have written so far is: </p>

<pre><code>SELECT     tblEntities.EntityID, tblEntities.ShortName, tblScheduling.ScheduleID
FROM         tblScheduling RIGHT OUTER JOIN
                      tblEntities ON tblScheduling.EntityID = tblEntities.EntityID
WHERE     (tblScheduling.SchedulingYearID = @SchedulingYearID) 
AND (tblEntities.Active = 1)
ORDER BY tblEntities.EntityID
</code></pre>

<p>My problem is that using this query it will not include active entities without schedule information (such as EntityID 4 in the example above). I can write the query to display all active entities and their schedule status fine, but once I start limiting it via the SchedulingYearID I lose those particular entities. </p>

<p>Are there any solutions that I am obviously missing without having to resort to subqueries, cursors, etc.? If not it's not a big deal, I just feel like I am missing something simple here.</p>
","<p>Try this... Join conditions are evaluated to produce the intermediate Join result set, and then, (for an outer join), all the rows from the ""Outer"" side are added back in before moving on... Where conditions are evaluated after all joins are done...  </p>

<pre><code>SELECT E.EntityID, E.ShortName, S.ScheduleID
FROM  tblEntities E 
     Left Join tblScheduling S 
        ON S.EntityID = E.EntityID
           And S.SchedulingYearID = @SchedulingYearID 
WHERE E.Active = 1
ORDER BY E.EntityID
</code></pre>

<p>I change your join order cause I prefer left joins... but it doesn't matter</p>
"
906,415920,0,0,sql,SQL code import into Access 2007,"<p>I basically need to know how to import SQL code into Access. I've tried one way but that requires me to do one table and one value at a time which takes a lot of time.</p>

<p>Can anyone help?</p>
","<p>I guess you are talking about ""importing"" both structure and data from SQL to ACCESS. ACCESS does not accept standard TSQL scripts that you could generate directly from your SQL Database. There are some commercial products like <a href=""http://www.SQLManager.net"" rel=""nofollow"">EMS</a> that can more or less do the job for you. EMS has a data exporter module that can take your SQL data in different formats, including Access. </p>

<p>Another way would be to open an Access file and write some basic VBA code, taking advantage of the DoCmd.TransferDatabase method, where you can link OR copy tables from other databases into Access.</p>

<p>I forgot if these methods also allow the transfer of a 'clean' database model, including primary keys and relations... You'll have to give it a try.</p>
"
905,415920,1,0,sql,SQL code import into Access 2007,"<p>I basically need to know how to import SQL code into Access. I've tried one way but that requires me to do one table and one value at a time which takes a lot of time.</p>

<p>Can anyone help?</p>
","<p>If you are trying to import data, rather than SQL code (see Duffymo's response),  there are two ways.</p>

<p>One is to go where the data is and dump a .CSV file and import that, as Duffymo responded.</p>

<p>The other is to create a table link from the Access database to a table in the source database.  If the two databases will talk to each other this way,  you can use the data in the remote table as if it were in the Access database.</p>
"
904,415920,0,0,sql,SQL code import into Access 2007,"<p>I basically need to know how to import SQL code into Access. I've tried one way but that requires me to do one table and one value at a time which takes a lot of time.</p>

<p>Can anyone help?</p>
","<p>Well, some days ago I needed to shift data from an Access database to SQL (reverse of what you're doing). I found it simpler to write a simple script that would read data from my access database and insert it into SQL.</p>

<p>I don't think doing what you need to do is any different.</p>

<p>I don't know if it will help, but I posting my code (It's a simple C# function). You can just change the connections and it will work. Of course I only had 3 fields so I hard-coded them. You can do the same for your db schema.</p>

<pre><code>protected void btnProcess_Click(object sender, EventArgs e)
{
    //Open the connections to the access and SQL databases
    string sqlDBCnn = @""Data Source=.\SQLEXPRESS;Integrated Security=True;AttachDBFileName=|DataDirectory|\mydb.mdf;user instance=true"";
    string accessDBCnn = @""Provider=Microsoft.Jet.OleDB.4.0;Data Source=C:\mydb.mdb"";

    OleDbConnection cnnAcc = new OleDbConnection(accessDBCnn);
    cnnAcc.Open();

    SqlConnection cnnSql = new SqlConnection(sqlDBCnn);
    cnnSql.Open();

    SqlCommand cmSql = new SqlCommand(""DELETE tablename"", cnnSql);
    cmSql.ExecuteNonQuery();

    //Retrieve the data from the Access Database
    OleDbCommand cmdAcc = new OleDbCommand(""SELECT * FROM tablename"", cnnAcc);
    OleDbDataReader drAcc = cmdAcc.ExecuteReader();

    using (drAcc)
    {
        if (drAcc.HasRows)
        {
            //Loop through the access database records and add them to the database
            while (drAcc.Read())
            {
                SqlCommand cmdSql = new SqlCommand(""INSERT INTO tablename(Category, Head, Val) VALUES(@cat,@head,@val)"",cnnSql);

                SqlParameter parCat = new SqlParameter(""cat"",System.Data.SqlDbType.VarChar,150);
                SqlParameter parHead = new SqlParameter(""head"",System.Data.SqlDbType.VarChar,150);
                SqlParameter parVal = new SqlParameter(""val"",System.Data.SqlDbType.VarChar);
                parCat.Value = drAcc[""Category""].ToString();
                parHead.Value = drAcc[""Head""].ToString();
                parVal.Value = drAcc[""Val""].ToString();
                cmdSql.Parameters.Add(parCat);
                cmdSql.Parameters.Add(parHead);
                cmdSql.Parameters.Add(parVal);

                cmdSql.ExecuteNonQuery();
            }
        }
    }

    lblMsg.Text = ""&lt;p /&gt; All Done Kapitone!"";

}
</code></pre>
"
903,415920,0,0,sql,SQL code import into Access 2007,"<p>I basically need to know how to import SQL code into Access. I've tried one way but that requires me to do one table and one value at a time which takes a lot of time.</p>

<p>Can anyone help?</p>
","<p>SQL code?  Or data?  ""one table and one value"" makes me think it's the latter.  If so, I'd suggest dumping the data out into a .csv file and importing that into Access tables.</p>

<p>Or maybe using a tool like Microsoft's DTS to map and move the data between sources.  That would be the best idea.</p>
"
897,406520,1,0,sql,Divide by zero error in stored procedure,"<p>Hi i executed the following stored procedure in .net web application. Then run the application. I got this error</p>

<p>"" Divide By zero error ""</p>

<p>Stored procedure:</p>

<pre><code>CREATE procedure Details(@Stringtext varchar(8000),@SearchStringtext varchar(100))
as begin
SELECT ({fn LENGTH(@Stringtext)}-
{fn LENGTH({fn REPLACE(@Stringtext, @SearchStringtext, '')})})/
{ fn LENGTH(@SearchStringtext)}AS String_Count

end
</code></pre>
","<p>The only division operation in this procedure, has <strong><code>fn LENGTH(@SearchStringtext)</code></strong> as the divisor.</p>

<p>Hence it seems that length of <code>**SearchStringtext**</code> is evaluating to zero. It might be possible that you are trying to search an Empty string.</p>

<p>Please check and then elaborate the question details, along with the DB platform.</p>
"
896,406520,1,0,sql,Divide by zero error in stored procedure,"<p>Hi i executed the following stored procedure in .net web application. Then run the application. I got this error</p>

<p>"" Divide By zero error ""</p>

<p>Stored procedure:</p>

<pre><code>CREATE procedure Details(@Stringtext varchar(8000),@SearchStringtext varchar(100))
as begin
SELECT ({fn LENGTH(@Stringtext)}-
{fn LENGTH({fn REPLACE(@Stringtext, @SearchStringtext, '')})})/
{ fn LENGTH(@SearchStringtext)}AS String_Count

end
</code></pre>
","<pre><code>{ fn LENGTH(@SearchStringtext)}
</code></pre>

<p>is evaluating to 0.</p>

<p>However, why is this a stored procedure? You are not using any db feature? Unless this is a simplified problem , all this (length, replace etc) could be done in your .net application</p>
"
895,406520,1,0,sql,Divide by zero error in stored procedure,"<p>Hi i executed the following stored procedure in .net web application. Then run the application. I got this error</p>

<p>"" Divide By zero error ""</p>

<p>Stored procedure:</p>

<pre><code>CREATE procedure Details(@Stringtext varchar(8000),@SearchStringtext varchar(100))
as begin
SELECT ({fn LENGTH(@Stringtext)}-
{fn LENGTH({fn REPLACE(@Stringtext, @SearchStringtext, '')})})/
{ fn LENGTH(@SearchStringtext)}AS String_Count

end
</code></pre>
","<p>The length of the SearchStringText is Zero and hence there is divide by zero error.
Make sure that when the function is called, the string is of non-zero length.
Alternatively check for length before doing the select</p>
"
894,406520,1,0,sql,Divide by zero error in stored procedure,"<p>Hi i executed the following stored procedure in .net web application. Then run the application. I got this error</p>

<p>"" Divide By zero error ""</p>

<p>Stored procedure:</p>

<pre><code>CREATE procedure Details(@Stringtext varchar(8000),@SearchStringtext varchar(100))
as begin
SELECT ({fn LENGTH(@Stringtext)}-
{fn LENGTH({fn REPLACE(@Stringtext, @SearchStringtext, '')})})/
{ fn LENGTH(@SearchStringtext)}AS String_Count

end
</code></pre>
","<p>If SearchStringtext is empty, the length of it becomes 0. Thus the stored procedure tries to divide by zero (which is an <a href=""http://en.wikipedia.org/wiki/Division_by_zero"" rel=""nofollow"">undefined thing to do</a>).</p>

<p>In other words the following part becomes zero:</p>

<pre><code>{ fn LENGTH(@SearchStringtext)}
</code></pre>

<p>You might want to add some logic (if statement perhaps) to prevent the division to happen if the SearchStringtext is empty.</p>
"
893,406520,0,0,sql,Divide by zero error in stored procedure,"<p>Hi i executed the following stored procedure in .net web application. Then run the application. I got this error</p>

<p>"" Divide By zero error ""</p>

<p>Stored procedure:</p>

<pre><code>CREATE procedure Details(@Stringtext varchar(8000),@SearchStringtext varchar(100))
as begin
SELECT ({fn LENGTH(@Stringtext)}-
{fn LENGTH({fn REPLACE(@Stringtext, @SearchStringtext, '')})})/
{ fn LENGTH(@SearchStringtext)}AS String_Count

end
</code></pre>
","<p>It seems that the length of SearchStringtext is 0 -- so the procedure tries to divide by zero.</p>
"
892,406520,3,0,sql,Divide by zero error in stored procedure,"<p>Hi i executed the following stored procedure in .net web application. Then run the application. I got this error</p>

<p>"" Divide By zero error ""</p>

<p>Stored procedure:</p>

<pre><code>CREATE procedure Details(@Stringtext varchar(8000),@SearchStringtext varchar(100))
as begin
SELECT ({fn LENGTH(@Stringtext)}-
{fn LENGTH({fn REPLACE(@Stringtext, @SearchStringtext, '')})})/
{ fn LENGTH(@SearchStringtext)}AS String_Count

end
</code></pre>
","<p>Evidently:</p>

<pre><code>{ fn LENGTH(@SearchStringtext)}
</code></pre>

<p>... is evaluating to zero.</p>
"
1010,467190,1,0,sql,SQL Server won't perform regular expression validation on XML column,"<p>I have an XML column in my table which contains this xsd snippet:</p>

<pre><code>&lt;xsd:element name=""Postcode"" minOccurs=""0""&gt;
    &lt;xsd:simpleType&gt;
        &lt;xsd:restriction base=""xsd:string""&gt;
            &lt;xsd:pattern value=""^[0-9]{4}$"" /&gt;
        &lt;/xsd:restriction&gt;
    &lt;/xsd:simpleType&gt;
&lt;/xsd:element&gt;
</code></pre>

<p>The regular expression should require a string containing 4 numerical digits.  It validates perfectly in Visual Studio and is a correct regular expression.</p>

<p>SQL Server, on the other hand, won't accept it.  The error message I receive is: </p>

<pre><code>XML Validation: Invalid simple type value: '1234'. Location: / * : Donor[1]/*:Postcode[1].
</code></pre>

<p>I have an email address regex working fine, but can't get this simple numerical regex to work.</p>
","<p>Does your source XML look like this:</p>

<pre><code>&lt;Postcode&gt;1234&lt;/Postcode&gt;
</code></pre>

<p>or like this:</p>

<pre><code>&lt;Postcode&gt;
    1234
&lt;/Postcode&gt;
</code></pre>

<p>Since you are trimming the string (with <code>^</code> and <code>$</code>) make sure that your XML looks like the former and not the latter.</p>
"
1011,467190,0,0,sql,SQL Server won't perform regular expression validation on XML column,"<p>I have an XML column in my table which contains this xsd snippet:</p>

<pre><code>&lt;xsd:element name=""Postcode"" minOccurs=""0""&gt;
    &lt;xsd:simpleType&gt;
        &lt;xsd:restriction base=""xsd:string""&gt;
            &lt;xsd:pattern value=""^[0-9]{4}$"" /&gt;
        &lt;/xsd:restriction&gt;
    &lt;/xsd:simpleType&gt;
&lt;/xsd:element&gt;
</code></pre>

<p>The regular expression should require a string containing 4 numerical digits.  It validates perfectly in Visual Studio and is a correct regular expression.</p>

<p>SQL Server, on the other hand, won't accept it.  The error message I receive is: </p>

<pre><code>XML Validation: Invalid simple type value: '1234'. Location: / * : Donor[1]/*:Postcode[1].
</code></pre>

<p>I have an email address regex working fine, but can't get this simple numerical regex to work.</p>
","<p>No, there is no whitespace around the string.</p>

<p>I do have an email address regex which works perfectly.   </p>
"
1012,467190,1,0,sql,SQL Server won't perform regular expression validation on XML column,"<p>I have an XML column in my table which contains this xsd snippet:</p>

<pre><code>&lt;xsd:element name=""Postcode"" minOccurs=""0""&gt;
    &lt;xsd:simpleType&gt;
        &lt;xsd:restriction base=""xsd:string""&gt;
            &lt;xsd:pattern value=""^[0-9]{4}$"" /&gt;
        &lt;/xsd:restriction&gt;
    &lt;/xsd:simpleType&gt;
&lt;/xsd:element&gt;
</code></pre>

<p>The regular expression should require a string containing 4 numerical digits.  It validates perfectly in Visual Studio and is a correct regular expression.</p>

<p>SQL Server, on the other hand, won't accept it.  The error message I receive is: </p>

<pre><code>XML Validation: Invalid simple type value: '1234'. Location: / * : Donor[1]/*:Postcode[1].
</code></pre>

<p>I have an email address regex working fine, but can't get this simple numerical regex to work.</p>
","<p>The XML Schema regex flavor doesn't support the start and end anchors; all matches are anchored at both ends, always.  It's probably trying to match '^' and '$' literally.</p>
"
869,378210,1,0,sql,C++ sql pass integer to sql string,"<p>I have built a database in MS Access.
There I have a table called Customers which also has a cell called Employee type: integer.
I also built a program in C++ which controls all data.</p>

<p>Let's say I have a string like this:</p>

<pre><code>string sqlString = ""SELECT * FROM Customers Where Customers.Employee = '"" + id + ""' "";
</code></pre>

<p>Id passes through my function correctly and is an integer, so I get an error in compilation saying: ""Invalid pointer addition"".</p>

<p>If I declare id as a string of course there's no error but there are no results in my form also.  If I declare in database cell Employee as text and build my query like this:</p>

<pre><code>string sqlString = ""SELECT * FROM Customers WHERE Customers.Employee = 128"";
</code></pre>

<p>I get results, but I need that Employee as an integer cause its a foreign key from another table.</p>

<p>So, what should I do with my query to have results passing integer as parameter through variable id, to be ok with the cell Employee from database which is also integer?
Any ideas? I would really appreciate some help here.</p>

<hr>

<p>As I said, if I convert id to string, there are no results in my form since Employee in database is an integer.  So this:</p>

<pre><code>std::ostringstream buf;
buf &lt;&lt; ""SELECT * FROM Customers Where Customers.Employee = '"" &lt;&lt; id  &lt;&lt; ""' "";
string str = buf.str();
</code></pre>

<p>won't do the job or any other conversion.</p>

<p>How can I pass id as an integer in my query?</p>
","<p>use </p>

<pre><code>std::ostringstream buf; buf &lt;&lt; ""SELECT * FROM Customers Where Customers.Employee = "" &lt;&lt; id ; string str = buf.str();
</code></pre>

<p>This should work please try '12'  --- quote should not be placed before and after 12</p>
"
868,378210,0,0,sql,C++ sql pass integer to sql string,"<p>I have built a database in MS Access.
There I have a table called Customers which also has a cell called Employee type: integer.
I also built a program in C++ which controls all data.</p>

<p>Let's say I have a string like this:</p>

<pre><code>string sqlString = ""SELECT * FROM Customers Where Customers.Employee = '"" + id + ""' "";
</code></pre>

<p>Id passes through my function correctly and is an integer, so I get an error in compilation saying: ""Invalid pointer addition"".</p>

<p>If I declare id as a string of course there's no error but there are no results in my form also.  If I declare in database cell Employee as text and build my query like this:</p>

<pre><code>string sqlString = ""SELECT * FROM Customers WHERE Customers.Employee = 128"";
</code></pre>

<p>I get results, but I need that Employee as an integer cause its a foreign key from another table.</p>

<p>So, what should I do with my query to have results passing integer as parameter through variable id, to be ok with the cell Employee from database which is also integer?
Any ideas? I would really appreciate some help here.</p>

<hr>

<p>As I said, if I convert id to string, there are no results in my form since Employee in database is an integer.  So this:</p>

<pre><code>std::ostringstream buf;
buf &lt;&lt; ""SELECT * FROM Customers Where Customers.Employee = '"" &lt;&lt; id  &lt;&lt; ""' "";
string str = buf.str();
</code></pre>

<p>won't do the job or any other conversion.</p>

<p>How can I pass id as an integer in my query?</p>
","<p>you can use boost::format with boost::str</p>

<pre><code>string = boost::str(boost::format(""This is a string with some %s and %d numbers"") %""strings"" %42);
</code></pre>

<p>this should be better approach since you will have all the replacement variable in one place at the end.</p>
"
867,378210,3,0,sql,C++ sql pass integer to sql string,"<p>I have built a database in MS Access.
There I have a table called Customers which also has a cell called Employee type: integer.
I also built a program in C++ which controls all data.</p>

<p>Let's say I have a string like this:</p>

<pre><code>string sqlString = ""SELECT * FROM Customers Where Customers.Employee = '"" + id + ""' "";
</code></pre>

<p>Id passes through my function correctly and is an integer, so I get an error in compilation saying: ""Invalid pointer addition"".</p>

<p>If I declare id as a string of course there's no error but there are no results in my form also.  If I declare in database cell Employee as text and build my query like this:</p>

<pre><code>string sqlString = ""SELECT * FROM Customers WHERE Customers.Employee = 128"";
</code></pre>

<p>I get results, but I need that Employee as an integer cause its a foreign key from another table.</p>

<p>So, what should I do with my query to have results passing integer as parameter through variable id, to be ok with the cell Employee from database which is also integer?
Any ideas? I would really appreciate some help here.</p>

<hr>

<p>As I said, if I convert id to string, there are no results in my form since Employee in database is an integer.  So this:</p>

<pre><code>std::ostringstream buf;
buf &lt;&lt; ""SELECT * FROM Customers Where Customers.Employee = '"" &lt;&lt; id  &lt;&lt; ""' "";
string str = buf.str();
</code></pre>

<p>won't do the job or any other conversion.</p>

<p>How can I pass id as an integer in my query?</p>
","<p>You could use sprintf, but in C++ you can do:</p>

<pre><code>std::ostringstream buf;
buf &lt;&lt; ""SELECT * FROM Customers Where Customers.Employee = '"" &lt;&lt; id  &lt;&lt; ""' "";
string str = buf.str();
</code></pre>

<p>(untested)</p>
"
866,378210,2,0,sql,C++ sql pass integer to sql string,"<p>I have built a database in MS Access.
There I have a table called Customers which also has a cell called Employee type: integer.
I also built a program in C++ which controls all data.</p>

<p>Let's say I have a string like this:</p>

<pre><code>string sqlString = ""SELECT * FROM Customers Where Customers.Employee = '"" + id + ""' "";
</code></pre>

<p>Id passes through my function correctly and is an integer, so I get an error in compilation saying: ""Invalid pointer addition"".</p>

<p>If I declare id as a string of course there's no error but there are no results in my form also.  If I declare in database cell Employee as text and build my query like this:</p>

<pre><code>string sqlString = ""SELECT * FROM Customers WHERE Customers.Employee = 128"";
</code></pre>

<p>I get results, but I need that Employee as an integer cause its a foreign key from another table.</p>

<p>So, what should I do with my query to have results passing integer as parameter through variable id, to be ok with the cell Employee from database which is also integer?
Any ideas? I would really appreciate some help here.</p>

<hr>

<p>As I said, if I convert id to string, there are no results in my form since Employee in database is an integer.  So this:</p>

<pre><code>std::ostringstream buf;
buf &lt;&lt; ""SELECT * FROM Customers Where Customers.Employee = '"" &lt;&lt; id  &lt;&lt; ""' "";
string str = buf.str();
</code></pre>

<p>won't do the job or any other conversion.</p>

<p>How can I pass id as an integer in my query?</p>
","<p>You need to convert id to a string, then your first approach should work.</p>

<p>See this question for how to do the conversion:
<a href=""http://stackoverflow.com/questions/228005/alternative-to-itoa-for-converting-integer-to-string-c"">http://stackoverflow.com/questions/228005/alternative-to-itoa-for-converting-integer-to-string-c</a></p>
"
1030,481050,0,0,sql,How to corretly load DataContext of Conditional Linq-to-SQL Stored Proc,"<p>I have a Stored Proc that do a validation on a parameter</p>

<p>ex.</p>

<pre><code>IF @SearchType = 'BNa'
BEGIN
    ... DO something
END
ELSE IF @SearchType = 'SNa'
BEGIN
    ... DO something
END
</code></pre>

<p>So by default the Stored Proc return a scalar value and if SearchType = something valid it will return a IMultipleValues.</p>

<p>The problem is that when I drop my Stored Proc in the DataContext designer, it creates the LINQ-to-SQL for a function that only returns a scalar int. It doesn't understands that the Strored Proc could return a IMultipleResults with a scalar value and a DataSet.</p>

<p>Anyone know how to made LINQ-to-SQL to extrapolate the possible return values?</p>
","<p>I can't answer your question directly, but have you tried using SQL Profiler to work out how the designer retrieves the metadata for your stored procedure? </p>

<p>I'm thinking that in your situation it may not be possible for the designer to figure things out for you. SQL Profiler will let you figure this out for sure either way...</p>

<p>I've had quite a positive experience with using SqlMetal (instead of the designer). To save you Googling the documentation is at <a href=""http://msdn.microsoft.com/en-us/library/bb386987.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/bb386987.aspx</a>.</p>

<p>One of the ways you can use SqlMetal is:</p>

<ol>
<li>Run SqlMetal to extract database metadata to a DBML file. </li>
<li>Run some custom processing on the DBML file (which is easy to do as it's just XML). </li>
<li>Run SqlMetal again to turn the updated DBML into code.</li>
</ol>

<p>Using this approach, you could correct the metadata being used for your stored procedure (assuming it can't be determined correctly).</p>

<p>The winning thing about this approach for me is that you can modify your database whenever you need to, and easily regenerate the matching strongly typed code, while still retaining a high degree of control over what is generated.</p>
"
1031,483940,3,0,sql,Oracle9i: Filter Expression Fails to Exclude Data at Runtime,"<p>I have a relatively simple select statement in a VB6 program that I have to maintain. (Suppress your natural tendency to shudder; I inherited the thing, I didn't write it.)</p>

<p>The statement is straightforward (reformatted for clarity):</p>

<pre><code>select distinct 
   b.ip_address 
from 
   code_table a, 
   location b 
where 
   a.code_item = b.which_id and 
   a.location_type_code = '15' and 
   a.code_status = 'R'
</code></pre>

<p>The table in question returns a list of IP addresses from the database. The key column in question is <code>code_status</code>. Some time ago, we realized that one of the IP addresses was no longer valid, so we changed its status to <code>I</code> (invalid) to exclude it from appearing in the query's results.</p>

<p>When you execute the query above in SQL Plus, or in SQL Developer, everything is fine. But when you execute it from VB6, the check against <code>code_status</code> is ignored, and the invalid IP address appears in the result set.</p>

<p>My first guess was that the results were cached somewhere. But, not being an Oracle expert, I have no idea where to look. </p>

<p>This is <em>ancient</em> VB6 code. The SQL is embedded in the application. At the moment, I don't have time to rewrite it as a stored procedure. (I will some day, given the chance.) But, I need to know what would cause this disparity in behavior and how to eliminate it. If it's happening here, it's likely happening somewhere else.</p>

<p>If anyone can suggest a good place to look, I'd be very appreciative.</p>
","<p>Some random ideas:</p>

<ul>
<li><p>Are you sure you committed the changes that invalidate the ip-address? Can someone else (using another db connection / user) see the changed code_status?</p></li>
<li><p>Are you sure that the results are not modified after they are returned from the database?</p></li>
<li><p>Are you sure that you are using the ""same"" database connection in SQLPlus as in the code (database, user etc.)?</p></li>
<li><p>Are you sure that that is indeed the SQL sent to the database? (You may check by tracing on the Oracle server or by debugging the VB code). Reformatting may have changed ""something"".</p></li>
</ul>

<p>Off the top of my head I can't think of any ""caching"" that might ""re-insert"" the unwanted ip. Hope something from the above gives you some ideas on where to look at.</p>
"
1032,483940,0,0,sql,Oracle9i: Filter Expression Fails to Exclude Data at Runtime,"<p>I have a relatively simple select statement in a VB6 program that I have to maintain. (Suppress your natural tendency to shudder; I inherited the thing, I didn't write it.)</p>

<p>The statement is straightforward (reformatted for clarity):</p>

<pre><code>select distinct 
   b.ip_address 
from 
   code_table a, 
   location b 
where 
   a.code_item = b.which_id and 
   a.location_type_code = '15' and 
   a.code_status = 'R'
</code></pre>

<p>The table in question returns a list of IP addresses from the database. The key column in question is <code>code_status</code>. Some time ago, we realized that one of the IP addresses was no longer valid, so we changed its status to <code>I</code> (invalid) to exclude it from appearing in the query's results.</p>

<p>When you execute the query above in SQL Plus, or in SQL Developer, everything is fine. But when you execute it from VB6, the check against <code>code_status</code> is ignored, and the invalid IP address appears in the result set.</p>

<p>My first guess was that the results were cached somewhere. But, not being an Oracle expert, I have no idea where to look. </p>

<p>This is <em>ancient</em> VB6 code. The SQL is embedded in the application. At the moment, I don't have time to rewrite it as a stored procedure. (I will some day, given the chance.) But, I need to know what would cause this disparity in behavior and how to eliminate it. If it's happening here, it's likely happening somewhere else.</p>

<p>If anyone can suggest a good place to look, I'd be very appreciative.</p>
","<p>In addition to the suggestions that IronGoofy has made, have you tried swapping round the last two clauses?</p>

<pre><code>where
   a.code_item = b.wich_id and
   a.code_status = 'R' and
   a.location_type_code = '15'
</code></pre>

<p>If you get a different set of results then this might point to some sort of wrangling going on that results in dodgy SQL actually be sent to the database.</p>
"
986,449140,2,0,sql,Reference generated primary key in SQL script,"<p>I'm trying to create a bunch of entries in a database with a single script and the problem I'm encountering is how to reference the generated primary key of the previous entry I created.</p>

<p>For example if I created a customer, then tried to create an order for that customer, how do I get the primary key generated for the customer?</p>

<p>I'm using SQLServer.</p>
","<p>If you are inserting multiple rows at once, you can get all the identities (for use in, say, creating related records) by using the <code>OUTPUT INTO</code> <a href=""http://www.sqlteam.com/article/using-the-output-clause-to-capture-identity-values-on-multi-row-inserts"" rel=""nofollow"">feature of SQL Server 2005 or later</a>.</p>

<p>This could avoid you having to write loops and cursors etc.</p>
"
985,449140,4,0,sql,Reference generated primary key in SQL script,"<p>I'm trying to create a bunch of entries in a database with a single script and the problem I'm encountering is how to reference the generated primary key of the previous entry I created.</p>

<p>For example if I created a customer, then tried to create an order for that customer, how do I get the primary key generated for the customer?</p>

<p>I'm using SQLServer.</p>
","<p>If available in your version, use SCOPE_IDENTITY() instead.  Safer than @@IDENTITY.</p>
"
984,449140,4,0,sql,Reference generated primary key in SQL script,"<p>I'm trying to create a bunch of entries in a database with a single script and the problem I'm encountering is how to reference the generated primary key of the previous entry I created.</p>

<p>For example if I created a customer, then tried to create an order for that customer, how do I get the primary key generated for the customer?</p>

<p>I'm using SQLServer.</p>
","<p>Like so:</p>

<pre><code>DECLARE @customerid int;
INSERT INTO customers(name) VALUES('Spencer');
SET @customerid = @@IDENTITY;
</code></pre>

<p><strong>EDIT:</strong></p>

<p>Apparently it needs to be SCOPE_IDENTITY() in order to function as expected with triggers.</p>

<pre><code>DECLARE @customerid int;
INSERT INTO customers(name) VALUES('Spencer');
SET @customerid = SCOPE_IDENTITY();
</code></pre>
"
971,445950,-1,0,sql,Is SQL the assembly for databases?,"<p>Talking about hibernate and others ORMs, the ORMs evangelists talk about SQL like the assembly language for Databases.</p>

<p>I think is soon to assert this, but I guess can be true on a near future, not sure.</p>

<p><strong>UPDATE:</strong> The analogy I was referring means <em>SQL</em> is to <em>assembly</em> what <em>ORM</em> is to <em>C/Java/C#</em>. Of course, an exact analogy is not possible. The question is if in the future, with more powerful computers the developers are going to use only <em>ORM</em> (or ORM like) instead of <em>SQL</em>.</p>
","<p>No, however you could possibly say SQL is the C of Databases. They are both <strike> procedural and imperative, and</strike> data oriented instead of object oriented. And as C its easier to model objects and functionality in higher languages but in the end C is the baseline for performance measures.</p>
"
958,443210,0,0,sql,Conversion between different units of measurement in SQL (in Access),"<p>I'm trying to program an access database but I'm using SQL for all my querying.  I've got the database almost complete but I have one query that has me stumped.  It is a database which contains recipes.  I have a table in which I have all the conversions for cooking (Tablespoon to Teaspoon, Teaspoon to Cup, etc.).  The user needs to be able to put in an ingredient using whatever units the recipe calls for (in other words, I cannot standardize the units, I have to find what they are).  Then I need to be able to convert these into a standardized unit.  This is where I'm having the problem because things like vegetables can come in cups, tablespoons, etc. whereas things like meats come in ounces, pounds, etc.  I want to avoid creating a bunch of vb if/then's.  I feel like there must be a way to do this with SQL but I can't seem to figure it out.</p>
","<p>as long as you are asking the user for the unit they are using, and you know what you are going for, then you should be able to just query the answer from the file.  Assuming your table looks something like:</p>

<p>fromUnit
fromUnitFactor (probably always 1)
ToUnit
ToUnitFactor (whatever it takes to get from the fromUnit to the toUnit)</p>

<p>then just query it out, you know what you are looking for, know what you you have.  Then just take the amount given by the user and multiply it by the toUnitFactor you get back.</p>

<p>The biggest problem with this is you need every combination of from and to in your table.</p>

<p>make sense?</p>
"
959,443210,1,0,sql,Conversion between different units of measurement in SQL (in Access),"<p>I'm trying to program an access database but I'm using SQL for all my querying.  I've got the database almost complete but I have one query that has me stumped.  It is a database which contains recipes.  I have a table in which I have all the conversions for cooking (Tablespoon to Teaspoon, Teaspoon to Cup, etc.).  The user needs to be able to put in an ingredient using whatever units the recipe calls for (in other words, I cannot standardize the units, I have to find what they are).  Then I need to be able to convert these into a standardized unit.  This is where I'm having the problem because things like vegetables can come in cups, tablespoons, etc. whereas things like meats come in ounces, pounds, etc.  I want to avoid creating a bunch of vb if/then's.  I feel like there must be a way to do this with SQL but I can't seem to figure it out.</p>
","<p>I think for cooking you have to separate two different types of units</p>

<ol>
<li>by weight</li>
<li>by volume</li>
</ol>

<p>You can't standardize these units, or what sense does it make to know that you need 2 cups of meet?</p>

<p>Then when you differentiate those two different types of units, you can standardize them two one unit. Maybe:</p>

<ol>
<li>cups, teaspoon,... in ml</li>
<li>meat, vegetables,... in g or pounds, or whatever</li>
</ol>

<p>If they all have the same base, then you're able to compare them.</p>
"
960,443210,3,0,sql,Conversion between different units of measurement in SQL (in Access),"<p>I'm trying to program an access database but I'm using SQL for all my querying.  I've got the database almost complete but I have one query that has me stumped.  It is a database which contains recipes.  I have a table in which I have all the conversions for cooking (Tablespoon to Teaspoon, Teaspoon to Cup, etc.).  The user needs to be able to put in an ingredient using whatever units the recipe calls for (in other words, I cannot standardize the units, I have to find what they are).  Then I need to be able to convert these into a standardized unit.  This is where I'm having the problem because things like vegetables can come in cups, tablespoons, etc. whereas things like meats come in ounces, pounds, etc.  I want to avoid creating a bunch of vb if/then's.  I feel like there must be a way to do this with SQL but I can't seem to figure it out.</p>
","<p>I would think about this differently.  You have different types of measures (volume, weight, count, etc.).  Each of those measures has different, convertible units.  Choosing a measure (ounces, for example), choose both a measure type and a particular unit.  I'd have a way of converting between units of the same measure type -- to support resizing recipes -- but I wouldn't worry about converting between different measure types.</p>

<p>Once you know the type, you can store all values in the database in terms of a base unit for that measure type.  Based on the value, and perhaps user preference, you can translate that to a suitable display unit when you show it.  I don't think this would be particularly easy to do in SQL and I wouldn't be afraid of doing the conversion in code.  You simply need to have a different display formatter for each measure type that chooses the appropriate unit and does the conversion.</p>
"
961,443210,0,0,sql,Conversion between different units of measurement in SQL (in Access),"<p>I'm trying to program an access database but I'm using SQL for all my querying.  I've got the database almost complete but I have one query that has me stumped.  It is a database which contains recipes.  I have a table in which I have all the conversions for cooking (Tablespoon to Teaspoon, Teaspoon to Cup, etc.).  The user needs to be able to put in an ingredient using whatever units the recipe calls for (in other words, I cannot standardize the units, I have to find what they are).  Then I need to be able to convert these into a standardized unit.  This is where I'm having the problem because things like vegetables can come in cups, tablespoons, etc. whereas things like meats come in ounces, pounds, etc.  I want to avoid creating a bunch of vb if/then's.  I feel like there must be a way to do this with SQL but I can't seem to figure it out.</p>
","<p>The user would have to provide you with the unit, and evey unit would have a type (weight, volume, etc.)  Your ""conversion table"" would just need to include a baseline for every unit type.  i.e. 8 oz to a cup, 128oz to a gallon.  Knowing those two things you can convert cups to gallons.</p>

<p>Doing this in access in a single query is a different story.  If you can do a little VBA, get cup to ounces in one call, then ounces to gallons in another, I think you'll have a much easier time.</p>
"
962,443210,0,0,sql,Conversion between different units of measurement in SQL (in Access),"<p>I'm trying to program an access database but I'm using SQL for all my querying.  I've got the database almost complete but I have one query that has me stumped.  It is a database which contains recipes.  I have a table in which I have all the conversions for cooking (Tablespoon to Teaspoon, Teaspoon to Cup, etc.).  The user needs to be able to put in an ingredient using whatever units the recipe calls for (in other words, I cannot standardize the units, I have to find what they are).  Then I need to be able to convert these into a standardized unit.  This is where I'm having the problem because things like vegetables can come in cups, tablespoons, etc. whereas things like meats come in ounces, pounds, etc.  I want to avoid creating a bunch of vb if/then's.  I feel like there must be a way to do this with SQL but I can't seem to figure it out.</p>
","<p>I got it to pull out the conversion factor for one record.  I just did it with queries.  I basically look up a column and a row (with sql, the column and row names are variablized) and that value is what I need to multiply by.  However, as we all know, you never just work with one record in sql.  Any ideas on how to expand this to incorporate all of the data?</p>
"
963,443210,0,0,sql,Conversion between different units of measurement in SQL (in Access),"<p>I'm trying to program an access database but I'm using SQL for all my querying.  I've got the database almost complete but I have one query that has me stumped.  It is a database which contains recipes.  I have a table in which I have all the conversions for cooking (Tablespoon to Teaspoon, Teaspoon to Cup, etc.).  The user needs to be able to put in an ingredient using whatever units the recipe calls for (in other words, I cannot standardize the units, I have to find what they are).  Then I need to be able to convert these into a standardized unit.  This is where I'm having the problem because things like vegetables can come in cups, tablespoons, etc. whereas things like meats come in ounces, pounds, etc.  I want to avoid creating a bunch of vb if/then's.  I feel like there must be a way to do this with SQL but I can't seem to figure it out.</p>
","<p>OK,</p>

<p>Just wanted to post my solution in case anyone has this problem in the future.  I actually make the table and populate it with all the other data that I'm interested in with SQL in the usual way.  Then I have a DCOUNT function to tell how many records there are which sets a variable.  Then I have a DLOOKUP function which tells me what to convert from and to and sets it in the new table for the record that I'm on.  Phew, I think I'm in over my head!  Thanks for the help folks.</p>
"
930,434680,2,0,sql,Access sharepoint list data in SQL,"<p>I am new to SharePoint development.  I have a list, this list has a column that is called <code>Todaysdate</code>. This column needs to be updated daily to today's actual date and since it contains ~20,000 rows I am NOT going to update it manually everyday.  Because it's used in a calculation row.</p>

<p>My question is can I just use SQL and update the rows in the UserData table that correspond to the <code>datetime</code> column that I need?</p>

<p>I can query the list of rows by something similar to</p>

<pre><code>Select * from UserData where tp_ListID = 'GUID'
</code></pre>

<p>but the data contained in the column <code>datetime3</code> is not just the <code>Todaysdate</code> information.  How do I return just the <code>Todaysdate</code> info?</p>
","<p>You really should not query let alone update the SharePoint content database directly using SQL. It is totally unsupported, so if you break something you are left alone, and the database schema may change with future service packs / releases.<br/>
Also as noesgard mentioned it in his comment you do not need it to use today's date in a calculated field, see <a href=""http://blogs.msdn.com/cjohnson/archive/2006/03/16/552314.aspx"" rel=""nofollow"">this blog entry</a> on how you can do that.</p>
"
929,432320,2,0,sql,Data Modeling: What is a good relational design when a table has several foreign key constrainst to a single table?,"<p>I have 2 tables: 
1. Employees
2. Vouchers</p>

<p>Employees table has a single primary key.
Vouchers table has 3 foreign key constraints referencing the Employees table.</p>

<p>The following is a sample T-SQL script (not the actual table script) to create both tables and their relationship in SQL Server:</p>

<pre><code>IF OBJECT_ID('dbo.Vouchers') IS NOT NULL
    DROP TABLE dbo.Vouchers
IF OBJECT_ID('dbo.Employees') IS NOT NULL
    DROP TABLE dbo.Employees
GO

CREATE TABLE Employees
(
  ObjectID     INT    NOT NULL   PRIMARY KEY    IDENTITY
)

CREATE TABLE Vouchers
(
  ObjectID     INT    NOT NULL   PRIMARY KEY    IDENTITY,
  IssuedBy     INT,
  ReceivedBy   INT,
  ApprovedBy   INT,

  CONSTRAINT fk_Vouchers_Employees_IssuedBy FOREIGN KEY (IssuedBy)
                                    REFERENCES Employees (ObjectID)
                                    ON UPDATE CASCADE
                                    ON DELETE NO ACTION,
 CONSTRAINT fk_Vouchers_Employees_ReceivedBy FOREIGN KEY (ReceivedBy)
                                    REFERENCES Employees (ObjectID)
                                    ON UPDATE CASCADE
                                    ON DELETE NO ACTION,
 CONSTRAINT fk_Vouchers_Employees_ApprovedBy FOREIGN KEY (ApprovedBy)
                                    REFERENCES Employees (ObjectID)
                                    ON UPDATE CASCADE
                                    ON DELETE NO ACTION 
)
</code></pre>

<p>But an error is thrown:</p>

<pre><code>Msg 1785, Level 16, State 0, Line 7
Introducing FOREIGN KEY constraint 'fk_Vouchers_Employees_ReceivedBy' on table 'Vouchers' may cause cycles or multiple cascade paths. Specify ON DELETE NO ACTION or ON UPDATE NO ACTION, or modify other FOREIGN KEY constraints.
</code></pre>

<p>I don't have an idea of what efficient solution is available here. The requirements on the relationship is that: whenever an Employee is deleted, the Voucher that references some of its columns to the Employee does not get deleted (ON DELETE CASCADE is not an option). Instead, the values of the columns (IssuedBy, ReceivedBy and/or ApprovedBy) that are referenced to the deleted Employee should be set to NULL (since the columns are NULLABLE).</p>

<p>Many thanks!</p>
","<p>I would not actually delete Employees, but instead use a trigger to set a flag to mark them as deleted.</p>

<p>I generally don't turn on cascade of Updates or Deletes, but instead require an application to explicitly perform these actions.</p>
"
928,432320,1,0,sql,Data Modeling: What is a good relational design when a table has several foreign key constrainst to a single table?,"<p>I have 2 tables: 
1. Employees
2. Vouchers</p>

<p>Employees table has a single primary key.
Vouchers table has 3 foreign key constraints referencing the Employees table.</p>

<p>The following is a sample T-SQL script (not the actual table script) to create both tables and their relationship in SQL Server:</p>

<pre><code>IF OBJECT_ID('dbo.Vouchers') IS NOT NULL
    DROP TABLE dbo.Vouchers
IF OBJECT_ID('dbo.Employees') IS NOT NULL
    DROP TABLE dbo.Employees
GO

CREATE TABLE Employees
(
  ObjectID     INT    NOT NULL   PRIMARY KEY    IDENTITY
)

CREATE TABLE Vouchers
(
  ObjectID     INT    NOT NULL   PRIMARY KEY    IDENTITY,
  IssuedBy     INT,
  ReceivedBy   INT,
  ApprovedBy   INT,

  CONSTRAINT fk_Vouchers_Employees_IssuedBy FOREIGN KEY (IssuedBy)
                                    REFERENCES Employees (ObjectID)
                                    ON UPDATE CASCADE
                                    ON DELETE NO ACTION,
 CONSTRAINT fk_Vouchers_Employees_ReceivedBy FOREIGN KEY (ReceivedBy)
                                    REFERENCES Employees (ObjectID)
                                    ON UPDATE CASCADE
                                    ON DELETE NO ACTION,
 CONSTRAINT fk_Vouchers_Employees_ApprovedBy FOREIGN KEY (ApprovedBy)
                                    REFERENCES Employees (ObjectID)
                                    ON UPDATE CASCADE
                                    ON DELETE NO ACTION 
)
</code></pre>

<p>But an error is thrown:</p>

<pre><code>Msg 1785, Level 16, State 0, Line 7
Introducing FOREIGN KEY constraint 'fk_Vouchers_Employees_ReceivedBy' on table 'Vouchers' may cause cycles or multiple cascade paths. Specify ON DELETE NO ACTION or ON UPDATE NO ACTION, or modify other FOREIGN KEY constraints.
</code></pre>

<p>I don't have an idea of what efficient solution is available here. The requirements on the relationship is that: whenever an Employee is deleted, the Voucher that references some of its columns to the Employee does not get deleted (ON DELETE CASCADE is not an option). Instead, the values of the columns (IssuedBy, ReceivedBy and/or ApprovedBy) that are referenced to the deleted Employee should be set to NULL (since the columns are NULLABLE).</p>

<p>Many thanks!</p>
","<p>From a design standpoint it seems good to have the 3 foreign keys you listed.  It looks like the error message you are getting relates to the ON UPDATE CASCADE options on your foreign keys (although I was able to create the table as specified).  Regardless, to get the behavior you mention wanting, I would recommend a trigger on the Employees table, that fires before you delete the record.  This trigger would find instances of the Employees.OjbectID in the Vouchers table and set them to NULL.</p>
"
970,445950,1,0,sql,Is SQL the assembly for databases?,"<p>Talking about hibernate and others ORMs, the ORMs evangelists talk about SQL like the assembly language for Databases.</p>

<p>I think is soon to assert this, but I guess can be true on a near future, not sure.</p>

<p><strong>UPDATE:</strong> The analogy I was referring means <em>SQL</em> is to <em>assembly</em> what <em>ORM</em> is to <em>C/Java/C#</em>. Of course, an exact analogy is not possible. The question is if in the future, with more powerful computers the developers are going to use only <em>ORM</em> (or ORM like) instead of <em>SQL</em>.</p>
","<p>No, no it's not.  People that say that have never coded assembly.</p>
"
972,445950,18,0,sql,Is SQL the assembly for databases?,"<p>Talking about hibernate and others ORMs, the ORMs evangelists talk about SQL like the assembly language for Databases.</p>

<p>I think is soon to assert this, but I guess can be true on a near future, not sure.</p>

<p><strong>UPDATE:</strong> The analogy I was referring means <em>SQL</em> is to <em>assembly</em> what <em>ORM</em> is to <em>C/Java/C#</em>. Of course, an exact analogy is not possible. The question is if in the future, with more powerful computers the developers are going to use only <em>ORM</em> (or ORM like) instead of <em>SQL</em>.</p>
","<p>Absolutely not. </p>

<p>Assembly language is a very low level language where you instruct the processor exactly what to do, including what registers you want to use etc. </p>

<p>SQL is a very high level language where you describe the semantics of what you want, and then a query optimiser decides how to execute it, so you don't even control what gets executed. It's an extremely powerful and flexible language of which any ORM offers at most a (fairly small) subset.</p>

<p>You'll notice that the .NET framework has introduced LINQ recently which is a way to introduce high level SQL-like constructs into languages like C# and VB. Rather than being like assembler, it's pretty easy to argue that SQL works at a higher level of abstraction than most mainstream programming languages.</p>
"
927,432320,3,0,sql,Data Modeling: What is a good relational design when a table has several foreign key constrainst to a single table?,"<p>I have 2 tables: 
1. Employees
2. Vouchers</p>

<p>Employees table has a single primary key.
Vouchers table has 3 foreign key constraints referencing the Employees table.</p>

<p>The following is a sample T-SQL script (not the actual table script) to create both tables and their relationship in SQL Server:</p>

<pre><code>IF OBJECT_ID('dbo.Vouchers') IS NOT NULL
    DROP TABLE dbo.Vouchers
IF OBJECT_ID('dbo.Employees') IS NOT NULL
    DROP TABLE dbo.Employees
GO

CREATE TABLE Employees
(
  ObjectID     INT    NOT NULL   PRIMARY KEY    IDENTITY
)

CREATE TABLE Vouchers
(
  ObjectID     INT    NOT NULL   PRIMARY KEY    IDENTITY,
  IssuedBy     INT,
  ReceivedBy   INT,
  ApprovedBy   INT,

  CONSTRAINT fk_Vouchers_Employees_IssuedBy FOREIGN KEY (IssuedBy)
                                    REFERENCES Employees (ObjectID)
                                    ON UPDATE CASCADE
                                    ON DELETE NO ACTION,
 CONSTRAINT fk_Vouchers_Employees_ReceivedBy FOREIGN KEY (ReceivedBy)
                                    REFERENCES Employees (ObjectID)
                                    ON UPDATE CASCADE
                                    ON DELETE NO ACTION,
 CONSTRAINT fk_Vouchers_Employees_ApprovedBy FOREIGN KEY (ApprovedBy)
                                    REFERENCES Employees (ObjectID)
                                    ON UPDATE CASCADE
                                    ON DELETE NO ACTION 
)
</code></pre>

<p>But an error is thrown:</p>

<pre><code>Msg 1785, Level 16, State 0, Line 7
Introducing FOREIGN KEY constraint 'fk_Vouchers_Employees_ReceivedBy' on table 'Vouchers' may cause cycles or multiple cascade paths. Specify ON DELETE NO ACTION or ON UPDATE NO ACTION, or modify other FOREIGN KEY constraints.
</code></pre>

<p>I don't have an idea of what efficient solution is available here. The requirements on the relationship is that: whenever an Employee is deleted, the Voucher that references some of its columns to the Employee does not get deleted (ON DELETE CASCADE is not an option). Instead, the values of the columns (IssuedBy, ReceivedBy and/or ApprovedBy) that are referenced to the deleted Employee should be set to NULL (since the columns are NULLABLE).</p>

<p>Many thanks!</p>
","<p>Strictly from a relational design point of view, the Vouchers table as three Foreign Keys. Whether you choose to enforce them, through CASCADE assertions or otherwise, is an implementation issue, but the relational design still exists. Presumably you want to enforce that, if one of the three fields is not NULL, then a matching record needs to exist. Or not. It's an implementation issue as to whether or not you care to enforce the design.</p>

<p>However, the violations you describe are assumed at your peril. The fact that you're asking this question suggests you may not fully appreciate all the ways these choices can lead into the swamp.</p>

<p>I think the error may be a consequence of the fact that more than one of the three might refer to the same employee.</p>

<p>BTW, I've in very few cases ever found it necessary to delete records in such a fashion that CASCADES are useful. Usually that would be used to prevent the database from being too big; and database capacity is less and less an issue over time.</p>
"
973,445950,3,0,sql,Is SQL the assembly for databases?,"<p>Talking about hibernate and others ORMs, the ORMs evangelists talk about SQL like the assembly language for Databases.</p>

<p>I think is soon to assert this, but I guess can be true on a near future, not sure.</p>

<p><strong>UPDATE:</strong> The analogy I was referring means <em>SQL</em> is to <em>assembly</em> what <em>ORM</em> is to <em>C/Java/C#</em>. Of course, an exact analogy is not possible. The question is if in the future, with more powerful computers the developers are going to use only <em>ORM</em> (or ORM like) instead of <em>SQL</em>.</p>
","<p>No, SQL is itself a high level abstraction layer that is (mostly) database agnostic.</p>
"
974,445950,0,0,sql,Is SQL the assembly for databases?,"<p>Talking about hibernate and others ORMs, the ORMs evangelists talk about SQL like the assembly language for Databases.</p>

<p>I think is soon to assert this, but I guess can be true on a near future, not sure.</p>

<p><strong>UPDATE:</strong> The analogy I was referring means <em>SQL</em> is to <em>assembly</em> what <em>ORM</em> is to <em>C/Java/C#</em>. Of course, an exact analogy is not possible. The question is if in the future, with more powerful computers the developers are going to use only <em>ORM</em> (or ORM like) instead of <em>SQL</em>.</p>
","<p>Don't believe that hogwash.</p>
"
975,445950,6,0,sql,Is SQL the assembly for databases?,"<p>Talking about hibernate and others ORMs, the ORMs evangelists talk about SQL like the assembly language for Databases.</p>

<p>I think is soon to assert this, but I guess can be true on a near future, not sure.</p>

<p><strong>UPDATE:</strong> The analogy I was referring means <em>SQL</em> is to <em>assembly</em> what <em>ORM</em> is to <em>C/Java/C#</em>. Of course, an exact analogy is not possible. The question is if in the future, with more powerful computers the developers are going to use only <em>ORM</em> (or ORM like) instead of <em>SQL</em>.</p>
","<p>No, relational algebra is the ""assembler code"" of database.</p>

<p>SQL is the ""C code"", readable and close enough to the ""hardware"" to be able to outperform all those other high level languages, provided you know what you're doing :-).</p>
"
976,445950,7,0,sql,Is SQL the assembly for databases?,"<p>Talking about hibernate and others ORMs, the ORMs evangelists talk about SQL like the assembly language for Databases.</p>

<p>I think is soon to assert this, but I guess can be true on a near future, not sure.</p>

<p><strong>UPDATE:</strong> The analogy I was referring means <em>SQL</em> is to <em>assembly</em> what <em>ORM</em> is to <em>C/Java/C#</em>. Of course, an exact analogy is not possible. The question is if in the future, with more powerful computers the developers are going to use only <em>ORM</em> (or ORM like) instead of <em>SQL</em>.</p>
","<p>I have heard a lot of b*s about impedence mismatch between relational and OO over hte years.</p>

<p>My answer has always been that there is indeed a very big impedence mismatch -- between the niave inflexable ""everything is an object and only an object"" and the wonderfully flexable and sophisticated ""data describes real world things; this data can be combined in different as yet unknown ways to produce mathematicaly provable results"".</p>

<p>OO is not the only fruit guys.</p>
"
977,445950,1,0,sql,Is SQL the assembly for databases?,"<p>Talking about hibernate and others ORMs, the ORMs evangelists talk about SQL like the assembly language for Databases.</p>

<p>I think is soon to assert this, but I guess can be true on a near future, not sure.</p>

<p><strong>UPDATE:</strong> The analogy I was referring means <em>SQL</em> is to <em>assembly</em> what <em>ORM</em> is to <em>C/Java/C#</em>. Of course, an exact analogy is not possible. The question is if in the future, with more powerful computers the developers are going to use only <em>ORM</em> (or ORM like) instead of <em>SQL</em>.</p>
","<p>If you do only online transaction processing you use only the simple sql statements. Hibernate can generate them for you. </p>

<p>But if you want to do reporting, data analyzing or speedy bulk actions you have to learn SQL, and you often will use the vendor specific SQL extensions. Querying hierarchical data for example is possible when you use vendor specific SQL. </p>

<p>If you want to use SQL properly you have to think in sets, not row-by-row tiny statements. Therefore I say it is the exact opposite of assembler. </p>
"
978,445950,-1,0,sql,Is SQL the assembly for databases?,"<p>Talking about hibernate and others ORMs, the ORMs evangelists talk about SQL like the assembly language for Databases.</p>

<p>I think is soon to assert this, but I guess can be true on a near future, not sure.</p>

<p><strong>UPDATE:</strong> The analogy I was referring means <em>SQL</em> is to <em>assembly</em> what <em>ORM</em> is to <em>C/Java/C#</em>. Of course, an exact analogy is not possible. The question is if in the future, with more powerful computers the developers are going to use only <em>ORM</em> (or ORM like) instead of <em>SQL</em>.</p>
","<p>It is, in the following sense: an ORM provides a high-level, domain-specific API which emits SQL statements, in the same way that a high-level language creates domain-specific APIs and emits machine-language statements.</p>

<p>I.e.:</p>

<ul>
<li>Orm is is a layer above SQL</li>
<li>And HLL is a layer above assembly</li>
</ul>

<p>However, I don't mean to imply that people will stop using SQL and prefer ORMs, in the same way that people have stopped using assembly and prefer HLLs.</p>
"
979,445950,2,0,sql,Is SQL the assembly for databases?,"<p>Talking about hibernate and others ORMs, the ORMs evangelists talk about SQL like the assembly language for Databases.</p>

<p>I think is soon to assert this, but I guess can be true on a near future, not sure.</p>

<p><strong>UPDATE:</strong> The analogy I was referring means <em>SQL</em> is to <em>assembly</em> what <em>ORM</em> is to <em>C/Java/C#</em>. Of course, an exact analogy is not possible. The question is if in the future, with more powerful computers the developers are going to use only <em>ORM</em> (or ORM like) instead of <em>SQL</em>.</p>
","<p>SQL shares some traits with assembly language:</p>

<ul>
<li>Coding in SQL directly gives you the opportunity to write very efficient code in a very compact way.</li>
<li>Using SQL effectively is a neglected skill by both professional software developers and by college curricula.</li>
<li>Because SQL is very compact, refactoring SQL tends to be wearisome and costly.</li>
<li>There's a large ""base of the pyramid"" of software developers who hate SQL with a passion and prefer to use layers of abstraction that mimic their preferred OO programming paradigm, even though these layers limit their effective use of SQL and result in slow, heavyweight applications.</li>
</ul>

<p>However, unlike assembly, SQL is a high-level, platform-independent language.  Also, there is no ANSI/ISO standard for assembly language.</p>
"
980,445950,1,0,sql,Is SQL the assembly for databases?,"<p>Talking about hibernate and others ORMs, the ORMs evangelists talk about SQL like the assembly language for Databases.</p>

<p>I think is soon to assert this, but I guess can be true on a near future, not sure.</p>

<p><strong>UPDATE:</strong> The analogy I was referring means <em>SQL</em> is to <em>assembly</em> what <em>ORM</em> is to <em>C/Java/C#</em>. Of course, an exact analogy is not possible. The question is if in the future, with more powerful computers the developers are going to use only <em>ORM</em> (or ORM like) instead of <em>SQL</em>.</p>
","<p>Let's compare writing parallelized SQL with writing parallelized assembler. </p>

<p>This the way to write a parallelized sql statement in Oracle:</p>

<pre><code>select /*+ parallel (e, 4)  */ deptno,count(*)
from employees e
group by deptno
</code></pre>

<p>Now I wish I could tell you how to write parallelized assembler but I strongly doubt it is as easy as adding something like <em>/</em>+ parallel (e,4) <em>/</em>. </p>
"
981,445950,0,0,sql,Is SQL the assembly for databases?,"<p>Talking about hibernate and others ORMs, the ORMs evangelists talk about SQL like the assembly language for Databases.</p>

<p>I think is soon to assert this, but I guess can be true on a near future, not sure.</p>

<p><strong>UPDATE:</strong> The analogy I was referring means <em>SQL</em> is to <em>assembly</em> what <em>ORM</em> is to <em>C/Java/C#</em>. Of course, an exact analogy is not possible. The question is if in the future, with more powerful computers the developers are going to use only <em>ORM</em> (or ORM like) instead of <em>SQL</em>.</p>
","<p>this will never happen.  SQL is really a dsl which assembler is decidedly not.  Mapping a relational db to an object model is useful but not the only purpose of dbs, that is there orms are a small part of what databases are used for, and therefore sql will always remain the dialect of choice for dealing with dbs!</p>
"
982,445950,0,0,sql,Is SQL the assembly for databases?,"<p>Talking about hibernate and others ORMs, the ORMs evangelists talk about SQL like the assembly language for Databases.</p>

<p>I think is soon to assert this, but I guess can be true on a near future, not sure.</p>

<p><strong>UPDATE:</strong> The analogy I was referring means <em>SQL</em> is to <em>assembly</em> what <em>ORM</em> is to <em>C/Java/C#</em>. Of course, an exact analogy is not possible. The question is if in the future, with more powerful computers the developers are going to use only <em>ORM</em> (or ORM like) instead of <em>SQL</em>.</p>
","<p>RPG is the assembly language of databases. :-)</p>
"
1033,483940,0,0,sql,Oracle9i: Filter Expression Fails to Exclude Data at Runtime,"<p>I have a relatively simple select statement in a VB6 program that I have to maintain. (Suppress your natural tendency to shudder; I inherited the thing, I didn't write it.)</p>

<p>The statement is straightforward (reformatted for clarity):</p>

<pre><code>select distinct 
   b.ip_address 
from 
   code_table a, 
   location b 
where 
   a.code_item = b.which_id and 
   a.location_type_code = '15' and 
   a.code_status = 'R'
</code></pre>

<p>The table in question returns a list of IP addresses from the database. The key column in question is <code>code_status</code>. Some time ago, we realized that one of the IP addresses was no longer valid, so we changed its status to <code>I</code> (invalid) to exclude it from appearing in the query's results.</p>

<p>When you execute the query above in SQL Plus, or in SQL Developer, everything is fine. But when you execute it from VB6, the check against <code>code_status</code> is ignored, and the invalid IP address appears in the result set.</p>

<p>My first guess was that the results were cached somewhere. But, not being an Oracle expert, I have no idea where to look. </p>

<p>This is <em>ancient</em> VB6 code. The SQL is embedded in the application. At the moment, I don't have time to rewrite it as a stored procedure. (I will some day, given the chance.) But, I need to know what would cause this disparity in behavior and how to eliminate it. If it's happening here, it's likely happening somewhere else.</p>

<p>If anyone can suggest a good place to look, I'd be very appreciative.</p>
","<p>There are Oracle bugs that result in incorrect answers. This surely isn't one of those times. Usually they involve some bizarre combination of views and functions and dblinks and lunar phases...</p>

<p>It's not cached anywhere. Oracle doesn't cache results until 11 and even then it knows to change the cache when the answer may change.</p>

<p>I would guess this is a data issue. You have a DISTINCT on the IP address in the query, why? If there's no unique constraint, there may be more than one copy of your IP address and you only fixed one of them.</p>

<p>And your Code_status is in a completely different table from your IP addresses. You set the status to ""I"" in the code table and you get the list of IPs from the Location table.</p>

<p>Stop thinking zebras and start thinking horses. This is almost certainly just data you do not fully understand. </p>

<p>Run this</p>

<pre><code>select 
   a.location_type_code, 
   a.code_status 
from 
   code_table a, 
   location b 
where 
   a.code_item = b.which_id and 
   b.ip_address = &lt;the one you think you fixed&gt;
</code></pre>

<p>I bet you get one row with an 'I' and another row with an 'R'</p>
"
1034,483940,0,0,sql,Oracle9i: Filter Expression Fails to Exclude Data at Runtime,"<p>I have a relatively simple select statement in a VB6 program that I have to maintain. (Suppress your natural tendency to shudder; I inherited the thing, I didn't write it.)</p>

<p>The statement is straightforward (reformatted for clarity):</p>

<pre><code>select distinct 
   b.ip_address 
from 
   code_table a, 
   location b 
where 
   a.code_item = b.which_id and 
   a.location_type_code = '15' and 
   a.code_status = 'R'
</code></pre>

<p>The table in question returns a list of IP addresses from the database. The key column in question is <code>code_status</code>. Some time ago, we realized that one of the IP addresses was no longer valid, so we changed its status to <code>I</code> (invalid) to exclude it from appearing in the query's results.</p>

<p>When you execute the query above in SQL Plus, or in SQL Developer, everything is fine. But when you execute it from VB6, the check against <code>code_status</code> is ignored, and the invalid IP address appears in the result set.</p>

<p>My first guess was that the results were cached somewhere. But, not being an Oracle expert, I have no idea where to look. </p>

<p>This is <em>ancient</em> VB6 code. The SQL is embedded in the application. At the moment, I don't have time to rewrite it as a stored procedure. (I will some day, given the chance.) But, I need to know what would cause this disparity in behavior and how to eliminate it. If it's happening here, it's likely happening somewhere else.</p>

<p>If anyone can suggest a good place to look, I'd be very appreciative.</p>
","<p>I'd suggest you have a look at the V$SQL system view to confirm that the query you believe the VB6 code is running is actually the query it is running.</p>

<p>Something along the lines of</p>

<pre><code>select sql_text, fetches
where sql_text like '%ip_address%'
</code></pre>

<p>Verify that the SQL_TEXT is the one you expect and that the FETCHES count goes up as you execute the code.</p>
"
721,327010,1,0,sql,"using a vector of column names, to generate a sql statement","<p>A problem that we need to solve regularly at my workplace is how to build sql statements based on user supplied table/column names.  The issue I am trying to address is the commas between column names.  </p>

<p>One technique looks something like this.</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    selectSql += "", ""; 
}

selectSql = selectSql(0, selectSql.len() - 2);

selectSql += ""FROM some-table"";
</code></pre>

<p>Another technique looks something like this</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    if (z &lt; columns.size() - 1) 
        selectSql += "", ""; 
}

selectSql += ""FROM some-table"";
</code></pre>

<p>I am not particularly enthralled by either of these implementations.</p>

<p>I am interesting in hearing ideas for other ways to address this issue, with an eye toward making the code easier to read/understand/maintain.</p>

<p>What alternate techniques are available?</p>
","<p>It doesn't have to be so complicated.</p>

<pre><code>string sql = ""SELECT "" + join(cols.begin(), cols.end(), "", "") + "" FROM some_table"";
</code></pre>

<p>where</p>

<pre><code>template &lt;typename I&gt;
string join(I begin, I end, const string&amp; sep){
   ostringstream out;
   for(; begin != end; ++begin){
      out &lt;&lt; *begin;
      if(begin+1 != end) out &lt;&lt; sep;
   }
   return out.str();
}
</code></pre>
"
722,327010,1,0,sql,"using a vector of column names, to generate a sql statement","<p>A problem that we need to solve regularly at my workplace is how to build sql statements based on user supplied table/column names.  The issue I am trying to address is the commas between column names.  </p>

<p>One technique looks something like this.</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    selectSql += "", ""; 
}

selectSql = selectSql(0, selectSql.len() - 2);

selectSql += ""FROM some-table"";
</code></pre>

<p>Another technique looks something like this</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    if (z &lt; columns.size() - 1) 
        selectSql += "", ""; 
}

selectSql += ""FROM some-table"";
</code></pre>

<p>I am not particularly enthralled by either of these implementations.</p>

<p>I am interesting in hearing ideas for other ways to address this issue, with an eye toward making the code easier to read/understand/maintain.</p>

<p>What alternate techniques are available?</p>
","<p>Not to belabor the point but take a look at boost::algorithm::join(). Here's an example in case you think that their documentation is too dense for words:</p>

<pre><code>std::string
build_sql(std::vector&lt;std::string&gt; const&amp; colNames,
          std::string const&amp; tableName)
{
    std::ostringstream sql;
    sql &lt;&lt; ""SELECT ""
        &lt;&lt; boost::algorithm::join(colNames, std::string("",""))
        &lt;&lt; "" FROM "" &lt;&lt; tableName;
    return sql.str();
}
</code></pre>

<p>When in doubt, look at Boost.org. They usually have a solution to most problems like this one already there.</p>
"
719,327010,2,0,sql,"using a vector of column names, to generate a sql statement","<p>A problem that we need to solve regularly at my workplace is how to build sql statements based on user supplied table/column names.  The issue I am trying to address is the commas between column names.  </p>

<p>One technique looks something like this.</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    selectSql += "", ""; 
}

selectSql = selectSql(0, selectSql.len() - 2);

selectSql += ""FROM some-table"";
</code></pre>

<p>Another technique looks something like this</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    if (z &lt; columns.size() - 1) 
        selectSql += "", ""; 
}

selectSql += ""FROM some-table"";
</code></pre>

<p>I am not particularly enthralled by either of these implementations.</p>

<p>I am interesting in hearing ideas for other ways to address this issue, with an eye toward making the code easier to read/understand/maintain.</p>

<p>What alternate techniques are available?</p>
","<p>We don't bother to remove the trailing comma.<br>
This is because you can select a constant and the SQL is still valid.</p>

<pre><code>SELECT A FROM T

-- Is the same as 

SELECT A,1 FROM T

-- Apart from there is an extra column named 1 where each value is 1
</code></pre>

<p>So using the STL to make it compact:</p>

<pre><code>#include &lt;sstream&gt;
#include &lt;iterator&gt;
#include &lt;algorithm&gt;

    std::stringstream           select;

    // Build select statement.
    select &lt;&lt; ""SELECT "";
    std::copy(col.begin(),col.end(),std::ostream_iterator&lt;std::string&gt;(select,"" , ""));
    select &lt;&lt; "" 1 FROM TABLE PLOP"";
</code></pre>
"
718,327010,5,0,sql,"using a vector of column names, to generate a sql statement","<p>A problem that we need to solve regularly at my workplace is how to build sql statements based on user supplied table/column names.  The issue I am trying to address is the commas between column names.  </p>

<p>One technique looks something like this.</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    selectSql += "", ""; 
}

selectSql = selectSql(0, selectSql.len() - 2);

selectSql += ""FROM some-table"";
</code></pre>

<p>Another technique looks something like this</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    if (z &lt; columns.size() - 1) 
        selectSql += "", ""; 
}

selectSql += ""FROM some-table"";
</code></pre>

<p>I am not particularly enthralled by either of these implementations.</p>

<p>I am interesting in hearing ideas for other ways to address this issue, with an eye toward making the code easier to read/understand/maintain.</p>

<p>What alternate techniques are available?</p>
","<p>In your case it is probably safe to assume that there is at least one column since otherwise there is no point in doing the select.  In that case you could do:</p>

<pre><code>selectSql  = ""SELECT "";
selectSql += columns[0]._name;

for (z = 1; z &lt; columns.size(); z++) {
   selectSql += "", "";
   selectSql += columns[z]._name;
}

selectSql += "" FROM some-table"";
</code></pre>
"
717,327010,0,0,sql,"using a vector of column names, to generate a sql statement","<p>A problem that we need to solve regularly at my workplace is how to build sql statements based on user supplied table/column names.  The issue I am trying to address is the commas between column names.  </p>

<p>One technique looks something like this.</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    selectSql += "", ""; 
}

selectSql = selectSql(0, selectSql.len() - 2);

selectSql += ""FROM some-table"";
</code></pre>

<p>Another technique looks something like this</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    if (z &lt; columns.size() - 1) 
        selectSql += "", ""; 
}

selectSql += ""FROM some-table"";
</code></pre>

<p>I am not particularly enthralled by either of these implementations.</p>

<p>I am interesting in hearing ideas for other ways to address this issue, with an eye toward making the code easier to read/understand/maintain.</p>

<p>What alternate techniques are available?</p>
","<pre><code>for (z = 0; z &lt; columns.size(); z++)
{
    if( z != 0 )
        selectSql += "", ""; 
    selectSql += columns[z]._name;
}
</code></pre>
"
716,327010,0,0,sql,"using a vector of column names, to generate a sql statement","<p>A problem that we need to solve regularly at my workplace is how to build sql statements based on user supplied table/column names.  The issue I am trying to address is the commas between column names.  </p>

<p>One technique looks something like this.</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    selectSql += "", ""; 
}

selectSql = selectSql(0, selectSql.len() - 2);

selectSql += ""FROM some-table"";
</code></pre>

<p>Another technique looks something like this</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    if (z &lt; columns.size() - 1) 
        selectSql += "", ""; 
}

selectSql += ""FROM some-table"";
</code></pre>

<p>I am not particularly enthralled by either of these implementations.</p>

<p>I am interesting in hearing ideas for other ways to address this issue, with an eye toward making the code easier to read/understand/maintain.</p>

<p>What alternate techniques are available?</p>
","<p>I would suggest building a generic join function to do this.  You can use the e.g. accumulate algorithm to join columns.</p>

<p>EDIT: <strong>See <a href=""http://stackoverflow.com/questions/327010/using-a-vector-of-column-names-to-generate-a-sql-statement#327862"">litb's implementation</a></strong>; it's much less nave.</p>

<pre><code>// Untested
#include &lt;numeric&gt;

template&lt;std::string separator&gt;
struct JoinColumns {
    std::string operator()(Column a, Column b) {
        return a._name + separator + b._name;
    }

    // Too lazy to come up with a better name
    std::string inArray(T array) {
        stl::accumulate(array.begin(), array.end(), std::string(), *this);
    }
};

selectSql += stl::accumulate(columns.begin(), columns.end(), std::string(), JoinColumns&lt;"", ""&gt;());
// or
selectSql += JoinColumns&lt;"", ""&gt;().inArray(columns);
</code></pre>

<p>You can get a cleaner syntax by using better wrappers, of course.</p>
"
706,319800,2,0,sql,"how to translate the SQL code ""having"" condition into LinqToSQL or LinqToEntites?","<p>Could you tell me how to translate the following SQL code to Linq To SQL or Linq To Entites?</p>

<p>The correct SQL code is: </p>

<blockquote>
  <p>select CollectId,url,userid,pubtime
  from Collect group by
  url,collectid,userid,pubtime  having
  pubtime >= (select max(pubtime) from
  collect d where d.url = collect.url  )
  order by Collect.pubtime desc</p>
</blockquote>

<p>The database table script is:</p>

<blockquote>
  <p>if exists (select * from sysobjects
  where id = OBJECT_ID('[Collect]') and
  OBJECTPROPERTY(id, 'IsUserTable') = 1)
  DROP TABLE [Collect]</p>
  
  <p>CREATE TABLE [Collect] ( [CollectId]
  [int]  IDENTITY (1, 1)  NOT NULL,
  [Url] [nvarchar]  (200) NULL, [UserId]
  [nvarchar]  (50) NULL, [PubTime]
  [datetime]  NULL)</p>
  
  <p>ALTER TABLE [Collect] WITH NOCHECK ADD
  CONSTRAINT [PK_Collect] PRIMARY KEY 
  NONCLUSTERED ( [CollectId] ) SET
  IDENTITY_INSERT [Collect] ON</p>
  
  <p>INSERT [Collect]
  ([CollectId],[Url],[UserId],[PubTime])
  VALUES (
  1,'www.sohu.com','Mike','2008-10-10
  0:00:00') INSERT [Collect]
  ([CollectId],[Url],[UserId],[PubTime])
  VALUES (
  2,'www.echina365.com','Lily','2008-10-15
  0:00:00') INSERT [Collect]
  ([CollectId],[Url],[UserId],[PubTime])
  VALUES (
  3,'www.php.com','Tom','2008-10-20
  0:00:00') INSERT [Collect]
  ([CollectId],[Url],[UserId],[PubTime])
  VALUES (
  4,'www.echina365.com','YaoMing','2008-10-23
  0:00:00') INSERT [Collect]
  ([CollectId],[Url],[UserId],[PubTime])
  VALUES (
  5,'www.echina365.com','Mike','2008-10-25
  0:00:00') INSERT [Collect]
  ([CollectId],[Url],[UserId],[PubTime])
  VALUES (
  6,'www.sohu.com','Jack','2008-10-26
  0:00:00') INSERT [Collect]
  ([CollectId],[Url],[UserId],[PubTime])
  VALUES (
  7,'www.echina365.com','Tracy','2008-11-2
  0:00:00') INSERT [Collect]
  ([CollectId],[Url],[UserId],[PubTime])
  VALUES (
  8,'www.php.com','YaoMing','2008-11-5
  0:00:00')</p>
  
  <p>SET IDENTITY_INSERT [Collect] OFF</p>
</blockquote>
","<p>Since your ""having"" condition isn't actually on an aggregated column, couldn't you just use the ""where"" clause?</p>

<pre><code>select distinct CollectId, url, userid, pubtime
from Collect
where pubtime &gt;= (select max(pubtime) from collect d where d.url = collect.url)
order by Collect.pubtime desc
</code></pre>

<p>This gets the same result given the dataset you've supplied. The LINQ statement then becomes reasonably simple:</p>

<pre><code>var rows = (from c in Collect
where c.PubTime &gt;= (
    from d in Collect
    where d.Url == c.Url
    select d.PubTime).Max()
orderby c.PubTime descending
select c).Distinct();
</code></pre>

<p>I could be misinterpreting your intent though. Perhaps my version of the query doesn't do exactly what you want. If so, leave me a comment and I'll delete the answer so as not to confuse the issue.</p>
"
701,309930,0,0,sql,SELECT with ORs including table joins,"<p>I've got a database with three tables: Books (with book details, PK is CopyID), Keywords (list of keywords, PK is ID) and KeywordsLink which is the many-many link table between Books and Keywords with the fields ID, BookID and KeywordID.</p>

<p>I'm trying to make an advanced search form in my app where you can search on various criteria. At the moment I have it working with Title, Author and Publisher (all from the Book table). It produces SQL like:</p>

<pre><code>SELECT * FROM Books WHERE Title Like '%Software%' OR Author LIKE '%Spolsky%';
</code></pre>

<p>I want to extend this search to also search using tags - basically to add another OR clause to search the tags. I've tried to do this by doing the following</p>

<pre><code>SELECT *
    FROM Books, Keywords, Keywordslink
    WHERE Title LIKE '%Joel%'
       OR (Name LIKE '%good%' AND BookID=Books.CopyID AND KeywordID=Keywords.ID)
</code></pre>

<p>I thought using the brackets might separate the 2nd part into its own kinda clause, so the join was only evaluated in that part - but it doesn't seem to be so. All it gives me is a long list of multiple copies of the one book that satisfies the <code>Title LIKE '%Joel%'</code> bit.</p>

<p>Is there a way of doing this using pure SQL, or would I have to use two SQL statements and combine them in my app (removing duplicates in the process).</p>

<p>I'm using MySQL at the moment if that matters, but the app uses ODBC and I'm hoping to make it DB agnostic (might even use SQLite eventually or have it so the user can choose what DB to use).</p>
","<p>It looks like Neil Barnwell has covered the answer that I would have given, but I'll add one thing...</p>

<p>Books can have more than one author. If your data model is really designed as your query implies you might want to consider changing it to accommodate that fact.</p>
"
700,309930,0,0,sql,SELECT with ORs including table joins,"<p>I've got a database with three tables: Books (with book details, PK is CopyID), Keywords (list of keywords, PK is ID) and KeywordsLink which is the many-many link table between Books and Keywords with the fields ID, BookID and KeywordID.</p>

<p>I'm trying to make an advanced search form in my app where you can search on various criteria. At the moment I have it working with Title, Author and Publisher (all from the Book table). It produces SQL like:</p>

<pre><code>SELECT * FROM Books WHERE Title Like '%Software%' OR Author LIKE '%Spolsky%';
</code></pre>

<p>I want to extend this search to also search using tags - basically to add another OR clause to search the tags. I've tried to do this by doing the following</p>

<pre><code>SELECT *
    FROM Books, Keywords, Keywordslink
    WHERE Title LIKE '%Joel%'
       OR (Name LIKE '%good%' AND BookID=Books.CopyID AND KeywordID=Keywords.ID)
</code></pre>

<p>I thought using the brackets might separate the 2nd part into its own kinda clause, so the join was only evaluated in that part - but it doesn't seem to be so. All it gives me is a long list of multiple copies of the one book that satisfies the <code>Title LIKE '%Joel%'</code> bit.</p>

<p>Is there a way of doing this using pure SQL, or would I have to use two SQL statements and combine them in my app (removing duplicates in the process).</p>

<p>I'm using MySQL at the moment if that matters, but the app uses ODBC and I'm hoping to make it DB agnostic (might even use SQLite eventually or have it so the user can choose what DB to use).</p>
","<p>I'm not aware of any way to accomplish a ""conditional join"" in SQL.  I think you'll be best served with executing the two statements separately and combining them in the application.  This approach is also more likely to stay DB-agnostic.</p>
"
699,309930,3,0,sql,SELECT with ORs including table joins,"<p>I've got a database with three tables: Books (with book details, PK is CopyID), Keywords (list of keywords, PK is ID) and KeywordsLink which is the many-many link table between Books and Keywords with the fields ID, BookID and KeywordID.</p>

<p>I'm trying to make an advanced search form in my app where you can search on various criteria. At the moment I have it working with Title, Author and Publisher (all from the Book table). It produces SQL like:</p>

<pre><code>SELECT * FROM Books WHERE Title Like '%Software%' OR Author LIKE '%Spolsky%';
</code></pre>

<p>I want to extend this search to also search using tags - basically to add another OR clause to search the tags. I've tried to do this by doing the following</p>

<pre><code>SELECT *
    FROM Books, Keywords, Keywordslink
    WHERE Title LIKE '%Joel%'
       OR (Name LIKE '%good%' AND BookID=Books.CopyID AND KeywordID=Keywords.ID)
</code></pre>

<p>I thought using the brackets might separate the 2nd part into its own kinda clause, so the join was only evaluated in that part - but it doesn't seem to be so. All it gives me is a long list of multiple copies of the one book that satisfies the <code>Title LIKE '%Joel%'</code> bit.</p>

<p>Is there a way of doing this using pure SQL, or would I have to use two SQL statements and combine them in my app (removing duplicates in the process).</p>

<p>I'm using MySQL at the moment if that matters, but the app uses ODBC and I'm hoping to make it DB agnostic (might even use SQLite eventually or have it so the user can choose what DB to use).</p>
","<p>Use <code>UNION</code>.</p>

<pre><code>(SELECT Books.* FROM &lt;first kind of search&gt;)
UNION
(SELECT Books.* FROM &lt;second kind of search&gt;)
</code></pre>

<p>The point is that you could write two (or more) simple and efficient queries instead of one complicated query that tries to do everything at once.</p>

<p>If number of resulting rows is low, then <code>UNION</code> will have very little overhead (and you can use faster <code>UNION ALL</code> if you don't have duplicates or don't care about them).</p>
"
698,309930,0,0,sql,SELECT with ORs including table joins,"<p>I've got a database with three tables: Books (with book details, PK is CopyID), Keywords (list of keywords, PK is ID) and KeywordsLink which is the many-many link table between Books and Keywords with the fields ID, BookID and KeywordID.</p>

<p>I'm trying to make an advanced search form in my app where you can search on various criteria. At the moment I have it working with Title, Author and Publisher (all from the Book table). It produces SQL like:</p>

<pre><code>SELECT * FROM Books WHERE Title Like '%Software%' OR Author LIKE '%Spolsky%';
</code></pre>

<p>I want to extend this search to also search using tags - basically to add another OR clause to search the tags. I've tried to do this by doing the following</p>

<pre><code>SELECT *
    FROM Books, Keywords, Keywordslink
    WHERE Title LIKE '%Joel%'
       OR (Name LIKE '%good%' AND BookID=Books.CopyID AND KeywordID=Keywords.ID)
</code></pre>

<p>I thought using the brackets might separate the 2nd part into its own kinda clause, so the join was only evaluated in that part - but it doesn't seem to be so. All it gives me is a long list of multiple copies of the one book that satisfies the <code>Title LIKE '%Joel%'</code> bit.</p>

<p>Is there a way of doing this using pure SQL, or would I have to use two SQL statements and combine them in my app (removing duplicates in the process).</p>

<p>I'm using MySQL at the moment if that matters, but the app uses ODBC and I'm hoping to make it DB agnostic (might even use SQLite eventually or have it so the user can choose what DB to use).</p>
","<p>You must also limit the product of the join by specifying something like</p>

<blockquote>
<pre>Books.FK1 = Keywords.FK1 and
Books.FK2 = Keywordslink.FK2 and
Keywords.FK3 = Keywordslink.FK3</pre>
</blockquote>

<p>But i don't know your exact data model so your solution may be slightly different.</p>
"
697,309930,3,0,sql,SELECT with ORs including table joins,"<p>I've got a database with three tables: Books (with book details, PK is CopyID), Keywords (list of keywords, PK is ID) and KeywordsLink which is the many-many link table between Books and Keywords with the fields ID, BookID and KeywordID.</p>

<p>I'm trying to make an advanced search form in my app where you can search on various criteria. At the moment I have it working with Title, Author and Publisher (all from the Book table). It produces SQL like:</p>

<pre><code>SELECT * FROM Books WHERE Title Like '%Software%' OR Author LIKE '%Spolsky%';
</code></pre>

<p>I want to extend this search to also search using tags - basically to add another OR clause to search the tags. I've tried to do this by doing the following</p>

<pre><code>SELECT *
    FROM Books, Keywords, Keywordslink
    WHERE Title LIKE '%Joel%'
       OR (Name LIKE '%good%' AND BookID=Books.CopyID AND KeywordID=Keywords.ID)
</code></pre>

<p>I thought using the brackets might separate the 2nd part into its own kinda clause, so the join was only evaluated in that part - but it doesn't seem to be so. All it gives me is a long list of multiple copies of the one book that satisfies the <code>Title LIKE '%Joel%'</code> bit.</p>

<p>Is there a way of doing this using pure SQL, or would I have to use two SQL statements and combine them in my app (removing duplicates in the process).</p>

<p>I'm using MySQL at the moment if that matters, but the app uses ODBC and I'm hoping to make it DB agnostic (might even use SQLite eventually or have it so the user can choose what DB to use).</p>
","<p>What you've done here is made a cartesian result set by having the tables joined with the commas but not having any join criteria.  Switch your statements to use outer join statements and that should allow you to reference the keywords.  I don't know your schema, but maybe something like this would work:</p>

<pre><code>SELECT 
  * 
FROM 
  Books 
  LEFT OUTER JOIN KeywordsLink ON KeywordsLink.BookID = Books.CopyID 
  LEFT OUTER JOIN Keywords ON Keywords.ID = KeywordsLink.KeywordID 
WHERE Books.Title LIKE '%JOEL%' 
      OR Keywords.Name LIKE '%GOOD%'
</code></pre>
"
1103,504920,0,0,sql,SQL tables subquery,"<p>I have two tables named <code>foo</code> and <code>bar</code>, hypothetically speaking.</p>

<p>foo has columns <code>foo_id</code>, <code>foo_fluff</code>
bar has columns <code>bar_id</code>, <code>foo_id</code>, <code>timestamp</code></p>

<p>I need a query which will retrieve return one row for any foo_id that the table bar contains, with the latest timestamp.</p>

<p>So, if bar has three rows, two of which have a foo_id of 1, and 1 of which has foo_id 2, it'll return 2 rows. For foo_id 1 it'll return the row which has the greater timestamp of the two rows.</p>
","<pre><code>SELECT timestamp FROM bar GROUP BY foo_id ORDER BY timestamp DESC
</code></pre>

<p>Just join the foo table on foo_id if you want to select the data from the foo table</p>
"
1104,504920,2,0,sql,SQL tables subquery,"<p>I have two tables named <code>foo</code> and <code>bar</code>, hypothetically speaking.</p>

<p>foo has columns <code>foo_id</code>, <code>foo_fluff</code>
bar has columns <code>bar_id</code>, <code>foo_id</code>, <code>timestamp</code></p>

<p>I need a query which will retrieve return one row for any foo_id that the table bar contains, with the latest timestamp.</p>

<p>So, if bar has three rows, two of which have a foo_id of 1, and 1 of which has foo_id 2, it'll return 2 rows. For foo_id 1 it'll return the row which has the greater timestamp of the two rows.</p>
","<p>I think this is what you are looking for (unless it must be a subquery and not a join)</p>

<pre><code>select max(bar.timestamp), foo.foo_fluff 
 from foo
 inner join bar
          on foo.foo_id = bar.foo_id
 group by foo.foo_fluff
</code></pre>
"
696,309930,7,0,sql,SELECT with ORs including table joins,"<p>I've got a database with three tables: Books (with book details, PK is CopyID), Keywords (list of keywords, PK is ID) and KeywordsLink which is the many-many link table between Books and Keywords with the fields ID, BookID and KeywordID.</p>

<p>I'm trying to make an advanced search form in my app where you can search on various criteria. At the moment I have it working with Title, Author and Publisher (all from the Book table). It produces SQL like:</p>

<pre><code>SELECT * FROM Books WHERE Title Like '%Software%' OR Author LIKE '%Spolsky%';
</code></pre>

<p>I want to extend this search to also search using tags - basically to add another OR clause to search the tags. I've tried to do this by doing the following</p>

<pre><code>SELECT *
    FROM Books, Keywords, Keywordslink
    WHERE Title LIKE '%Joel%'
       OR (Name LIKE '%good%' AND BookID=Books.CopyID AND KeywordID=Keywords.ID)
</code></pre>

<p>I thought using the brackets might separate the 2nd part into its own kinda clause, so the join was only evaluated in that part - but it doesn't seem to be so. All it gives me is a long list of multiple copies of the one book that satisfies the <code>Title LIKE '%Joel%'</code> bit.</p>

<p>Is there a way of doing this using pure SQL, or would I have to use two SQL statements and combine them in my app (removing duplicates in the process).</p>

<p>I'm using MySQL at the moment if that matters, but the app uses ODBC and I'm hoping to make it DB agnostic (might even use SQLite eventually or have it so the user can choose what DB to use).</p>
","<p>You need to join the 3 tables together, which gives you a tablular resultset.  You can then check any columns you like, and make sure you get <em>distinct</em> results (i.e. no duplicates).</p>

<p>Like this:</p>

<pre><code>select distinct b.*
from books b
left join keywordslink kl on kl.bookid = b.bookid
left join keywords k on kl.keywordid = k.keywordid
where b.title like '%assd%'
or k.keyword like '%asdsad%'
</code></pre>

<p>You should also try to avoid starting your LIKE values with a percent sign (%), as this means SQL Server can't use an index on that column and has to perform a full (and slow) table scan.  This starts to make your query into a ""starts with"" query.</p>

<p>Maybe consider the full-text search options in SQL Server, also.</p>
"
695,309930,1,0,sql,SELECT with ORs including table joins,"<p>I've got a database with three tables: Books (with book details, PK is CopyID), Keywords (list of keywords, PK is ID) and KeywordsLink which is the many-many link table between Books and Keywords with the fields ID, BookID and KeywordID.</p>

<p>I'm trying to make an advanced search form in my app where you can search on various criteria. At the moment I have it working with Title, Author and Publisher (all from the Book table). It produces SQL like:</p>

<pre><code>SELECT * FROM Books WHERE Title Like '%Software%' OR Author LIKE '%Spolsky%';
</code></pre>

<p>I want to extend this search to also search using tags - basically to add another OR clause to search the tags. I've tried to do this by doing the following</p>

<pre><code>SELECT *
    FROM Books, Keywords, Keywordslink
    WHERE Title LIKE '%Joel%'
       OR (Name LIKE '%good%' AND BookID=Books.CopyID AND KeywordID=Keywords.ID)
</code></pre>

<p>I thought using the brackets might separate the 2nd part into its own kinda clause, so the join was only evaluated in that part - but it doesn't seem to be so. All it gives me is a long list of multiple copies of the one book that satisfies the <code>Title LIKE '%Joel%'</code> bit.</p>

<p>Is there a way of doing this using pure SQL, or would I have to use two SQL statements and combine them in my app (removing duplicates in the process).</p>

<p>I'm using MySQL at the moment if that matters, but the app uses ODBC and I'm hoping to make it DB agnostic (might even use SQLite eventually or have it so the user can choose what DB to use).</p>
","<pre><code>SELECT * FROM books WHERE title LIKE'%Joel%' OR bookid IN 
         (SELECT bookid FROM keywordslink WHERE keywordid IN
         (SELECT id FROM keywords WHERE name LIKE '%good%'))
</code></pre>

<p>Beware that older versions of MySQL didn't like subselects.  I think they've fixed that.</p>
"
694,308650,0,0,sql,Select X Most Recent Non-Consecutive Days Worth of Data,"<p>Anyone got any insight as to select x number of non-consecutive days worth of data? Dates are standard sql datetime. So for example I'd like to select 5 most recent days worth of data, but there could be many days gap between records, so just selecting records from 5 days ago and more recent will not do.</p>
","<p>This should do it and be reasonably good from a performance standpoint. You didn't mention how to handle ties, so you can add the WITH TIES clause if you need to do that.</p>

<pre><code>SELECT TOP (@number_to_return)
     *   -- Write out your columns here
FROM
     dbo.MyTable
ORDER BY
     MyDateColumn DESC
</code></pre>
"
1108,506980,1,0,sql,MySQL sorting the result using a field of a different table,"<p>I have 3 tables of the following structure</p>

<pre><code>    products
    {
        pid
        pname
        plocation...
    }

    services
    {
        s_id
        s_name
        s_location...
    }

    txn
    {
        tid
        pid...
    }
</code></pre>

<p>I am using the following query to get the values I require.</p>

<pre><code>    $dbquery = ""SELECT DISTINCT products.pid AS id,
                   products.pname AS name,
                   products.p_desc AS description,
                   products.p_loc AS location,
                   products.category AS category,
                   products.p_uid AS userid,
                   products.add_date AS dateadded,
                   products.isaproduct AS whatisit
              FROM products
             WHERE products.pname
              LIKE '%"".$keyword.""%'
               AND category = '"".$refine_value.""'
             UNION
             SELECT DISTINCT services.s_id AS id,
                   services.s_name AS name,
                   services.s_desc AS description,
                   services.s_category AS category,
                   services.s_uid AS userid,
                   services.s_location AS location,
                   services.date_added AS dateadded,
                   services.isaservice AS whatisit
              FROM services
             WHERE services.s_name
              LIKE '%"".$keyword.""%'
               AND s_category = '"".$refine_value.""'
</code></pre>

<p>I need to order the values I select by getting the count of pid in txn table which I get in the query above.</p>

<p>How can I do this?</p>
","<p>First of all, use parameterized queries instead of building a query string like that. It bothers me.</p>

<p>But it looks like all you're really needing to do is to group by the pid column in the txn table.</p>

<p>Define a view like</p>

<pre><code>SELECT pid, COUNT(tid) tid_count
FROM txn
GROUP BY pid
</code></pre>

<p>And join it into your query, then order by tid_count.</p>
"
1109,511140,10,0,sql,MySQL - Need help to figure out multiple joins,"<p>I am using the following query to get the transactions from a table made to and from a user. I then want to retrieve the username for the sender_id and for the recipient_id. However I can only seem to get it for the recipient_id or the sender_id. Anyone have any ideas how I can get both.</p>

<pre><code>SELECT us.name, ta.amount, ta.recipient_id, ta.sender_id, ta.timestamp_insert
    	FROM  `transactions` AS ta
    	JOIN users AS us
    	ON ta.recipient_id=us.u_id
    	WHERE ta.sender_id =111111 OR ta.recipient_id = 111111
    	LIMIT 0 , 10
</code></pre>

<p><strong>Transactions Table Columns:</strong></p>

<p>transaction_id<br />
tw_id<br />
tw<br />
sender_id<br />
recipient_id<br />
amount<br />
timestamp_insert<br />
timestamp_start 
timestamp_complete
transaction_status</p>

<p><strong>User Table Columns:</strong></p>

<p>u_id, 
name</p>
","<p>You need to join twice, thus:</p>

<pre><code>SELECT ta.amount, ta.recipient_id, ta.sender_id, ta.timestamp_insert, sender.name as Sender, recipient.name as Recipient
        FROM  `transactions` AS ta
        JOIN users AS recipient
        ON ta.recipient_id=recipient.u_id
        JOIN users AS sender
        ON ta.sender_id=sender.u_id
        WHERE ta.sender_id =111111 OR ta.recipient_id = 111111
        LIMIT 0 , 10
</code></pre>
"
693,308650,1,0,sql,Select X Most Recent Non-Consecutive Days Worth of Data,"<p>Anyone got any insight as to select x number of non-consecutive days worth of data? Dates are standard sql datetime. So for example I'd like to select 5 most recent days worth of data, but there could be many days gap between records, so just selecting records from 5 days ago and more recent will not do.</p>
","<p>Following the approach <a href=""http://stackoverflow.com/questions/308650/select-x-most-recent-non-consecutive-days-worth-of-data#308670"">Tony Andrews</a> suggested, here is a way of doing it in T-SQL:</p>

<pre><code>SELECT
  Value,
  ValueDate
FROM
  Data
WHERE
  ValueDate &gt;= 
  (
    SELECT 
      CONVERT(DATETIME, MIN(TruncatedDate))
    FROM 
      (
         SELECT DISTINCT TOP 5 
           CONVERT(VARCHAR, ValueDate, 102) TruncatedDate
         FROM 
           Event
         ORDER BY 
           TruncatedDate DESC
      ) d
  )
ORDER BY
  ValueDate DESC
</code></pre>
"
692,308650,0,0,sql,Select X Most Recent Non-Consecutive Days Worth of Data,"<p>Anyone got any insight as to select x number of non-consecutive days worth of data? Dates are standard sql datetime. So for example I'd like to select 5 most recent days worth of data, but there could be many days gap between records, so just selecting records from 5 days ago and more recent will not do.</p>
","<p>I don't know the SQL Server syntax, but you need to:</p>

<p>1) Select the dates (with time component truncated) in descending order</p>

<p>2) Pick off top 5</p>

<p>3) Obtain 5th value</p>

<p>4) Select data where the datetime >= 5th value</p>

<p>Something like this ""pseudo-SQL"":</p>

<pre><code>select *
from data
where datetime &gt;=
( select top 1 date
  from
  ( select top 5 date from
    ( select truncated(datetime) as date
      from data
      order by truncated(datetime) desc
    )
    order by date
  )
)
</code></pre>
"
684,301060,0,0,sql,How to find recent sql update operations acting upon a certain table (SQL Server 2005),"<p>say I want to find the latest added rows (UPDATE by any user, not necessarily the one which is executing UPDATE)  in XX table.</p>
","<p><a href=""http://msdn.microsoft.com/en-us/library/ms187929.aspx"" rel=""nofollow"">SQL Server Profiler</a> will allow you to track hits to the database in real time.  You can set filters on a number of properties to ge the output you need.</p>
"
683,301060,2,0,sql,How to find recent sql update operations acting upon a certain table (SQL Server 2005),"<p>say I want to find the latest added rows (UPDATE by any user, not necessarily the one which is executing UPDATE)  in XX table.</p>
","<p>You would need to use a Transaction Log reader tool. There are several free ones available as well as commercial offerings.</p>

<ul>
<li><a href=""http://www.apexsql.com/sql_tools_log.asp"" rel=""nofollow"">ApexSQL Log</a> </li>
</ul>

<p>You could also try <a href=""http://www.mssqlcity.com/Articles/KnowHow/ViewLog.htm"" rel=""nofollow"">this</a> undocumented command:</p>

<pre><code> DBCC LOG(&lt;database name&gt;[,{0|1|2|3|4}]).
</code></pre>

<p>If you're using SQL Server 2000, RedGate have a free tool called <a href=""http://www.red-gate.com/products/SQL_Log_Rescue/index.htm"" rel=""nofollow"">SQL Log Rescue</a>.</p>

<p>EDIT:  Documentation for DBC LOG: 
<a href=""http://infocenter.sybase.com/help/index.jsp?topic=/com.sybase.39996_1250/html/svrtsg/svrtsg102.htm"" rel=""nofollow"">(1)</a> <a href=""http://www.mssqlcity.com/Articles/Undoc/SQL2000UndocDBCC.htm#part_2_8"" rel=""nofollow"">(2)</a></p>
"
682,301060,0,0,sql,How to find recent sql update operations acting upon a certain table (SQL Server 2005),"<p>say I want to find the latest added rows (UPDATE by any user, not necessarily the one which is executing UPDATE)  in XX table.</p>
","<p>Please refer to SQL Docs &amp; look for OUTPUT clause (that you can use with UPDATE/INSERT to get the affected records).</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ms177564.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms177564.aspx</a></p>
"
674,298580,1,0,sql,Subsonic Join issue,"<p>For those of you who are decent with subsonic!</p>

<pre><code>        TblNewsCollection col =
            new Select().From(Tables.TblNews)
                .InnerJoin(Tables.TblContent)
                .Paged(currentPage, pageSize)
                .OrderDesc(TblContent.Columns.PubDate)
                .ExecuteAsCollection&lt;TblNewsCollection&gt;();
</code></pre>

<p>The above works, no problem, but when I try to add a where clause</p>

<pre><code>        TblNewsCollection col =
            new Select().From(Tables.TblNews)
                .InnerJoin(Tables.TblContent)
                .Where(TblContent.Columns.UserFK)
                .IsEqualTo(guidUserFK)
                .Paged(currentPage, pageSize)
                .OrderDesc(TblContent.Columns.PubDate)
                .ExecuteAsCollection&lt;TblNewsCollection&gt;();
</code></pre>

<p>I get this message</p>

<pre><code>System.InvalidCastException: Object must implement IConvertible.
at System.Convert.ChangeType(Object value, Type conversionType, IFormatProvider provider)
at System.Data.SqlClient.SqlParameter.CoerceValue(Object value, MetaType destinationType) 
System.InvalidCastException: Failed to convert parameter value from a Guid to a String.
</code></pre>

<p>I've tried it from other fields, for example a bit field in a database it says it can't convert from bool to bit!</p>

<p>Seems to only be an issue on where statements after joins</p>
","<p>I found that joins work better using the TableColumnSchema as in the above Northwind example as opposed to the column name.</p>
"
720,327010,3,0,sql,"using a vector of column names, to generate a sql statement","<p>A problem that we need to solve regularly at my workplace is how to build sql statements based on user supplied table/column names.  The issue I am trying to address is the commas between column names.  </p>

<p>One technique looks something like this.</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    selectSql += "", ""; 
}

selectSql = selectSql(0, selectSql.len() - 2);

selectSql += ""FROM some-table"";
</code></pre>

<p>Another technique looks something like this</p>

<pre><code>selectSql  = ""SELECT "";

for (z = 0; z &lt; columns.size(); z++)
{
    selectSql += columns[z]._name;
    if (z &lt; columns.size() - 1) 
        selectSql += "", ""; 
}

selectSql += ""FROM some-table"";
</code></pre>

<p>I am not particularly enthralled by either of these implementations.</p>

<p>I am interesting in hearing ideas for other ways to address this issue, with an eye toward making the code easier to read/understand/maintain.</p>

<p>What alternate techniques are available?</p>
","<p>Rather than applying a work around each time again, you can fix the problem once and for all by writing a function object, and using that like strager proposed (though his implementation is rather not C++):</p>

<pre><code>struct join {
    std::string sep;
    join(std::string const&amp; sep): sep(sep) { }

    template&lt;typename Column&gt;
    std::string operator()(Column const&amp; a, Column const&amp; b) const {
        return a._name + sep + b._name;
    }
};
</code></pre>

<p>As i don't know your column type, i've left it templated. Now, whenever you want to build a query, just do </p>

<pre><code>std::string query = std::accumulate(cols.begin(), cols.end(), 
    std::string(""SELECT ""), join("", "")) + "" FROM some-table;"";
</code></pre>
"
1228,546410,1,0,sql,How to UNPIVOT to split columns into rows?,"<p>I've got a sql query (using MS-SQL 2005) that generates data with these columns:</p>

<pre><code>TimeStamp | SpeedMax | SpeedMin | HeightMax | HeightMin
-------------------------------------------------------
10        | 50       | 10       | 300       | 70
</code></pre>

<p>The form I need it in though is this:</p>

<pre><code>TimeStamp | Speed | Height
---------------------------
10        | 50    | 300          &lt;-- one row for the max values 
10        | 10    | 70           &lt;-- a second row for the min values
</code></pre>

<p>Given the first result set... what query would I need to get the data into the second format? I think it might involve an unpivot, but I'm new to that, and am having trouble working out what to write.</p>

<p>Thank you very much.</p>
","<p>Try</p>

<pre><code>SELECT TimeStamp, SpeedMax AS Speed, HeightMax AS Height
FROM Table
UNION ALL
SELECT TimeStamp, SpeedMin AS Speed, HeightMin AS Height
FROM Table
</code></pre>
"
806,354010,1,0,sql,How do I do a join in SQL based on table name?,"<p>Ok, so we have a bunch of tables that are named like this:</p>

<pre><code>training_data_001
training_data_002
training_data_003
training_data_004
training_data_005
</code></pre>

<p>And then to find those we look at a field in another table, let's just call it master.training_type.</p>

<p>Anyway, I was wondering if anyone knew of a way to do a weird table name based join with this kind of data.  Something like this:</p>

<pre><code>SELECT foo FROM master WHERE id = ? 
INNER JOIN training_data_${master.training_type}
ON foo.id = training_data_${master.training_type}.foo_id
</code></pre>

<p>I know that I can do this on the client side, but it would be nice to have the db do it.</p>

<p>Also note: it's SQL Server.</p>

<p><strong>Update</strong>: I decided to just do it on the client side.  Thanks anyway everyone.</p>

<p>Thanks!</p>

<p>-fREW</p>
","<p>If the tables are all the same structure, create a <a href=""http://msdn.microsoft.com/en-us/library/aa933141(SQL.80).aspx"" rel=""nofollow"">Partitioned View</a> across the tables and join against the view.  You need to make a check constraint on a column (perhaps a date) so that the query optimiser can do partition elimination.</p>
"
804,354010,2,0,sql,How do I do a join in SQL based on table name?,"<p>Ok, so we have a bunch of tables that are named like this:</p>

<pre><code>training_data_001
training_data_002
training_data_003
training_data_004
training_data_005
</code></pre>

<p>And then to find those we look at a field in another table, let's just call it master.training_type.</p>

<p>Anyway, I was wondering if anyone knew of a way to do a weird table name based join with this kind of data.  Something like this:</p>

<pre><code>SELECT foo FROM master WHERE id = ? 
INNER JOIN training_data_${master.training_type}
ON foo.id = training_data_${master.training_type}.foo_id
</code></pre>

<p>I know that I can do this on the client side, but it would be nice to have the db do it.</p>

<p>Also note: it's SQL Server.</p>

<p><strong>Update</strong>: I decided to just do it on the client side.  Thanks anyway everyone.</p>

<p>Thanks!</p>

<p>-fREW</p>
","<p>You can only use dynamic SQL to read master.training_type to build a string that you then execute using <code>EXEC (@stringvar)</code></p>
"
817,355560,0,0,sql,How to sort the data in alphanumeric values,"<p>I have these values: <code>d1, d45, d79, d33, d100</code></p>

<p>I want to sort these variables in ascending order from my table.</p>

<p>What is the query to get the output as:</p>

<pre><code>d1
d33
d45
d79
d100
</code></pre>
","<p>If we can assume that the data values only contain the letter d and a numeric value, then you can also use:</p>

<pre><code>select column from YourTable
order by convert(int, replace(column, 'd', ''))
</code></pre>

<p>If it contains any other letters, then this method rapidly becomes unusable:</p>

<pre><code>select column from YourTable
order by convert(int, 
    	replace(replace(replace(replace(replace(
    		column, 'a', ''),
    			'b', ''),
    			'c', ''),
    			'd', ''), 
    			'e', '')
    	)
</code></pre>
"
816,355560,0,0,sql,How to sort the data in alphanumeric values,"<p>I have these values: <code>d1, d45, d79, d33, d100</code></p>

<p>I want to sort these variables in ascending order from my table.</p>

<p>What is the query to get the output as:</p>

<pre><code>d1
d33
d45
d79
d100
</code></pre>
","<p>If you can guarantee a pattern of /\w\d+/ ...</p>

<p>In postgres: </p>

<pre><code>select foo from bar order by cast(substring(foo from 2) as int)
</code></pre>

<p>..and similar will exist for other SQL flavours. Expensive mind.</p>

<p>edit: androids solution looks good too:</p>

<pre><code>..order by char_length(foo),foo
</code></pre>
"
815,355560,1,0,sql,How to sort the data in alphanumeric values,"<p>I have these values: <code>d1, d45, d79, d33, d100</code></p>

<p>I want to sort these variables in ascending order from my table.</p>

<p>What is the query to get the output as:</p>

<pre><code>d1
d33
d45
d79
d100
</code></pre>
","<p>What you want is called a ""natural sort"". For Microsoft SQL Server 2005, see <a href=""http://stackoverflow.com/questions/34509/natural-human-alpha-numeric-sort-in-microsoft-sql-2005"">this question</a>. For other languages, see (for example) <a href=""http://stackoverflow.com/questions/127913/sorting-strings-is-much-harder-than-you-thought"">this other question</a>.</p>
"
814,355560,0,0,sql,How to sort the data in alphanumeric values,"<p>I have these values: <code>d1, d45, d79, d33, d100</code></p>

<p>I want to sort these variables in ascending order from my table.</p>

<p>What is the query to get the output as:</p>

<pre><code>d1
d33
d45
d79
d100
</code></pre>
","<p>Sorry, not SQL answer at all. :) For variant with one letter only order by length and alpha.</p>
"
808,354010,1,0,sql,How do I do a join in SQL based on table name?,"<p>Ok, so we have a bunch of tables that are named like this:</p>

<pre><code>training_data_001
training_data_002
training_data_003
training_data_004
training_data_005
</code></pre>

<p>And then to find those we look at a field in another table, let's just call it master.training_type.</p>

<p>Anyway, I was wondering if anyone knew of a way to do a weird table name based join with this kind of data.  Something like this:</p>

<pre><code>SELECT foo FROM master WHERE id = ? 
INNER JOIN training_data_${master.training_type}
ON foo.id = training_data_${master.training_type}.foo_id
</code></pre>

<p>I know that I can do this on the client side, but it would be nice to have the db do it.</p>

<p>Also note: it's SQL Server.</p>

<p><strong>Update</strong>: I decided to just do it on the client side.  Thanks anyway everyone.</p>

<p>Thanks!</p>

<p>-fREW</p>
","<p>The partitioned view is one possible approach. Since you are only selecting the foo column, are you really just checking for existence of a row in the training table via the INNER JOIN? Also, it looks like you're trying to use foo as an alias in your join, but it's not set up that way in your SELECT clause. As a result I'm guessing here on what you really want.</p>

<p>Another question... is the set of training tables static? Are you expecting to be able to add a new table with a new suffix number and have it just work?</p>

<p>Another possible solution:</p>

<pre><code>SELECT
     foo
FROM
     dbo.master m
WHERE
     (training_type = '001' AND EXISTS (SELECT * FROM dbo.training_data_001 WHERE foo_id = m.id)) OR
     (training_type = '002' AND EXISTS (SELECT * FROM dbo.training_data_002 WHERE foo_id = m.id)) OR
     (training_type = '003' AND EXISTS (SELECT * FROM dbo.training_data_003 WHERE foo_id = m.id)) OR
     (training_type = '004' AND EXISTS (SELECT * FROM dbo.training_data_004 WHERE foo_id = m.id)) OR
     (training_type = '005' AND EXISTS (SELECT * FROM dbo.training_data_005 WHERE foo_id = m.id))
</code></pre>

<p>If you actually want to return columns from the training data tables then you could use something like:</p>

<pre><code>SELECT
     m.id,
     COALESCE(t1.my_col, t2.my_col, t3.my_col, t4.my_col, t5.my_col) AS my_col
FROM
     dbo.master m
LEFT OUTER JOIN dbo.training_data_001 t1 ON m.training_type = '001' AND t1.foo_id = m.id
LEFT OUTER JOIN dbo.training_data_002 t1 ON m.training_type = '002' AND t2.foo_id = m.id
LEFT OUTER JOIN dbo.training_data_003 t1 ON m.training_type = '003' AND t3.foo_id = m.id
LEFT OUTER JOIN dbo.training_data_004 t1 ON m.training_type = '004' AND t4.foo_id = m.id
LEFT OUTER JOIN dbo.training_data_005 t1 ON m.training_type = '005' AND t5.foo_id = m.id
</code></pre>
"
807,354010,1,0,sql,How do I do a join in SQL based on table name?,"<p>Ok, so we have a bunch of tables that are named like this:</p>

<pre><code>training_data_001
training_data_002
training_data_003
training_data_004
training_data_005
</code></pre>

<p>And then to find those we look at a field in another table, let's just call it master.training_type.</p>

<p>Anyway, I was wondering if anyone knew of a way to do a weird table name based join with this kind of data.  Something like this:</p>

<pre><code>SELECT foo FROM master WHERE id = ? 
INNER JOIN training_data_${master.training_type}
ON foo.id = training_data_${master.training_type}.foo_id
</code></pre>

<p>I know that I can do this on the client side, but it would be nice to have the db do it.</p>

<p>Also note: it's SQL Server.</p>

<p><strong>Update</strong>: I decided to just do it on the client side.  Thanks anyway everyone.</p>

<p>Thanks!</p>

<p>-fREW</p>
","<p>do something like this:</p>

<pre><code>create view training_data_all as
select '001' as training_type, * from training_data_001
union all
select '002' as training_type, * from training_data_002
union all
select '003' as training_type, * from training_data_003
union all
select '004' as training_type, * from training_data_004
union all
select '005' as training_type, * from training_data_005
</code></pre>

<p>then just select and join to/from it:</p>

<pre><code>SELECT foo FROM master WHERE id = ? 
INNER JOIN training_data_all
ON foo.id = training_data_all.foo_id
WHERE training_data_all.training_type = ${master.training_type}
</code></pre>

<p>If the table list is to grow/shrink over time, you can write this same view dynamically based on the tables that exists by doing some lookups into the system tables.  </p>

<p>None of this is very efficient though.  Can you just ETL this data into a combined table at some fixed interval?</p>
"
727,337240,1,0,sql,Why is Visual Studio's table adapter query not returning the same data as the stored procedure it represents?,"<p>I'm using a table adapter in Visual Studio to make a query to a stored procedure in my SQL Server 2005 database.  When I make the call via my website application it returns nothing.  When I make the same call via SQL Server Manager it returns the expected data.</p>

<p>I put a breakpoint on the call to the adapter's <code>getData</code> method and looked at all the parameters and their values and matched them in a query from server management to make sure.  I'm sending the following query:</p>

<pre><code>getData(string, date, date, int, int?, int?, string, int?, string)
</code></pre>

<p>further</p>

<pre><code>getData('0000-rtg', '1/1/2007', '3/12/2008', 0, null, null, null, null, null)
</code></pre>

<p>I guess I'm wondering if Visual Studio does something with the <code>null</code>'s before it tries to send the query to the SQL server.  If not, how do I fix this problem?</p>

<p>EDIT:
All these values are passed by variables, I just typed what was in those variables at that break point.  </p>
","<p>Dates need to have quotes around them in SQL else they don't work.  </p>
"
805,354010,1,0,sql,How do I do a join in SQL based on table name?,"<p>Ok, so we have a bunch of tables that are named like this:</p>

<pre><code>training_data_001
training_data_002
training_data_003
training_data_004
training_data_005
</code></pre>

<p>And then to find those we look at a field in another table, let's just call it master.training_type.</p>

<p>Anyway, I was wondering if anyone knew of a way to do a weird table name based join with this kind of data.  Something like this:</p>

<pre><code>SELECT foo FROM master WHERE id = ? 
INNER JOIN training_data_${master.training_type}
ON foo.id = training_data_${master.training_type}.foo_id
</code></pre>

<p>I know that I can do this on the client side, but it would be nice to have the db do it.</p>

<p>Also note: it's SQL Server.</p>

<p><strong>Update</strong>: I decided to just do it on the client side.  Thanks anyway everyone.</p>

<p>Thanks!</p>

<p>-fREW</p>
","<p>You can only do it with dynamic SQL in a stored proc.  You can also generate views or stored procs in advance with code generation if you don't want to do it on the fly for security or other reasons.</p>
"
1057,489140,0,0,sql,SQL Logical AND operator for bit fields,"<p>I have 2 tables that have a many to many relationship; An Individual can belong to many Groups.  A Group can have many Individuals.  </p>

<p>Individuals basically just have their Primary Key ID</p>

<p>Groups have a Primary Key ID, IndividualID (same as the ID in the Individual Table), and a bit flag for if that group is the primary group for the individual</p>

<p>In theory, all but one of the entries for any given individual in the group table should have that bit flag set to false, because every individual must have exactly 1 primary group.</p>

<p>I know that for my current dataset, this assumption doesn't hold true, and I have some individuals that have the primary flag for ALL their groups set to false.</p>

<p>I'm having trouble generating a query that will return those individuals to me.</p>

<p>The closest I've gotten is:</p>

<p>SELECT * FROM Individual i 
LEFT JOIN Group g ON g.IndividualID = i.ID
      WHERE g.IsPrimaryGroup = 0</p>

<p>but going further than that with SUM or MAX doesn't work, because the field is a bit field, and not a numeric.  </p>

<p>Any suggestions?</p>
","<p>You need to include the IsPrimaryGroup condition into the JOIN clause. This query finds all individuals with no PrimaryGroup set:</p>

<pre><code>SELECT * FROM Individual i
LEFT OUTER JOIN Group g ON g.IndividualID = i.ID AND g.IsPrimaryGroup = 1
WHERE g.ID IS NULL
</code></pre>

<p>However, the ideal way to solve your problem (in terms of relational db) is to have a PrimaryGroupID in the Individual table.</p>
"
1058,489140,1,0,sql,SQL Logical AND operator for bit fields,"<p>I have 2 tables that have a many to many relationship; An Individual can belong to many Groups.  A Group can have many Individuals.  </p>

<p>Individuals basically just have their Primary Key ID</p>

<p>Groups have a Primary Key ID, IndividualID (same as the ID in the Individual Table), and a bit flag for if that group is the primary group for the individual</p>

<p>In theory, all but one of the entries for any given individual in the group table should have that bit flag set to false, because every individual must have exactly 1 primary group.</p>

<p>I know that for my current dataset, this assumption doesn't hold true, and I have some individuals that have the primary flag for ALL their groups set to false.</p>

<p>I'm having trouble generating a query that will return those individuals to me.</p>

<p>The closest I've gotten is:</p>

<p>SELECT * FROM Individual i 
LEFT JOIN Group g ON g.IndividualID = i.ID
      WHERE g.IsPrimaryGroup = 0</p>

<p>but going further than that with SUM or MAX doesn't work, because the field is a bit field, and not a numeric.  </p>

<p>Any suggestions?</p>
","<p>Don't know your data...but....that LEFT JOIN is an INNER JOIN</p>

<p>what happens when you change the WHERE to AND</p>

<pre><code>SELECT * FROM Individual i 
LEFT JOIN Group g ON g.IndividualID = i.ID 
AND g.IsPrimaryGroup = 0
</code></pre>

<p>Here try running this....untested of course since you didn't provide any ample data</p>

<pre><code>SELECT SUM(convert(int,g.IsPrimaryGroup)), i.ID 
FROM Individual i 
LEFT JOIN [Group] g ON g.IndividualID = i.ID 
AND g.IsPrimaryGroup = 0
GROUP BY i.ID
HAVING COUNT(*) &gt; 1
</code></pre>
"
1059,489140,1,0,sql,SQL Logical AND operator for bit fields,"<p>I have 2 tables that have a many to many relationship; An Individual can belong to many Groups.  A Group can have many Individuals.  </p>

<p>Individuals basically just have their Primary Key ID</p>

<p>Groups have a Primary Key ID, IndividualID (same as the ID in the Individual Table), and a bit flag for if that group is the primary group for the individual</p>

<p>In theory, all but one of the entries for any given individual in the group table should have that bit flag set to false, because every individual must have exactly 1 primary group.</p>

<p>I know that for my current dataset, this assumption doesn't hold true, and I have some individuals that have the primary flag for ALL their groups set to false.</p>

<p>I'm having trouble generating a query that will return those individuals to me.</p>

<p>The closest I've gotten is:</p>

<p>SELECT * FROM Individual i 
LEFT JOIN Group g ON g.IndividualID = i.ID
      WHERE g.IsPrimaryGroup = 0</p>

<p>but going further than that with SUM or MAX doesn't work, because the field is a bit field, and not a numeric.  </p>

<p>Any suggestions?</p>
","<p>Try not using a bit field if you need to do SUM and MAX - use a TINYINT instead. In addition, from what I remember bit fields can not be indexed, so you will loose some performance in your joins.</p>
"
1060,489140,1,0,sql,SQL Logical AND operator for bit fields,"<p>I have 2 tables that have a many to many relationship; An Individual can belong to many Groups.  A Group can have many Individuals.  </p>

<p>Individuals basically just have their Primary Key ID</p>

<p>Groups have a Primary Key ID, IndividualID (same as the ID in the Individual Table), and a bit flag for if that group is the primary group for the individual</p>

<p>In theory, all but one of the entries for any given individual in the group table should have that bit flag set to false, because every individual must have exactly 1 primary group.</p>

<p>I know that for my current dataset, this assumption doesn't hold true, and I have some individuals that have the primary flag for ALL their groups set to false.</p>

<p>I'm having trouble generating a query that will return those individuals to me.</p>

<p>The closest I've gotten is:</p>

<p>SELECT * FROM Individual i 
LEFT JOIN Group g ON g.IndividualID = i.ID
      WHERE g.IsPrimaryGroup = 0</p>

<p>but going further than that with SUM or MAX doesn't work, because the field is a bit field, and not a numeric.  </p>

<p>Any suggestions?</p>
","<p>Update: Got it working with a subselect.  Select IndividualID from Group where the primary group is false, and individualID NOT IN (select IndividualID from Group where primary group is true)</p>
"
1061,489140,0,0,sql,SQL Logical AND operator for bit fields,"<p>I have 2 tables that have a many to many relationship; An Individual can belong to many Groups.  A Group can have many Individuals.  </p>

<p>Individuals basically just have their Primary Key ID</p>

<p>Groups have a Primary Key ID, IndividualID (same as the ID in the Individual Table), and a bit flag for if that group is the primary group for the individual</p>

<p>In theory, all but one of the entries for any given individual in the group table should have that bit flag set to false, because every individual must have exactly 1 primary group.</p>

<p>I know that for my current dataset, this assumption doesn't hold true, and I have some individuals that have the primary flag for ALL their groups set to false.</p>

<p>I'm having trouble generating a query that will return those individuals to me.</p>

<p>The closest I've gotten is:</p>

<p>SELECT * FROM Individual i 
LEFT JOIN Group g ON g.IndividualID = i.ID
      WHERE g.IsPrimaryGroup = 0</p>

<p>but going further than that with SUM or MAX doesn't work, because the field is a bit field, and not a numeric.  </p>

<p>Any suggestions?</p>
","<pre><code>SELECT COUNT(bitflag),individualId 
FROM Groups
WHERE bitflag = 1
GROUP BY individualId
ORDER BY SUM(bitFlag)
HAVING COUNT(bitFlag) &lt;&gt; 1
</code></pre>

<p>That will give you each individual and how many primary groups they have</p>
"
1062,489140,0,0,sql,SQL Logical AND operator for bit fields,"<p>I have 2 tables that have a many to many relationship; An Individual can belong to many Groups.  A Group can have many Individuals.  </p>

<p>Individuals basically just have their Primary Key ID</p>

<p>Groups have a Primary Key ID, IndividualID (same as the ID in the Individual Table), and a bit flag for if that group is the primary group for the individual</p>

<p>In theory, all but one of the entries for any given individual in the group table should have that bit flag set to false, because every individual must have exactly 1 primary group.</p>

<p>I know that for my current dataset, this assumption doesn't hold true, and I have some individuals that have the primary flag for ALL their groups set to false.</p>

<p>I'm having trouble generating a query that will return those individuals to me.</p>

<p>The closest I've gotten is:</p>

<p>SELECT * FROM Individual i 
LEFT JOIN Group g ON g.IndividualID = i.ID
      WHERE g.IsPrimaryGroup = 0</p>

<p>but going further than that with SUM or MAX doesn't work, because the field is a bit field, and not a numeric.  </p>

<p>Any suggestions?</p>
","<p>I don't know if this is optimal from a performance standpoint, but I believe something along these lines should work.  I'm using OrgIndividual as the name of the resolution table between the Individal and the Group.<br/><br/>SELECT DISTINCT(i.IndividualID)<br/>
FROM<br/>
&nbsp;&nbsp;Individual i INNER JOIN OrgIndividual oi<br/>
&nbsp;&nbsp;&nbsp;&nbsp;ON i.IndividualID = oi.IndividualID AND oi.PrimaryOrg = 0<br/>
&nbsp;&nbsp;LEFT JOIN OrgIndividual oip<br/>
&nbsp;&nbsp;&nbsp;&nbsp;ON oi.IndividualID = oip.IndividualID AND oi.PrimaryOrg = 1<br/>
WHERE<br/>
&nbsp;&nbsp;oi2.IndividualID IS NULL</p>
"
1063,489140,0,0,sql,SQL Logical AND operator for bit fields,"<p>I have 2 tables that have a many to many relationship; An Individual can belong to many Groups.  A Group can have many Individuals.  </p>

<p>Individuals basically just have their Primary Key ID</p>

<p>Groups have a Primary Key ID, IndividualID (same as the ID in the Individual Table), and a bit flag for if that group is the primary group for the individual</p>

<p>In theory, all but one of the entries for any given individual in the group table should have that bit flag set to false, because every individual must have exactly 1 primary group.</p>

<p>I know that for my current dataset, this assumption doesn't hold true, and I have some individuals that have the primary flag for ALL their groups set to false.</p>

<p>I'm having trouble generating a query that will return those individuals to me.</p>

<p>The closest I've gotten is:</p>

<p>SELECT * FROM Individual i 
LEFT JOIN Group g ON g.IndividualID = i.ID
      WHERE g.IsPrimaryGroup = 0</p>

<p>but going further than that with SUM or MAX doesn't work, because the field is a bit field, and not a numeric.  </p>

<p>Any suggestions?</p>
","<pre><code>SELECT IndividualID
FROM Group g
WHERE NOT EXISTS (
    SELECT NULL FROM Group
    WHERE PrimaryOrg = 1
    AND IndividualID = g.IndividualID)
GROUP BY IndividualID
</code></pre>
"
728,337240,1,0,sql,Why is Visual Studio's table adapter query not returning the same data as the stored procedure it represents?,"<p>I'm using a table adapter in Visual Studio to make a query to a stored procedure in my SQL Server 2005 database.  When I make the call via my website application it returns nothing.  When I make the same call via SQL Server Manager it returns the expected data.</p>

<p>I put a breakpoint on the call to the adapter's <code>getData</code> method and looked at all the parameters and their values and matched them in a query from server management to make sure.  I'm sending the following query:</p>

<pre><code>getData(string, date, date, int, int?, int?, string, int?, string)
</code></pre>

<p>further</p>

<pre><code>getData('0000-rtg', '1/1/2007', '3/12/2008', 0, null, null, null, null, null)
</code></pre>

<p>I guess I'm wondering if Visual Studio does something with the <code>null</code>'s before it tries to send the query to the SQL server.  If not, how do I fix this problem?</p>

<p>EDIT:
All these values are passed by variables, I just typed what was in those variables at that break point.  </p>
","<p>Use Sql Profiler to see how the sql sent to sql server actually looks like. This has helped me many times.</p>
"
1042,485340,0,-1,sql,Highest Performance Database Storage Mechanism,"<p>I need ideas to implement a (really) high performance in-memory Database/Storage Mechanism. In the range of storing 20,000+ objects, with each object updated every 5 or so seconds.  <strong>I would like a FOSS solution</strong>.</p>

<p>What is my best option? What are your experiences?</p>

<p>I am working primarily in Java, but I need the datastore to have good performance so the datastore solution need not be java centric.</p>

<p>I also need like to be able to Query these objects and I need to be able to restore all of the objects on program startup.</p>
","<p>What level of durability do you need? 20,000 updates every 5 seconds will probably be difficult for most IO hardware in terms of number of transactions if you write the data back to disc for every one.</p>

<p>If you can afford to lose some updates, you could probably flush it to disc every 100ms with no problem with fairly cheap hardware if your database and OS support doing that.</p>

<p>If it's really an in-memory database that you don't want to flush to disc often, that sounds pretty trivial. I've heard that H2 is pretty good, but SQLite may work as well. A properly tuned MySQL instance could also do it (But may be more convoluted)</p>
"
1040,485340,1,-1,sql,Highest Performance Database Storage Mechanism,"<p>I need ideas to implement a (really) high performance in-memory Database/Storage Mechanism. In the range of storing 20,000+ objects, with each object updated every 5 or so seconds.  <strong>I would like a FOSS solution</strong>.</p>

<p>What is my best option? What are your experiences?</p>

<p>I am working primarily in Java, but I need the datastore to have good performance so the datastore solution need not be java centric.</p>

<p>I also need like to be able to Query these objects and I need to be able to restore all of the objects on program startup.</p>
","<p>An in-memory storage ?</p>

<p>1) a simple C 'malloc' array where all your structures would be indexed.</p>

<p>2) berkeleyDB: <a href=""http://www.oracle.com/technology/products/berkeley-db/index.html"" rel=""nofollow"">http://www.oracle.com/technology/products/berkeley-db/index.html</a>. It is fast because you build your own indexes (secondary database) and there is no SQL expression to be evaluated.</p>
"
1039,485340,1,-1,sql,Highest Performance Database Storage Mechanism,"<p>I need ideas to implement a (really) high performance in-memory Database/Storage Mechanism. In the range of storing 20,000+ objects, with each object updated every 5 or so seconds.  <strong>I would like a FOSS solution</strong>.</p>

<p>What is my best option? What are your experiences?</p>

<p>I am working primarily in Java, but I need the datastore to have good performance so the datastore solution need not be java centric.</p>

<p>I also need like to be able to Query these objects and I need to be able to restore all of the objects on program startup.</p>
","<p>Depends exactly how you need to query it, but have you looked into memcached?</p>

<p><a href=""http://www.danga.com/memcached/"" rel=""nofollow"">http://www.danga.com/memcached/</a></p>

<p>Other options could include <a href=""http://dev.mysql.com/doc/refman/5.0/en/memory-storage-engine.html"" rel=""nofollow"">MySQL MEMORY Tables</a>, the <a href=""http://php.net/manual/en/function.apc-add.php"" rel=""nofollow"">APC Cache</a> if you're using PHP.</p>

<p>Some more detail about the project/requirements would be helpful.</p>
"
1041,485340,3,-1,sql,Highest Performance Database Storage Mechanism,"<p>I need ideas to implement a (really) high performance in-memory Database/Storage Mechanism. In the range of storing 20,000+ objects, with each object updated every 5 or so seconds.  <strong>I would like a FOSS solution</strong>.</p>

<p>What is my best option? What are your experiences?</p>

<p>I am working primarily in Java, but I need the datastore to have good performance so the datastore solution need not be java centric.</p>

<p>I also need like to be able to Query these objects and I need to be able to restore all of the objects on program startup.</p>
","<p><a href=""http://sqlite.org/"" rel=""nofollow"">SQLite</a> is an open-source self-contained database that supports in-memory databases (just connect to <code>:memory:</code>). It has bindings for many popular programming languages.  It's a traditional SQL-based relational database, but you don't run a separate server  just use it as a library in your program.  It's pretty quick.  Whether it's quick enough, I don't know, but it may be worth an experiment.</p>

<p><a href=""http://www.zentus.com/sqlitejdbc/"" rel=""nofollow"">Java driver</a>.</p>
"
1038,485340,1,-1,sql,Highest Performance Database Storage Mechanism,"<p>I need ideas to implement a (really) high performance in-memory Database/Storage Mechanism. In the range of storing 20,000+ objects, with each object updated every 5 or so seconds.  <strong>I would like a FOSS solution</strong>.</p>

<p>What is my best option? What are your experiences?</p>

<p>I am working primarily in Java, but I need the datastore to have good performance so the datastore solution need not be java centric.</p>

<p>I also need like to be able to Query these objects and I need to be able to restore all of the objects on program startup.</p>
","<p>Check out <a href=""http://hsqldb.org/"" rel=""nofollow"">HSQLDB</a> and <a href=""http://www.prevayler.org/"" rel=""nofollow"">Prevayler</a>.  Prevayler is a paradigm shift from traditional RDBMS - one which I have used (the paradigm, that is, not specifically Prevayler) in a number of projects and found it to have real merit.</p>
"
1043,485340,0,-1,sql,Highest Performance Database Storage Mechanism,"<p>I need ideas to implement a (really) high performance in-memory Database/Storage Mechanism. In the range of storing 20,000+ objects, with each object updated every 5 or so seconds.  <strong>I would like a FOSS solution</strong>.</p>

<p>What is my best option? What are your experiences?</p>

<p>I am working primarily in Java, but I need the datastore to have good performance so the datastore solution need not be java centric.</p>

<p>I also need like to be able to Query these objects and I need to be able to restore all of the objects on program startup.</p>
","<p>Oracle TimesTen In-Memory Database. See: <a href=""http://www.informationweek.com/whitepaper/Business-Intelligence/Datamarts-Data-Warehouses/oracle-timesten-in-memory-databas-wp1228511232361"" rel=""nofollow"">http://www.informationweek.com/whitepaper/Business-Intelligence/Datamarts-Data-Warehouses/oracle-timesten-in-memory-databas-wp1228511232361</a></p>
"
1044,485340,1,-1,sql,Highest Performance Database Storage Mechanism,"<p>I need ideas to implement a (really) high performance in-memory Database/Storage Mechanism. In the range of storing 20,000+ objects, with each object updated every 5 or so seconds.  <strong>I would like a FOSS solution</strong>.</p>

<p>What is my best option? What are your experiences?</p>

<p>I am working primarily in Java, but I need the datastore to have good performance so the datastore solution need not be java centric.</p>

<p>I also need like to be able to Query these objects and I need to be able to restore all of the objects on program startup.</p>
","<p>Look at some of the products listed here: <a href=""http://en.wikipedia.org/wiki/In-memory_database"" rel=""nofollow"">http://en.wikipedia.org/wiki/In-memory_database</a></p>
"
1037,485340,1,-1,sql,Highest Performance Database Storage Mechanism,"<p>I need ideas to implement a (really) high performance in-memory Database/Storage Mechanism. In the range of storing 20,000+ objects, with each object updated every 5 or so seconds.  <strong>I would like a FOSS solution</strong>.</p>

<p>What is my best option? What are your experiences?</p>

<p>I am working primarily in Java, but I need the datastore to have good performance so the datastore solution need not be java centric.</p>

<p>I also need like to be able to Query these objects and I need to be able to restore all of the objects on program startup.</p>
","<p>are you updating 20K objects every 5 seconds or updating one of the 20K every 5 seconds?</p>

<p>What kind of objects? Why is a traditional RDBMS not sufficient?</p>
"
215,100780,1,-3,sql,MySQL Training videos,"<p>Hi were can I find training videos for MySQL ?  </p>
","<p>In youtube you find somethings like 
mysql install: <a href=""http://www.youtube.com/watch?v=KQcFP3GcQ0s"" rel=""nofollow"">http://www.youtube.com/watch?v=KQcFP3GcQ0s</a></p>

<p>mysql trainning: <a href=""http://www.youtube.com/watch?v=BHq-bORKncA"" rel=""nofollow"">http://www.youtube.com/watch?v=BHq-bORKncA</a></p>

<p>Google presentation about mysql tunning (hot) <a href=""http://www.youtube.com/watch?v=u70mkgDnDdU"" rel=""nofollow"">http://www.youtube.com/watch?v=u70mkgDnDdU</a></p>

<p>You have anothers google presentations about mysql, just search in youtube and googlevideos :-)</p>
"
216,100780,0,-3,sql,MySQL Training videos,"<p>Hi were can I find training videos for MySQL ?  </p>
","<p>And don't forget: <a href=""http://dev.mysql.com/"" rel=""nofollow"">http://dev.mysql.com/</a></p>

<p>This is a good resource to back up anything you find in any videos. I can't recommend any videos as I have no experience with them, sorry. </p>
"
